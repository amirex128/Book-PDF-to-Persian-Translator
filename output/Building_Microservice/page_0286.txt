Broadly speaking, all of the container orchestration platforms, including Kubernetes,
provide these capabilities in some shape or form. If you look at general purpose
schedulers like Mesos or Nomad, managed solutions like AWS’s ECS, Docker Swarm
Mode, and so on, you’ll see a similar featureset. But for reasons we’ll explore shortly,
Kubernetes has won this space. It also has one or two interesting concepts that are
worth exploring briefly.
A Simplified View of Kubernetes Concepts
There are many other concepts in Kubernetes, so you’ll forgive me for not going into
all of them (that would definitely justify a book in itself). What I’ll try to do here is
outline the key ideas you’ll need to engage with when you first start working with the
tool. Let’s look into the concept of a cluster first, as shown in Figure 8-22.
Figure 8-22. A simple overview of Kubernetes topology
Fundamentally, a Kubernetes cluster consists of two things. First, there’s a set of
machines that the workloads will run on called the nodes. Secondly, there’s a set of
controlling software that manages these nodes and is referred to as the control plane.
These nodes could be running physical machines or virtual machines under the
hood. Rather than scheduling a container, Kubernetes instead schedules something it
calls a pod. A pod consists of one or more containers that will be deployed together.
Commonly, you’ll have only one container in a pod—for example, an instance of
your microservice. There are some occasions (rare, in my experience) where having
260 
| 
Chapter 8: Deployment
