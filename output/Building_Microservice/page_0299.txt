Here, the parallel run is done within a single process, with Scientist helping to com‐
pare the invocations.
With blue-green deployment, feature toggles, canary releases, and
parallel runs we’ve just scratched the surface of the field of progres‐
sive delivery. These ideas can work well together (we’ve already
touched on how you could use feature toggles to implement a can‐
ary rollout for example), but you probably want to ease yourself in.
To start off, just remember to separate the two concepts of deploy‐
ment and release. Next, start looking for ways to help you deploy
your software more frequently, but in a safe manner. Work with
your product owner or other business stakeholders to understand
how some of these techniques can help you go faster, but also help
reduce failures too.
Summary
OK, so we covered a lot of ground here. Let’s briefly recap before we move on. Firstly,
let’s remind ourselves of the principles for deployment that I outlined earlier:
Isolated execution
Run microservice instances in an isolated fashion where they have their own
computing resources, and their execution cannot impact other microservice
instances running nearby.
Focus on automation
Choose technology that allows for a high degree of automation, and adopt auto‐
mation as a core part of your culture.
Infrastructure as code
Represent the configuration for your infrastructure to ease automation and pro‐
mote information sharing. Store this code in source control to allow for environ‐
ments to be re-created.
Aim for zero-downtime deployment
Take independent deployability further, and ensure that deploying a new version
of a microservice can be done without any downtime to users of your service (be
it humans or other microservices).
Desired state management
Use a platform that maintains your microservice in a defined state, launching
new instances if required in the event of outage or traffic increases.
In addition, I shared my own guidelines for selecting the right deployment platform:
Summary 
| 
273
