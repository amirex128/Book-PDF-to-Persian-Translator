Fundamentally, running lots of microservice instances on the same machine (virtual
or physical) ends up drastically undermining one of the key principles of microservi‐
ces as a whole—independent deployability. It follows, therefore, that we really want
to run microservice instances in isolation, as we see in Figure 8-11.
Figure 8-11. A single microservice per host
Each microservice instance gets its own isolated execution environment. It can install
its own dependencies, and have its own set of ring-fenced resources.
As my old colleague Neal Ford puts it, many of our working practices around deploy‐
ment and host management are an attempt to optimize for scarcity of resources. In
the past, if we wanted another machine to achieve isolation, our only option was to
buy or rent another physical machine. This often had a large lead time to it and resul‐
ted in a long-term financial commitment. In my experience, it’s not uncommon for
clients to provision new servers only every two to three years, and trying to get addi‐
tional machines outside of these timelines is difficult. But on-demand computing
platforms have drastically reduced the costs of computing resources, and improve‐
ments in virtualization technology mean there is more flexibility, even for in-house
hosted infrastructure.
With containerization joining the mix, we have more options than ever before for
provisioning an isolated execution environment. As Figure 8-12 shows, broadly
speaking, we go from the extreme of having dedicated physical machines for our
services, which gives us the best isolation but probably the highest cost, to containers
at the other end, which gives us weaker isolation but tends to be more cost effective
and much faster to provision. We’ll come back to some of the specifics around tech‐
nology such as containerization later in this chapter.
230 
| 
Chapter 8: Deployment
