As a simple example of this in action, let’s revisit our earlier example of the Catalog
service and take a look at the different environments. In Figure 8-9, the local devel‐
oper laptop has our service deployed as a single instance running locally. The soft‐
ware is fast to build but is deployed as a single instance running on very different
hardware from what we expect in production. In the CI environment, we deploy two
copies of our service to test against, making sure our load balancing logic is working
OK. We deploy both instances to the same machine—this keeps costs down and
makes things faster, and it still gives us enough feedback at this stage in the process.
Figure 8-9. A microservice can vary in how it is deployed from one environment to the
next
Finally, in production, our microservice is deployed as four instances, spread across
four machines, which in turn are distributed across two different data centers.
This is just an example of how you might use environments; exactly what setup you’ll
need will vary greatly depending on what you are building and how you deploy it.
You might, for example, have multiple production environments if you need to
deploy one copy of your software for each customer.
The key thing, though, is that the exact topology of your microservice will change
from environment to environment. You therefore need to find ways to change the
number of instances from one environment to another, along with any environment-
specific configuration. You also want to build your service instances once and once
only, so it follows that any environment-specific information needs to be separate
from the deployed service artifact.
How you go about varying the topology of your microservice from one environment
to another will depend greatly on the mechanism you use for deployment, and also
From Logical to Physical 
| 
227
