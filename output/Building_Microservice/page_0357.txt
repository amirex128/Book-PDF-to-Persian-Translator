that were triggered in real-world conditions and were considered to be contributing
factors in the crashes. From the report:
Human factors research has identified that, for non-normal conditions, such as those
involving a system failure with multiple alerts, where there may be multiple flight crew
actions required, providing pilots with understanding as to which actions must take
priority is a critical need. This is particularly true in the case of functions implemented
across multiple airplane systems because a failure in one system within highly integra‐
ted system architectures can present multiple alerts and indications to the flight crew
as each interfacing system registers the failure...Thus, it is important that system inter‐
actions and the flight deck interface be designed to help direct pilots to the highest pri‐
ority action(s).
So here we’re talking about operating a nuclear reactor and flying an aircraft. I sus‐
pect that many of you right now are wondering what this has to do with the system
you are building. Now it’s possible (if not likely) that you aren’t building safety-
critical systems like this, but there is a lot we can learn from these examples. Both
involve highly complex, interrelated systems in which a problem in one area can
cause a problem in another. And when we generate too many alerts, or we don’t give
operators the ability to prioritize what alerts should be focused on, disaster can fol‐
low. Overwhelming an operator with alerts can cause real issues. From the report
again:
In addition, research into pilot responses to multiple/simultaneous anomalous situa‐
tions, along with data from accidents, indicates that multiple competing alerts may
exceed available mental resources and narrow attentional focus leading to delayed or
inadequately prioritized responses.
So think twice about simply throwing up more alerts to an operator—you might not
get what you want.
Alarm Versus Alert
When looking more broadly into the topic of alerting, I found a lot of incredibly use‐
ful research and practice from a number of contexts, many of which were not specifi‐
cally talking about alerting in IT systems. The term alarm is commonly encountered
when looking into this topic in engineering and beyond, whereas we tend to use the
term alert more commonly in IT. I spoke to a few people who see a distinction
between these two terms, but oddly enough, what distinctions people drew between
these two terms didn’t seem consistent. Based on the fact that most people seem to
see the terms alert and alarm as practically the same, and on the fact that where a
distinction was drawn between the two it wasn’t consistent, I have decided to stand‐
ardize on the term alert for this book.
Building Blocks for Observability 
| 
331
