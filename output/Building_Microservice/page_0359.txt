All too often, unfortunately, the people providing information to our alerting systems
and the people actually on the receiving ends of our alerts are different people. From
Shorrock again:
Understanding the nature of alarm handling, and the associated design issues, can help
you—the expert in your work—to be a more informed user, helping to bring about the
best alarm systems to support your work.
One technique that can help reduce the number of alerts vying for our attention
involves shifting how we think about which issues require us to bring them to opera‐
tors’ attention in the first place. Let’s explore this topic next.
Semantic Monitoring
With semantic monitoring, we are defining a model for what the acceptable seman‐
tics of our system are. What are the properties the system has to have for us to think
it is operating within acceptable means? To a great extent, semantic monitoring
requires a shift in our behavior. Rather than looking for the presence of errors, we
instead need to be constantly asking one question: is the system behaving the way
that we expect? If it is behaving correctly, then this better helps us understand how to
prioritize dealing with the errors we are seeing.
The next thing to work out is how do you define a model for a correctly behaving
system. You can get super formal with this approach (quite literally, with some
organizations making use of formal methods for this), but making some simple value
statements can get you a long way. For example, in the case of MusicCorp, what has
to be true for us to be satisfied that the system is working correctly? Well, perhaps we
say that:
• New customers can register to join.
• We are selling at least $20,000 worth of products per hour during our peak time.
• We are shipping orders out at a rate that is normal.
If these three statements can prove to be correct, then broadly speaking we feel that
the system is operating well enough. Coming back to our earlier discussions of SLAs
and SLOs, our model for semantic correctness would be expected to greatly exceed
our obligations in an SLA, and we would expect to have concrete SLOs that allow us
to track against this model. Put another way, making these statements about how we
expect our software to be acting will go a long way toward our identifying SLOs.
One of the biggest challenges is in getting agreement as to what this model is. As you
can see, we aren’t talking about low level things like “disk usage shouldn’t exceed
95%”; we’re making higher-level statements about our system. As the operator of
the system, or the person who wrote and tested the microservice, you may not be in a
position to decide what these value statements should be. In a product-driven
Building Blocks for Observability 
| 
333
