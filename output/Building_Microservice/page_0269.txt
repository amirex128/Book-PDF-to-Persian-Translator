With containers, we don’t just benefit from the resources saved by not needing a
hypervisor; we also gain in terms of feedback. Linux containers are much faster to
provision than full-fat virtual machines. It isn’t uncommon for a VM to take many
minutes to start—but with Linux containers, startup can take just a few seconds. You
also have finer-grained control over the containers themselves in terms of assigning
resources to them, which makes it much easier to tweak the settings to get the most
out of the underlying hardware.
Due to the more lightweight nature of containers, we can have many more of them
running on the same hardware than would be possible with VMs. By deploying one
service per container, as in Figure 8-16, we get a degree of isolation from other con‐
tainers (although this isn’t perfect) and can do so much more cost-effectively than
would be possible if we wanted to run each service in its own VM. Coming back to
our sock drawer analogy from earlier, with containers the sock drawer dividers are
much thinner than they are for VMs, meaning a higher proportion of the sock
drawer gets used for socks.
Figure 8-16. Running services in separate containers
Containers can be used well with full-fat virtualization too; in fact, this is common.
I’ve seen more than one project provision a large AWS EC2 instance and run multi‐
ple containers on it to get the best of both worlds: an on-demand ephemeral compute
platform in the form of EC2, coupled with highly flexible and fast containers running
on top of it.
Deployment Options 
| 
243
