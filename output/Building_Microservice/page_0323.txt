possible. However, while something like this might be the future for development, it’s
certainly not the present for the vast majority of us.
Fundamentally, I do think that the use of cloud environments to allow a developer to
run more microservices for their development and test cycles is missing the point,
resulting in more complexity than is needed, in addition to higher costs. Ideally, you
want to aim for a developer needing to run only the microservices they actually work
on. If a developer is part of a team that owns five microservices, then that developer
needs to be able to run those microservices as effectively as possible, and for fast feed‐
back my preference would always be for them to run locally.
But what if the five microservices your team owns want to call out to other systems
and microservices that are owned by other teams? Without them, the local develop‐
ment and test environment won’t function, will it? Here again, stubbing comes to the
rescue. I should be able to stand up local stubs that mimic the microservices that are
out of scope for my team. The only real microservices you should be running locally
are the ones you are working on. If you are working in an organization where you are
expected to work on hundreds of different microservices, well then, you’ve got much
bigger problems to deal with—this is a topic we’ll explore in more depth in “Strong
Versus Collective Ownership” on page 499.
From Preproduction to In-Production Testing
Historically, most of the focus of testing has been around testing our systems before
we get to production. With our tests, we are defining a series of models with which
we hope to prove whether our system works and behaves as we would like, both func‐
tionally and nonfunctionally. But if our models are not perfect, we will encounter
problems when our systems are used in anger. Bugs slip into production, new failure
modes are discovered, and our users use the system in ways we could never expect.
One reaction to this is often to define more and more tests, and refine our models, to
catch more issues early and reduce the number of problems we encounter with our
running production system. However, at a certain point we have to accept that we hit
diminishing returns with this approach. With testing prior to deployment, we cannot
reduce the chance of failure to zero.
The complexity of a distributed system is such that it can be infeasible to catch all
potential problems that might occur before we hit production itself.
Generically speaking, the purpose of a test is to give us feedback as to whether or not
our software is of sufficient quality. Ideally, we want that feedback as soon as possible,
and we’d like to be able to spot if there is a problem with our software before an end
user experiences that issue. This is why a lot of testing is done before we release our
software.
From Preproduction to In-Production Testing 
| 
297
