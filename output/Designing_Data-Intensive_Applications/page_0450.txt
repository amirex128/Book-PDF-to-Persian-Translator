upon a large ecosystem of existing libraries to do things like parsing, natural language
analysis, image analysis, and running numerical or statistical algorithms.
The freedom to easily run arbitrary code is what has long distinguished batch pro‐
cessing systems of MapReduce heritage from MPP databases (see “Comparing
Hadoop to Distributed Databases” on page 414); although databases have facilities
for writing user-defined functions, they are often cumbersome to use and not well
integrated with the package managers and dependency management systems that are
widely used in most programming languages (such as Maven for Java, npm for Java‐
Script, and Rubygems for Ruby).
However, dataflow engines have found that there are also advantages to incorporat‐
ing more declarative features in areas besides joins. For example, if a callback func‐
tion contains only a simple filtering condition, or it just selects some fields from a
record, then there is significant CPU overhead in calling the function on every
record. If such simple filtering and mapping operations are expressed in a declarative
way, the query optimizer can take advantage of column-oriented storage layouts (see
“Column-Oriented Storage” on page 95) and read only the required columns from
disk. Hive, Spark DataFrames, and Impala also use vectorized execution (see “Mem‐
ory bandwidth and vectorized processing” on page 99): iterating over data in a tight
inner loop that is friendly to CPU caches, and avoiding function calls. Spark gener‐
ates JVM bytecode [79] and Impala uses LLVM to generate native code for these
inner loops [41].
By incorporating declarative aspects in their high-level APIs, and having query opti‐
mizers that can take advantage of them during execution, batch processing frame‐
works begin to look more like MPP databases (and can achieve comparable
performance). At the same time, by having the extensibility of being able to run arbi‐
trary code and read data in arbitrary formats, they retain their flexibility advantage.
Specialization for different domains
While the extensibility of being able to run arbitrary code is useful, there are also
many common cases where standard processing patterns keep reoccurring, and so it
is worth having reusable implementations of the common building blocks. Tradition‐
ally, MPP databases have served the needs of business intelligence analysts and busi‐
ness reporting, but that is just one among many domains in which batch processing
is used.
Another domain of increasing importance is statistical and numerical algorithms,
which are needed for machine learning applications such as classification and recom‐
mendation systems. Reusable implementations are emerging: for example, Mahout
implements various algorithms for machine learning on top of MapReduce, Spark,
and Flink, while MADlib implements similar functionality inside a relational MPP
database (Apache HAWQ) [54].
428 
| 
Chapter 10: Batch Processing
