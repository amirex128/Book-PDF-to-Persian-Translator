tem with plenty of spare capacity can easily drain queues, whereas in a highly utilized
system, long queues can build up very quickly.
In public clouds and multi-tenant datacenters, resources are shared among many
customers: the network links and switches, and even each machine’s network inter‐
face and CPUs (when running on virtual machines), are shared. Batch workloads
such as MapReduce (see Chapter 10) can easily saturate network links. As you have
no control over or insight into other customers’ usage of the shared resources, net‐
work delays can be highly variable if someone near you (a noisy neighbor) is using a
lot of resources [28, 29].
In such environments, you can only choose timeouts experimentally: measure the
distribution of network round-trip times over an extended period, and over many
machines, to determine the expected variability of delays. Then, taking into account
your application’s characteristics, you can determine an appropriate trade-off
between failure detection delay and risk of premature timeouts.
Even better, rather than using configured constant timeouts, systems can continually
measure response times and their variability (jitter), and automatically adjust time‐
outs according to the observed response time distribution. This can be done with a
Phi Accrual failure detector [30], which is used for example in Akka and Cassandra
[31]. TCP retransmission timeouts also work similarly [27].
Synchronous Versus Asynchronous Networks
Distributed systems would be a lot simpler if we could rely on the network to deliver
packets with some fixed maximum delay, and not to drop packets. Why can’t we
solve this at the hardware level and make the network reliable so that the software
doesn’t need to worry about it?
To answer this question, it’s interesting to compare datacenter networks to the tradi‐
tional fixed-line telephone network (non-cellular, non-VoIP), which is extremely
reliable: delayed audio frames and dropped calls are very rare. A phone call requires a
constantly low end-to-end latency and enough bandwidth to transfer the audio sam‐
ples of your voice. Wouldn’t it be nice to have similar reliability and predictability in
computer networks?
When you make a call over the telephone network, it establishes a circuit: a fixed,
guaranteed amount of bandwidth is allocated for the call, along the entire route
between the two callers. This circuit remains in place until the call ends [32]. For
example, an ISDN network runs at a fixed rate of 4,000 frames per second. When a
call is established, it is allocated 16 bits of space within each frame (in each direction).
Thus, for the duration of the call, each side is guaranteed to be able to send exactly 16
bits of audio data every 250 microseconds [33, 34].
284 
| 
Chapter 8: The Trouble with Distributed Systems
