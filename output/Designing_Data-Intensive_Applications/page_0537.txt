Another example of this pattern occurs in fraud prevention: in order to assess the risk
of whether a particular purchase event is fraudulent, you can examine the reputation
scores of the user’s IP address, email address, billing address, shipping address, and
so on. Each of these reputation databases is itself partitioned, and so collecting the
scores for a particular purchase event requires a sequence of joins with differently
partitioned datasets [49].
The internal query execution graphs of MPP databases have similar characteristics
(see “Comparing Hadoop to Distributed Databases” on page 414). If you need to per‐
form this kind of multi-partition join, it is probably simpler to use a database that
provides this feature than to implement it using a stream processor. However, treat‐
ing queries as streams provides an option for implementing large-scale applications
that run against the limits of conventional off-the-shelf solutions. 
Aiming for Correctness
With stateless services that only read data, it is not a big deal if something goes
wrong: you can fix the bug and restart the service, and everything returns to normal.
Stateful systems such as databases are not so simple: they are designed to remember
things forever (more or less), so if something goes wrong, the effects also potentially
last forever—which means they require more careful thought [50].
We want to build applications that are reliable and correct (i.e., programs whose
semantics are well defined and understood, even in the face of various faults). For
approximately four decades, the transaction properties of atomicity, isolation, and
durability (Chapter 7) have been the tools of choice for building correct applications.
However, those foundations are weaker than they seem: witness for example the con‐
fusion of weak isolation levels (see “Weak Isolation Levels” on page 233).
In some areas, transactions are being abandoned entirely and replaced with models
that offer better performance and scalability, but much messier semantics (see for
example “Leaderless Replication” on page 177). Consistency is often talked about, but
poorly defined (see “Consistency” on page 224 and Chapter 9). Some people assert
that we should “embrace weak consistency” for the sake of better availability, while
lacking a clear idea of what that actually means in practice.
For a topic that is so important, our understanding and our engineering methods are
surprisingly flaky. For example, it is very difficult to determine whether it is safe to
run a particular application at a particular transaction isolation level or replication
configuration [51, 52]. Often simple solutions appear to work correctly when concur‐
rency is low and there are no faults, but turn out to have many subtle bugs in more
demanding circumstances.
For example, Kyle Kingsbury’s Jepsen experiments [53] have highlighted the stark
discrepancies between some products’ claimed safety guarantees and their actual
Aiming for Correctness 
| 
515
