ies is likely to suffer. This can in turn cause operational problems in other parts
of the system [35].
• Normally, MapReduce provides a clean all-or-nothing guarantee for job output:
if a job succeeds, the result is the output of running every task exactly once, even
if some tasks failed and had to be retried along the way; if the entire job fails, no
output is produced. However, writing to an external system from inside a job
produces externally visible side effects that cannot be hidden in this way. Thus,
you have to worry about the results from partially completed jobs being visible to
other systems, and the complexities of Hadoop task attempts and speculative
execution.
A much better solution is to build a brand-new database inside the batch job and
write it as files to the job’s output directory in the distributed filesystem, just like the
search indexes in the last section. Those data files are then immutable once written,
and can be loaded in bulk into servers that handle read-only queries. Various key-
value stores support building database files in MapReduce jobs, including Voldemort
[46], Terrapin [47], ElephantDB [48], and HBase bulk loading [49].
Building these database files is a good use of MapReduce: using a mapper to extract a
key and then sorting by that key is already a lot of the work required to build an
index. Since most of these key-value stores are read-only (the files can only be written
once by a batch job and are then immutable), the data structures are quite simple. For
example, they do not require a WAL (see “Making B-trees reliable” on page 82).
When loading data into Voldemort, the server continues serving requests to the old
data files while the new data files are copied from the distributed filesystem to the
server’s local disk. Once the copying is complete, the server atomically switches over
to querying the new files. If anything goes wrong in this process, it can easily switch
back to the old files again, since they are still there and immutable [46]. 
Philosophy of batch process outputs
The Unix philosophy that we discussed earlier in this chapter (“The Unix Philoso‐
phy” on page 394) encourages experimentation by being very explicit about dataflow:
a program reads its input and writes its output. In the process, the input is left
unchanged, any previous output is completely replaced with the new output, and
there are no other side effects. This means that you can rerun a command as often as
you like, tweaking or debugging it, without messing up the state of your system.
The handling of output from MapReduce jobs follows the same philosophy. By treat‐
ing inputs as immutable and avoiding side effects (such as writing to external data‐
bases), batch jobs not only achieve good performance but also become much easier to
maintain:
MapReduce and Distributed Filesystems 
| 
413
