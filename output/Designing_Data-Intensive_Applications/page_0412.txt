Batch processing systems (offline systems)
A batch processing system takes a large amount of input data, runs a job to pro‐
cess it, and produces some output data. Jobs often take a while (from a few
minutes to several days), so there normally isn’t a user waiting for the job to fin‐
ish. Instead, batch jobs are often scheduled to run periodically (for example, once
a day). The primary performance measure of a batch job is usually throughput
(the time it takes to crunch through an input dataset of a certain size). We dis‐
cuss batch processing in this chapter.
Stream processing systems (near-real-time systems)
Stream processing is somewhere between online and offline/batch processing (so
it is sometimes called near-real-time or nearline processing). Like a batch pro‐
cessing system, a stream processor consumes inputs and produces outputs
(rather than responding to requests). However, a stream job operates on events
shortly after they happen, whereas a batch job operates on a fixed set of input
data. This difference allows stream processing systems to have lower latency than
the equivalent batch systems. As stream processing builds upon batch process‐
ing, we discuss it in Chapter 11.
As we shall see in this chapter, batch processing is an important building block in our
quest to build reliable, scalable, and maintainable applications. For example, Map‐
Reduce, a batch processing algorithm published in 2004 [1], was (perhaps over-
enthusiastically) called “the algorithm that makes Google so massively scalable” [2]. It
was subsequently implemented in various open source data systems, including
Hadoop, CouchDB, and MongoDB.
MapReduce is a fairly low-level programming model compared to the parallel pro‐
cessing systems that were developed for data warehouses many years previously [3,
4], but it was a major step forward in terms of the scale of processing that could be
achieved on commodity hardware. Although the importance of MapReduce is now
declining [5], it is still worth understanding, because it provides a clear picture of
why and how batch processing is useful.
In fact, batch processing is a very old form of computing. Long before programmable
digital computers were invented, punch card tabulating machines—such as the Hol‐
lerith machines used in the 1890 US Census [6]—implemented a semi-mechanized
form of batch processing to compute aggregate statistics from large inputs. And Map‐
Reduce bears an uncanny resemblance to the electromechanical IBM card-sorting
machines that were widely used for business data processing in the 1940s and 1950s
[7]. As usual, history has a tendency of repeating itself.
In this chapter, we will look at MapReduce and several other batch processing algo‐
rithms and frameworks, and explore how they are used in modern data systems. But
first, to get started, we will look at data processing using standard Unix tools. Even if
you are already familiar with them, a reminder about the Unix philosophy is worth‐
390 
| 
Chapter 10: Batch Processing
