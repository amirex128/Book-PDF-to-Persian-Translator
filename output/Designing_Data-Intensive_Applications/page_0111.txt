tially distributed across several machines. This has led to the development of in-
memory databases.
Some in-memory key-value stores, such as Memcached, are intended for caching use
only, where it’s acceptable for data to be lost if a machine is restarted. But other in-
memory databases aim for durability, which can be achieved with special hardware
(such as battery-powered RAM), by writing a log of changes to disk, by writing peri‐
odic snapshots to disk, or by replicating the in-memory state to other machines.
When an in-memory database is restarted, it needs to reload its state, either from disk
or over the network from a replica (unless special hardware is used). Despite writing
to disk, it’s still an in-memory database, because the disk is merely used as an
append-only log for durability, and reads are served entirely from memory. Writing
to disk also has operational advantages: files on disk can easily be backed up,
inspected, and analyzed by external utilities.
Products such as VoltDB, MemSQL, and Oracle TimesTen are in-memory databases
with a relational model, and the vendors claim that they can offer big performance
improvements by removing all the overheads associated with managing on-disk data
structures [41, 42]. RAMCloud is an open source, in-memory key-value store with
durability (using a log-structured approach for the data in memory as well as the data
on disk) [43]. Redis and Couchbase provide weak durability by writing to disk asyn‐
chronously.
Counterintuitively, the performance advantage of in-memory databases is not due to
the fact that they don’t need to read from disk. Even a disk-based storage engine may
never need to read from disk if you have enough memory, because the operating sys‐
tem caches recently used disk blocks in memory anyway. Rather, they can be faster
because they can avoid the overheads of encoding in-memory data structures in a
form that can be written to disk [44].
Besides performance, another interesting area for in-memory databases is providing
data models that are difficult to implement with disk-based indexes. For example,
Redis offers a database-like interface to various data structures such as priority
queues and sets. Because it keeps all data in memory, its implementation is compara‐
tively simple.
Recent research indicates that an in-memory database architecture could be extended
to support datasets larger than the available memory, without bringing back the over‐
heads of a disk-centric architecture [45]. The so-called anti-caching approach works
by evicting the least recently used data from memory to disk when there is not
enough memory, and loading it back into memory when it is accessed again in the
future. This is similar to what operating systems do with virtual memory and swap
files, but the database can manage memory more efficiently than the OS, as it can
work at the granularity of individual records rather than entire memory pages. This
Data Structures That Power Your Database 
| 
89
