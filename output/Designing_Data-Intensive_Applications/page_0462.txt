slices entirely and simply processing every event as it happens. That is the idea
behind stream processing.
In general, a “stream” refers to data that is incrementally made available over time.
The concept appears in many places: in the stdin and stdout of Unix, programming
languages (lazy lists) [2], filesystem APIs (such as Java’s FileInputStream), TCP con‐
nections, delivering audio and video over the internet, and so on.
In this chapter we will look at event streams as a data management mechanism: the
unbounded, incrementally processed counterpart to the batch data we saw in the
last chapter. We will first discuss how streams are represented, stored, and transmit‐
ted over a network. In “Databases and Streams” on page 451 we will investigate
the relationship between streams and databases. And finally, in “Processing Streams”
on page 464 we will explore approaches and tools for processing those streams
continually, and ways that they can be used to build applications.
Transmitting Event Streams
In the batch processing world, the inputs and outputs of a job are files (perhaps on a
distributed filesystem). What does the streaming equivalent look like?
When the input is a file (a sequence of bytes), the first processing step is usually to
parse it into a sequence of records. In a stream processing context, a record is more
commonly known as an event, but it is essentially the same thing: a small, self-
contained, immutable object containing the details of something that happened at
some point in time. An event usually contains a timestamp indicating when it hap‐
pened according to a time-of-day clock (see “Monotonic Versus Time-of-Day
Clocks” on page 288).
For example, the thing that happened might be an action that a user took, such as
viewing a page or making a purchase. It might also originate from a machine, such as
a periodic measurement from a temperature sensor, or a CPU utilization metric. In
the example of “Batch Processing with Unix Tools” on page 391, each line of the web
server log is an event.
An event may be encoded as a text string, or JSON, or perhaps in some binary form,
as discussed in Chapter 4. This encoding allows you to store an event, for example by
appending it to a file, inserting it into a relational table, or writing it to a document
database. It also allows you to send the event over the network to another node in
order to process it.
In batch processing, a file is written once and then potentially read by multiple jobs.
Analogously, in streaming terminology, an event is generated once by a producer
(also known as a publisher or sender), and then potentially processed by multiple con‐
sumers (subscribers or recipients) [3]. In a filesystem, a filename identifies a set of
440 
| 
Chapter 11: Stream Processing
