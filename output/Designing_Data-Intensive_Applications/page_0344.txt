reaching consensus in spite of network faults and process failures is a surprisingly
tricky problem.
Once you have an implementation of consensus, applications can use it for various
purposes. For example, say you have a database with single-leader replication. If the
leader dies and you need to fail over to another node, the remaining database nodes
can use consensus to elect a new leader. As discussed in “Handling Node Outages” on
page 156, it’s important that there is only one leader, and that all nodes agree who the
leader is. If two nodes both believe that they are the leader, that situation is called split
brain, and it often leads to data loss. Correct implementations of consensus help
avoid such problems.
Later in this chapter, in “Distributed Transactions and Consensus” on page 352, we
will look into algorithms to solve consensus and related problems. But first we first
need to explore the range of guarantees and abstractions that can be provided in a
distributed system.
We need to understand the scope of what can and cannot be done: in some situa‐
tions, it’s possible for the system to tolerate faults and continue working; in other sit‐
uations, that is not possible. The limits of what is and isn’t possible have been
explored in depth, both in theoretical proofs and in practical implementations. We
will get an overview of those fundamental limits in this chapter.
Researchers in the field of distributed systems have been studying these topics for
decades, so there is a lot of material—we’ll only be able to scratch the surface. In this
book we don’t have space to go into details of the formal models and proofs, so we
will stick with informal intuitions. The literature references offer plenty of additional
depth if you’re interested.
Consistency Guarantees
In “Problems with Replication Lag” on page 161 we looked at some timing issues that
occur in a replicated database. If you look at two database nodes at the same moment
in time, you’re likely to see different data on the two nodes, because write requests
arrive on different nodes at different times. These inconsistencies occur no matter
what replication method the database uses (single-leader, multi-leader, or leaderless
replication).
Most replicated databases provide at least eventual consistency, which means that if
you stop writing to the database and wait for some unspecified length of time, then
eventually all read requests will return the same value [1]. In other words, the incon‐
sistency is temporary, and it eventually resolves itself (assuming that any faults in the
network are also eventually repaired). A better name for eventual consistency may be
convergence, as we expect all replicas to eventually converge to the same value [2].
322 
| 
Chapter 9: Consistency and Consensus
