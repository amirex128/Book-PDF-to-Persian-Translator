profile update)? Put another way: if state changes over time, and you join with some
state, what point in time do you use for the join [45]?
Such time dependence can occur in many places. For example, if you sell things, you
need to apply the right tax rate to invoices, which depends on the country or state,
the type of product, and the date of sale (since tax rates change from time to time).
When joining sales to a table of tax rates, you probably want to join with the tax rate
at the time of the sale, which may be different from the current tax rate if you are
reprocessing historical data.
If the ordering of events across streams is undetermined, the join becomes nondeter‐
ministic [87], which means you cannot rerun the same job on the same input and
necessarily get the same result: the events on the input streams may be interleaved in
a different way when you run the job again.
In data warehouses, this issue is known as a slowly changing dimension (SCD), and it
is often addressed by using a unique identifier for a particular version of the joined
record: for example, every time the tax rate changes, it is given a new identifier, and
the invoice includes the identifier for the tax rate at the time of sale [88, 89]. This
change makes the join deterministic, but has the consequence that log compaction is
not possible, since all versions of the records in the table need to be retained. 
Fault Tolerance
In the final section of this chapter, let’s consider how stream processors can tolerate
faults. We saw in Chapter 10 that batch processing frameworks can tolerate faults
fairly easily: if a task in a MapReduce job fails, it can simply be started again on
another machine, and the output of the failed task is discarded. This transparent retry
is possible because input files are immutable, each task writes its output to a separate
file on HDFS, and output is only made visible when a task completes successfully.
In particular, the batch approach to fault tolerance ensures that the output of the
batch job is the same as if nothing had gone wrong, even if in fact some tasks did fail.
It appears as though every input record was processed exactly once—no records are
skipped, and none are processed twice. Although restarting tasks means that records
may in fact be processed multiple times, the visible effect in the output is as if they
had only been processed once. This principle is known as exactly-once semantics,
although effectively-once would be a more descriptive term [90].
The same issue of fault tolerance arises in stream processing, but it is less straightfor‐
ward to handle: waiting until a task is finished before making its output visible is not
an option, because a stream is infinite and so you can never finish processing it.
476 
| 
Chapter 11: Stream Processing
