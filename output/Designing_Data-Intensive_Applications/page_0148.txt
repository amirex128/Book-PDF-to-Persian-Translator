base. A reader can fetch a record, extract the version number, and then fetch the
writer’s schema for that version number from the database. Using that writer’s
schema, it can decode the rest of the record. (Espresso [23] works this way, for
example.)
Sending records over a network connection
When two processes are communicating over a bidirectional network connec‐
tion, they can negotiate the schema version on connection setup and then use
that schema for the lifetime of the connection. The Avro RPC protocol (see
“Dataflow Through Services: REST and RPC” on page 131) works like this.
A database of schema versions is a useful thing to have in any case, since it acts as
documentation and gives you a chance to check schema compatibility [24]. As the
version number, you could use a simple incrementing integer, or you could use a
hash of the schema.
Dynamically generated schemas
One advantage of Avro’s approach, compared to Protocol Buffers and Thrift, is that
the schema doesn’t contain any tag numbers. But why is this important? What’s the
problem with keeping a couple of numbers in the schema?
The difference is that Avro is friendlier to dynamically generated schemas. For exam‐
ple, say you have a relational database whose contents you want to dump to a file, and
you want to use a binary format to avoid the aforementioned problems with textual
formats (JSON, CSV, SQL). If you use Avro, you can fairly easily generate an Avro
schema (in the JSON representation we saw earlier) from the relational schema and
encode the database contents using that schema, dumping it all to an Avro object
container file [25]. You generate a record schema for each database table, and each
column becomes a field in that record. The column name in the database maps to the
field name in Avro.
Now, if the database schema changes (for example, a table has one column added and
one column removed), you can just generate a new Avro schema from the updated
database schema and export data in the new Avro schema. The data export process
does not need to pay any attention to the schema change—it can simply do the
schema conversion every time it runs. Anyone who reads the new data files will see
that the fields of the record have changed, but since the fields are identified by name,
the updated writer’s schema can still be matched up with the old reader’s schema.
By contrast, if you were using Thrift or Protocol Buffers for this purpose, the field
tags would likely have to be assigned by hand: every time the database schema
changes, an administrator would have to manually update the mapping from data‐
base column names to field tags. (It might be possible to automate this, but the
schema generator would have to be very careful to not assign previously used field
126 
| 
Chapter 4: Encoding and Evolution
