• Many internet-related applications are online, in the sense that they need to be
able to serve users with low latency at any time. Making the service unavailable—
for example, stopping the cluster for repair—is not acceptable. In contrast, off‐
line (batch) jobs like weather simulations can be stopped and restarted with fairly
low impact.
• Supercomputers are typically built from specialized hardware, where each node
is quite reliable, and nodes communicate through shared memory and remote
direct memory access (RDMA). On the other hand, nodes in cloud services are
built from commodity machines, which can provide equivalent performance at
lower cost due to economies of scale, but also have higher failure rates.
• Large datacenter networks are often based on IP and Ethernet, arranged in Clos
topologies to provide high bisection bandwidth [9]. Supercomputers often use
specialized network topologies, such as multi-dimensional meshes and toruses
[10], which yield better performance for HPC workloads with known communi‐
cation patterns.
• The bigger a system gets, the more likely it is that one of its components is bro‐
ken. Over time, broken things get fixed and new things break, but in a system
with thousands of nodes, it is reasonable to assume that something is always bro‐
ken [7]. When the error handling strategy consists of simply giving up, a large
system can end up spending a lot of its time recovering from faults rather than
doing useful work [8].
• If the system can tolerate failed nodes and still keep working as a whole, that is a
very useful feature for operations and maintenance: for example, you can per‐
form a rolling upgrade (see Chapter 4), restarting one node at a time, while the
service continues serving users without interruption. In cloud environments, if
one virtual machine is not performing well, you can just kill it and request a new
one (hoping that the new one will be faster).
• In a geographically distributed deployment (keeping data geographically close to
your users to reduce access latency), communication most likely goes over the
internet, which is slow and unreliable compared to local networks. Supercom‐
puters generally assume that all of their nodes are close together.
If we want to make distributed systems work, we must accept the possibility of partial
failure and build fault-tolerance mechanisms into the software. In other words, we
need to build a reliable system from unreliable components. (As discussed in “Relia‐
bility” on page 6, there is no such thing as perfect reliability, so we’ll need to under‐
stand the limits of what we can realistically promise.)
Even in smaller systems consisting of only a few nodes, it’s important to think about
partial failure. In a small system, it’s quite likely that most of the components are
working correctly most of the time. However, sooner or later, some part of the system
276 
| 
Chapter 8: The Trouble with Distributed Systems
