recorded in an append-only ledger, which is essentially a log of events describing
money, goods, or services that have changed hands. The accounts, such as profit and
loss or the balance sheet, are derived from the transactions in the ledger by adding
them up [53].
If a mistake is made, accountants don’t erase or change the incorrect transaction in
the ledger—instead, they add another transaction that compensates for the mistake,
for example refunding an incorrect charge. The incorrect transaction still remains in
the ledger forever, because it might be important for auditing reasons. If incorrect
figures, derived from the incorrect ledger, have already been published, then the fig‐
ures for the next accounting period include a correction. This process is entirely nor‐
mal in accounting [54].
Although such auditability is particularly important in financial systems, it is also
beneficial for many other systems that are not subject to such strict regulation. As
discussed in “Philosophy of batch process outputs” on page 413, if you accidentally
deploy buggy code that writes bad data to a database, recovery is much harder if the
code is able to destructively overwrite data. With an append-only log of immutable
events, it is much easier to diagnose what happened and recover from the problem.
Immutable events also capture more information than just the current state. For
example, on a shopping website, a customer may add an item to their cart and then
remove it again. Although the second event cancels out the first event from the point
of view of order fulfillment, it may be useful to know for analytics purposes that the
customer was considering a particular item but then decided against it. Perhaps they
will choose to buy it in the future, or perhaps they found a substitute. This informa‐
tion is recorded in an event log, but would be lost in a database that deletes items
when they are removed from the cart [42].
Deriving several views from the same event log
Moreover, by separating mutable state from the immutable event log, you can derive
several different read-oriented representations from the same log of events. This
works just like having multiple consumers of a stream (Figure 11-5): for example, the
analytic database Druid ingests directly from Kafka using this approach [55], Pista‐
chio is a distributed key-value store that uses Kafka as a commit log [56], and Kafka
Connect sinks can export data from Kafka to various different databases and indexes
[41]. It would make sense for many other storage and indexing systems, such as
search servers, to similarly take their input from a distributed log (see “Keeping Sys‐
tems in Sync” on page 452).
Having an explicit translation step from an event log to a database makes it easier to
evolve your application over time: if you want to introduce a new feature that
presents your existing data in some new way, you can use the event log to build a
separate read-optimized view for the new feature, and run it alongside the existing
Databases and Streams 
| 
461
