sees the record from the user database first, followed by the activity events in time‐
stamp order—this technique is known as a secondary sort [26].
The reducer can then perform the actual join logic easily: the reducer function is
called once for every user ID, and thanks to the secondary sort, the first value is
expected to be the date-of-birth record from the user database. The reducer stores the
date of birth in a local variable and then iterates over the activity events with the same
user ID, outputting pairs of viewed-url and viewer-age-in-years. Subsequent Map‐
Reduce jobs could then calculate the distribution of viewer ages for each URL, and
cluster by age group.
Since the reducer processes all of the records for a particular user ID in one go, it only
needs to keep one user record in memory at any one time, and it never needs to make
any requests over the network. This algorithm is known as a sort-merge join, since
mapper output is sorted by key, and the reducers then merge together the sorted lists
of records from both sides of the join.
Bringing related data together in the same place
In a sort-merge join, the mappers and the sorting process make sure that all the nec‐
essary data to perform the join operation for a particular user ID is brought together
in the same place: a single call to the reducer. Having lined up all the required data in
advance, the reducer can be a fairly simple, single-threaded piece of code that can
churn through records with high throughput and low memory overhead.
One way of looking at this architecture is that mappers “send messages” to the reduc‐
ers. When a mapper emits a key-value pair, the key acts like the destination address
to which the value should be delivered. Even though the key is just an arbitrary string
(not an actual network address like an IP address and port number), it behaves like
an address: all key-value pairs with the same key will be delivered to the same desti‐
nation (a call to the reducer).
Using the MapReduce programming model has separated the physical network com‐
munication aspects of the computation (getting the data to the right machine) from
the application logic (processing the data once you have it). This separation contrasts
with the typical use of databases, where a request to fetch data from a database often
occurs somewhere deep inside a piece of application code [36]. Since MapReduce
handles all network communication, it also shields the application code from having
to worry about partial failures, such as the crash of another node: MapReduce trans‐
parently retries failed tasks without affecting the application logic.
GROUP BY
Besides joins, another common use of the “bringing related data to the same place”
pattern is grouping records by some key (as in the GROUP BY clause in SQL). All
406 
| 
Chapter 10: Batch Processing
