Limitations of consensus
Consensus algorithms are a huge breakthrough for distributed systems: they bring
concrete safety properties (agreement, integrity, and validity) to systems where every‐
thing else is uncertain, and they nevertheless remain fault-tolerant (able to make pro‐
gress as long as a majority of nodes are working and reachable). They provide total
order broadcast, and therefore they can also implement linearizable atomic opera‐
tions in a fault-tolerant way (see “Implementing linearizable storage using total order
broadcast” on page 350).
Nevertheless, they are not used everywhere, because the benefits come at a cost.
The process by which nodes vote on proposals before they are decided is a kind of
synchronous replication. As discussed in “Synchronous Versus Asynchronous Repli‐
cation” on page 153, databases are often configured to use asynchronous replication.
In this configuration, some committed data can potentially be lost on failover—but
many people choose to accept this risk for the sake of better performance.
Consensus systems always require a strict majority to operate. This means you need a
minimum of three nodes in order to tolerate one failure (the remaining two out of
three form a majority), or a minimum of five nodes to tolerate two failures (the
remaining three out of five form a majority). If a network failure cuts off some nodes
from the rest, only the majority portion of the network can make progress, and the
rest is blocked (see also “The Cost of Linearizability” on page 335).
Most consensus algorithms assume a fixed set of nodes that participate in voting,
which means that you can’t just add or remove nodes in the cluster. Dynamic mem‐
bership extensions to consensus algorithms allow the set of nodes in the cluster to
change over time, but they are much less well understood than static membership
algorithms.
Consensus systems generally rely on timeouts to detect failed nodes. In environments
with highly variable network delays, especially geographically distributed systems, it
often happens that a node falsely believes the leader to have failed due to a transient
network issue. Although this error does not harm the safety properties, frequent
leader elections result in terrible performance because the system can end up spend‐
ing more time choosing a leader than doing any useful work.
Sometimes, consensus algorithms are particularly sensitive to network problems. For
example, Raft has been shown to have unpleasant edge cases [106]: if the entire net‐
work is working correctly except for one particular network link that is consistently
unreliable, Raft can get into situations where leadership continually bounces between
two nodes, or the current leader is continually forced to resign, so the system effec‐
tively never makes progress. Other consensus algorithms have similar problems, and
designing algorithms that are more robust to unreliable networks is still an open
research problem. 
Distributed Transactions and Consensus 
| 
369
