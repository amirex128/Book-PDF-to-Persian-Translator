behavior in the presence of network problems and crashes. Even if infrastructure
products like databases were free from problems, application code would still need to
correctly use the features they provide, which is error-prone if the configuration is
hard to understand (which is the case with weak isolation levels, quorum configura‐
tions, and so on).
If your application can tolerate occasionally corrupting or losing data in unpredicta‐
ble ways, life is a lot simpler, and you might be able to get away with simply crossing
your fingers and hoping for the best. On the other hand, if you need stronger assur‐
ances of correctness, then serializability and atomic commit are established
approaches, but they come at a cost: they typically only work in a single datacenter
(ruling out geographically distributed architectures), and they limit the scale and
fault-tolerance properties you can achieve.
While the traditional transaction approach is not going away, I also believe it is not
the last word in making applications correct and resilient to faults. In this section I
will suggest some ways of thinking about correctness in the context of dataflow archi‐
tectures.
The End-to-End Argument for Databases
Just because an application uses a data system that provides comparatively strong
safety properties, such as serializable transactions, that does not mean the application
is guaranteed to be free from data loss or corruption. For example, if an application
has a bug that causes it to write incorrect data, or delete data from a database, serial‐
izable transactions aren’t going to save you.
This example may seem frivolous, but it is worth taking seriously: application bugs
occur, and people make mistakes. I used this example in “State, Streams, and Immut‐
ability” on page 459 to argue in favor of immutable and append-only data, because it
is easier to recover from such mistakes if you remove the ability of faulty code to
destroy good data.
Although immutability is useful, it is not a cure-all by itself. Let’s look at a more sub‐
tle example of data corruption that can occur.
Exactly-once execution of an operation
In “Fault Tolerance” on page 476 we encountered an idea called exactly-once (or
effectively-once) semantics. If something goes wrong while processing a message, you
can either give up (drop the message—i.e., incur data loss) or try again. If you try
again, there is the risk that it actually succeeded the first time, but you just didn’t find
out about the success, and so the message ends up being processed twice.
Processing twice is a form of data corruption: it is undesirable to charge a customer
twice for the same service (billing them too much) or increment a counter twice
516 
| 
Chapter 12: The Future of Data Systems
