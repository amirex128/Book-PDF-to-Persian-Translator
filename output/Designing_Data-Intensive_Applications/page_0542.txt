against network attackers, but not against compromises of the server. Only end-to-
end encryption and authentication can protect against all of these things.
Although the low-level features (TCP duplicate suppression, Ethernet checksums,
WiFi encryption) cannot provide the desired end-to-end features by themselves, they
are still useful, since they reduce the probability of problems at the higher levels. For
example, HTTP requests would often get mangled if we didn’t have TCP putting the
packets back in the right order. We just need to remember that the low-level reliabil‐
ity features are not by themselves sufficient to ensure end-to-end correctness.
Applying end-to-end thinking in data systems
This brings me back to my original thesis: just because an application uses a data sys‐
tem that provides comparatively strong safety properties, such as serializable transac‐
tions, that does not mean the application is guaranteed to be free from data loss or
corruption. The application itself needs to take end-to-end measures, such as dupli‐
cate suppression, as well.
That is a shame, because fault-tolerance mechanisms are hard to get right. Low-level
reliability mechanisms, such as those in TCP, work quite well, and so the remaining
higher-level faults occur fairly rarely. It would be really nice to wrap up the remain‐
ing high-level fault-tolerance machinery in an abstraction so that application code
needn’t worry about it—but I fear that we have not yet found the right abstraction.
Transactions have long been seen as a good abstraction, and I do believe that they are
useful. As discussed in the introduction to Chapter 7, they take a wide range of possi‐
ble issues (concurrent writes, constraint violations, crashes, network interruptions,
disk failures) and collapse them down to two possible outcomes: commit or abort.
That is a huge simplification of the programming model, but I fear that it is not
enough.
Transactions are expensive, especially when they involve heterogeneous storage tech‐
nologies (see “Distributed Transactions in Practice” on page 360). When we refuse to
use distributed transactions because they are too expensive, we end up having to
reimplement fault-tolerance mechanisms in application code. As numerous examples
throughout this book have shown, reasoning about concurrency and partial failure is
difficult and counterintuitive, and so I suspect that most application-level mecha‐
nisms do not work correctly. The consequence is lost or corrupted data.
For these reasons, I think it is worth exploring fault-tolerance abstractions that make
it easy to provide application-specific end-to-end correctness properties, but also
maintain good performance and good operational characteristics in a large-scale dis‐
tributed environment. 
520 
| 
Chapter 12: The Future of Data Systems
