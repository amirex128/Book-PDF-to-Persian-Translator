But then the database landscape changed: weaker consistency guarantees became the
norm under the banner of NoSQL, and less mature storage technologies became
widely used. Yet, because the audit mechanisms had not been developed, we contin‐
ued building applications on the basis of blind trust, even though this approach had
now become more dangerous. Let’s think for a moment about designing for audita‐
bility.
Designing for auditability
If a transaction mutates several objects in a database, it is difficult to tell after the fact
what that transaction means. Even if you capture the transaction logs (see “Change
Data Capture” on page 454), the insertions, updates, and deletions in various tables
do not necessarily give a clear picture of why those mutations were performed. The
invocation of the application logic that decided on those mutations is transient and
cannot be reproduced.
By contrast, event-based systems can provide better auditability. In the event sourc‐
ing approach, user input to the system is represented as a single immutable event,
and any resulting state updates are derived from that event. The derivation can be
made deterministic and repeatable, so that running the same log of events through
the same version of the derivation code will result in the same state updates.
Being explicit about dataflow (see “Philosophy of batch process outputs” on page
413) makes the provenance of data much clearer, which makes integrity checking
much more feasible. For the event log, we can use hashes to check that the event stor‐
age has not been corrupted. For any derived state, we can rerun the batch and stream
processors that derived it from the event log in order to check whether we get the
same result, or even run a redundant derivation in parallel.
A deterministic and well-defined dataflow also makes it easier to debug and trace the
execution of a system in order to determine why it did something [4, 69]. If some‐
thing unexpected occurred, it is valuable to have the diagnostic capability to repro‐
duce the exact circumstances that led to the unexpected event—a kind of time-travel
debugging capability.
The end-to-end argument again
If we cannot fully trust that every individual component of the system will be free
from corruption—that every piece of hardware is fault-free and that every piece of
software is bug-free—then we must at least periodically check the integrity of our
data. If we don’t check, we won’t find out about corruption until it is too late and it
has caused some downstream damage, at which point it will be much harder and
more expensive to track down the problem.
Checking the integrity of data systems is best done in an end-to-end fashion (see
“The End-to-End Argument for Databases” on page 516): the more systems we can
Aiming for Correctness 
| 
531
