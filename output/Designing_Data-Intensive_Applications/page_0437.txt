(which happens to always run the sort utility between the map phase and the reduce
phase). We saw how you can implement various join and grouping operations on top
of these primitives.
When the MapReduce paper [1] was published, it was—in some sense—not at all
new. All of the processing and parallel join algorithms that we discussed in the last
few sections had already been implemented in so-called massively parallel processing
(MPP) databases more than a decade previously [3, 40]. For example, the Gamma
database machine, Teradata, and Tandem NonStop SQL were pioneers in this area
[52].
The biggest difference is that MPP databases focus on parallel execution of analytic
SQL queries on a cluster of machines, while the combination of MapReduce and a
distributed filesystem [19] provides something much more like a general-purpose
operating system that can run arbitrary programs.
Diversity of storage
Databases require you to structure data according to a particular model (e.g., rela‐
tional or documents), whereas files in a distributed filesystem are just byte sequences,
which can be written using any data model and encoding. They might be collections
of database records, but they can equally well be text, images, videos, sensor readings,
sparse matrices, feature vectors, genome sequences, or any other kind of data.
To put it bluntly, Hadoop opened up the possibility of indiscriminately dumping data
into HDFS, and only later figuring out how to process it further [53]. By contrast,
MPP databases typically require careful up-front modeling of the data and query pat‐
terns before importing the data into the database’s proprietary storage format.
From a purist’s point of view, it may seem that this careful modeling and import is
desirable, because it means users of the database have better-quality data to work
with. However, in practice, it appears that simply making data available quickly—
even if it is in a quirky, difficult-to-use, raw format—is often more valuable than try‐
ing to decide on the ideal data model up front [54].
The idea is similar to a data warehouse (see “Data Warehousing” on page 91): simply
bringing data from various parts of a large organization together in one place is val‐
uable, because it enables joins across datasets that were previously disparate. The
careful schema design required by an MPP database slows down that centralized data
collection; collecting data in its raw form, and worrying about schema design later,
allows the data collection to be speeded up (a concept sometimes known as a “data
lake” or “enterprise data hub” [55]).
Indiscriminate data dumping shifts the burden of interpreting the data: instead of
forcing the producer of a dataset to bring it into a standardized format, the interpre‐
tation of the data becomes the consumer’s problem (the schema-on-read approach
MapReduce and Distributed Filesystems 
| 
415
