Even if network faults are rare in your environment, the fact that faults can occur
means that your software needs to be able to handle them. Whenever any communi‐
cation happens over a network, it may fail—there is no way around it.
If the error handling of network faults is not defined and tested, arbitrarily bad things
could happen: for example, the cluster could become deadlocked and permanently
unable to serve requests, even when the network recovers [20], or it could even delete
all of your data [21]. If software is put in an unanticipated situation, it may do arbi‐
trary unexpected things.
Handling network faults doesn’t necessarily mean tolerating them: if your network is
normally fairly reliable, a valid approach may be to simply show an error message to
users while your network is experiencing problems. However, you do need to know
how your software reacts to network problems and ensure that the system can
recover from them. It may make sense to deliberately trigger network problems and
test the system’s response (this is the idea behind Chaos Monkey; see “Reliability” on
page 6).
Detecting Faults
Many systems need to automatically detect faulty nodes. For example:
• A load balancer needs to stop sending requests to a node that is dead (i.e., take it
out of rotation).
• In a distributed database with single-leader replication, if the leader fails, one of
the followers needs to be promoted to be the new leader (see “Handling Node
Outages” on page 156).
Unfortunately, the uncertainty about the network makes it difficult to tell whether a
node is working or not. In some specific circumstances you might get some feedback
to explicitly tell you that something is not working:
• If you can reach the machine on which the node should be running, but no pro‐
cess is listening on the destination port (e.g., because the process crashed), the
operating system will helpfully close or refuse TCP connections by sending a RST
or FIN packet in reply. However, if the node crashed while it was handling your
request, you have no way of knowing how much data was actually processed by
the remote node [22].
• If a node process crashed (or was killed by an administrator) but the node’s oper‐
ating system is still running, a script can notify other nodes about the crash so
that another node can take over quickly without having to wait for a timeout to
expire. For example, HBase does this [23].
280 
| 
Chapter 8: The Trouble with Distributed Systems
