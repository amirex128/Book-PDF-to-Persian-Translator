CHAPTER 9
Consistency and Consensus
Is it better to be alive and wrong or right and dead?
—Jay Kreps, A Few Notes on Kafka and Jepsen (2013)
Lots of things can go wrong in distributed systems, as discussed in Chapter 8. The
simplest way of handling such faults is to simply let the entire service fail, and show
the user an error message. If that solution is unacceptable, we need to find ways of
tolerating faults—that is, of keeping the service functioning correctly, even if some
internal component is faulty.
In this chapter, we will talk about some examples of algorithms and protocols for
building fault-tolerant distributed systems. We will assume that all the problems
from Chapter 8 can occur: packets can be lost, reordered, duplicated, or arbitrarily
delayed in the network; clocks are approximate at best; and nodes can pause (e.g., due
to garbage collection) or crash at any time.
The best way of building fault-tolerant systems is to find some general-purpose
abstractions with useful guarantees, implement them once, and then let applications
rely on those guarantees. This is the same approach as we used with transactions in
Chapter 7: by using a transaction, the application can pretend that there are no
crashes (atomicity), that nobody else is concurrently accessing the database (isola‐
tion), and that storage devices are perfectly reliable (durability). Even though crashes,
race conditions, and disk failures do occur, the transaction abstraction hides those
problems so that the application doesn’t need to worry about them.
We will now continue along the same lines, and seek abstractions that can allow an
application to ignore some of the problems with distributed systems. For example,
one of the most important abstractions for distributed systems is consensus: that is,
getting all of the nodes to agree on something. As we shall see in this chapter, reliably
321
