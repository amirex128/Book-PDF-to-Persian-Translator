• If a safety property is violated, we can point at a particular point in time at which
it was broken (for example, if the uniqueness property was violated, we can iden‐
tify the particular operation in which a duplicate fencing token was returned).
After a safety property has been violated, the violation cannot be undone—the
damage is already done.
• A liveness property works the other way round: it may not hold at some point in
time (for example, a node may have sent a request but not yet received a
response), but there is always hope that it may be satisfied in the future (namely
by receiving a response).
An advantage of distinguishing between safety and liveness properties is that it helps
us deal with difficult system models. For distributed algorithms, it is common to
require that safety properties always hold, in all possible situations of a system model
[88]. That is, even if all nodes crash, or the entire network fails, the algorithm must
nevertheless ensure that it does not return a wrong result (i.e., that the safety proper‐
ties remain satisfied).
However, with liveness properties we are allowed to make caveats: for example, we
could say that a request needs to receive a response only if a majority of nodes have
not crashed, and only if the network eventually recovers from an outage. The defini‐
tion of the partially synchronous model requires that eventually the system returns to
a synchronous state—that is, any period of network interruption lasts only for a finite
duration and is then repaired.
Mapping system models to the real world
Safety and liveness properties and system models are very useful for reasoning about
the correctness of a distributed algorithm. However, when implementing an algo‐
rithm in practice, the messy facts of reality come back to bite you again, and it
becomes clear that the system model is a simplified abstraction of reality.
For example, algorithms in the crash-recovery model generally assume that data in
stable storage survives crashes. However, what happens if the data on disk is corrup‐
ted, or the data is wiped out due to hardware error or misconfiguration [91]? What
happens if a server has a firmware bug and fails to recognize its hard drives on
reboot, even though the drives are correctly attached to the server [92]?
Quorum algorithms (see “Quorums for reading and writing” on page 179) rely on a
node remembering the data that it claims to have stored. If a node may suffer from
amnesia and forget previously stored data, that breaks the quorum condition, and
thus breaks the correctness of the algorithm. Perhaps a new system model is needed,
in which we assume that stable storage mostly survives crashes, but may sometimes
be lost. But that model then becomes harder to reason about.
Knowledge, Truth, and Lies 
| 
309
