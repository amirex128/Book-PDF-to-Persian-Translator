vi. This example assumes that there is exactly one entry for each key in the hash table, which is probably true
with a user database (a user ID uniquely identifies a user). In general, the hash table may need to contain
several entries with the same key, and the join operator will output all matches for a key.
Broadcast hash joins
The simplest way of performing a map-side join applies in the case where a large
dataset is joined with a small dataset. In particular, the small dataset needs to be small
enough that it can be loaded entirely into memory in each of the mappers.
For example, imagine in the case of Figure 10-2 that the user database is small
enough to fit in memory. In this case, when a mapper starts up, it can first read the
user database from the distributed filesystem into an in-memory hash table. Once
this is done, the mapper can scan over the user activity events and simply look up the
user ID for each event in the hash table.vi
There can still be several map tasks: one for each file block of the large input to the
join (in the example of Figure 10-2, the activity events are the large input). Each of
these mappers loads the small input entirely into memory.
This simple but effective algorithm is called a broadcast hash join: the word broadcast
reflects the fact that each mapper for a partition of the large input reads the entirety
of the small input (so the small input is effectively “broadcast” to all partitions of the
large input), and the word hash reflects its use of a hash table. This join method is
supported by Pig (under the name “replicated join”), Hive (“MapJoin”), Cascading,
and Crunch. It is also used in data warehouse query engines such as Impala [41].
Instead of loading the small join input into an in-memory hash table, an alternative is
to store the small join input in a read-only index on the local disk [42]. The fre‐
quently used parts of this index will remain in the operating system’s page cache, so
this approach can provide random-access lookups almost as fast as an in-memory
hash table, but without actually requiring the dataset to fit in memory.
Partitioned hash joins
If the inputs to the map-side join are partitioned in the same way, then the hash join
approach can be applied to each partition independently. In the case of Figure 10-2,
you might arrange for the activity events and the user database to each be partitioned
based on the last decimal digit of the user ID (so there are 10 partitions on either
side). For example, mapper 3 first loads all users with an ID ending in 3 into a hash
table, and then scans over all the activity events for each user whose ID ends in 3.
If the partitioning is done correctly, you can be sure that all the records you might
want to join are located in the same numbered partition, and so it is sufficient for
each mapper to only read one partition from each of the input datasets. This has the
advantage that each mapper can load a smaller amount of data into its hash table.
MapReduce and Distributed Filesystems 
| 
409
