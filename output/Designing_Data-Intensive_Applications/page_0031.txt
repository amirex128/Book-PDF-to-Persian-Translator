• A service that the system depends on that slows down, becomes unresponsive, or
starts returning corrupted responses.
• Cascading failures, where a small fault in one component triggers a fault in
another component, which in turn triggers further faults [10].
The bugs that cause these kinds of software faults often lie dormant for a long time
until they are triggered by an unusual set of circumstances. In those circumstances, it
is revealed that the software is making some kind of assumption about its environ‐
ment—and while that assumption is usually true, it eventually stops being true for
some reason [11].
There is no quick solution to the problem of systematic faults in software. Lots of
small things can help: carefully thinking about assumptions and interactions in the
system; thorough testing; process isolation; allowing processes to crash and restart;
measuring, monitoring, and analyzing system behavior in production. If a system is
expected to provide some guarantee (for example, in a message queue, that the num‐
ber of incoming messages equals the number of outgoing messages), it can constantly
check itself while it is running and raise an alert if a discrepancy is found [12].
Human Errors
Humans design and build software systems, and the operators who keep the systems
running are also human. Even when they have the best intentions, humans are
known to be unreliable. For example, one study of large internet services found that
configuration errors by operators were the leading cause of outages, whereas hard‐
ware faults (servers or network) played a role in only 10–25% of outages [13].
How do we make our systems reliable, in spite of unreliable humans? The best sys‐
tems combine several approaches:
• Design systems in a way that minimizes opportunities for error. For example,
well-designed abstractions, APIs, and admin interfaces make it easy to do “the
right thing” and discourage “the wrong thing.” However, if the interfaces are too
restrictive people will work around them, negating their benefit, so this is a tricky
balance to get right.
• Decouple the places where people make the most mistakes from the places where
they can cause failures. In particular, provide fully featured non-production
sandbox environments where people can explore and experiment safely, using
real data, without affecting real users.
• Test thoroughly at all levels, from unit tests to whole-system integration tests and
manual tests [3]. Automated testing is widely used, well understood, and espe‐
cially valuable for covering corner cases that rarely arise in normal operation.
Reliability 
| 
9
