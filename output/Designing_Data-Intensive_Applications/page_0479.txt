model as a table into which transactions can insert tuples, but which cannot be quer‐
ied. The stream then consists of the log of tuples that committed transactions have
written to this special table, in the order they were committed. External consumers
can asynchronously consume this log and use it to update derived data systems.
Kafka Connect [41] is an effort to integrate change data capture tools for a wide
range of database systems with Kafka. Once the stream of change events is in Kafka, it
can be used to update derived data systems such as search indexes, and also feed into
stream processing systems as discussed later in this chapter. 
Event Sourcing
There are some parallels between the ideas we’ve discussed here and event sourcing, a
technique that was developed in the domain-driven design (DDD) community [42,
43, 44]. We will discuss event sourcing briefly, because it incorporates some useful
and relevant ideas for streaming systems.
Similarly to change data capture, event sourcing involves storing all changes to the
application state as a log of change events. The biggest difference is that event sourc‐
ing applies the idea at a different level of abstraction:
• In change data capture, the application uses the database in a mutable way,
updating and deleting records at will. The log of changes is extracted from the
database at a low level (e.g., by parsing the replication log), which ensures that
the order of writes extracted from the database matches the order in which they
were actually written, avoiding the race condition in Figure 11-4. The application
writing to the database does not need to be aware that CDC is occurring.
• In event sourcing, the application logic is explicitly built on the basis of immuta‐
ble events that are written to an event log. In this case, the event store is append-
only, and updates or deletes are discouraged or prohibited. Events are designed
to reflect things that happened at the application level, rather than low-level state
changes.
Event sourcing is a powerful technique for data modeling: from an application point
of view it is more meaningful to record the user’s actions as immutable events, rather
than recording the effect of those actions on a mutable database. Event sourcing
makes it easier to evolve applications over time, helps with debugging by making it
easier to understand after the fact why something happened, and guards against
application bugs (see “Advantages of immutable events” on page 460).
For example, storing the event “student cancelled their course enrollment” clearly
expresses the intent of a single action in a neutral fashion, whereas the side effects
“one entry was deleted from the enrollments table, and one cancellation reason was
added to the student feedback table” embed a lot of assumptions about the way the
Databases and Streams 
| 
457
