the nodes that store the data being queried. This is a reasonable design, but not the
only possible one. It is also possible to represent read requests as streams of events,
and send both the read events and the write events through a stream processor; the
processor responds to read events by emitting the result of the read to an output
stream [46].
When both the writes and the reads are represented as events, and routed to the same
stream operator in order to be handled, we are in fact performing a stream-table join
between the stream of read queries and the database. The read event needs to be sent
to the database partition holding the data (see “Request Routing” on page 214), just
like batch and stream processors need to copartition inputs on the same key when
joining (see “Reduce-Side Joins and Grouping” on page 403).
This correspondence between serving requests and performing joins is quite funda‐
mental [47]. A one-off read request just passes the request through the join operator
and then immediately forgets it; a subscribe request is a persistent join with past and
future events on the other side of the join.
Recording a log of read events potentially also has benefits with regard to tracking
causal dependencies and data provenance across a system: it would allow you to
reconstruct what the user saw before they made a particular decision. For example, in
an online shop, it is likely that the predicted shipping date and the inventory status
shown to a customer affect whether they choose to buy an item [4]. To analyze this
connection, you need to record the result of the user’s query of the shipping and
inventory status.
Writing read events to durable storage thus enables better tracking of causal depen‐
dencies (see “Ordering events to capture causality” on page 493), but it incurs addi‐
tional storage and I/O cost. Optimizing such systems to reduce the overhead is still
an open research problem [2]. But if you already log read requests for operational
purposes, as a side effect of request processing, it is not such a great change to make
the log the source of the requests instead.
Multi-partition data processing
For queries that only touch a single partition, the effort of sending queries through a
stream and collecting a stream of responses is perhaps overkill. However, this idea
opens the possibility of distributed execution of complex queries that need to com‐
bine data from several partitions, taking advantage of the infrastructure for message
routing, partitioning, and joining that is already provided by stream processors.
Storm’s distributed RPC feature supports this usage pattern (see “Message passing
and RPC” on page 468). For example, it has been used to compute the number of
people who have seen a URL on Twitter—i.e., the union of the follower sets of every‐
one who has tweeted that URL [48]. As the set of Twitter users is partitioned, this
computation requires combining results from many partitions.
514 
| 
Chapter 12: The Future of Data Systems
