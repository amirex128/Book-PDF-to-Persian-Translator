ence is just that the data is being collected by corporations rather than government
agencies [96].
Not all data collection necessarily qualifies as surveillance, but examining it as such
can help us understand our relationship with the data collector. Why are we seem‐
ingly happy to accept surveillance by corporations? Perhaps you feel you have noth‐
ing to hide—in other words, you are totally in line with existing power structures,
you are not a marginalized minority, and you needn’t fear persecution [97]. Not
everyone is so fortunate. Or perhaps it’s because the purpose seems benign—it’s not
overt coercion and conformance, but merely better recommendations and more per‐
sonalized marketing. However, combined with the discussion of predictive analytics
from the last section, that distinction seems less clear.
We are already seeing car insurance premiums linked to tracking devices in cars, and
health insurance coverage that depends on people wearing a fitness tracking device.
When surveillance is used to determine things that hold sway over important aspects
of life, such as insurance coverage or employment, it starts to appear less benign.
Moreover, data analysis can reveal surprisingly intrusive things: for example, the
movement sensor in a smartwatch or fitness tracker can be used to work out what
you are typing (for example, passwords) with fairly good accuracy [98]. And algo‐
rithms for analysis are only going to get better.
Consent and freedom of choice
We might assert that users voluntarily choose to use a service that tracks their activ‐
ity, and they have agreed to the terms of service and privacy policy, so they consent to
data collection. We might even claim that users are receiving a valuable service in
return for the data they provide, and that the tracking is necessary in order to provide
the service. Undoubtedly, social networks, search engines, and various other free
online services are valuable to users—but there are problems with this argument.
Users have little knowledge of what data they are feeding into our databases, or how
it is retained and processed—and most privacy policies do more to obscure than to
illuminate. Without understanding what happens to their data, users cannot give any
meaningful consent. Often, data from one user also says things about other people
who are not users of the service and who have not agreed to any terms. The derived
datasets that we discussed in this part of the book—in which data from the entire
user base may have been combined with behavioral tracking and external data sour‐
ces—are precisely the kinds of data of which users cannot have any meaningful
understanding.
Moreover, data is extracted from users through a one-way process, not a relationship
with true reciprocity, and not a fair value exchange. There is no dialog, no option for
users to negotiate how much data they provide and what service they receive in
538 
| 
Chapter 12: The Future of Data Systems
