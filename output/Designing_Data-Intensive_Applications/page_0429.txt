records with the same key form a group, and the next step is often to perform some
kind of aggregation within each group—for example:
• Counting the number of records in each group (like in our example of counting
page views, which you would express as a COUNT(*) aggregation in SQL)
• Adding up the values in one particular field (SUM(fieldname)) in SQL
• Picking the top k records according to some ranking function
The simplest way of implementing such a grouping operation with MapReduce is to
set up the mappers so that the key-value pairs they produce use the desired grouping
key. The partitioning and sorting process then brings together all the records with the
same key in the same reducer. Thus, grouping and joining look quite similar when
implemented on top of MapReduce.
Another common use for grouping is collating all the activity events for a particular
user session, in order to find out the sequence of actions that the user took—a pro‐
cess called sessionization [37]. For example, such analysis could be used to work out
whether users who were shown a new version of your website are more likely to make
a purchase than those who were shown the old version (A/B testing), or to calculate
whether some marketing activity is worthwhile.
If you have multiple web servers handling user requests, the activity events for a par‐
ticular user are most likely scattered across various different servers’ log files. You can
implement sessionization by using a session cookie, user ID, or similar identifier as
the grouping key and bringing all the activity events for a particular user together in
one place, while distributing different users’ events across different partitions.
Handling skew
The pattern of “bringing all records with the same key to the same place” breaks
down if there is a very large amount of data related to a single key. For example, in a
social network, most users might be connected to a few hundred people, but a small
number of celebrities may have many millions of followers. Such disproportionately
active database records are known as linchpin objects [38] or hot keys.
Collecting all activity related to a celebrity (e.g., replies to something they posted) in a
single reducer can lead to significant skew (also known as hot spots)—that is, one
reducer that must process significantly more records than the others (see “Skewed
Workloads and Relieving Hot Spots” on page 205). Since a MapReduce job is only
complete when all of its mappers and reducers have completed, any subsequent jobs
must wait for the slowest reducer to complete before they can start.
If a join input has hot keys, there are a few algorithms you can use to compensate.
For example, the skewed join method in Pig first runs a sampling job to determine
which keys are hot [39]. When performing the actual join, the mappers send any
MapReduce and Distributed Filesystems 
| 
407
