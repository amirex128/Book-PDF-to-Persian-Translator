The limits of total ordering
With systems that are small enough, constructing a totally ordered event log is
entirely feasible (as demonstrated by the popularity of databases with single-leader
replication, which construct precisely such a log). However, as systems are scaled
toward bigger and more complex workloads, limitations begin to emerge:
• In most cases, constructing a totally ordered log requires all events to pass
through a single leader node that decides on the ordering. If the throughput of
events is greater than a single machine can handle, you need to partition it across
multiple machines (see “Partitioned Logs” on page 446). The order of events in
two different partitions is then ambiguous.
• If the servers are spread across multiple geographically distributed datacenters,
for example in order to tolerate an entire datacenter going offline, you typically
have a separate leader in each datacenter, because network delays make synchro‐
nous cross-datacenter coordination inefficient (see “Multi-Leader Replication”
on page 168). This implies an undefined ordering of events that originate in two
different datacenters.
• When applications are deployed as microservices (see “Dataflow Through Serv‐
ices: REST and RPC” on page 131), a common design choice is to deploy each
service and its durable state as an independent unit, with no durable state shared
between services. When two events originate in different services, there is no
defined order for those events.
• Some applications maintain client-side state that is updated immediately on user
input (without waiting for confirmation from a server), and even continue to
work offline (see “Clients with offline operation” on page 170). With such appli‐
cations, clients and servers are very likely to see events in different orders.
In formal terms, deciding on a total order of events is known as total order broadcast,
which is equivalent to consensus (see “Consensus algorithms and total order broad‐
cast” on page 366). Most consensus algorithms are designed for situations in which
the throughput of a single node is sufficient to process the entire stream of events,
and these algorithms do not provide a mechanism for multiple nodes to share the
work of ordering the events. It is still an open research problem to design consensus
algorithms that can scale beyond the throughput of a single node and that work well
in a geographically distributed setting.
Ordering events to capture causality
In cases where there is no causal link between events, the lack of a total order is not a
big problem, since concurrent events can be ordered arbitrarily. Some other cases are
easy to handle: for example, when there are multiple updates of the same object, they
can be totally ordered by routing all updates for a particular object ID to the same log
Data Integration 
| 
493
