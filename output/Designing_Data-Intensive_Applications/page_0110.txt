index on (date, temperature) in order to efficiently search for all the observations
during the year 2013 where the temperature was between 25 and 30℃. With a one-
dimensional index, you would have to either scan over all the records from 2013
(regardless of temperature) and then filter them by temperature, or vice versa. A 2D
index could narrow down by timestamp and temperature simultaneously. This tech‐
nique is used by HyperDex [36].
Full-text search and fuzzy indexes
All the indexes discussed so far assume that you have exact data and allow you to
query for exact values of a key, or a range of values of a key with a sort order. What
they don’t allow you to do is search for similar keys, such as misspelled words. Such
fuzzy querying requires different techniques.
For example, full-text search engines commonly allow a search for one word to be
expanded to include synonyms of the word, to ignore grammatical variations of
words, and to search for occurrences of words near each other in the same document,
and support various other features that depend on linguistic analysis of the text. To
cope with typos in documents or queries, Lucene is able to search text for words
within a certain edit distance (an edit distance of 1 means that one letter has been
added, removed, or replaced) [37].
As mentioned in “Making an LSM-tree out of SSTables” on page 78, Lucene uses a
SSTable-like structure for its term dictionary. This structure requires a small in-
memory index that tells queries at which offset in the sorted file they need to look for
a key. In LevelDB, this in-memory index is a sparse collection of some of the keys,
but in Lucene, the in-memory index is a finite state automaton over the characters in
the keys, similar to a trie [38]. This automaton can be transformed into a Levenshtein
automaton, which supports efficient search for words within a given edit distance
[39].
Other fuzzy search techniques go in the direction of document classification and
machine learning. See an information retrieval textbook for more detail [e.g., 40].
Keeping everything in memory
The data structures discussed so far in this chapter have all been answers to the limi‐
tations of disks. Compared to main memory, disks are awkward to deal with. With
both magnetic disks and SSDs, data on disk needs to be laid out carefully if you want
good performance on reads and writes. However, we tolerate this awkwardness
because disks have two significant advantages: they are durable (their contents are
not lost if the power is turned off), and they have a lower cost per gigabyte than
RAM.
As RAM becomes cheaper, the cost-per-gigabyte argument is eroded. Many datasets
are simply not that big, so it’s quite feasible to keep them entirely in memory, poten‐
88 
| 
Chapter 3: Storage and Retrieval
