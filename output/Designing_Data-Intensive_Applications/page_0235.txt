ber of partitions, the size of each partition is proportional to the size of the dataset. In
both of these cases, the number of partitions is independent of the number of nodes.
A third option, used by Cassandra and Ketama, is to make the number of partitions
proportional to the number of nodes—in other words, to have a fixed number of par‐
titions per node [23, 27, 28]. In this case, the size of each partition grows proportion‐
ally to the dataset size while the number of nodes remains unchanged, but when you
increase the number of nodes, the partitions become smaller again. Since a larger
data volume generally requires a larger number of nodes to store, this approach also
keeps the size of each partition fairly stable.
When a new node joins the cluster, it randomly chooses a fixed number of existing
partitions to split, and then takes ownership of one half of each of those split parti‐
tions while leaving the other half of each partition in place. The randomization can
produce unfair splits, but when averaged over a larger number of partitions (in Cas‐
sandra, 256 partitions per node by default), the new node ends up taking a fair share
of the load from the existing nodes. Cassandra 3.0 introduced an alternative rebalanc‐
ing algorithm that avoids unfair splits [29].
Picking partition boundaries randomly requires that hash-based partitioning is used
(so the boundaries can be picked from the range of numbers produced by the hash
function). Indeed, this approach corresponds most closely to the original definition
of consistent hashing [7] (see “Consistent Hashing” on page 204). Newer hash func‐
tions can achieve a similar effect with lower metadata overhead [8].
Operations: Automatic or Manual Rebalancing
There is one important question with regard to rebalancing that we have glossed
over: does the rebalancing happen automatically or manually?
There is a gradient between fully automatic rebalancing (the system decides automat‐
ically when to move partitions from one node to another, without any administrator
interaction) and fully manual (the assignment of partitions to nodes is explicitly con‐
figured by an administrator, and only changes when the administrator explicitly
reconfigures it). For example, Couchbase, Riak, and Voldemort generate a suggested
partition assignment automatically, but require an administrator to commit it before
it takes effect.
Fully automated rebalancing can be convenient, because there is less operational
work to do for normal maintenance. However, it can be unpredictable. Rebalancing
is an expensive operation, because it requires rerouting requests and moving a large
amount of data from one node to another. If it is not done carefully, this process can
overload the network or the nodes and harm the performance of other requests while
the rebalancing is in progress.
Rebalancing Partitions 
| 
213
