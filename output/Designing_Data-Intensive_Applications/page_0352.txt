iii. Strictly speaking, ZooKeeper and etcd provide linearizable writes, but reads may be stale, since by default
they can be served by any one of the replicas. You can optionally request a linearizable read: etcd calls this a
quorum read [16], and in ZooKeeper you need to call sync() before the read [15]; see “Implementing linear‐
izable storage using total order broadcast” on page 350.
Relying on Linearizability
In what circumstances is linearizability useful? Viewing the final score of a sporting
match is perhaps a frivolous example: a result that is outdated by a few seconds is
unlikely to cause any real harm in this situation. However, there a few areas in which
linearizability is an important requirement for making a system work correctly.
Locking and leader election
A system that uses single-leader replication needs to ensure that there is indeed only
one leader, not several (split brain). One way of electing a leader is to use a lock: every
node that starts up tries to acquire the lock, and the one that succeeds becomes the
leader [14]. No matter how this lock is implemented, it must be linearizable: all nodes
must agree which node owns the lock; otherwise it is useless.
Coordination services like Apache ZooKeeper [15] and etcd [16] are often used to
implement distributed locks and leader election. They use consensus algorithms to
implement linearizable operations in a fault-tolerant way (we discuss such algorithms
later in this chapter, in “Fault-Tolerant Consensus” on page 364).iii There are still
many subtle details to implementing locks and leader election correctly (see for
example the fencing issue in “The leader and the lock” on page 301), and libraries like
Apache Curator [17] help by providing higher-level recipes on top of ZooKeeper.
However, a linearizable storage service is the basic foundation for these coordination
tasks.
Distributed locking is also used at a much more granular level in some distributed
databases, such as Oracle Real Application Clusters (RAC) [18]. RAC uses a lock per
disk page, with multiple nodes sharing access to the same disk storage system. Since
these linearizable locks are on the critical path of transaction execution, RAC deploy‐
ments usually have a dedicated cluster interconnect network for communication
between database nodes.
Constraints and uniqueness guarantees
Uniqueness constraints are common in databases: for example, a username or email
address must uniquely identify one user, and in a file storage service there cannot be
two files with the same path and filename. If you want to enforce this constraint as
the data is written (such that if two people try to concurrently create a user or a file
with the same name, one of them will be returned an error), you need linearizability.
330 
| 
Chapter 9: Consistency and Consensus
