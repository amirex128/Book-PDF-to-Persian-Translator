<!DOCTYPE html>
<html lang="fa" dir="rtl">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Designing_Data-Intensive_Applications - فارسی</title>
    <link rel="stylesheet" href="fontiran.css">
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/line-numbers/prism-line-numbers.min.css" rel="stylesheet" />
    <style>
        @page {
            size: A4;
            margin: 2cm;
        }
        body {
            font-family: IRANSansX, Tahoma, Arial, sans-serif;
            line-height: 1.8;
            text-align: right;
            direction: rtl;
            margin: 0;
            padding: 20px;
            background-color: white;
        }
        .book-title {
            text-align: center;
            font-size: 24pt;
            margin: 3cm 0 1cm 0;
        }
        .book-subtitle {
            text-align: center;
            font-size: 18pt;
            margin-bottom: 3cm;
        }
        .toc {
            margin: 2cm 0;
            padding: 1cm;
            background-color: #f8f9fa;
            border-radius: 5px;
            page-break-after: always;
        }
        .toc h2 {
            margin-bottom: 1cm;
        }
        .toc ul {
            list-style-type: none;
            padding: 0;
        }
        .toc li {
            margin: 0.5cm 0;
            padding-right: 1cm;
        }
        .toc a {
            text-decoration: none;
            color: #2980b9;
        }
        .chapter {
            margin-bottom: 1cm;
            page-break-before: always;
        }
        .chapter:first-of-type {
            page-break-before: avoid;
        }
        .chapter-content {
            margin-bottom: 1cm;
        }
        .persian-translation {
            font-size: 14pt;
        }
        .page-images {
            text-align: center;
            margin: 1cm 0;
            page-break-before: always;
        }
        .page-images img {
            max-width: 100%;
            height: auto;
            margin: 0.5cm 0;
        }
        pre {
            direction: ltr;
            text-align: left;
            background-color: #f5f5f5;
            padding: 15px;
            border-radius: 5px;
            overflow-x: auto;
            margin: 15px 0;
        }
        code {
            font-family: 'Courier New', Courier, monospace;
            direction: ltr;
            text-align: left;
        }
        span[dir="ltr"] {
            display: inline-block;
            direction: ltr;
            text-align: left;
        }
        .page-number {
            text-align: center;
            margin-top: 1cm;
            font-size: 10pt;
            color: #7f8c8d;
        }
    </style>
</head>
<body>
    <h1 class="book-title">Designing_Data-Intensive_Applications</h1>
    <h2 class="book-subtitle">نسخه ترجمه شده</h2>
        <!-- Page 0001 -->
        <div class="chapter" id="page-0001">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<h3>Martin Kleppmann</h3>
<h4>Designing Data-Intensive Applications</h4>
<p><em>THE BIG IDEAS BEHIND RELIABLE, SCALABLE, AND MAINTAINABLE SYSTEMS</em></p>
<br/>
<p>در این کتاب، <strong>Martin Kleppmann</strong> به بررسی عمیق مفاهیم و تکنیک‌های اساسی برای طراحی <strong>Data-Intensive Applications</strong> می‌پردازد. این کتاب، ایده‌های بزرگ و مهمی را در پشت سیستم‌های قابل اطمینان، مقیاس‌پذیر و قابل نگهداری ارائه می‌دهد.</p>
<br/>
<p>در این اثر، شما با موضوعات زیر آشنا خواهید شد:</p>
<ul>
<li><strong>Reliability (قابلیت اطمینان):</strong> چگونه می‌توان سیستم‌هایی ساخت که بدون از دست دادن داده‌ها یا باگ‌ها به درستی کار کنند؟ این شامل بحث‌هایی در مورد خطاهای سخت‌افزاری و نرم‌افزاری، و همچنین تکنیک‌های تحمل خطا مانند replication (تکثیر داده‌ها) و failover (بازیابی پس از خرابی) است.</li>
<li><strong>Scalability (مقیاس‌پذیری):</strong> چگونه می‌توان سیستم‌هایی را طراحی کرد که با افزایش حجم داده‌ها و تعداد کاربران، همچنان عملکرد خوبی داشته باشند؟ این بخش شامل مباحثی در مورد معماری‌های توزیع‌شده، partitioning (تقسیم داده‌ها)، load balancing (توازن بار) و optimizatio (بهینه‌سازی) است.</li>
<li><strong>Maintainability (قابلیت نگهداری):</strong> چگونه می‌توان سیستم‌هایی را ساخت که در طول زمان، به راحتی قابل درک، تغییر و تعمیر باشند؟ این شامل مباحثی در مورد طراحی ماژولار، documentation (مستندسازی) و testing (تست) است.</li>
</ul>
<br/>
<p>کتاب "Designing Data-Intensive Applications" به زبان‌های برنامه‌نویسی، فریم‌ورک‌ها و تکنولوژی‌های خاص وابسته نیست، بلکه بر روی اصول اساسی طراحی سیستم‌های توزیع‌شده تمرکز دارد. بنابراین، این کتاب برای مهندسان نرم‌افزاری که در زمینه‌های مختلفی از جمله <strong>Backend</strong> و <strong>Frontend</strong> کار می‌کنند، مفید است.</p>
<br/>
<p>این کتاب، یک منبع ارزشمند برای درک عمیق‌تر <strong>REST</strong> و <strong>Microservices</strong> و همچنین یادگیری در مورد چالش‌های معماری سیستم‌های پیچیده است.</p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 1" src="page_0001/image_1.png"/></div>
<div class="page-image"><img alt="Image from page 1" src="page_0001/image_2.png"/></div>
</div>
                <div class="page-number">صفحه 0001</div>
            </div>
        </div>
        <!-- Page 0003 -->
        <div class="chapter" id="page-0003">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<h3>Martin Kleppmann</h3>
<h4>Designing Data-Intensive Applications</h4>
<p><em>The Big Ideas Behind Reliable, Scalable, and Maintainable Systems</em></p>
<br/>
<p>این کتاب بر اساس مفاهیم و ایده‌های کلیدی در مورد طراحی <strong>Data-Intensive Applications</strong> است.</p>
<br/>
<p>شهرهای ذکر شده در زیر به عنوان محل‌های انتشار کتاب و یا مرتبط با نویسنده هستند:</p>
<ul>
<li>Boston</li>
<li>Farnham</li>
<li>Sebastopol</li>
<li>Tokyo</li>
<li>Beijing</li>
</ul>
<br/>
<p>این شهرها دوباره تکرار شده‌اند، احتمالاً به منظور تاکید یا برای اهداف خاص چاپ:</p>
<ul>
<li>Boston</li>
<li>Farnham</li>
<li>Sebastopol</li>
<li>Tokyo</li>
<li>Beijing</li>
</ul>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0003</div>
            </div>
        </div>
        <!-- Page 0004 -->
        <div class="chapter" id="page-0004">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>978-1-449-37332-0</p>
<p>[LSI]</p>
<h3>Designing Data-Intensive Applications</h3>
<p>by <strong>Martin Kleppmann</strong></p>
<br/>
<p>Copyright © 2017 Martin Kleppmann. All rights reserved.</p>
<p>Printed in the United States of America.</p>
<br/>
<p>Published by O’Reilly Media, Inc., 1005 Gravenstein Highway North, Sebastopol, CA 95472.</p>
<br/>
<p>کتاب‌های O’Reilly را می‌توان برای استفاده‌های آموزشی، تجاری یا تبلیغاتی خریداری کرد. نسخه‌های آنلاین نیز برای اکثر عناوین در دسترس هستند (http://oreilly.com/safari). برای اطلاعات بیشتر، با بخش فروش شرکتی/موسسه‌ای ما تماس بگیرید: 800-998-9938 یا corporate@oreilly.com.</p>
<br/>
<p><strong>Editors:</strong> Ann Spencer and Marie Beaugureau</p>
<p><strong>Indexer:</strong> Ellen Troutman-Zaig</p>
<p><strong>Production Editor:</strong> Kristen Brown</p>
<p><strong>Interior Designer:</strong> David Futato</p>
<p><strong>Copyeditor:</strong> Rachel Head</p>
<p><strong>Cover Designer:</strong> Karen Montgomery</p>
<p><strong>Proofreader:</strong> Amanda Kersey</p>
<p><strong>Illustrator:</strong> Rebecca Demarest</p>
<br/>
<p>March 2017:
   First Edition</p>
<br/>
<h4>Revision History for the First Edition</h4>
<p>2017-03-01: First Release</p>
<br/>
<p>See http://oreilly.com/catalog/errata.csp?isbn=9781449373320 for release details.</p>
<br/>
<p>The O’Reilly logo is a registered trademark of O’Reilly Media, Inc. Designing Data-Intensive Applications,
   the cover image, and related trade dress are trademarks of O’Reilly Media, Inc.</p>
<br/>
<p>While the publisher and the author have used good faith efforts to ensure that the information and
   instructions contained in this work are accurate, the publisher and the author disclaim all responsibility
   for errors or omissions, including without limitation responsibility for damages resulting from the use of
   or reliance on this work. Use of the information and instructions contained in this work is at your own
   risk. If any code samples or other technology this work contains or describes is subject to open source
   licenses or the intellectual property rights of others, it is your responsibility to ensure that your use
   thereof complies with such licenses and/or rights.</p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0004</div>
            </div>
        </div>
        <!-- Page 0005 -->
        <div class="chapter" id="page-0005">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>تکنولوژی یک نیروی قدرتمند در جامعه ما است. <strong>Data</strong>, <strong>software</strong>, و ارتباطات می‌توانند برای اهداف بد استفاده شوند:</p>
<ul>
<li>برای تحکیم ساختارهای قدرت ناعادلانه</li>
<li>برای تضعیف حقوق بشر</li>
<li>و برای محافظت از منافع شخصی.</li>
</ul>
<br/>
<p>اما آن‌ها همچنین می‌توانند برای اهداف خوب استفاده شوند:</p>
<ul>
<li>برای شنیده شدن صدای افرادی که نماینده‌ای ندارند</li>
<li>برای ایجاد فرصت برای همه</li>
<li>و برای جلوگیری از فجایع.</li>
</ul>
<br/>
<p>این کتاب به همه کسانی که در جهت اهداف خوب کار می‌کنند، تقدیم می‌شود.</p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0005</div>
            </div>
        </div>
        <!-- Page 0007 -->
        <div class="chapter" id="page-0007">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p><strong>Computing</strong> is pop culture. […] Pop culture holds a disdain for history. Pop culture is all
   about identity and feeling like you’re participating. It has nothing to do with cooperation,
   the past or the future—it’s living in the present. I think the same is true of most people who
   write code for money. They have no idea where [their culture came from].</p>
<br/>
<p>—Alan Kay, in interview with Dr Dobb’s Journal (2012)</p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0007</div>
            </div>
        </div>
        <!-- Page 0009 -->
        <div class="chapter" id="page-0009">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<h3>Table of Contents</h3>
<p>Preface. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . xiii</p>
<h4>Part I.
   Foundations of Data Systems</h4>
<p>1. Reliable, Scalable, and Maintainable Applications. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3
   Thinking About Data Systems 4
   Reliability 6
   Hardware Faults 7
   Software Errors 8
   Human Errors 9
   How Important Is Reliability? 10
   Scalability 10
   Describing Load 11
   Describing Performance 13
   Approaches for Coping with Load 17
   Maintainability 18
   Operability: Making Life Easy for Operations 19
   Simplicity: Managing Complexity 20
   Evolvability: Making Change Easy 21
   Summary 22</p>
<p>2. Data Models and Query Languages. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27
   Relational Model Versus Document Model 28
   The Birth of NoSQL 29
   The Object-Relational Mismatch 29
   Many-to-One and Many-to-Many Relationships 33
   Are Document Databases Repeating History? 36
   vii</p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0009</div>
            </div>
        </div>
        <!-- Page 0010 -->
        <div class="chapter" id="page-0010">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>Relational Versus Document Databases Today 38
   Query Languages for Data 42
   Declarative Queries on the Web 44
   MapReduce Querying 46
   Graph-Like Data Models 49
   Property Graphs 50
   The Cypher Query Language 52
   Graph Queries in SQL 53
   Triple-Stores and SPARQL 55
   The Foundation: Datalog 60
   Summary 63</p>
<p>3. Storage and Retrieval. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 69
   Data Structures That Power Your Database 70
   Hash Indexes 72
   SSTables and LSM-Trees 76
   B-Trees 79
   Comparing B-Trees and LSM-Trees 83
   Other Indexing Structures 85
   Transaction Processing or Analytics? 90
   Data Warehousing 91
   Stars and Snowflakes: Schemas for Analytics 93
   Column-Oriented Storage 95
   Column Compression 97
   Sort Order in Column Storage 99
   Writing to Column-Oriented Storage 101
   Aggregation: Data Cubes and Materialized Views 101
   Summary 103</p>
<p>4. Encoding and Evolution. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 111
   Formats for Encoding Data 112
   Language-Specific Formats 113
   JSON, XML, and Binary Variants 114
   Thrift and Protocol Buffers 117
   Avro 122
   The Merits of Schemas 127
   Modes of Dataflow 128
   Dataflow Through Databases 129
   Dataflow Through Services: REST and RPC 131
   Message-Passing Dataflow 136
   Summary 139
   viii | Table of Contents</p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0010</div>
            </div>
        </div>
        <!-- Page 0011 -->
        <div class="chapter" id="page-0011">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<h4>Part II.
   Distributed Data</h4>
<p>5. Replication. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 151
   Leaders and Followers 152
   Synchronous Versus Asynchronous Replication 153
   Setting Up New Followers 155
   Handling Node Outages 156
   Implementation of Replication Logs 158
   Problems with Replication Lag 161
   Reading Your Own Writes 162
   Monotonic Reads 164
   Consistent Prefix Reads 165
   Solutions for Replication Lag 167
   Multi-Leader Replication 168
   Use Cases for Multi-Leader Replication 168
   Handling Write Conflicts 171
   Multi-Leader Replication Topologies 175
   Leaderless Replication 177
   Writing to the Database When a Node Is Down 177
   Limitations of Quorum Consistency 181
   Sloppy Quorums and Hinted Handoff 183
   Detecting Concurrent Writes 184
   Summary 192</p>
<p>6. Partitioning. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 199
   Partitioning and Replication 200
   Partitioning of Key-Value Data 201
   Partitioning by Key Range 202
   Partitioning by Hash of Key 203
   Skewed Workloads and Relieving Hot Spots 205
   Partitioning and Secondary Indexes 206
   Partitioning Secondary Indexes by Document 206
   Partitioning Secondary Indexes by Term 208
   Rebalancing Partitions 209
   Strategies for Rebalancing 210
   Operations: Automatic or Manual Rebalancing 213
   Request Routing 214
   Parallel Query Execution 216
   Summary 216</p>
<p>7. Transactions. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 221
   The Slippery Concept of a Transaction 222
   Table of Contents | ix</p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0011</div>
            </div>
        </div>
        <!-- Page 0012 -->
        <div class="chapter" id="page-0012">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>The Meaning of ACID 223
   Single-Object and Multi-Object Operations 228
   Weak Isolation Levels 233
   Read Committed 234
   Snapshot Isolation and Repeatable Read 237
   Preventing Lost Updates 242
   Write Skew and Phantoms 246
   Serializability 251
   Actual Serial Execution 252
   Two-Phase Locking (2PL) 257
   Serializable Snapshot Isolation (SSI) 261
   Summary 266</p>
<p>8. The Trouble with Distributed Systems. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 273
   Faults and Partial Failures 274
   Cloud Computing and Supercomputing 275
   Unreliable Networks 277
   Network Faults in Practice 279
   Detecting Faults 280
   Timeouts and Unbounded Delays 281
   Synchronous Versus Asynchronous Networks 284
   Unreliable Clocks 287
   Monotonic Versus Time-of-Day Clocks 288
   Clock Synchronization and Accuracy 289
   Relying on Synchronized Clocks 291
   Process Pauses 295
   Knowledge, Truth, and Lies 300
   The Truth Is Defined by the Majority 300
   Byzantine Faults 304
   System Model and Reality 306
   Summary 310</p>
<p>9. Consistency and Consensus. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 321
   Consistency Guarantees 322
   Linearizability 324
   What Makes a System Linearizable? 325
   Relying on Linearizability 330
   Implementing Linearizable Systems 332
   The Cost of Linearizability 335
   Ordering Guarantees 339
   Ordering and Causality 339
   Sequence Number Ordering 343
   x | Table of Contents</p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0012</div>
            </div>
        </div>
        <!-- Page 0013 -->
        <div class="chapter" id="page-0013">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>Total Order Broadcast 348
   Distributed Transactions and Consensus 352
   Atomic Commit and Two-Phase Commit (2PC) 354
   Distributed Transactions in Practice 360
   Fault-Tolerant Consensus 364
   Membership and Coordination Services 370
   Summary 373</p>
<h4>Part III.
   Derived Data</h4>
<p>10. Batch Processing. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 389
   Batch Processing with Unix Tools 391
   Simple Log Analysis 391
   The Unix Philosophy 394
   MapReduce and Distributed Filesystems 397
   MapReduce Job Execution 399
   Reduce-Side Joins and Grouping 403
   Map-Side Joins 408
   The Output of Batch Workflows 411
   Comparing Hadoop to Distributed Databases 414
   Beyond MapReduce 419
   Materialization of Intermediate State 419
   Graphs and Iterative Processing 424
   High-Level APIs and Languages 426
   Summary 429</p>
<p>11. Stream Processing. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 439
   Transmitting Event Streams 440
   Messaging Systems 441
   Partitioned Logs 446
   Databases and Streams 451
   Keeping Systems in Sync 452
   Change Data Capture 454
   Event Sourcing 457
   State, Streams, and Immutability 459
   Processing Streams 464
   Uses of Stream Processing 465
   Reasoning About Time 468
   Stream Joins 472
   Fault Tolerance 476
   Summary 479
   xi | Table of Contents</p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0013</div>
            </div>
        </div>
        <!-- Page 0014 -->
        <div class="chapter" id="page-0014">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>12. The Future of Data Systems. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 489
   Data Integration 490
   Combining Specialized Tools by Deriving Data 490
   Batch and Stream Processing 494
   Unbundling Databases 499
   Composing Data Storage Technologies 499
   Designing Applications Around Dataflow 504
   Observing Derived State 509
   Aiming for Correctness 515
   The End-to-End Argument for Databases 516
   Enforcing Constraints 521
   Timeliness and Integrity 524
   Trust, but Verify 528
   Doing the Right Thing 533
   Predictive Analytics 533
   Privacy and Tracking 536
   Summary 543</p>
<p>Glossary. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 553</p>
<p>Index. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 559
   xii | Table of Contents</p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0014</div>
            </div>
        </div>
        <!-- Page 0015 -->
        <div class="chapter" id="page-0015">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<h3>Preface</h3>
<p>اگر در سال‌های اخیر در <strong>software engineering</strong>، به‌ویژه در سیستم‌های <strong>server-side</strong> و <strong>Backend</strong> کار کرده‌اید، احتمالاً با انبوهی از کلمات کلیدی مرتبط با ذخیره‌سازی و پردازش <strong>data</strong> بمباران شده‌اید. <strong>NoSQL</strong>! <strong>Big Data</strong>! <strong>Web-scale</strong>! <strong>Sharding</strong>! <strong>Eventual consistency</strong>! <strong>ACID</strong>! <strong>CAP theorem</strong>! <strong>Cloud services</strong>! <strong>MapReduce</strong>! <strong>Real-time</strong>!</p>
<p>در دهه گذشته، ما شاهد تحولات جالبی در <strong>databases</strong>، در <strong>distributed systems</strong> و در روش‌هایی که <strong>applications</strong> را بر روی آن‌ها می‌سازیم، بوده‌ایم. نیروهای محرک مختلفی برای این پیشرفت‌ها وجود دارد:</p>
<ul>
<li>شرکت‌های اینترنتی مانند <strong>Google</strong>، <strong>Yahoo!</strong>، <strong>Amazon</strong>، <strong>Facebook</strong>، <strong>LinkedIn</strong>، <strong>Microsoft</strong> و <strong>Twitter</strong> حجم عظیمی از <strong>data</strong> و ترافیک را مدیریت می‌کنند و آن‌ها را مجبور می‌کند تا ابزارهای جدیدی ایجاد کنند که به آن‌ها امکان می‌دهد این مقیاس را به‌طور کارآمد مدیریت کنند.</li>
<li>کسب‌وکارها باید چابک باشند، فرضیه‌ها را ارزان آزمایش کنند و با کوتاه نگه داشتن چرخه‌های توسعه و انعطاف‌پذیر نگه داشتن مدل‌های <strong>data</strong>، سریع به بینش‌های جدید بازار پاسخ دهند.</li>
<li><strong>Free</strong> و <strong>open source software</strong> بسیار موفق شده است و اکنون در بسیاری از محیط‌ها به نرم‌افزار تجاری یا سفارشی درون‌سازمانی ترجیح داده می‌شود.</li>
<li>سرعت ساعت <strong>CPU</strong> به سختی در حال افزایش است، اما پردازنده‌های چند هسته‌ای استاندارد هستند و شبکه‌ها در حال سریع‌تر شدن هستند. این بدان معناست که <strong>parallelism</strong> فقط در حال افزایش است.</li>
<li>حتی اگر روی یک تیم کوچک کار می‌کنید، اکنون می‌توانید سیستم‌هایی بسازید که در سراسر ماشین‌های زیاد و حتی چندین منطقه جغرافیایی توزیع شده‌اند، به لطف زیرساخت‌ها به‌عنوان یک <strong>service (IaaS)</strong> مانند <strong>Amazon Web Services</strong>.</li>
<li>انتظار می‌رود که بسیاری از <strong>services</strong> اکنون در دسترس باشند. زمان از کار افتادن طولانی به دلیل قطعی یا نگهداری به طور فزاینده‌ای غیرقابل قبول می‌شود.</li>
</ul>
<p><strong>Data-intensive applications</strong> با استفاده از این پیشرفت‌های تکنولوژیکی، مرزهای آنچه را که ممکن است، جابه‌جا می‌کنند. ما یک <strong>application</strong> را <strong>data-intensive</strong> می‌نامیم اگر <strong>data</strong> چالش اصلی آن باشد—مقدار <strong>data</strong>، پیچیدگی <strong>data</strong> یا سرعت در
   Preface | xiii</p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0015</div>
            </div>
        </div>
        <!-- Page 0016 -->
        <div class="chapter" id="page-0016">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>که در آن <strong>data</strong> در حال تغییر است—برخلاف محاسبات فشرده، که در آن چرخه‌های <strong>CPU</strong> گلوگاه هستند.</p>
<p>ابزارها و فناوری‌هایی که به <strong>data-intensive applications</strong> کمک می‌کنند تا <strong>data</strong> را ذخیره و پردازش کنند، به سرعت با این تغییرات سازگار شده‌اند. انواع جدید سیستم‌های <strong>database</strong> (“<strong>NoSQL</strong>”) توجه زیادی را به خود جلب کرده‌اند، اما صف‌های پیام، کش‌ها، فهرست‌های جستجو، فریم‌ورک‌ها برای پردازش دسته‌ای و جریانی، و فناوری‌های مرتبط نیز بسیار مهم هستند. بسیاری از <strong>applications</strong> از ترکیبی از این موارد استفاده می‌کنند.</p>
<p>کلمات کلیدی که این فضا را پر می‌کنند، نشانه‌ای از اشتیاق برای امکانات جدید است که چیز بسیار خوبی است. با این حال، به‌عنوان مهندسان و معماران <strong>software</strong>، ما همچنین باید درک فنی دقیق و دقیقی از فناوری‌های مختلف و مبادلات آن‌ها داشته باشیم، اگر بخواهیم <strong>applications</strong> خوبی بسازیم. برای آن درک، ما باید عمیق‌تر از کلمات کلیدی بکنیم.</p>
<p>خوشبختانه، در پشت تغییرات سریع در فناوری، اصول پایداری وجود دارد که همچنان صادق هستند، مهم نیست از کدام نسخه از یک ابزار خاص استفاده می‌کنید. اگر آن اصول را درک کنید، می‌توانید ببینید که هر ابزاری در کجا قرار می‌گیرد، چگونه از آن به‌خوبی استفاده کنید و چگونه از آسیب‌های آن اجتناب کنید. اینجاست که این کتاب وارد می‌شود.</p>
<p>هدف این کتاب این است که به شما کمک کند در چشم‌انداز متنوع و در حال تغییر سریع فناوری‌ها برای پردازش و ذخیره <strong>data</strong> حرکت کنید. این کتاب یک آموزش برای یک ابزار خاص نیست، و همچنین یک کتاب درسی پر از تئوری خشک نیست. در عوض، ما به نمونه‌هایی از سیستم‌های <strong>data</strong> موفق نگاه خواهیم کرد: فناوری‌هایی که پایه و اساس بسیاری از <strong>applications</strong> محبوب را تشکیل می‌دهند و باید نیازهای مقیاس‌پذیری، عملکرد و قابلیت اطمینان را در تولید روزانه برآورده کنند.</p>
<p>ما به درون سیستم‌های آن سیستم‌ها خواهیم پرداخت، الگوریتم‌های کلیدی آن‌ها را جدا می‌کنیم، در مورد اصول و مبادلاتی که باید انجام دهند، بحث خواهیم کرد. در این سفر، ما سعی خواهیم کرد راه‌های مفیدی برای تفکر در مورد سیستم‌های <strong>data</strong> پیدا کنیم—نه فقط نحوه عملکرد آن‌ها، بلکه همچنین چرا آن‌ها این‌گونه کار می‌کنند و چه سؤالاتی باید بپرسیم.</p>
<p>پس از خواندن این کتاب، در موقعیت خوبی قرار خواهید داشت تا تصمیم بگیرید که کدام نوع فناوری برای چه منظوری مناسب است و درک کنید که چگونه می‌توان ابزارها را ترکیب کرد تا پایه و اساس یک معماری <strong>application</strong> خوب را تشکیل دهند. شما آماده نخواهید بود که موتور ذخیره‌سازی <strong>database</strong> خود را از ابتدا بسازید، اما خوشبختانه این به‌ندرت ضروری است. با این حال، شما یک شهود خوب برای کارهایی که سیستم‌های شما در زیر کاپوت انجام می‌دهند، توسعه خواهید داد تا بتوانید در مورد رفتار آن‌ها استدلال کنید، تصمیمات طراحی خوبی بگیرید و هر مشکلی را که ممکن است پیش بیاید، ردیابی کنید.</p>
<h4>Who Should Read This Book?</h4>
<p>اگر <strong>applications</strong> را توسعه می‌دهید که نوعی <strong>server/backend</strong> برای ذخیره‌سازی یا پردازش <strong>data</strong> دارند، و <strong>applications</strong> شما از اینترنت استفاده می‌کنند (به‌عنوان‌مثال، <strong>web applications</strong>، <strong>mobile apps</strong>، یا حسگرهای متصل به اینترنت)، پس این کتاب برای شماست.</p>
<p>xiv | Preface</p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0016</div>
            </div>
        </div>
        <!-- Page 0017 -->
        <div class="chapter" id="page-0017">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>این کتاب برای مهندسان <strong>software</strong>، معماران <strong>software</strong> و مدیران فنی است که عاشق کدنویسی هستند. این امر به‌ویژه در صورتی مرتبط است که نیاز به تصمیم‌گیری در مورد <strong>architecture</strong> سیستم‌هایی دارید که روی آن‌ها کار می‌کنید—به‌عنوان‌مثال، اگر نیاز به انتخاب ابزارهایی برای حل یک مشکل خاص دارید و می‌خواهید بدانید که چگونه بهترین روش را برای اعمال آن‌ها به‌کار برید. اما حتی اگر در مورد ابزارهای خود هیچ انتخابی ندارید، این کتاب به شما کمک می‌کند تا نقاط قوت و ضعف آن‌ها را بهتر درک کنید.</p>
<p>شما باید مقداری تجربه در ساخت <strong>web-based applications</strong> یا <strong>network services</strong> داشته باشید و باید با <strong>relational databases</strong> و <strong>SQL</strong> آشنا باشید. هر <strong>non-relational databases</strong> و سایر ابزارهای مرتبط با <strong>data</strong> که می‌شناسید یک امتیاز است، اما ضروری نیست. درک کلی پروتکل‌های شبکه‌ای رایج مانند <strong>TCP</strong> و <strong>HTTP</strong> مفید است. انتخاب زبان برنامه‌نویسی یا فریم‌ورک شما هیچ تفاوتی برای این کتاب ایجاد نمی‌کند.</p>
<p>اگر هر یک از موارد زیر برای شما صدق می‌کند، این کتاب را ارزشمند خواهید یافت:</p>
<ul>
<li>شما می‌خواهید یاد بگیرید که چگونه سیستم‌های <strong>data</strong> را مقیاس‌پذیر کنید، به‌عنوان‌مثال، برای پشتیبانی از برنامه‌های <strong>web</strong> یا <strong>mobile</strong> با میلیون‌ها کاربر.</li>
<li>شما باید <strong>applications</strong> را در دسترس قرار دهید (به حداقل رساندن زمان خرابی) و از نظر عملیاتی قوی.</li>
<li>شما به دنبال راه‌هایی برای آسان‌تر کردن نگهداری سیستم‌ها در درازمدت هستید، حتی با رشد و تغییر الزامات و فناوری‌ها.</li>
<li>شما یک کنجکاوی طبیعی برای نحوه عملکرد چیزها دارید و می‌خواهید بدانید در داخل وب‌سایت‌های بزرگ و <strong>online services</strong> چه می‌گذرد. این کتاب، درون <strong>databases</strong> و سیستم‌های پردازش <strong>data</strong> مختلف را تجزیه می‌کند و کاوش در تفکر روشن‌بینانه‌ای که به طراحی آن‌ها منتهی شده است، بسیار سرگرم‌کننده است.</li>
</ul>
<p>گاهی اوقات، هنگام بحث در مورد سیستم‌های <strong>data</strong> مقیاس‌پذیر، مردم نظراتی در این راستا ارائه می‌دهند: "شما <strong>Google</strong> یا <strong>Amazon</strong> نیستید. نگران مقیاس نباشید و فقط از یک <strong>relational database</strong> استفاده کنید." در این گفته حقیقت وجود دارد: ساختن برای مقیاسی که به آن نیاز ندارید، تلاش هدر رفته است و ممکن است شما را در یک طراحی غیرقابل انعطاف قفل کند. در واقع، این یک نوع بهینه‌سازی زودرس است. با این حال، انتخاب ابزار مناسب برای این کار نیز مهم است و فناوری‌های مختلف هرکدام نقاط قوت و ضعف خاص خود را دارند. همان‌طور که خواهیم دید، <strong>relational databases</strong> مهم هستند اما آخرین کلمه در مورد برخورد با <strong>data</strong> نیستند.</p>
<h4>Scope of This Book</h4>
<p>این کتاب تلاش نمی‌کند دستورالعمل‌های دقیقی در مورد نحوه نصب یا استفاده از بسته‌های <strong>software</strong> یا <strong>APIs</strong> خاص ارائه دهد، زیرا در حال حاضر مستندات زیادی برای آن موارد وجود دارد. در عوض ما در مورد اصول و مبادلات مختلفی که برای سیستم‌های <strong>data</strong> اساسی هستند بحث می‌کنیم و تصمیمات طراحی مختلفی را که توسط محصولات مختلف گرفته شده است، بررسی می‌کنیم.</p>
<p>Preface | xv</p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0017</div>
            </div>
        </div>
        <!-- Page 0018 -->
        <div class="chapter" id="page-0018">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>در نسخه‌های <strong>ebook</strong> ما پیوندهایی را به متن کامل منابع <strong>online</strong> گنجانده‌ایم. همه پیوندها در زمان انتشار تأیید شدند، اما متأسفانه پیوندها به دلیل ماهیت وب تمایل به خراب شدن دارند. اگر به یک پیوند خراب برخوردید، یا اگر در حال خواندن یک نسخه چاپی از این کتاب هستید، می‌توانید منابع را با استفاده از یک موتور جستجو جستجو کنید. برای مقالات علمی، می‌توانید عنوان را در <strong>Google Scholar</strong> جستجو کنید تا فایل‌های <strong>PDF</strong> با دسترسی آزاد را پیدا کنید. از طرف دیگر، می‌توانید تمام مراجع را در <strong>https://github.com/ept/ddia-references</strong> پیدا کنید، جایی که ما پیوندهای به‌روز را نگهداری می‌کنیم.</p>
<p>ما در درجه اول به <strong>architecture</strong> سیستم‌های <strong>data</strong> و روش‌های ادغام آن‌ها در <strong>data-intensive applications</strong> نگاه می‌کنیم. این کتاب فضای کافی برای پوشش <strong>deployment</strong>، <strong>operations</strong>، <strong>security</strong>، مدیریت و سایر حوزه‌ها ندارد—این‌ها موضوعات پیچیده و مهمی هستند و ما با یادداشت‌های جانبی سطحی در این کتاب، آن‌ها را به‌خوبی انجام نمی‌دهیم. آن‌ها شایسته کتاب‌های خودشان هستند.</p>
<p>بسیاری از فناوری‌های شرح داده شده در این کتاب در قلمرو کلمه کلیدی <strong>Big Data</strong> قرار می‌گیرند. با این حال، اصطلاح "<strong>Big Data</strong>" بیش از حد استفاده شده و تعریف نشده است، که در یک بحث مهندسی جدی مفید نیست. این کتاب از اصطلاحات کم ابهام‌تری مانند سیستم‌های تک گرهی در مقابل توزیع‌شده، یا <strong>online/interactive</strong> در مقابل سیستم‌های <strong>offline/batch processing</strong> استفاده می‌کند.</p>
<p>این کتاب گرایش به سمت <strong>free</strong> و <strong>open source software (FOSS)</strong> دارد، زیرا خواندن، اصلاح و اجرای کد منبع یک راه عالی برای درک چگونگی عملکرد چیزی با جزئیات است. <strong>Open platforms</strong> همچنین خطر <strong>vendor lock-in</strong> را کاهش می‌دهند. با این حال، در صورت لزوم، ما همچنین در مورد <strong>software</strong> اختصاصی (<strong>closed-source software</strong>، <strong>software as a service</strong>، یا <strong>software</strong> درون‌سازمانی شرکت‌ها که فقط در ادبیات توضیح داده شده است اما به‌طور عمومی منتشر نشده است) بحث می‌کنیم.</p>
<h4>Outline of This Book</h4>
<p>این کتاب به سه بخش تقسیم شده است:</p>
<ol>
<li>در قسمت I، ما در مورد ایده‌های اساسی که اساس طراحی <strong>data-intensive applications</strong> را تشکیل می‌دهند، بحث می‌کنیم. ما در فصل 1 با بحث در مورد آنچه که در واقع در تلاش برای دستیابی به آن هستیم، شروع می‌کنیم: <strong>reliability</strong>، <strong>scalability</strong> و <strong>maintainability</strong>؛ چگونه باید در مورد آن‌ها فکر کنیم. و چگونه می‌توانیم به آن‌ها دست یابیم. در فصل 2 ما چندین مدل <strong>data</strong> و زبان‌های <strong>query</strong> مختلف را مقایسه می‌کنیم و می‌بینیم که چگونه برای موقعیت‌های مختلف مناسب هستند. در فصل 3 ما در مورد <strong>storage engines</strong> صحبت می‌کنیم: اینکه <strong>databases</strong> چگونه <strong>data</strong> را روی دیسک مرتب می‌کنند تا بتوانیم دوباره آن را به‌طور کارآمد پیدا کنیم. فصل 4 به قالب‌بندی برای رمزگذاری <strong>data (serialization)</strong> و تکامل <strong>schemas</strong> در طول زمان می‌پردازد.</li>
<li>در قسمت II، ما از <strong>data</strong> ذخیره شده در یک ماشین به <strong>data</strong> که در چندین ماشین توزیع شده است، می‌رویم. این اغلب برای مقیاس‌پذیری ضروری است، اما مجموعه‌ای از چالش‌های منحصربه‌فرد را به همراه دارد. ما ابتدا در مورد <strong>replication (فصل 5)</strong>، <strong>partitioning/sharding (فصل 6)</strong> و <strong>transactions (فصل 7)</strong> بحث می‌کنیم. سپس وارد
    xvi | Preface</li>
</ol>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0018</div>
            </div>
        </div>
        <!-- Page 0019 -->
        <div class="chapter" id="page-0019">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p><strong>more detail</strong> on the problems with distributed systems (فصل 8) و این‌که رسیدن به <strong>consistency</strong> و <strong>consensus</strong> در یک سیستم توزیع‌شده (فصل 9) به چه معناست.</p>
<p>3. در قسمت III، ما سیستم‌هایی را مورد بحث قرار می‌دهیم که برخی از مجموعه‌های <strong>data</strong> را از مجموعه‌های <strong>data</strong> دیگر مشتق می‌کنند. <strong>Derived data</strong> اغلب در سیستم‌های ناهمگن رخ می‌دهد: هنگامی‌که هیچ <strong>database</strong> وجود ندارد که بتواند همه کارها را به‌خوبی انجام دهد، <strong>applications</strong> باید چندین <strong>databases</strong>، کش‌ها، <strong>indexes</strong> و غیره را ادغام کنند. در فصل 10 ما با یک رویکرد پردازش دسته‌ای برای <strong>derived data</strong> شروع می‌کنیم و با پردازش جریانی در فصل 11 بر روی آن بنا می‌کنیم. در نهایت، در فصل 12 ما همه چیز را در کنار هم قرار می‌دهیم و در مورد رویکردهایی برای ساخت <strong>applications</strong> قابل اعتماد، مقیاس‌پذیر و قابل نگهداری در آینده بحث می‌کنیم.</p>
<h4>References and Further Reading</h4>
<p>بیشتر آنچه در این کتاب مورد بحث قرار می‌دهیم، قبلاً به یک شکل یا شکل دیگری در جاهای دیگر گفته شده است—در ارائه‌های کنفرانس، مقالات تحقیقاتی، پست‌های وبلاگ، کد، ردیاب‌های باگ، لیست‌های پستی و <strong>engineering folklore</strong>. این کتاب مهم‌ترین ایده‌ها را از منابع مختلف خلاصه می‌کند و در سراسر متن به ادبیات اصلی اشاره می‌کند. مراجع در پایان هر فصل یک منبع عالی هستند، اگر می‌خواهید یک منطقه را با جزئیات بیشتر بررسی کنید و بیشتر آن‌ها به‌صورت <strong>online</strong> در دسترس هستند.</p>
<h4>O’Reilly Safari</h4>
<p><strong>Safari</strong> (که قبلاً <strong>Safari Books Online</strong> نام داشت) یک پلت فرم آموزشی و مرجع مبتنی بر عضویت برای شرکت‌ها، دولت، مربیان و افراد است.</p>
<p>اعضا به هزاران کتاب، ویدئوهای آموزشی، مسیرهای یادگیری، آموزش‌های تعاملی و لیست‌های پخش انتخاب‌شده از بیش از 250 ناشر، از جمله <strong>O’Reilly Media, Harvard Business Review, Prentice Hall Professional, Addison-Wesley Professional, Microsoft Press, Sams, Que, Peachpit Press, Adobe, Focal Press, Cisco Press, John Wiley &amp; Sons, Syngress, Morgan Kaufmann, IBM Redbooks, Packt, Adobe Press, FT Press, Apress, Manning, New Riders, McGraw-Hill, Jones &amp; Bartlett, and Course Technology</strong>، دسترسی دارند.</p>
<p>برای اطلاعات بیشتر، لطفاً به <strong>http://oreilly.com/safari</strong> مراجعه کنید.
   Preface | xvii</p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 19" src="page_0019/image_1.png"/></div>
</div>
                <div class="page-number">صفحه 0019</div>
            </div>
        </div>
        <!-- Page 0020 -->
        <div class="chapter" id="page-0020">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<h4>How to Contact Us</h4>
<p>لطفاً نظرات و سؤالات مربوط به این کتاب را به ناشر ارسال کنید:</p>
<p>O’Reilly Media, Inc.</p>
<p>1005 Gravenstein Highway North</p>
<p>Sebastopol, CA 95472</p>
<p>800-998-9938 (در ایالات متحده یا کانادا)</p>
<p>707-829-0515 (بین‌المللی یا محلی)</p>
<p>707-829-0104 (فکس)</p>
<p>ما یک صفحه <strong>web</strong> برای این کتاب داریم، که در آن خطاهای چاپی، نمونه‌ها و هر اطلاعات اضافی را فهرست می‌کنیم. می‌توانید از این صفحه در <strong>http://bit.ly/designing-data-intensive-apps</strong> به این صفحه دسترسی داشته باشید.</p>
<p>برای نظر دادن یا پرسیدن سؤالات فنی در مورد این کتاب، ایمیل را به <strong>bookquestions@oreilly.com</strong> ارسال کنید.</p>
<p>برای اطلاعات بیشتر در مورد کتاب‌ها، دوره‌ها، کنفرانس‌ها و اخبار ما، به وب‌سایت ما در <strong>http://www.oreilly.com</strong> مراجعه کنید.</p>
<p>ما را در <strong>Facebook</strong> پیدا کنید: <strong>http://facebook.com/oreilly</strong></p>
<p>ما را در <strong>Twitter</strong> دنبال کنید: <strong>http://twitter.com/oreillymedia</strong></p>
<p>ما را در <strong>YouTube</strong> تماشا کنید: <strong>http://www.youtube.com/oreillymedia</strong></p>
<h4>Acknowledgments</h4>
<p>این کتاب تلفیقی و نظام‌مند از تعداد زیادی از ایده‌ها و دانش افراد دیگر است که تجربه را از تحقیقات دانشگاهی و <strong>industrial practice</strong> ترکیب می‌کند. در <strong>computing</strong> ما تمایل داریم به چیزهایی جذب شویم که جدید و براق هستند، اما فکر می‌کنم چیزهای زیادی برای یادگیری از کارهایی که قبلاً انجام شده‌اند، داریم. این کتاب بیش از 800 مرجع به مقالات، پست‌های وبلاگ، گفتگوها، مستندات و موارد دیگر دارد و آن‌ها یک منبع یادگیری ارزشمند برای من بوده‌اند. من از نویسندگان این مطالب برای به اشتراک گذاشتن دانش خود بسیار سپاسگزارم.</p>
<p>من همچنین از مکالمات شخصی چیزهای زیادی یاد گرفته‌ام، با تشکر از تعداد زیادی از افرادی که وقت گذاشته‌اند تا ایده‌ها را مورد بحث قرار دهند یا صبورانه چیزها را برای من توضیح دهند. به‌طور خاص، مایلم از <strong>Joe Adler, Ross Anderson, Peter Bailis, Márton Balassi, Alastair Beresford, Mark Callaghan, Mat Clayton, Patrick Collison, Sean Cribbs, Shirshanka Das, Niklas Ekström, Stephan Ewen, Alan Fekete, Gyula Fóra, Camille Fournier, Andres Freund, John Garbutt, Seth Gilbert, Tom Haggett, Pat Helland, Joe Hellerstein, Jakob Homan, Heidi Howard, John Hugg, Julian Hyde, Conrad Irwin, Evan Jones, Flavio Junqueira, Jessica Kerr, Kyle Kingsbury, Jay Kreps, Carl Lerche, Nicolas Liochon, Steve Loughran, Lee Mallabone, Nathan Marz, Caitie</strong>
   xviii | Preface</p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0020</div>
            </div>
        </div>
        <!-- Page 0021 -->
        <div class="chapter" id="page-0021">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p><strong>McCaffrey, Josie McLellan, Christopher Meiklejohn, Ian Meyers, Neha Narkhede,
   Neha Narula, Cathy O’Neil, Onora O’Neill, Ludovic Orban, Zoran Perkov, Julia
   Powles, Chris Riccomini, Henry Robinson, David Rosenthal, Jennifer Rullmann,
   Matthew Sackman, Martin Scholl, Amit Sela, Gwen Shapira, Greg Spurrier, Sam
   Stokes, Ben Stopford, Tom Stuart, Diana Vasile, Rahul Vohra, Pete Warden, and
   Brett Wooldridge.</strong></p>
<p>چندین نفر دیگر با بررسی پیش‌نویس‌ها و ارائه بازخورد، در نوشتن این کتاب بسیار ارزشمند بوده‌اند. برای این مشارکت‌ها من به‌ویژه مدیون <strong>Raul Agepati, Tyler Akidau, Mattias Andersson, Sasha Baranov, Veena Basavaraj, David Beyer, Jim Brikman, Paul Carey, Raul Castro Fernandez, Joseph Chow, Derek Elkins, Sam Elliott, Alexander Gallego, Mark Grover, Stu Halloway, Heidi Howard, Nicola Kleppmann, Stefan Kruppa, Bjorn Madsen, Sander Mak, Stefan Podkowinski, Phil Potter, Hamid Ramazani, Sam Stokes, and Ben Summers</strong> هستم. البته من مسئولیت تمام اشتباهات یا نظرات ناخوشایند باقی‌مانده در این کتاب را بر عهده می‌گیرم.</p>
<p>برای کمک به واقعی شدن این کتاب و برای صبرشان در مورد نوشتن کند و درخواست‌های غیرمعمولم، از سردبیرانم <strong>Marie Beaugureau, Mike Loukides, Ann
   Spencer</strong>، و تمام تیم <strong>O’Reilly</strong> سپاسگزارم. برای کمک به پیدا کردن کلمات مناسب، از <strong>Rachel Head</strong> تشکر می‌کنم. برای اینکه با وجود تعهدات کاری دیگر، به من زمان و آزادی نوشتن را دادید، از <strong>Alastair Beresford, Susan Goodhue, Neha Narkhede, and Kevin Scott</strong> تشکر می‌کنم.</p>
<p>تشکر ویژه از <strong>Shabbir Diwan and Edie Freedman</strong>، که با دقت بسیار، نقشه‌هایی را که همراه فصل‌ها هستند، مصور کردند. این فوق‌العاده است که آن‌ها ایده غیرمتعارف ایجاد نقشه‌ها را پذیرفتند و آن‌ها را بسیار زیبا و جذاب کردند.</p>
<p>در نهایت، عشق من به خانواده و دوستانم، که بدون آن‌ها نمی‌توانستم این روند نوشتن را که تقریباً چهار سال طول کشید، طی کنم. شما بهترین هستید.</p>
<p>Preface | xix</p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0021</div>
            </div>
        </div>
        <!-- Page 0023 -->
        <div class="chapter" id="page-0023">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<h4>PART I</h4>
<h4>Foundations of Data Systems</h4>
<p>چهار فصل اول به ایده‌های اساسی می‌پردازد که برای همه سیستم‌های <strong>data</strong> اعمال می‌شود، چه روی یک ماشین واحد اجرا شوند و چه در یک <strong>cluster</strong> از ماشین‌ها توزیع شوند:</p>
<ol>
<li>فصل 1 اصطلاحات و رویکردی را معرفی می‌کند که ما در سراسر این کتاب از آن استفاده خواهیم کرد. این بررسی می‌کند که ما در واقع با کلماتی مانند <strong>reliability</strong>، <strong>scalability</strong> و <strong>maintainability</strong> چه منظوری داریم و چگونه می‌توانیم سعی کنیم به این اهداف برسیم.</li>
<li>فصل 2 چندین مدل <strong>data</strong> و زبان‌های <strong>query</strong> مختلف را مقایسه می‌کند—قابل مشاهده‌ترین عامل تمایز بین <strong>databases</strong> از دیدگاه یک <strong>developer</strong>. ما خواهیم دید که چگونه مدل‌های مختلف برای موقعیت‌های مختلف مناسب هستند.</li>
<li>فصل 3 به درون سیستم‌های <strong>storage engines</strong> می‌پردازد و به نحوه چیدمان <strong>data</strong> توسط <strong>databases</strong> روی دیسک نگاه می‌کند. موتورهای ذخیره‌سازی مختلف برای حجم کاری متفاوت بهینه شده‌اند و انتخاب درست می‌تواند تأثیر زیادی بر عملکرد داشته باشد.</li>
<li>فصل 4 قالب‌های مختلفی را برای رمزگذاری <strong>data (serialization)</strong> مقایسه می‌کند و به‌ویژه بررسی می‌کند که چگونه در محیطی که الزامات <strong>application</strong> تغییر می‌کند و <strong>schemas</strong> نیاز به انطباق با گذشت زمان دارند، این کار را انجام می‌دهند.</li>
</ol>
<p>بعداً، قسمت II به مسائل خاص سیستم‌های <strong>data</strong> توزیع‌شده می‌پردازد.</p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0023</div>
            </div>
        </div>
        <!-- Page 0025 -->
        <div class="chapter" id="page-0025">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<h3>CHAPTER 1</h3>
<h3>Reliable, Scalable, and
   Maintainable Applications</h3>
<p>اینترنت آن‌قدر خوب انجام شد که اکثر مردم آن را به‌عنوان یک منبع طبیعی مانند اقیانوس آرام در نظر می‌گیرند، نه چیزی که ساخته دست بشر باشد. آخرین باری که یک فناوری با چنین مقیاسی بدون خطا بود، کی بود؟</p>
<p>—Alan Kay, in interview with Dr Dobb’s Journal (2012)</p>
<p>امروزه بسیاری از <strong>applications</strong> <strong>data-intensive</strong> هستند، برخلاف <strong>compute-intensive</strong>. قدرت <strong>CPU</strong> خام به‌ندرت یک عامل محدودکننده برای این <strong>applications</strong> است—مشکلات بزرگ‌تر معمولاً حجم <strong>data</strong>، پیچیدگی <strong>data</strong> و سرعتی است که در آن در حال تغییر است.</p>
<p>یک <strong>data-intensive application</strong> معمولاً از <strong>building blocks</strong> استاندارد ساخته می‌شود که عملکرد موردنیاز را ارائه می‌دهند. به‌عنوان‌مثال، بسیاری از <strong>applications</strong> به موارد زیر نیاز دارند:</p>
<ul>
<li>ذخیره <strong>data</strong> به‌طوری‌که آن‌ها یا یک <strong>application</strong> دیگر، بتوانند بعداً آن را دوباره پیدا کنند (<strong>databases</strong>)</li>
<li>نتیجه یک عملیات پرهزینه را به خاطر بسپارید تا سرعت خواندن را افزایش دهید (<strong>caches</strong>)</li>
<li>به کاربران اجازه دهید <strong>data</strong> را بر اساس کلمه کلیدی جستجو کنند یا آن را به روش‌های مختلف فیلتر کنند (<strong>search indexes</strong>)</li>
<li>یک پیام را به فرآیند دیگری ارسال کنید تا به‌صورت <strong>asynchronously</strong> رسیدگی شود (پردازش جریانی)</li>
<li>به‌طور دوره‌ای مقدار زیادی از <strong>data</strong> انباشته شده را خرد کنید (پردازش دسته‌ای)</li>
</ul>
<p>اگر این به‌طور دردناکی واضح به نظر می‌رسد، فقط به این دلیل است که این سیستم‌های <strong>data</strong> یک انتزاع بسیار موفق هستند: ما همیشه از آن‌ها استفاده می‌کنیم، بدون اینکه زیاد فکر کنیم. هنگام ساختن یک <strong>application</strong>، اکثر مهندسان خواب نوشتن یک موتور ذخیره‌سازی <strong>data</strong> جدید را از ابتدا نمی‌بینند، زیرا <strong>databases</strong> یک ابزار کاملاً خوب برای این کار هستند.</p>
<p>3</p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0025</div>
            </div>
        </div>
        <!-- Page 0026 -->
        <div class="chapter" id="page-0026">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>اما واقعیت به آن سادگی نیست. بسیاری از سیستم‌های <strong>database</strong> با ویژگی‌های مختلف وجود دارند، زیرا <strong>applications</strong> مختلف نیازهای متفاوتی دارند. رویکردهای مختلفی برای <strong>caching</strong>، چندین روش برای ساخت <strong>search indexes</strong> و غیره وجود دارد. هنگام ساختن یک <strong>application</strong>، ما همچنان باید بفهمیم که کدام ابزارها و کدام رویکردها برای کار مورد نظر مناسب‌تر هستند. و ترکیب ابزارها زمانی که نیاز دارید کاری را انجام دهید که یک ابزار واحد به تنهایی نمی‌تواند انجام دهد، می‌تواند دشوار باشد.</p>
<p>این کتاب سفری است از طریق اصول و عملکردهای سیستم‌های <strong>data</strong> و نحوه استفاده از آن‌ها برای ساخت <strong>data-intensive applications</strong>. ما بررسی خواهیم کرد که ابزارهای مختلف چه چیز مشترکی دارند، چه چیزی آن‌ها را متمایز می‌کند و چگونه به ویژگی‌های خود می‌رسند.</p>
<p>در این فصل، با بررسی مبانی آنچه که در تلاش برای دستیابی به آن هستیم شروع می‌کنیم: سیستم‌های <strong>data</strong> قابل اعتماد، مقیاس‌پذیر و قابل نگهداری. ما روشن خواهیم کرد که این موارد به چه معنا هستند، برخی از روش‌های تفکر در مورد آن‌ها را شرح می‌دهیم و به اصول اولیه‌ای که برای فصل‌های بعدی به آن‌ها نیاز خواهیم داشت، می‌پردازیم. در فصل‌های بعدی لایه به لایه ادامه خواهیم داد، و به تصمیمات طراحی مختلفی که باید هنگام کار بر روی یک <strong>data-intensive application</strong> در نظر گرفته شوند، نگاه خواهیم کرد.</p>
<h4>Thinking About Data Systems</h4>
<p>ما معمولاً در مورد <strong>databases</strong>، صف‌ها، <strong>caches</strong> و غیره به‌عنوان دسته‌های بسیار متفاوتی از ابزارها فکر می‌کنیم. اگرچه یک <strong>database</strong> و یک صف پیام شباهت‌های سطحی دارند—هر دو <strong>data</strong> را برای مدتی ذخیره می‌کنند—الگوهای دسترسی آن‌ها بسیار متفاوت است، که به معنای ویژگی‌های عملکردی متفاوت و در نتیجه پیاده‌سازی‌های بسیار متفاوت است.</p>
<p>بنابراین چرا باید همه آن‌ها را تحت یک اصطلاح چتری مانند سیستم‌های <strong>data</strong> جمع کنیم؟</p>
<p>بسیاری از ابزارهای جدید برای ذخیره‌سازی و پردازش <strong>data</strong> در سال‌های اخیر پدیدار شده‌اند. آن‌ها برای انواع مختلف موارد استفاده بهینه شده‌اند و دیگر به‌خوبی در دسته‌های سنتی قرار نمی‌گیرند [1]. به‌عنوان‌مثال، <strong>datastores</strong> وجود دارند که به‌عنوان صف‌های پیام (<strong>Redis</strong>) نیز استفاده می‌شوند، و صف‌های پیام با تضمین‌های دوام <strong>database-like</strong> (<strong>Apache Kafka</strong>) وجود دارند. مرزهای بین دسته‌ها در حال محو شدن هستند.</p>
<p>ثانیاً، به‌طور فزاینده‌ای <strong>applications</strong> زیادی اکنون نیازهای آن‌قدر زیاد یا گسترده‌ای دارند که یک ابزار واحد دیگر نمی‌تواند تمام نیازهای پردازش و ذخیره‌سازی <strong>data</strong> خود را برآورده کند. در عوض، کار به وظایفی تقسیم می‌شود که می‌توانند به‌طور مؤثر بر روی یک ابزار واحد انجام شوند و آن ابزارهای مختلف با استفاده از کد <strong>application</strong> به هم متصل می‌شوند.</p>
<p>به‌عنوان‌مثال، اگر یک لایه <strong>caching</strong> مدیریت شده توسط <strong>application</strong> (با استفاده از <strong>Memcached</strong> یا مشابه) یا یک <strong>full-text search server</strong> (مانند <strong>Elasticsearch</strong> یا <strong>Solr</strong>) جدا از <strong>database</strong> اصلی خود دارید، معمولاً این مسئولیت کد <strong>application</strong> است که آن <strong>caches</strong> و <strong>indexes</strong> را با <strong>database</strong> اصلی همگام نگه دارد. شکل 1-1 نگاهی اجمالی به این موضوع می‌دهد (ما در فصل‌های بعدی به جزئیات خواهیم پرداخت).</p>
<p>4 | Chapter 1: Reliable, Scalable, and Maintainable Applications</p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0026</div>
            </div>
        </div>
        <!-- Page 0027 -->
        <div class="chapter" id="page-0027">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>شکل 1-1. یک معماری احتمالی برای یک سیستم <strong>data</strong> که چندین مؤلفه را ترکیب می‌کند.</p>
<p>هنگامی‌که چندین ابزار را برای ارائه یک <strong>service</strong> ترکیب می‌کنید، رابط <strong>service</strong> یا <strong>application programming interface (API)</strong> معمولاً این جزئیات پیاده‌سازی را از <strong>clients</strong> پنهان می‌کند. اکنون شما اساساً یک سیستم <strong>data</strong> جدید و با هدف خاص از اجزای کوچک‌تر و با هدف عمومی ایجاد کرده‌اید. سیستم <strong>data</strong> ترکیبی شما ممکن است تضمین‌های خاصی را ارائه دهد: به‌عنوان‌مثال، این‌که <strong>cache</strong> به‌درستی با نوشتن‌ها باطل یا به‌روزرسانی می‌شود تا <strong>clients</strong> خارجی نتایج سازگار را ببینند. شما اکنون نه تنها یک <strong>application developer</strong> هستید، بلکه یک طراح سیستم <strong>data</strong> نیز هستید.</p>
<p>اگر در حال طراحی یک سیستم یا <strong>service data</strong> هستید، سؤالات دشوار زیادی مطرح می‌شود. چگونه اطمینان حاصل می‌کنید که <strong>data</strong> صحیح و کامل باقی می‌ماند، حتی زمانی که در داخل مشکلی پیش می‌آید؟ چگونه عملکرد خوب و مداومی را به <strong>clients</strong> ارائه می‌دهید، حتی زمانی که بخش‌هایی از سیستم شما خراب شده‌اند؟ چگونه مقیاس می‌دهید تا افزایش بار را مدیریت کنید؟ یک <strong>API</strong> خوب برای <strong>service</strong> چگونه است؟</p>
<p>عوامل زیادی وجود دارد که ممکن است بر طراحی یک سیستم <strong>data</strong> تأثیر بگذارند، از جمله مهارت‌ها و تجربه افراد درگیر، وابستگی‌های سیستم‌های قدیمی، مقیاس زمانی برای تحویل، تحمل سازمان شما نسبت به انواع مختلف ریسک، محدودیت‌های نظارتی و غیره. این عوامل تا حد زیادی به شرایط بستگی دارد.</p>
<p>Thinking About Data Systems | 5</p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 27" src="page_0027/image_1.png"/></div>
</div>
                <div class="page-number">صفحه 0027</div>
            </div>
        </div>
        <!-- Page 0028 -->
        <div class="chapter" id="page-0028">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>در این کتاب، ما بر روی سه نگرانی تمرکز می‌کنیم که در اکثر سیستم‌های <strong>software</strong> مهم هستند:</p>
<h4>Reliability</h4>
<p>سیستم باید حتی در مواجهه با ناملایمات (خطاهای سخت‌افزاری یا نرم‌افزاری، و حتی خطای انسانی) به‌درستی به کار خود ادامه دهد (انجام عملکرد صحیح در سطح عملکرد موردنظر). به “<strong>Reliability</strong>” در صفحه 6 مراجعه کنید.</p>
<h4>Scalability</h4>
<p>با بزرگ شدن سیستم (در حجم <strong>data</strong>، حجم ترافیک یا پیچیدگی)، باید راه‌های منطقی برای مقابله با این رشد وجود داشته باشد. به “<strong>Scalability</strong>” در صفحه 10 مراجعه کنید.</p>
<h4>Maintainability</h4>
<p>با گذشت زمان، افراد مختلفی بر روی سیستم کار خواهند کرد (مهندسی و <strong>operations</strong>، هم حفظ رفتار فعلی و هم انطباق سیستم با موارد استفاده جدید)، و همه آن‌ها باید بتوانند به‌طور مؤثر روی آن کار کنند. به “<strong>Maintainability</strong>” در صفحه 18 مراجعه کنید.</p>
<p>این کلمات اغلب بدون درک روشنی از معنای آن‌ها در اطراف ریخته می‌شوند. به دلیل علاقه به <strong>thoughtful engineering</strong>، ما بقیه این فصل را صرف بررسی راه‌های تفکر در مورد <strong>reliability</strong>، <strong>scalability</strong> و <strong>maintainability</strong> می‌کنیم. سپس، در فصل‌های بعدی، ما به تکنیک‌ها، <strong>architectures</strong> و الگوریتم‌های مختلفی نگاه خواهیم کرد که برای دستیابی به این اهداف استفاده می‌شوند.</p>
<h4>Reliability</h4>
<p>همه یک ایده شهودی دارند که برای قابل اعتماد یا غیرقابل اعتماد بودن یک چیز چه معنایی دارد. برای <strong>software</strong>، انتظارات معمول عبارت‌اند از:</p>
<ul>
<li><strong>application</strong>، عملکردی را که کاربر انتظار داشت، انجام می‌دهد.</li>
<li>می‌تواند اشتباهات کاربر یا استفاده از <strong>software</strong> را به روش‌های غیرمنتظره تحمل کند.</li>
<li>عملکرد آن برای مورد استفاده موردنیاز، تحت بار و حجم <strong>data</strong> مورد انتظار، به‌اندازه کافی خوب است.</li>
<li>سیستم از هرگونه دسترسی و سوءاستفاده غیرمجاز جلوگیری می‌کند.</li>
</ul>
<p>اگر همه آن چیزها در کنار هم به معنای "درست کار کردن" هستند، در این صورت می‌توانیم <strong>reliability</strong> را تقریباً به معنای "ادامه کار صحیح، حتی زمانی که اوضاع خراب می‌شود" درک کنیم.</p>
<p>چیزهایی که می‌توانند اشتباه شوند، <strong>faults</strong> نامیده می‌شوند و سیستم‌هایی که <strong>faults</strong> را پیش‌بینی می‌کنند و می‌توانند با آن‌ها مقابله کنند، <strong>fault-tolerant</strong> یا <strong>resilient</strong> نامیده می‌شوند. اصطلاح اول کمی گمراه‌کننده است: این نشان می‌دهد که ما می‌توانیم یک سیستم را نسبت به هر نوع <strong>fault</strong> ممکن تحمل کنیم، که در واقعیت امکان‌پذیر نیست. اگر کل سیاره زمین (و تمام سرورهای روی آن) توسط یک سیاهچاله بلعیده شود، تحمل آن <strong>fault</strong> نیازمند <strong>web hosting</strong> در
   6 | Chapter 1: Reliable, Scalable, and Maintainable Applications</p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0028</div>
            </div>
        </div>
        <!-- Page 0029 -->
        <div class="chapter" id="page-0029">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>فضای موجود—برای تأیید آن آیتم بودجه شانس بیاورید. بنابراین فقط منطقی است که در مورد تحمل انواع خاصی از <strong>faults</strong> صحبت کنیم.</p>
<p>توجه داشته باشید که یک <strong>fault</strong> با یک <strong>failure</strong> یکسان نیست [2]. یک <strong>fault</strong> معمولاً به‌عنوان یک جزء سیستم که از <strong>spec</strong> خود منحرف می‌شود تعریف می‌شود، درحالی‌که یک <strong>failure</strong> زمانی است که سیستم به‌طورکلی از ارائه <strong>service</strong> موردنیاز به کاربر متوقف می‌شود. کاهش احتمال یک <strong>fault</strong> به صفر غیرممکن است؛ بنابراین معمولاً بهترین کار این است که مکانیسم‌های تحمل <strong>fault</strong> را طراحی کنید که از ایجاد <strong>failures</strong> توسط <strong>faults</strong> جلوگیری می‌کند. در این کتاب ما چندین تکنیک را برای ساخت سیستم‌های قابل اعتماد از قطعات غیرقابل اعتماد پوشش می‌دهیم.</p>
<p>برخلاف شهود، در چنین سیستم‌های تحمل <strong>fault</strong>، می‌تواند منطقی باشد که میزان <strong>faults</strong> را با راه‌اندازی عمدی آن‌ها افزایش دهید—به‌عنوان‌مثال، با کشتن تصادفی فرآیندهای فردی بدون هشدار. بسیاری از باگ‌های مهم در واقع به دلیل مدیریت خطای ضعیف هستند [3]؛ با ایجاد عمدی <strong>faults</strong>، شما اطمینان حاصل می‌کنید که ماشین‌آلات تحمل <strong>fault</strong> به‌طور مداوم مورد استفاده و آزمایش قرار می‌گیرند، که می‌تواند اعتماد شما را به این‌که <strong>faults</strong> به‌درستی مدیریت می‌شوند، در زمانی که به‌طور طبیعی رخ می‌دهند، افزایش دهد. <strong>Netflix Chaos Monkey</strong> [4] نمونه‌ای از این رویکرد است.</p>
<p>اگرچه ما به‌طورکلی ترجیح می‌دهیم <strong>faults</strong> را تحمل کنیم تا از <strong>faults</strong> جلوگیری کنیم، مواردی وجود دارد که در آن‌ها پیشگیری بهتر از درمان است (مثلاً، زیرا هیچ درمانی وجود ندارد). این مورد در مسائل امنیتی، به‌عنوان‌مثال، وجود دارد: اگر یک مهاجم یک سیستم را به خطر انداخته و به <strong>data</strong> حساس دسترسی پیدا کرده باشد، آن رویداد را نمی‌توان خنثی کرد. بااین‌حال، این کتاب بیشتر با انواع <strong>faults</strong> سروکار دارد که می‌توان آن‌ها را درمان کرد، همان‌طور که در بخش‌های زیر توضیح داده شده است.</p>
<h4>Hardware Faults</h4>
<p>وقتی به علل <strong>system failure</strong> فکر می‌کنیم، <strong>hardware faults</strong> سریعاً به ذهن خطور می‌کنند. هارد دیسک‌ها خراب می‌شوند، <strong>RAM</strong> معیوب می‌شود، شبکه برق خاموش می‌شود، کسی کابل شبکه اشتباه را جدا می‌کند. هرکسی که با <strong>datacenters</strong> بزرگ کار کرده باشد، می‌تواند به شما بگوید که این اتفاقات در تمام مدت زمانی که شما ماشین‌های زیادی دارید، رخ می‌دهد.</p>
<p>گزارش شده است که هارد دیسک‌ها میانگین زمان خرابی (<strong>MTTF</strong>) حدود 10 تا 50 سال دارند [5، 6]. بنابراین، در یک <strong>storage cluster</strong> با 10000 دیسک، باید به‌طور متوسط انتظار داشته باشیم که یک دیسک در روز از بین برود.</p>
<p>اولین پاسخ ما معمولاً این است که افزونگی را به اجزای سخت‌افزاری جداگانه اضافه کنیم تا میزان <strong>failure</strong> سیستم را کاهش دهیم. دیسک‌ها ممکن است در پیکربندی <strong>RAID</strong> راه‌اندازی شوند، سرورها ممکن است دارای منبع تغذیه دوگانه و <strong>CPUs</strong> قابل تعویض باشند و <strong>datacenters</strong> ممکن است دارای باتری و ژنراتورهای دیزلی برای برق پشتیبان باشند. هنگامی‌که یک مؤلفه از بین می‌رود، مؤلفه اضافی می‌تواند جایگزین آن شود درحالی‌که مؤلفه شکسته شده جایگزین می‌شود. این رویکرد نمی‌تواند به‌طور کامل از ایجاد مشکلات سخت‌افزاری برای ایجاد <strong>failures</strong> جلوگیری کند، اما به‌خوبی درک شده است و اغلب می‌تواند یک دستگاه را برای سال‌ها بدون وقفه در حال اجرا نگه دارد.</p>
<p>Reliability | 7</p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0029</div>
            </div>
        </div>
        <!-- Page 0030 -->
        <div class="chapter" id="page-0030">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>i. Defined in “Approaches for Coping with Load” on page 17.</p>
<p>تا همین اواخر، افزونگی اجزای سخت‌افزاری برای اکثر <strong>applications</strong> کافی بود، زیرا باعث می‌شود خرابی کامل یک ماشین به‌طورکلی نادر باشد. تا زمانی که بتوانید یک <strong>backup</strong> را نسبتاً سریع روی یک دستگاه جدید بازیابی کنید، خرابی در صورت <strong>failure</strong> در اکثر <strong>applications</strong> فاجعه‌بار نیست. بنابراین، افزونگی چند ماشینی فقط توسط تعداد کمی از <strong>applications</strong> که در آن‌ها <strong>high availability</strong> کاملاً ضروری بود، موردنیاز بود.</p>
<p>با این حال، با افزایش حجم <strong>data</strong> و تقاضای محاسباتی <strong>applications</strong>، <strong>applications</strong> بیشتری شروع به استفاده از تعداد بیشتری از ماشین‌ها کرده‌اند که به‌طور متناسب میزان <strong>hardware faults</strong> را افزایش می‌دهد. علاوه بر این، در برخی از پلتفرم‌های <strong>cloud</strong> مانند <strong>Amazon Web Services (AWS)</strong> نسبتاً معمول است که نمونه‌های ماشین مجازی بدون هشدار در دسترس نباشند [7]، زیرا پلتفرم‌ها برای اولویت‌بندی انعطاف‌پذیری و <strong>elasticityi</strong> نسبت به قابلیت اطمینان یک ماشین واحد طراحی شده‌اند.</p>
<p>ازاین‌رو، حرکت به‌سمت سیستم‌هایی است که می‌توانند از دست رفتن کل ماشین‌ها را تحمل کنند، با استفاده از تکنیک‌های تحمل <strong>software fault</strong> به جای یا علاوه بر افزونگی سخت‌افزاری. چنین سیستم‌هایی مزایای عملیاتی نیز دارند: یک سیستم تک سروری در صورت نیاز به راه‌اندازی مجدد دستگاه (برای اعمال وصله‌های امنیتی سیستم‌عامل، به‌عنوان‌مثال) به زمان از کار افتادگی برنامه‌ریزی شده نیاز دارد، درحالی‌که سیستمی که می‌تواند خرابی ماشین را تحمل کند، می‌تواند یک گره را در یک زمان وصله کند، بدون از کار افتادن کل سیستم (یک <strong>rolling upgrade</strong>؛ به فصل 4 مراجعه کنید).</p>
<h4>Software Errors</h4>
<p>ما معمولاً به <strong>hardware faults</strong> به‌عنوان تصادفی و مستقل از یکدیگر فکر می‌کنیم: خرابی دیسک یک دستگاه به این معنی نیست که دیسک دستگاه دیگری از کار می‌افتد. ممکن است همبستگی‌های ضعیفی وجود داشته باشد (به‌عنوان‌مثال به دلیل یک علت مشترک، مانند دما در قفسه سرور)، اما در غیر این صورت بعید است که تعداد زیادی از اجزای سخت‌افزاری هم‌زمان از کار بیفتند.</p>
<p>نوع دیگری از <strong>fault</strong>، یک خطای سیستماتیک در سیستم است [8]. پیش‌بینی چنین <strong>faults</strong> دشوارتر است، و از آنجا که در گره‌ها همبستگی دارند، تمایل دارند که <strong>system failures</strong> بیشتری را نسبت به <strong>hardware faults</strong> بدون همبستگی ایجاد کنند [5]. نمونه‌ها عبارت‌اند از:</p>
<ul>
<li>یک باگ <strong>software</strong> که باعث می‌شود هر نمونه از یک <strong>application server</strong> هنگام دریافت ورودی بد، از کار بیفتد. به‌عنوان‌مثال، ثانیه جهشی در 30 ژوئن 2012 را در نظر بگیرید که باعث شد بسیاری از <strong>applications</strong> به‌طور هم‌زمان به دلیل یک باگ در هسته <strong>Linux</strong> آویزان شوند [9].</li>
<li>یک فرآیند فراری که از یک منبع مشترک استفاده می‌کند—زمان <strong>CPU</strong>، حافظه، فضای دیسک یا پهنای باند شبکه.</li>
</ul>
<p>8 | Chapter 1: Reliable, Scalable, and Maintainable Applications</p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0030</div>
            </div>
        </div>
        <!-- Page 0031 -->
        <div class="chapter" id="page-0031">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<ul>
<li>یک <strong>service</strong> که سیستم به آن وابسته است، کند می‌شود، پاسخگو نمی‌شود یا شروع به بازگرداندن پاسخ‌های خراب می‌کند.</li>
<li><strong>Cascading failures</strong>، جایی که یک <strong>fault</strong> کوچک در یک مؤلفه، یک <strong>fault</strong> را در مؤلفه دیگری ایجاد می‌کند، که به‌نوبه خود <strong>faults</strong> بیشتری را ایجاد می‌کند [10].</li>
</ul>
<p>باگ‌هایی که باعث این نوع <strong>software faults</strong> می‌شوند، اغلب برای مدت طولانی خاموش می‌مانند تا زمانی که توسط مجموعه‌ای غیرعادی از شرایط ایجاد شوند. در آن شرایط، مشخص می‌شود که <strong>software</strong> نوعی فرضیاتی را در مورد محیط خود ایجاد می‌کند—و درحالی‌که آن فرضیه معمولاً درست است، به‌دلایلی در نهایت از درست بودن باز می‌ایستد [11].</p>
<p>هیچ راه‌حل سریعی برای مشکل <strong>systematic faults</strong> در <strong>software</strong> وجود ندارد. بسیاری از موارد کوچک می‌توانند کمک کنند: با دقت در مورد فرضیات و تعاملات در سیستم فکر کردن؛ تست کامل؛ ایزوله کردن فرآیندها؛ اجازه دادن به فرآیندها برای <strong>crash</strong> و راه‌اندازی مجدد؛ اندازه‌گیری، نظارت و تجزیه‌وتحلیل رفتار سیستم در تولید. اگر انتظار می‌رود که یک سیستم تضمینی را ارائه دهد (به‌عنوان‌مثال، در یک صف پیام، این‌که تعداد پیام‌های ورودی با تعداد پیام‌های خروجی برابر است)، می‌تواند به‌طور مداوم در حین اجرا خود را بررسی کند و در صورت یافتن مغایرت هشدار دهد [12].</p>
<h4>Human Errors</h4>
<p>انسان‌ها سیستم‌های <strong>software</strong> را طراحی و می‌سازند، و اپراتورهایی که سیستم‌ها را در حال اجرا نگه می‌دارند نیز انسان هستند. حتی زمانی که بهترین نیت‌ها را دارند، انسان‌ها غیرقابل‌اعتماد هستند. به‌عنوان‌مثال، یک مطالعه در مورد <strong>internet services</strong> بزرگ نشان داد که خطاهای پیکربندی توسط اپراتورها عامل اصلی <strong>outages</strong> بودند، درحالی‌که <strong>hardware faults</strong> (سرورها یا شبکه) تنها در 10 تا 25 درصد از <strong>outages</strong> نقش داشتند [13].</p>
<p>چگونه سیستم‌های خود را با وجود انسان‌های غیرقابل‌اعتماد قابل اعتماد می‌کنیم؟ بهترین سیستم‌ها چندین رویکرد را ترکیب می‌کنند:</p>
<ul>
<li>سیستم‌ها را به گونه‌ای طراحی کنید که فرصت‌های خطا را به حداقل برساند. به‌عنوان‌مثال، انتزاع‌های خوب طراحی شده، <strong>APIs</strong> و رابط‌های مدیریتی، انجام "کار درست" را آسان می‌کند و "کار اشتباه" را دلسرد می‌کند. بااین‌حال، اگر رابط‌ها بیش از حد محدودکننده باشند، مردم از آن‌ها استفاده می‌کنند و مزیت آن‌ها را باطل می‌کنند، بنابراین این یک تعادل دشوار است که درست باشد.</li>
<li>مکان‌هایی را که مردم بیشترین اشتباه را مرتکب می‌شوند، از مکان‌هایی که می‌توانند باعث <strong>failures</strong> شوند، جدا کنید. به‌طور خاص، محیط‌های <strong>sandbox</strong> غیرتولیدی با ویژگی‌های کامل ارائه دهید که در آن افراد بتوانند با استفاده از <strong>data</strong> واقعی، بدون تأثیر بر کاربران واقعی، به‌طور ایمن کاوش و آزمایش کنند.</li>
<li>به‌طور کامل در همه سطوح، از <strong>unit tests</strong> گرفته تا تست‌های یکپارچه‌سازی کل سیستم و تست‌های دستی، تست کنید [3]. تست خودکار به‌طور گسترده مورد استفاده قرار می‌گیرد، به‌خوبی درک می‌شود و به‌ویژه برای پوشش موارد گوشه‌ای که به‌ندرت در عملیات عادی رخ می‌دهند، ارزشمند است.</li>
</ul>
<p>Reliability | 9</p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0031</div>
            </div>
        </div>
        <!-- Page 0032 -->
        <div class="chapter" id="page-0032">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<ul>
<li>اجازه بازیابی سریع و آسان از خطاهای انسانی، برای به حداقل رساندن تأثیر در صورت <strong>failure</strong>. به‌عنوان‌مثال، ایجاد سرعت در بازگرداندن تغییرات پیکربندی، معرفی تدریجی کد جدید (به‌طوری‌که هر باگ غیرمنتظره فقط بر زیرمجموعه‌ای کوچک از کاربران تأثیر بگذارد) و ارائه ابزارهایی برای محاسبه مجدد <strong>data</strong> (در صورت مشخص شدن نادرست بودن محاسبات قدیمی).</li>
<li>نظارت دقیق و روشنی مانند معیارهای عملکرد و نرخ خطا راه‌اندازی کنید. در سایر رشته‌های مهندسی به این <strong>telemetry</strong> اشاره می‌شود. (هنگامی‌که یک موشک از زمین خارج شد، <strong>telemetry</strong> برای ردیابی آنچه در حال رخ دادن است و برای درک <strong>failures</strong> ضروری است [14].) نظارت می‌تواند سیگنال‌های هشدار اولیه را به ما نشان دهد و به ما امکان می‌دهد بررسی کنیم که آیا فرضیات یا محدودیت‌هایی نقض می‌شود یا خیر. وقتی مشکلی پیش می‌آید، متریک‌ها می‌توانند در تشخیص مشکل ارزشمند باشند.</li>
<li>پیاده‌سازی شیوه‌های مدیریت خوب و آموزش—یک جنبه پیچیده و مهم، و فراتر از محدوده این کتاب.</li>
</ul>
<h4>How Important Is Reliability?</h4>
<p><strong>Reliability</strong> فقط برای نیروگاه‌های هسته‌ای و نرم‌افزار کنترل ترافیک هوایی نیست—انتظار می‌رود <strong>applications</strong> پیش پا افتاده‌تر نیز به‌طور قابل‌اعتماد کار کنند. باگ‌ها در <strong>business applications</strong> باعث از دست رفتن بهره‌وری می‌شوند (و اگر ارقام به‌درستی گزارش نشوند، ریسک‌های قانونی ایجاد می‌شود)، و <strong>outages</strong> سایت‌های تجارت الکترونیک می‌تواند هزینه‌های هنگفتی از نظر از دست دادن درآمد و آسیب به شهرت داشته باشد.</p>
<p>حتی در <strong>applications</strong> "غیر بحرانی" ما در قبال کاربران خود مسئولیت داریم. والدین را در نظر بگیرید که تمام عکس‌ها و ویدئوهای فرزندان خود را در <strong>photo application</strong> شما ذخیره می‌کنند [15]. اگر آن <strong>database</strong> ناگهان خراب شود، چه احساسی خواهند داشت؟ آیا آن‌ها می‌دانند چگونه آن را از یک <strong>backup</strong> بازیابی کنند؟</p>
<p>موقعیت‌هایی وجود دارد که در آن‌ها ممکن است ما <strong>reliability</strong> را قربانی کنیم تا هزینه توسعه (به‌عنوان‌مثال، هنگام توسعه یک محصول نمونه اولیه برای یک بازار اثبات نشده) یا هزینه عملیاتی (به‌عنوان‌مثال، برای یک <strong>service</strong> با حاشیه سود بسیار کم) را کاهش دهیم—اما ما باید بسیار آگاه باشیم که چه زمانی در حال کوتاه آمدن هستیم.</p>
<h4>Scalability</h4>
<p>حتی اگر یک سیستم امروزه به‌طور قابل‌اعتماد کار می‌کند، به این معنی نیست که لزوماً در آینده به‌طور قابل‌اعتماد کار خواهد کرد. یک دلیل رایج برای تنزل کیفیت، افزایش بار است: شاید سیستم از 10000 کاربر هم‌زمان به 100000 کاربر هم‌زمان یا از 1 میلیون به 10 میلیون کاربر افزایش یافته باشد. شاید در حال پردازش حجم <strong>data</strong> بسیار بیشتری نسبت به قبل است.</p>
<p><strong>Scalability</strong> اصطلاحی است که ما برای توصیف توانایی یک سیستم برای مقابله با افزایش بار استفاده می‌کنیم. با این حال، توجه داشته باشید که این یک برچسب تک بعدی نیست که بتوانیم به یک سیستم متصل کنیم: گفتن "X مقیاس‌پذیر است" یا "Y مقیاس‌پذیر نیست" بی‌معنی است. در عوض، بحث در مورد</p>
<p>10 | Chapter 1: Reliable, Scalable, and Maintainable Applications</p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0032</div>
            </div>
        </div>
        <!-- Page 0033 -->
        <div class="chapter" id="page-0033">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>ii. A term borrowed from electronic engineering, where it describes the number of logic gate inputs that are
   attached to another gate’s output. The output needs to supply enough current to drive all the attached inputs.</p>
<p>در سیستم‌های پردازش تراکنش، ما از آن برای توصیف تعداد درخواست‌ها به سرویس‌های دیگری استفاده می‌کنیم که برای ارائه یک درخواست ورودی باید انجام دهیم.</p>
<p><strong>scalability</strong> به‌معنای در نظر گرفتن سؤالاتی مانند "اگر سیستم به روش خاصی رشد کند، گزینه‌های ما برای مقابله با رشد چیست؟" و "چگونه می‌توانیم منابع محاسباتی را برای رسیدگی به بار اضافی اضافه کنیم؟"</p>
<h4>Describing Load</h4>
<p>ابتدا، ما باید بار فعلی را بر روی سیستم به‌طور مختصر توصیف کنیم؛ تنها در این صورت می‌توانیم در مورد سؤالات رشد (چه اتفاقی می‌افتد اگر بار ما دو برابر شود؟) بحث کنیم. بار را می‌توان با چند عدد توصیف کرد که ما آن‌ها را <strong>load parameters</strong> می‌نامیم. بهترین انتخاب پارامترها به <strong>architecture</strong> سیستم شما بستگی دارد: ممکن است درخواست در ثانیه به یک <strong>web server</strong>، نسبت خواندن به نوشتن در یک <strong>database</strong>، تعداد کاربران فعال هم‌زمان در یک اتاق گفتگو، <strong>hit rate</strong> روی یک <strong>cache</strong> یا چیز دیگری باشد. شاید <strong>average case</strong> برای شما مهم باشد، یا شاید گلوگاه شما تحت سلطه تعداد کمی از موارد شدید باشد.</p>
<p>برای ملموس‌تر کردن این ایده، بیایید <strong>Twitter</strong> را به‌عنوان مثال در نظر بگیریم، با استفاده از <strong>data</strong> منتشر شده در نوامبر 2012 [16]. دو مورد از عملیات اصلی <strong>Twitter</strong> عبارت‌اند از:</p>
<ul>
<li><strong>Post tweet</strong></li>
<p>یک کاربر می‌تواند یک پیام جدید را برای دنبال‌کنندگان خود منتشر کند (4.6k درخواست/ثانیه به‌طور متوسط، بیش از 12k درخواست/ثانیه در اوج).</p>
<li><strong>Home timeline</strong></li>
<p>یک کاربر می‌تواند توییت‌های ارسال شده توسط افرادی را که دنبال می‌کند، مشاهده کند (300k درخواست/ثانیه).</p>
</ul>
<p>به‌سادگی رسیدگی به 12000 نوشتن در ثانیه (نرخ اوج برای ارسال توییت) نسبتاً آسان خواهد بود. با این حال، چالش مقیاس‌پذیری <strong>Twitter</strong>، در درجه اول به دلیل حجم توییت نیست، بلکه به دلیل <strong>fan-outii</strong> است—هر کاربر افراد زیادی را دنبال می‌کند و هر کاربر توسط افراد زیادی دنبال می‌شود. به‌طورکلی دو راه برای پیاده‌سازی این دو عملیات وجود دارد:</p>
<ol>
<li>ارسال یک توییت به‌سادگی توییت جدید را در مجموعه جهانی توییت‌ها درج می‌کند. هنگامی‌که یک کاربر جدول زمانی خانه خود را درخواست می‌کند، تمام افرادی را که دنبال می‌کند جستجو می‌کند، تمام توییت‌های هر یک از آن کاربران را پیدا می‌کند و آن‌ها را ادغام می‌کند (بر اساس زمان مرتب‌شده). در یک <strong>relational database</strong> مانند شکل 1-2، می‌توانید یک <strong>query</strong> مانند موارد زیر بنویسید:</li>
<pre><code class="language-sql">SELECT tweets.*, users.* FROM tweets
  JOIN users   ON tweets.sender_id    = users.id
  JOIN follows ON follows.followee_id = users.id
  WHERE follows.follower_id = current_user
</code></pre>
</ol>
<p>Scalability | 11</p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0033</div>
            </div>
        </div>
        <!-- Page 0034 -->
        <div class="chapter" id="page-0034">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<ol>
<li>نگهداری از یک <strong>cache</strong> برای جدول زمانی <strong>home</strong> هر کاربر—مانند یک صندوق پستی از توییت‌ها برای هر کاربر دریافت‌کننده (به شکل 1-3 مراجعه کنید). هنگامی‌که یک کاربر یک توییت را منتشر می‌کند، تمام افرادی را که آن کاربر را دنبال می‌کنند، جستجو می‌کند و توییت جدید را در هر یک از <strong>caches</strong> جدول زمانی <strong>home</strong> آن‌ها درج می‌کند. سپس درخواست برای خواندن جدول زمانی <strong>home</strong> ارزان است، زیرا نتیجه آن از قبل محاسبه شده است.</li>
</ol>
<p>شکل 1-2. <strong>Schema</strong> رابطه‌ای ساده برای پیاده‌سازی یک جدول زمانی <strong>home Twitter</strong>.</p>
<p>شکل 1-3. <strong>Data pipeline</strong> <strong>Twitter</strong> برای تحویل توییت‌ها به دنبال‌کنندگان، با <strong>load parameters</strong> از نوامبر 2012 [16].</p>
<p>اولین نسخه <strong>Twitter</strong> از رویکرد 1 استفاده می‌کرد، اما سیستم‌ها برای همگام شدن با بار <strong>home timeline queries</strong> تلاش می‌کردند، بنابراین این شرکت به رویکرد 2 روی آورد. این کار بهتر است زیرا میانگین نرخ توییت‌های منتشر شده تقریباً دو مرتبه کمتر از نرخ خواندن جدول زمانی <strong>home</strong> است، بنابراین در این مورد ترجیح داده می‌شود که کار بیشتری در زمان نوشتن و کمتر در زمان خواندن انجام شود.</p>
<p>با این حال، نقطه ضعف رویکرد 2 این است که ارسال یک توییت اکنون به کار اضافی زیادی نیاز دارد. به‌طور متوسط، یک توییت به حدود 75 دنبال‌کننده تحویل داده می‌شود، بنابراین 4.6 هزار توییت در ثانیه به 345 هزار نوشتن در ثانیه به <strong>caches</strong> جدول زمانی <strong>home</strong> تبدیل می‌شود. اما این میانگین این واقعیت را پنهان می‌کند که تعداد دنبال‌کنندگان هر کاربر به‌شدت متفاوت است و برخی از کاربران
   12 | Chapter 1: Reliable, Scalable, and Maintainable Applications</p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 34" src="page_0034/image_1.png"/></div>
<div class="page-image"><img alt="Image from page 34" src="page_0034/image_2.png"/></div>
</div>
                <div class="page-number">صفحه 0034</div>
            </div>
        </div>
        <!-- Page 0035 -->
        <div class="chapter" id="page-0035">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>iii. در یک دنیای ایده‌آل، زمان اجرای یک <strong>batch job</strong>، اندازه مجموعه <strong>dataset</strong> تقسیم بر <strong>throughput</strong> است. در عمل، زمان اجرا اغلب طولانی‌تر است، به دلیل <strong>skew</strong> (<strong>data</strong> به‌طور مساوی در بین فرآیندهای <strong>worker</strong> توزیع نمی‌شود) و نیاز به انتظار برای تکمیل کندترین کار.</p>
<p>بیش از 30 میلیون دنبال‌کننده دارند. این بدان معناست که یک توییت واحد ممکن است منجر به بیش از 30 میلیون نوشتن به جدول زمانی <strong>home</strong> شود! انجام این کار به‌موقع—<strong>Twitter</strong> تلاش می‌کند توییت‌ها را در عرض پنج ثانیه به دنبال‌کنندگان تحویل دهد—یک چالش بزرگ است.</p>
<p>در مثال <strong>Twitter</strong>، توزیع دنبال‌کنندگان در هر کاربر (شاید با توجه به این‌که این کاربران چقدر توییت می‌کنند) یک <strong>load parameter</strong> کلیدی برای بحث در مورد مقیاس‌پذیری است، زیرا <strong>load fan-out</strong> را تعیین می‌کند. <strong>application</strong> شما ممکن است ویژگی‌های بسیار متفاوتی داشته باشد، اما می‌توانید اصول مشابهی را برای استدلال در مورد <strong>load</strong> آن اعمال کنید.</p>
<p>آخرین پیچش حکایت <strong>Twitter</strong>: اکنون که رویکرد 2 به‌طور کامل پیاده‌سازی شده است، <strong>Twitter</strong> در حال حرکت به سمت ترکیبی از هر دو رویکرد است. توییت‌های اکثر کاربران همچنان در زمان ارسال، به جدول زمانی <strong>home</strong> <strong>fanned out</strong> می‌شوند، اما تعداد کمی از کاربران با تعداد بسیار زیادی دنبال‌کننده (به‌عنوان‌مثال، افراد مشهور) از این <strong>fan-out</strong> مستثنی می‌شوند. توییت‌های هر فرد مشهوری که یک کاربر ممکن است دنبال کند، جداگانه واکشی می‌شوند و با جدول زمانی <strong>home</strong> آن کاربر ادغام می‌شوند، مانند رویکرد 1. این رویکرد ترکیبی قادر به ارائه عملکرد خوب به‌طور مداوم است. ما این مثال را در فصل 12 پس از پوشش برخی از زمینه‌های فنی بیشتر، دوباره بررسی خواهیم کرد.</p>
<h4>Describing Performance</h4>
<p>هنگامی‌که <strong>load</strong> را روی سیستم خود توصیف کردید، می‌توانید بررسی کنید که چه اتفاقی می‌افتد وقتی <strong>load</strong> افزایش می‌یابد. می‌توانید از دو طریق به آن نگاه کنید:</p>
<ul>
<li>وقتی یک <strong>load parameter</strong> را افزایش می‌دهید و منابع سیستم (<strong>CPU</strong>، حافظه، پهنای باند شبکه و غیره) را بدون تغییر نگه می‌دارید، عملکرد سیستم شما چگونه تحت تأثیر قرار می‌گیرد؟</li>
<li>وقتی یک <strong>load parameter</strong> را افزایش می‌دهید، اگر می‌خواهید عملکرد را بدون تغییر نگه دارید، چقدر باید منابع را افزایش دهید؟</li>
</ul>
<p>هر دو سؤال به اعداد عملکرد نیاز دارند، بنابراین بیایید به‌طور خلاصه به توصیف عملکرد یک سیستم نگاهی بیندازیم.</p>
<p>در یک سیستم پردازش دسته‌ای مانند <strong>Hadoop</strong>، ما معمولاً به <strong>throughput</strong> اهمیت می‌دهیم—تعداد رکوردهایی که می‌توانیم در ثانیه پردازش کنیم، یا کل زمانی که طول می‌کشد تا یک <strong>job</strong> را روی یک <strong>dataset</strong> با اندازه مشخص اجرا کنیم.iii در سیستم‌های <strong>online</strong>، آنچه معمولاً مهم‌تر است، زمان پاسخ <strong>service</strong> است—یعنی، زمان بین ارسال درخواست از سوی یک <strong>client</strong> و دریافت پاسخ.</p>
<p>Scalability | 13</p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0035</div>
            </div>
        </div>
        <!-- Page 0036 -->
        <div class="chapter" id="page-0036">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<h4>Latency and response time</h4>
<p><strong>Latency</strong> و <strong>response time</strong> اغلب مترادف استفاده می‌شوند، اما یکسان نیستند. <strong>response time</strong> چیزی است که <strong>client</strong> می‌بیند: علاوه بر زمان واقعی برای پردازش درخواست (زمان <strong>service</strong>)، شامل تأخیرهای شبکه و تأخیرهای صف نیز می‌شود. <strong>Latency</strong>، مدت زمانی است که یک درخواست منتظر است تا رسیدگی شود—در این مدت نهفته است و منتظر <strong>service</strong> است [17].</p>
<p>حتی اگر شما فقط یک درخواست را بارها و بارها انجام دهید، در هر بار کمی <strong>response time</strong> متفاوتی دریافت خواهید کرد. در عمل، در یک سیستم که انواع درخواست‌ها را مدیریت می‌کند، <strong>response time</strong> می‌تواند بسیار متفاوت باشد. بنابراین ما باید در مورد <strong>response time</strong> نه به‌عنوان یک عدد واحد، بلکه به‌عنوان توزیعی از مقادیری که می‌توانید اندازه‌گیری کنید، فکر کنیم.</p>
<p>در شکل 1-4، هر میله خاکستری نشان‌دهنده یک درخواست به یک <strong>service</strong> است و ارتفاع آن نشان می‌دهد که آن درخواست چقدر طول کشیده است. اکثر درخواست‌ها نسبتاً سریع هستند، اما استثناهایی وجود دارد که زمان بیشتری می‌برند. شاید درخواست‌های کندتر ذاتا گران‌تر باشند، به‌عنوان‌مثال، زیرا آن‌ها <strong>data</strong> بیشتری را پردازش می‌کنند. اما حتی در سناریویی که فکر می‌کنید همه درخواست‌ها باید زمان یکسانی را ببرند، تنوعی وجود دارد: تأخیر اضافی تصادفی می‌تواند با یک <strong>context switch</strong> به یک فرآیند پس‌زمینه، از دست رفتن یک بسته شبکه و انتقال مجدد <strong>TCP</strong>، مکث جمع‌آوری <strong>garbage</strong>، یک خطای صفحه که خواندن از دیسک را مجبور می‌کند، ارتعاشات مکانیکی در قفسه سرور [18] یا بسیاری از علل دیگر ایجاد شود.</p>
<p>شکل 1-4. نشان دادن میانگین و <strong>percentiles</strong>: زمان پاسخ برای نمونه‌ای از 100 درخواست به یک <strong>service</strong>.</p>
<p>معمول است که <strong>average response time</strong> یک <strong>service</strong> گزارش شود. (دقیقاً، اصطلاح "میانگین" به هیچ فرمول خاصی اشاره ندارد، اما در عمل معمولاً به‌عنوان میانگین حسابی درک می‌شود: با توجه به <strong>n</strong> مقدار، تمام مقادیر را جمع کنید و بر <strong>n</strong> تقسیم کنید.) با این حال، اگر می‌خواهید <strong>response time</strong> "معمول" خود را بدانید، میانگین یک معیار خیلی خوب نیست، زیرا به شما نمی‌گوید که چند کاربر در واقع آن تأخیر را تجربه کرده‌اند.</p>
<p>معمولاً بهتر است از <strong>percentiles</strong> استفاده کنید. اگر لیست <strong>response time</strong> خود را بگیرید و آن را از سریع‌ترین تا کندترین مرتب کنید، سپس میانه نقطه میانی است: به‌عنوان‌مثال، اگر شما</p>
<p>14 | Chapter 1: Reliable, Scalable, and Maintainable Applications</p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 36" src="page_0036/image_1.png"/></div>
<div class="page-image"><img alt="Image from page 36" src="page_0036/image_2.png"/></div>
</div>
                <div class="page-number">صفحه 0036</div>
            </div>
        </div>
        <!-- Page 0037 -->
        <div class="chapter" id="page-0037">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p><strong>median response time</strong>، 200 میلی‌ثانیه است، به این معنی که نیمی از درخواست‌های شما در کمتر از 200 میلی‌ثانیه و نیمی از درخواست‌های شما بیشتر از آن طول می‌کشد.</p>
<p>اگر می‌خواهید بدانید که کاربران معمولاً چقدر باید منتظر بمانند، این باعث می‌شود که میانگین یک معیار خوب باشد: نیمی از درخواست‌های کاربر در کمتر از <strong>median response time</strong> ارائه می‌شوند، و نیم دیگر بیشتر از میانگین زمان می‌برند. میانه به‌عنوان <strong>50th percentile</strong> نیز شناخته می‌شود، و گاهی اوقات به‌صورت <strong>p50</strong> خلاصه می‌شود. توجه داشته باشید که میانه به یک درخواست واحد اشاره دارد؛ اگر کاربر چندین درخواست را انجام دهد (در طول یک جلسه، یا به دلیل اینکه چندین منبع در یک صفحه واحد گنجانده شده‌اند)، احتمال این‌که حداقل یکی از آن‌ها کندتر از میانه باشد، بسیار بیشتر از 50٪ است.</p>
<p>به منظور اطلاع از میزان بد بودن <strong>outliers</strong> خود، می‌توانید به <strong>percentiles</strong> بالاتر نگاه کنید: <strong>95th</strong>، <strong>99th</strong> و <strong>99.9th percentiles</strong> رایج هستند (به‌اختصار <strong>p95</strong>، <strong>p99</strong> و <strong>p999</strong>). آن‌ها آستانه‌های زمان پاسخ هستند که در آن‌ها 95٪، 99٪ یا 99.9٪ از درخواست‌ها سریع‌تر از آن آستانه خاص هستند. به‌عنوان‌مثال، اگر زمان پاسخ <strong>95th percentile</strong> 1.5 ثانیه باشد، به این معنی است که 95 درخواست از 100 درخواست کمتر از 1.5 ثانیه طول می‌کشد، و 5 درخواست از 100 درخواست 1.5 ثانیه یا بیشتر طول می‌کشد. این در شکل 1-4 نشان داده شده است.</p>
<p><strong>Percentiles</strong> بالای زمان پاسخ، که به‌عنوان <strong>tail latencies</strong> نیز شناخته می‌شوند، مهم هستند زیرا مستقیماً بر تجربه کاربران از <strong>service</strong> تأثیر می‌گذارند. به‌عنوان‌مثال، <strong>Amazon</strong> الزامات زمان پاسخ را برای <strong>services</strong> داخلی از نظر <strong>99.9th percentile</strong> توصیف می‌کند، حتی اگر فقط 1 در 1000 درخواست را تحت تأثیر قرار دهد. این به این دلیل است که مشتریانی که کندترین درخواست‌ها را دارند، اغلب کسانی هستند که بیشترین <strong>data</strong> را در حساب‌های خود دارند، زیرا آن‌ها خریدهای زیادی انجام داده‌اند—به این معنی که آن‌ها ارزشمندترین مشتریان هستند [19]. مهم است که آن مشتریان را با اطمینان از سریع بودن وب‌سایت برای آن‌ها خوشحال نگه دارید: <strong>Amazon</strong> همچنین مشاهده کرده است که افزایش 100 میلی‌ثانیه‌ای در <strong>response time</strong>، فروش را 1٪ کاهش می‌دهد [20]، و دیگران گزارش می‌دهند که کاهش سرعت 1 ثانیه‌ای، یک معیار رضایت مشتری را 16٪ کاهش می‌دهد [21، 22].</p>
<p>از سوی دیگر، بهینه‌سازی <strong>99.99th percentile</strong> (کندترین 1 در 10000 درخواست) برای اهداف <strong>Amazon</strong> بسیار گران و بی‌فایده تلقی شد. کاهش زمان پاسخ در <strong>percentiles</strong> بسیار بالا دشوار است زیرا آن‌ها به‌راحتی تحت تأثیر رویدادهای تصادفی خارج از کنترل شما قرار می‌گیرند و مزایا در حال کاهش هستند.</p>
<p>به‌عنوان‌مثال، <strong>percentiles</strong> اغلب در <strong>service level objectives (SLOs)</strong> و <strong>service level agreements (SLAs)</strong> استفاده می‌شوند، قراردادهایی که عملکرد و در دسترس بودن مورد انتظار یک <strong>service</strong> را تعریف می‌کنند. یک <strong>SLA</strong> ممکن است بیان کند که اگر <strong>service</strong> دارای <strong>median response time</strong> کمتر از 200 میلی‌ثانیه و <strong>99th percentile</strong> زیر 1 ثانیه باشد، <strong>service</strong> در نظر گرفته می‌شود (اگر <strong>response time</strong> طولانی‌تر باشد، ممکن است از کار بیفتد)، و ممکن است از <strong>service</strong> خواسته شود که حداقل 99.9٪ از زمان را فعال باشد. این معیارها انتظارات را برای <strong>clients</strong> <strong>service</strong> تعیین می‌کنند و به مشتریان اجازه می‌دهند در صورت عدم رعایت <strong>SLA</strong>، درخواست بازپرداخت کنند.</p>
<p>تاخیرهای <strong>Queueing</strong> اغلب بخش بزرگی از <strong>response time</strong> را در <strong>percentiles</strong> بالا تشکیل می‌دهند. ازآنجایی‌که یک سرور می‌تواند تنها تعداد کمی از موارد را به‌طور موازی پردازش کند (محدود، برای
   Scalability | 15</p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0037</div>
            </div>
        </div>
        <!-- Page 0038 -->
        <div class="chapter" id="page-0038">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>به‌عنوان‌مثال، با تعداد هسته‌های <strong>CPU</strong> آن)، تنها تعداد کمی از درخواست‌های کند طول می‌کشد تا پردازش درخواست‌های بعدی را متوقف کنند—اثری که گاهی اوقات به‌عنوان مسدود کردن <strong>head-of-line</strong> شناخته می‌شود. حتی اگر پردازش آن درخواست‌های بعدی روی سرور سریع باشد، <strong>client</strong> زمان پاسخ کلی کندی را به دلیل زمان انتظار برای تکمیل درخواست قبلی مشاهده خواهد کرد. به دلیل این اثر، اندازه‌گیری زمان پاسخ در سمت <strong>client</strong> مهم است.</p>
<p>هنگام تولید مصنوعی <strong>load</strong> به‌منظور آزمایش مقیاس‌پذیری یک سیستم، <strong>client</strong> تولیدکننده <strong>load</strong> باید به‌طور مستقل از زمان پاسخ، درخواست‌ها را ارسال کند. اگر <strong>client</strong> قبل از ارسال درخواست بعدی، منتظر تکمیل درخواست قبلی بماند، این رفتار اثر دارد که صف‌ها را در آزمایش به‌طور مصنوعی کوتاه‌تر از واقعیت نگه می‌دارد، که اندازه‌گیری‌ها را منحرف می‌کند [23].</p>
<h4>Percentiles in Practice</h4>
<p><strong>Percentiles</strong> بالا به‌ویژه در سرویس‌های <strong>backend</strong> که چندین بار به‌عنوان بخشی از ارائه یک درخواست <strong>end-user</strong> واحد فراخوانی می‌شوند، اهمیت پیدا می‌کنند. حتی اگر تماس‌ها را به‌صورت موازی انجام دهید، درخواست <strong>end-user</strong> هنوز باید منتظر بماند تا کندترین تماس‌های موازی تکمیل شود. فقط یک تماس کند طول می‌کشد تا کل درخواست <strong>end-user</strong> کند شود، همان‌طور که در شکل 1-5 نشان داده شده است. حتی اگر تنها درصد کمی از تماس‌های <strong>backend</strong> کند باشند، اگر یک درخواست <strong>end-user</strong> به چندین تماس <strong>backend</strong> نیاز داشته باشد، احتمال دریافت یک تماس کند افزایش می‌یابد، و بنابراین نسبت بیشتری از درخواست‌های <strong>end-user</strong> در نهایت کند می‌شوند (اثری که به‌عنوان <strong>tail latency amplification</strong> شناخته می‌شود [24]).</p>
<p>اگر می‌خواهید <strong>percentiles</strong> زمان پاسخ را به داشبوردهای نظارت <strong>services</strong> خود اضافه کنید، باید آن‌ها را به‌طور مداوم به‌طور مؤثر محاسبه کنید. به‌عنوان‌مثال، ممکن است بخواهید یک پنجره چرخشی از زمان‌های پاسخ درخواست‌ها را در 10 دقیقه گذشته نگه دارید. هر دقیقه، میانه و <strong>percentiles</strong> مختلف را در مقادیر موجود در آن پنجره محاسبه می‌کنید و آن متریک‌ها را روی یک نمودار ترسیم می‌کنید.</p>
<p>پیاده‌سازی ساده این است که لیستی از زمان‌های پاسخ را برای همه درخواست‌ها در پنجره زمانی نگه دارید و آن لیست را هر دقیقه مرتب کنید. اگر این برای شما خیلی ناکارآمد است، الگوریتم‌هایی وجود دارند که می‌توانند یک تقریب خوب از <strong>percentiles</strong> را با حداقل هزینه <strong>CPU</strong> و حافظه محاسبه کنند، مانند <strong>forward decay</strong> [25]، <strong>t-digest</strong> [26] یا <strong>HdrHistogram</strong> [27]. مراقب باشید که میانگین‌گیری <strong>percentiles</strong>، به‌عنوان‌مثال، برای کاهش وضوح زمان یا ترکیب <strong>data</strong> از چندین دستگاه، از نظر ریاضی بی‌معنی است—روش درست برای جمع‌آوری <strong>data</strong> زمان پاسخ، افزودن هیستوگرام‌ها است [28].</p>
<p>16 | Chapter 1: Reliable, Scalable, and Maintainable Applications</p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0038</div>
            </div>
        </div>
        <!-- Page 0039 -->
        <div class="chapter" id="page-0039">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>شکل 1-5. هنگامی‌که برای ارائه یک درخواست به چندین تماس <strong>backend</strong> نیاز است، تنها یک درخواست <strong>backend</strong> کند طول می‌کشد تا کل درخواست <strong>end-user</strong> را کند کند.</p>
<h4>Approaches for Coping with Load</h4>
<p>اکنون که در مورد پارامترهای توصیف <strong>load</strong> و متریک‌های اندازه‌گیری عملکرد بحث کردیم، می‌توانیم با جدیت در مورد <strong>scalability</strong> بحث کنیم: چگونه عملکرد خوب را حتی زمانی که پارامترهای <strong>load</strong> ما تا حدودی افزایش می‌یابد، حفظ کنیم؟</p>
<p>یک <strong>architecture</strong> که برای یک سطح از <strong>load</strong> مناسب است، بعید است که با 10 برابر آن <strong>load</strong> مقابله کند. اگر روی یک <strong>service</strong> با رشد سریع کار می‌کنید، بنابراین احتمالاً در هر مرتبه بزرگی از افزایش <strong>load</strong> نیاز به تجدیدنظر در <strong>architecture</strong> خود خواهید داشت—یا شاید حتی بیشتر از آن.</p>
<p>مردم اغلب از یک دوگانگی بین <strong>scaling up</strong> (<strong>vertical scaling</strong>، انتقال به یک ماشین قدرتمندتر) و <strong>scaling out</strong> (<strong>horizontal scaling</strong>، توزیع <strong>load</strong> در چندین ماشین کوچک‌تر) صحبت می‌کنند. توزیع <strong>load</strong> در چندین ماشین نیز به‌عنوان <strong>shared-nothing architecture</strong> شناخته می‌شود. یک سیستم که می‌تواند روی یک ماشین واحد اجرا شود، اغلب ساده‌تر است، اما ماشین‌های <strong>high-end</strong> می‌توانند بسیار گران‌قیمت شوند، بنابراین بارهای کاری بسیار فشرده اغلب نمی‌توانند از <strong>scaling out</strong> اجتناب کنند. درواقعیت، <strong>architectures</strong> خوب معمولاً شامل ترکیبی عمل‌گرایانه از رویکردها هستند: به‌عنوان‌مثال، استفاده از چندین ماشین نسبتاً قدرتمند هنوز هم می‌تواند ساده‌تر و ارزان‌تر از تعداد زیادی ماشین مجازی کوچک باشد.</p>
<p>برخی از سیستم‌ها <strong>elastic</strong> هستند، به این معنی که آن‌ها می‌توانند به‌طور خودکار منابع محاسباتی را در صورت تشخیص افزایش <strong>load</strong> اضافه کنند، درحالی‌که سایر سیستم‌ها به‌صورت دستی مقیاس‌بندی می‌شوند (یک انسان ظرفیت را تجزیه‌وتحلیل می‌کند و تصمیم می‌گیرد ماشین‌های بیشتری به سیستم اضافه کند). یک سیستم <strong>elastic</strong> می‌تواند مفید باشد اگر <strong>load</strong> بسیار غیرقابل‌پیش‌بینی باشد، اما سیستم‌های مقیاس‌شده به‌صورت دستی ساده‌تر هستند و ممکن است غافلگیری‌های عملیاتی کمتری داشته باشند (به "<strong>Rebalancing Partitions</strong>" در صفحه 209 مراجعه کنید).</p>
<p>Scalability | 17</p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 39" src="page_0039/image_1.png"/></div>
</div>
                <div class="page-number">صفحه 0039</div>
            </div>
        </div>
        <!-- Page 0040 -->
        <div class="chapter" id="page-0040">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>در حالی که توزیع <strong>stateless services</strong> در ماشین‌های متعدد نسبتاً ساده است، انتقال سیستم‌های <strong>data</strong> <strong>stateful</strong> از یک گره واحد به یک راه‌اندازی توزیع‌شده می‌تواند پیچیدگی‌های زیادی را به همراه داشته باشد. به همین دلیل، خرد متعارف تا همین اواخر این بود که <strong>database</strong> خود را روی یک گره واحد نگه دارید (<strong>scale up</strong>) تا زمانی که هزینه مقیاس‌بندی یا الزامات <strong>high-availability</strong> شما را مجبور به توزیع آن کند.</p>
<p>با بهتر شدن ابزارها و انتزاع‌ها برای سیستم‌های توزیع‌شده، این خرد متعارف ممکن است تغییر کند، حداقل برای برخی از انواع <strong>applications</strong>. قابل تصور است که سیستم‌های <strong>data</strong> توزیع‌شده در آینده، حتی برای مواردی که حجم زیادی از <strong>data</strong> یا ترافیک را مدیریت نمی‌کنند، به حالت پیش‌فرض تبدیل می‌شوند. در طول بقیه این کتاب، ما انواع مختلفی از سیستم‌های <strong>data</strong> توزیع‌شده را پوشش خواهیم داد و بحث خواهیم کرد که چگونه آن‌ها نه تنها از نظر مقیاس‌پذیری، بلکه از نظر سهولت استفاده و قابلیت نگهداری نیز عمل می‌کنند.</p>
<p><strong>architecture</strong> سیستم‌هایی که در مقیاس بزرگ کار می‌کنند، معمولاً بسیار خاص <strong>application</strong> هستند—چیزی به‌عنوان یک <strong>architecture</strong> مقیاس‌پذیر عمومی و همه‌کاره وجود ندارد (که به‌طور غیررسمی به‌عنوان سس مقیاس‌بندی جادویی شناخته می‌شود). ممکن است مشکل حجم خواندن، حجم نوشتن، حجم <strong>data</strong> برای ذخیره، پیچیدگی <strong>data</strong>، الزامات زمان پاسخ، الگوهای دسترسی، یا (معمولاً) ترکیبی از همه این‌ها به‌علاوه بسیاری از مسائل دیگر باشد.</p>
<p>به‌عنوان‌مثال، سیستمی که برای مدیریت 100000 درخواست در ثانیه، هرکدام به اندازه 1 کیلوبایت طراحی شده است، با سیستمی که برای 3 درخواست در دقیقه، هرکدام به اندازه 2 گیگابایت طراحی شده است، بسیار متفاوت است—حتی اگر دو سیستم دارای <strong>throughput</strong> یکسان باشند.</p>
<p>یک <strong>architecture</strong> که برای یک <strong>application</strong> خاص به‌خوبی مقیاس می‌شود، بر اساس فرضیات عملیاتی که رایج خواهند بود و کدام یک نادر خواهد بود—<strong>load parameters</strong>—ساخته شده است. اگر آن فرضیات اشتباه از آب درآیند، تلاش مهندسی برای مقیاس‌بندی در بهترین حالت هدر می‌رود و در بدترین حالت نتیجه معکوس دارد. در یک راه‌اندازی اولیه یا یک محصول اثبات نشده، معمولاً مهم‌تر است که بتوانید به‌سرعت روی ویژگی‌های محصول تکرار کنید تا این‌که مقیاس‌پذیری را به یک <strong>load</strong> فرضی در آینده برسانید.</p>
<p>اگرچه آن‌ها خاص یک <strong>application</strong> خاص هستند، با این وجود <strong>architectures</strong> مقیاس‌پذیر معمولاً از <strong>building blocks</strong> با هدف عمومی ساخته شده‌اند که در الگوهای آشنا مرتب شده‌اند. در این کتاب ما در مورد آن <strong>building blocks</strong> و الگوها بحث می‌کنیم.</p>
<h4>Maintainability</h4>
<p>به خوبی شناخته شده است که اکثر هزینه <strong>software</strong>، نه در توسعه اولیه آن، بلکه در نگهداری مداوم آن است—رفع باگ‌ها، عملیاتی نگه داشتن سیستم‌های آن، بررسی <strong>failures</strong>، انطباق آن با پلتفرم‌های جدید، اصلاح آن برای موارد استفاده جدید، بازپرداخت بدهی فنی و افزودن ویژگی‌های جدید.</p>
<p>با این حال، متأسفانه، بسیاری از افرادی که روی سیستم‌های <strong>software</strong> کار می‌کنند از نگهداری از سیستم‌های به اصطلاح قدیمی خوششان نمی‌آید—شاید شامل رفع اشتباهات دیگران باشد، یا کار</p>
<p>18 | Chapter 1: Reliable, Scalable, and Maintainable Applications</p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0040</div>
            </div>
        </div>
        <!-- Page 0041 -->
        <div class="chapter" id="page-0041">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>بامشکلات کار کردن با پلتفرم‌هایی که اکنون منسوخ شده‌اند، یا سیستم‌هایی که مجبور به انجام کارهایی شده‌اند که هرگز برای آن‌ها در نظر گرفته نشده‌اند. هر سیستم قدیمی به روش خاص خود ناخوشایند است، بنابراین ارائه توصیه‌های کلی برای برخورد با آن‌ها دشوار است.</p>
<p>با این حال، ما می‌توانیم و باید <strong>software</strong> را به گونه‌ای طراحی کنیم که امیدواریم درد را در طول نگهداری به حداقل برساند و درنتیجه از ایجاد <strong>software</strong> قدیمی خودداری کنیم. برای این منظور، ما به سه اصل طراحی برای سیستم‌های <strong>software</strong> توجه ویژه‌ای خواهیم داشت:</p>
<h4>Operability</h4>
<p>برای تیم‌های عملیاتی آسان کنید تا سیستم را به‌آرامی اجرا کنند.</p>
<h4>Simplicity</h4>
<p>برای مهندسان جدید آسان کنید تا سیستم را درک کنند، با حذف هر چه بیشتر پیچیدگی از سیستم. (توجه داشته باشید این همان سادگی رابط کاربری نیست.)</p>
<h4>Evolvability</h4>
<p>برای مهندسان آسان کنید تا تغییراتی را در سیستم در آینده ایجاد کنند، و آن را با موارد استفاده غیرمنتظره با تغییر الزامات تطبیق دهند. همچنین به‌عنوان توسعه‌پذیری، قابلیت اصلاح یا انعطاف‌پذیری شناخته می‌شود.</p>
<p>همان‌طور که قبلاً با <strong>reliability</strong> و <strong>scalability</strong> ذکر شد، هیچ راه‌حل آسانی برای دستیابی به این اهداف وجود ندارد. در عوض، ما سعی خواهیم کرد با در نظر گرفتن <strong>operability</strong>، <strong>simplicity</strong> و <strong>evolvability</strong> در مورد سیستم‌ها فکر کنیم.</p>
<h4>Operability: Making Life Easy for Operations</h4>
<p>پیشنهاد شده است که "عملیات خوب اغلب می‌تواند محدودیت‌های <strong>software</strong> بد (یا ناقص) را دور بزند، اما <strong>software</strong> خوب نمی‌تواند به‌طور قابل‌اعتماد با عملیات بد اجرا شود" [12]. درحالی‌که برخی از جنبه‌های عملیات را می‌توان و باید خودکار کرد، این همچنان بر عهده انسان‌هاست که در وهله اول آن اتوماسیون را راه‌اندازی کنند و اطمینان حاصل کنند که به‌درستی کار می‌کند.</p>
<p>تیم‌های عملیاتی برای حفظ عملکرد روان یک سیستم <strong>software</strong> حیاتی هستند. یک تیم عملیاتی خوب معمولاً مسئول موارد زیر و موارد دیگر است [29]:</p>
<ul>
<li>نظارت بر سلامت سیستم و بازیابی سریع <strong>service</strong> در صورت ورود به حالت بد</li>
<li>ردیابی علت مشکلات، مانند <strong>system failures</strong> یا عملکرد ضعیف شده</li>
<li>به‌روز نگه‌داشتن <strong>software</strong> و پلتفرم‌ها، از جمله وصله‌های امنیتی</li>
<li>زیر نظر گرفتن چگونگی تأثیر سیستم‌های مختلف بر یکدیگر، به‌طوری‌که از یک تغییر مشکل‌ساز قبل از ایجاد خسارت می‌توان اجتناب کرد</li>
</ul>
<p>Maintainability | 19</p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0041</div>
            </div>
        </div>
        <!-- Page 0042 -->
        <div class="chapter" id="page-0042">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<h3>پیش‌بینی مشکلات آینده و حل آن‌ها</h3>
<p>
        •  Anticipating future problems and solving them before they occur (به عنوان مثال، capacity planning)
    </p>
<p>
        •  Establishing good practices and tools for deployment, configuration manage‐ment, and more
    </p>
<p>
        •  Performing complex maintenance tasks, such as moving an application from one platform to another
    </p>
<p>
        •  Maintaining the security of the system as configuration changes are made
    </p>
<p>
        •  Defining processes that make operations predictable and help keep the production environment stable
    </p>
<p>
        •  Preserving the organization’s knowledge about the system, even as individual people come and go
    </p>
<p>
<em>عملکرد خوب</em> به معنای آسان کردن کارهای روتین است، که به تیم عملیات اجازه می‌دهد تا تلاش‌های خود را بر روی فعالیت‌های با ارزش بالا متمرکز کنند. سیستم‌های داده می‌توانند کارهای مختلفی را برای آسان کردن کارهای روتین انجام دهند، از جمله:
    </p>
<p>
        • Providing visibility into the runtime behavior and internals of the system, with good monitoring
    </p>
<p>
        •  Providing good support for automation and integration with standard tools
    </p>
<p>
        •  Avoiding dependency on individual machines (allowing machines to be taken down for maintenance while the system as a whole continues running uninter‐rupted)
    </p>
<p>
        •  Providing good documentation and an easy-to-understand operational model (“If I do X, Y will happen”)
    </p>
<p>
        •  Providing good default behavior, but also giving administrators the freedom to override defaults when needed
    </p>
<p>
        •  Self-healing where appropriate, but also giving administrators manual control over the system state when needed
    </p>
<p>
        •  Exhibiting predictable behavior, minimizing surprises
    </p>
<h4>سادگی: مدیریت پیچیدگی</h4>
<p>
        پروژه‌های نرم‌افزاری کوچک می‌توانند کد <strong>بسیار ساده و گویا</strong> داشته باشند، اما با بزرگتر شدن پروژه‌ها، اغلب بسیار پیچیده و دشوار می‌شوند. این پیچیدگی سرعت همه کسانی را که نیاز به کار بر روی سیستم دارند، کاهش می‌دهد و باعث افزایش هزینه‌های نگهداری می‌شود. یک پروژه نرم‌افزاری که در پیچیدگی غرق شده است، گاهی اوقات به عنوان یک big ball of mud [30] توصیف می‌شود.
    </p>
<p>
        20 | Chapter 1: Reliable, Scalable, and Maintainable Applications
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0042</div>
            </div>
        </div>
        <!-- Page 0043 -->
        <div class="chapter" id="page-0043">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<h3>علائم پیچیدگی</h3>
<p>
        متغیرهای مختلفی از علائم پیچیدگی وجود دارد: انفجار فضای حالت، coupling تنگاتنگ ماژول‌ها، وابستگی‌های درهم‌تنیده، نام‌گذاری و اصطلاحات ناسازگار، hacks با هدف حل مشکلات performance، special-casing برای دور زدن issues در جای دیگر، و موارد بسیار دیگر. در این مورد مطالب زیادی گفته شده است [31, 32, 33].
    </p>
<p>
        هنگامی که پیچیدگی، maintenance را دشوار می‌کند، بودجه‌ها و برنامه‌ها اغلب over‐run می‌شوند. در نرم‌افزار پیچیده، خطر بیشتری برای معرفی bugs هنگام ایجاد تغییر وجود دارد: هنگامی که درک و استدلال سیستم برای developers سخت‌تر می‌شود، فرض‌های پنهان، عواقب ناخواسته، و تعاملات غیرمنتظره، راحت‌تر نادیده گرفته می‌شوند. برعکس، کاهش پیچیدگی به شدت قابلیت maintenance نرم‌افزار را بهبود می‌بخشد و بنابراین سادگی باید یک هدف کلیدی برای سیستم‌هایی باشد که ما می‌سازیم.
    </p>
<p>
        ساده‌تر کردن یک سیستم لزوماً به معنای کاهش عملکرد آن نیست؛ همچنین می‌تواند به معنای حذف پیچیدگی تصادفی باشد. Moseley و Marks [32] پیچیدگی را accidental تعریف می‌کنند اگر ذاتی در مشکلی که نرم‌افزار حل می‌کند (همانطور که توسط کاربران دیده می‌شود) نباشد، اما فقط از پیاده‌سازی ناشی شود.
    </p>
<p>
        یکی از بهترین ابزارهایی که برای حذف پیچیدگی accidental در اختیار داریم، abstraction است. یک abstraction خوب می‌تواند مقدار زیادی از جزئیات پیاده‌سازی را پشت یک façade تمیز و ساده برای درک پنهان کند. یک abstraction خوب همچنین می‌تواند برای طیف گسترده‌ای از applications مختلف استفاده شود. نه تنها این reuse از reimplementing یک چیز مشابه چندین بار کارآمدتر است، بلکه منجر به نرم‌افزار با کیفیت بالاتری نیز می‌شود، زیرا پیشرفت‌های کیفیت در جزء abstraction شده، به همه applications که از آن استفاده می‌کنند، سود می‌رساند.
    </p>
<p>
        به عنوان مثال، زبان‌های برنامه‌نویسی high-level، abstractions هستند که machine code، CPU registers و syscalls را پنهان می‌کنند. SQL یک abstraction است که ساختارهای داده on-disk و in-memory پیچیده، درخواست‌های concurrent از سایر clients و inconsistencies پس از crashes را پنهان می‌کند. البته، هنگام برنامه‌نویسی در یک زبان high-level، ما همچنان از machine code استفاده می‌کنیم. ما فقط مستقیماً از آن استفاده نمی‌کنیم، زیرا abstraction زبان برنامه‌نویسی ما را از فکر کردن در مورد آن نجات می‌دهد.
    </p>
<p>
        با این حال، یافتن abstractions خوب بسیار دشوار است. در زمینه distributed systems، اگرچه الگوریتم‌های خوب زیادی وجود دارد، اما اینکه چگونه باید آن‌ها را در abstractions بسته‌بندی کنیم تا به ما کمک کند پیچیدگی سیستم را در یک سطح قابل مدیریت نگه داریم، بسیار کمتر مشخص است.
    </p>
<p>
        در سراسر این کتاب، ما چشمان خود را برای abstractions خوب باز نگه می‌داریم که به ما امکان می‌دهد بخش‌هایی از یک سیستم بزرگ را به components تعریف شده و قابل استفاده مجدد استخراج کنیم.
    </p>
<h4>Evolvability: آسان کردن تغییر</h4>
<p>
        بسیار بعید است که requirements سیستم شما برای همیشه بدون تغییر باقی بمانند. احتمال بیشتری وجود دارد که آن‌ها در نوسان مداوم باشند: شما حقایق جدیدی یاد می‌گیرید، use cases قبلاً پیش‌بینی نشده ظهور می‌کنند، اولویت‌های تجاری تغییر می‌کنند، users، new ها را درخواست می‌کنند.
    </p>
<p>
        Maintainability | 21
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0043</div>
            </div>
        </div>
        <!-- Page 0044 -->
        <div class="chapter" id="page-0044">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        features، پلتفرم‌های جدید جایگزین پلتفرم‌های قدیمی می‌شوند، الزامات قانونی یا نظارتی تغییر می‌کنند، رشد سیستم تغییرات معماری را اجباری می‌کند و غیره.
    </p>
<p>
        از نظر فرآیندهای سازمانی، الگوهای کاری Agile یک چارچوب برای انطباق با تغییر فراهم می‌کنند. جامعه Agile همچنین ابزارها و الگوهای فنی را توسعه داده است که هنگام developing نرم‌افزار در یک محیط frequently changing، مانند test-driven development (TDD) و refactoring، مفید هستند.
    </p>
<p>
        اکثر بحث‌ها در مورد این تکنیک‌های Agile بر یک مقیاس نسبتاً کوچک و محلی متمرکز هستند (چند فایل source code در داخل یک application). در این کتاب، ما به دنبال راه‌هایی برای افزایش agility در سطح یک data system بزرگتر هستیم، شاید شامل چندین application یا سرویس مختلف با ویژگی‌های متفاوت باشد. به عنوان مثال، چگونه معماری Twitter را برای مونتاژ home timelines ("Describing Load" در صفحه 11) از رویکرد 1 به رویکرد 2 "refactor" می‌کنید؟
    </p>
<p>
        سهولتی که با آن می‌توانید یک data system را اصلاح کنید و آن را با تغییر require‐ments وفق دهید، ارتباط نزدیکی با سادگی و abstractions آن دارد: سیستم‌های ساده و آسان برای درک معمولاً راحت‌تر از سیستم‌های پیچیده اصلاح می‌شوند. اما از آنجایی که این یک ایده بسیار مهم است، ما از یک کلمه متفاوت برای اشاره به agility در سطح data sys‐tem استفاده خواهیم کرد: evolvability [34].
    </p>
<h4>خلاصه</h4>
<p>
        در این فصل، ما برخی از راه‌های اساسی تفکر در مورد data-intensive applications را بررسی کرده‌ایم. این اصول ما را در بقیه کتاب راهنمایی می‌کند، جایی که به جزئیات عمیق فنی می‌پردازیم.
    </p>
<p>
        یک application باید الزامات مختلفی را برای مفید بودن برآورده کند. الزامات functional (آنچه باید انجام دهد، مانند اجازه دادن به ذخیره، بازیابی، جستجو و پردازش داده‌ها به روش‌های مختلف) و برخی از الزامات nonfunctional (ویژگی‌های کلی مانند security، reliability، compliance، scalability، compatibility و maintainability) وجود دارد. در این فصل ما reliability، scalability و maintainability را با جزئیات مورد بحث قرار دادیم.
    </p>
<p>
        Reliability به معنای درست کار کردن سیستم‌ها است، حتی زمانی که faults رخ می‌دهد. Faults می‌تواند در سخت‌افزار (به طور معمول تصادفی و غیر مرتبط)، نرم‌افزار (bugs معمولاً systematic هستند و مقابله با آن‌ها دشوار است) و انسان (که به ناچار اشتباه می‌کنند) باشد. تکنیک‌های fault-tolerance می‌توانند انواع خاصی از faults را از end user پنهان کنند.
    </p>
<p>
        Scalability به معنای داشتن استراتژی‌هایی برای خوب نگه داشتن performance است، حتی زمانی که load افزایش می‌یابد. برای بحث در مورد scalability، ابتدا باید راه‌هایی برای توصیف load و performance به صورت کمی داشته باشیم. ما به طور خلاصه به home timelines توییتر به عنوان مثالی از توصیف load و response time percentiles به عنوان راهی برای اندازه‌گیری per‐
    </p>
<p>
        22 | Chapter 1: Reliable, Scalable, and Maintainable Applications
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0044</div>
            </div>
        </div>
        <!-- Page 0045 -->
        <div class="chapter" id="page-0045">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        formance. در یک سیستم scalable، می‌توانید ظرفیت پردازش را اضافه کنید تا تحت high load، قابل اطمینان باقی بمانید.
    </p>
<p>
        Maintainability جنبه‌های زیادی دارد، اما در اصل در مورد بهتر کردن زندگی برای تیم‌های engineering و operations است که نیاز به کار با سیستم دارند. Abstractions خوب می‌تواند به کاهش پیچیدگی و آسان‌تر کردن سیستم برای اصلاح و انطباق با new use cases کمک کند. Good operability به معنای داشتن visibility خوب در سلامت سیستم و داشتن راه‌های موثر برای مدیریت آن است.
    </p>
<p>
        متأسفانه هیچ راه‌حل آسانی برای reliable، scalable یا maintainable کردن applications وجود ندارد. با این حال، الگوها و تکنیک‌های خاصی وجود دارد که در انواع مختلف applications دوباره ظاهر می‌شوند. در چند فصل آینده، ما به برخی از نمونه‌های data systems نگاهی می‌اندازیم و تجزیه و تحلیل می‌کنیم که چگونه به سمت این اهداف کار می‌کنند.
    </p>
<p>
        بعداً در کتاب، در قسمت III، ما به الگوهایی برای سیستم‌هایی نگاه خواهیم کرد که از چندین component که با هم کار می‌کنند، تشکیل شده‌اند، مانند آنچه در شکل 1-1 نشان داده شده است.
    </p>
<h4>References</h4>
<p>
        [1] Michael Stonebraker and Uğur Çetintemel: “‘One Size Fits All’: An Idea Whose Time Has Come and Gone,” at 21st International Conference on Data Engineering (ICDE), April 2005.
    </p>
<p>
        [2] Walter L. Heimerdinger and Charles B. Weinstock: “A Conceptual Framework for System Fault Tolerance,” Technical Report CMU/SEI-92-TR-033, Software Engi‐neering Institute, Carnegie Mellon University, October 1992.
    </p>
<p>
        [3] Ding Yuan, Yu Luo, Xin Zhuang, et al.: “Simple Testing Can Prevent Most Criti‐cal Failures: An Analysis of Production Failures in Distributed Data-Intensive Sys‐tems,” at 11th USENIX Symposium on Operating Systems Design and Implementation (OSDI), October 2014.
    </p>
<p>
        [4] Yury Izrailevsky and Ariel Tseitlin: “The Netflix Simian Army,” techblog.net‐flix.com, July 19, 2011.
    </p>
<p>
        [5] Daniel Ford, François Labelle, Florentina I. Popovici, et al.: “Availability in Glob‐ally Distributed Storage Systems,” at 9th USENIX Symposium on Operating Systems Design and Implementation (OSDI), October 2010.
    </p>
<p>
        [6] Brian Beach: “Hard Drive Reliability Update – Sep 2014,” backblaze.com, Septem‐ber 23, 2014.
    </p>
<p>
        [7] Laurie Voss: “AWS: The Good, the Bad and the Ugly,” blog.awe.sm, December 18, 2012.
    </p>
<p>
        Summary | 23
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0045</div>
            </div>
        </div>
        <!-- Page 0046 -->
        <div class="chapter" id="page-0046">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        [8] Haryadi S. Gunawi, Mingzhe Hao, Tanakorn Leesatapornwongsa, et al.: “What Bugs Live in the Cloud?,” at 5th ACM Symposium on Cloud Computing (SoCC), November 2014. doi:10.1145/2670979.2670986
    </p>
<p>
        [9] Nelson Minar: “Leap Second Crashes Half the Internet,” somebits.com, July 3, 2012.
    </p>
<p>
        [10] Amazon Web Services: “Summary of the Amazon EC2 and Amazon RDS Service Disruption in the US East Region,” aws.amazon.com, April 29, 2011.
    </p>
<p>
        [11] Richard I. Cook: “How Complex Systems Fail,” Cognitive Technologies Laboratory, April 2000.
    </p>
<p>
        [12] Jay Kreps: “Getting Real About Distributed System Reliability,” blog.empathy‐box.com, March 19, 2012.
    </p>
<p>
        [13] David Oppenheimer, Archana Ganapathi, and David A. Patterson: “Why Do Internet Services Fail, and What Can Be Done About It?,” at 4th USENIX Symposium on Internet Technologies and Systems (USITS), March 2003.
    </p>
<p>
        [14] Nathan Marz: “Principles of Software Engineering, Part 1,” nathanmarz.com, April 2, 2013.
    </p>
<p>
        [15] Michael Jurewitz: “The Human Impact of Bugs,” jury.me, March 15, 2013.
    </p>
<p>
        [16] Raffi Krikorian: “Timelines at Scale,” at QCon San Francisco, November 2012.
    </p>
<p>
        [17] Martin Fowler: Patterns of Enterprise Application Architecture. Addison Wesley, 2002. ISBN: 978-0-321-12742-6
    </p>
<p>
        [18] Kelly Sommers: “After all that run around, what caused 500ms disk latency even when we replaced physical server?” twitter.com, November 13, 2014.
    </p>
<p>
        [19] Giuseppe DeCandia, Deniz Hastorun, Madan Jampani, et al.: “Dynamo: Amazon’s Highly Available Key-Value Store,” at 21st ACM Symposium on Operating Sys‐tems Principles (SOSP), October 2007.
    </p>
<p>
        [20] Greg Linden: “Make Data Useful,” slides from presentation at Stanford Univer‐sity Data Mining class (CS345), December 2006.
    </p>
<p>
        [21] Tammy Everts: “The Real Cost of Slow Time vs Downtime,” webperformanceto‐day.com, November 12, 2014.
    </p>
<p>
        [22] Jake Brutlag: “Speed Matters for Google Web Search,” googleresearch.blog‐spot.co.uk, June 22, 2009.
    </p>
<p>
        [23] Tyler Treat: “Everything You Know About Latency Is Wrong,” bravenew‐geek.com, December 12, 2015.
    </p>
<p>
        24 | Chapter 1: Reliable, Scalable, and Maintainable Applications
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0046</div>
            </div>
        </div>
        <!-- Page 0047 -->
        <div class="chapter" id="page-0047">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        [24] Jeffrey Dean and Luiz André Barroso: “The Tail at Scale,” Communications of the ACM, volume 56, number 2, pages 74–80, February 2013. doi:10.1145/2408776.2408794
    </p>
<p>
        [25] Graham Cormode, Vladislav Shkapenyuk, Divesh Srivastava, and Bojian Xu: “Forward Decay: A Practical Time Decay Model for Streaming Systems,” at 25th IEEE International Conference on Data Engineering (ICDE), March 2009.
    </p>
<p>
        [26] Ted Dunning and Otmar Ertl: “Computing Extremely Accurate Quantiles Using t-Digests,” github.com, March 2014.
    </p>
<p>
        [27] Gil Tene: “HdrHistogram,” hdrhistogram.org.
    </p>
<p>
        [28] Baron Schwartz: “Why Percentiles Don’t Work the Way You Think,” vividcor‐tex.com, December 7, 2015.
    </p>
<p>
        [29] James Hamilton: “On Designing and Deploying Internet-Scale Services,” at 21st Large Installation System Administration Conference (LISA), November 2007.
    </p>
<p>
        [30] Brian Foote and Joseph Yoder: “Big Ball of Mud,” at 4th Conference on Pattern Languages of Programs (PLoP), September 1997.
    </p>
<p>
        [31] Frederick P Brooks: “No Silver Bullet – Essence and Accident in Software Engi‐neering,” in The Mythical Man-Month, Anniversary edition, Addison-Wesley, 1995. ISBN: 978-0-201-83595-3
    </p>
<p>
        [32] Ben Moseley and Peter Marks: “Out of the Tar Pit,” at BCS Software Practice Advancement (SPA), 2006.
    </p>
<p>
        [33] Rich Hickey: “Simple Made Easy,” at Strange Loop, September 2011.
    </p>
<p>
        [34] Hongyu Pei Breivold, Ivica Crnkovic, and Peter J. Eriksson: “Analyzing Software Evolvability,” at 32nd Annual IEEE International Computer Software and Applica‐tions Conference (COMPSAC), July 2008. doi:10.1109/COMPSAC.2008.50
    </p>
<p>
        Summary | 25
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0047</div>
            </div>
        </div>
        <!-- Page 0049 -->
        <div class="chapter" id="page-0049">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<h3>فصل 2</h3>
<h4>Data Models و Query Languages</h4>
<p>
        The limits of my language mean the limits of my world.
        —Ludwig Wittgenstein, Tractatus Logico-Philosophicus (1922)
    </p>
<p>
        Data models شاید مهم‌ترین بخش در توسعه software باشند، زیرا آن‌ها چنین تأثیر عمیقی دارند: نه تنها بر نحوه نوشته شدن software، بلکه بر نحوه تفکر ما در مورد مشکلی که در حال حل آن هستیم.
    </p>
<p>
        اکثر applications با layering یک data model بر روی دیگری ساخته می‌شوند. برای هر layer، سوال کلیدی این است: چگونه در terms of لایه بعدی پایین‌تر نشان داده می‌شود؟ به عنوان مثال:
    </p>
<p>
        1.  به عنوان یک developer application، شما به دنیای واقعی نگاه می‌کنید (که در آن افراد، سازمان‌ها، کالاها، اقدامات، جریان‌های پولی، سنسورها و غیره وجود دارد) و آن را در terms of objects یا data structures و APIs که آن data structures را دستکاری می‌کنند، مدل‌سازی می‌کنید. آن structures اغلب مختص application شما هستند.
    </p>
<p>
        2.  هنگامی که می‌خواهید آن data structures را ذخیره کنید، آن‌ها را در terms of یک data model general-purpose، مانند JSON یا XML documents، جداول در یک relational database یا یک graph model، بیان می‌کنید.
    </p>
<p>
        3.  مهندسانی که software database شما را ساخته‌اند، در مورد یک راه برای نشان دادن آن data JSON/XML/relational/graph در terms of bytes in memory، on disk یا on a network تصمیم گرفتند. این نمایش ممکن است به داده‌ها اجازه دهد تا به روش‌های مختلف query، searched، manipulated و processed شوند.
    </p>
<p>
        4.  در سطوح پایین‌تر، مهندسان سخت‌افزار چگونگی نمایش bytes را در terms of electrical currents، pulses of light، magnetic fields و موارد دیگر مشخص کرده‌اند.
    </p>
<p>
        در یک application پیچیده ممکن است سطوح واسطه‌ای بیشتری وجود داشته باشد، مانند APIs که بر روی APIs ساخته شده‌اند، اما ایده اساسی هنوز یکسان است: هر layer پیچیدگی layers زیر خود را با ارائه یک data model تمیز پنهان می‌کند. این abstractions به شما اجازه می‌دهد.
    </p>
<p>
        27
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0049</div>
            </div>
        </div>
        <!-- Page 0050 -->
        <div class="chapter" id="page-0050">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        groups of people—به عنوان مثال، مهندسان vendor database و developers application که از database آن‌ها استفاده می‌کنند—برای کار موثر با هم.
    </p>
<p>
        انواع مختلفی از data models وجود دارد و هر data model فرضیاتی را در مورد نحوه استفاده از آن در بر می‌گیرد. برخی از انواع usage آسان هستند و برخی پشتیبانی نمی‌شوند. برخی از operations سریع هستند و برخی عملکرد بدی دارند. برخی از data transformations طبیعی هستند و برخی دیگر ناخوشایند.
    </p>
<p>
        به‌دست آوردن تسلط بر یک data model (فکر کنید چند کتاب در مورد relational data modeling وجود دارد) می‌تواند تلاش زیادی بطلبد. ساختن software به اندازه کافی سخت است، حتی زمانی که با یک data model کار می‌کنید و نگران عملکردهای داخلی آن نیستید. اما از آنجایی که data model چنین تأثیر عمیقی بر آنچه software بالای آن می‌تواند انجام دهد و نمی‌تواند انجام دهد، دارد، انتخاب موردی که برای application مناسب باشد، مهم است.
    </p>
<p>
        در این فصل ما به طیف وسیعی از data models general-purpose برای data storage و querying (نقطه 2 در لیست قبلی) نگاه خواهیم کرد. به طور خاص، ما relational model، document model و چند data models مبتنی بر graph را مقایسه خواهیم کرد. ما همچنین به زبان‌های query مختلف نگاهی خواهیم داشت و use cases آن‌ها را مقایسه خواهیم کرد. در فصل 3 ما در مورد نحوه عملکرد storage engines بحث خواهیم کرد. یعنی نحوه پیاده‌سازی واقعی این data models (نقطه 3 در لیست).
    </p>
<h4>Relational Model Versus Document Model</h4>
<p>
        شناخته‌شده‌ترین data model امروزی احتمالاً مربوط به SQL است که بر اساس relational model است که توسط Edgar Codd در سال 1970 [1] پیشنهاد شده است: داده‌ها به relations (که در SQL tables نامیده می‌شوند) سازمان‌دهی می‌شوند، جایی که هر relation یک collection نامرتب از tuples (rows در SQL) است.
    </p>
<p>
        Relational model یک proposal تئوری بود و بسیاری از مردم در آن زمان شک داشتند که آیا می‌توان آن را به طور موثر پیاده‌سازی کرد یا خیر. با این حال، تا اواسط دهه 1980، relational database management systems (RDBMSes) و SQL به ابزارهای انتخابی برای اکثر افرادی تبدیل شده بودند که نیاز به ذخیره و query داده‌ها با نوعی ساختار منظم داشتند. تسلط relational databases حدود 25 تا 30 سال به طول انجامیده است - یک ابدیت در تاریخ computing.
    </p>
<p>
        ریشه‌های relational databases در پردازش داده‌های کسب‌وکار نهفته است که در دهه‌های 1960 و 70 بر روی mainframe computers انجام می‌شد. از دیدگاه امروزی، use cases پیش پا افتاده به نظر می‌رسند: معمولاً transaction processing (وارد کردن فروش یا تراکنش‌های بانکی، رزرو بلیط هواپیما، نگهداری سهام در انبارها) و batch processing (صدور فاکتور مشتری، حقوق و دستمزد، گزارش‌دهی).
    </p>
<p>
        سایر databases در آن زمان، developers application را مجبور می‌کردند که در مورد internal representation داده‌ها در database بسیار فکر کنند. هدف relational model پنهان کردن آن implementation detail در پشت یک interface تمیزتر بود.
    </p>
<p>
        در طول سال‌ها، رویکردهای رقیب زیادی برای data storage و querying وجود داشته است. در دهه‌های 1970 و اوایل دهه 1980، network model و hierarchical model
    </p>
<p>
        28 | Chapter 2: Data Models and Query Languages
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0050</div>
            </div>
        </div>
        <!-- Page 0051 -->
        <div class="chapter" id="page-0051">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        were the main alternatives, but the relational model came to dominate them. Object databases در اواخر دهه 1980 و اوایل دهه 1990 آمدند و دوباره رفتند. XML databases در اوایل دهه 2000 ظاهر شدند، اما تنها پذیرش niche را دیده‌اند. هر رقیب relational model در زمان خود تبلیغات زیادی ایجاد کرد، اما هرگز دوام نیاورد [2].
    </p>
<p>
        همانطور که computers بسیار قدرتمندتر و networked شدند، آن‌ها شروع به استفاده برای اهداف فزاینده‌ای متنوع کردند. و به طرز چشمگیری، relational databases فراتر از scope اصلی خود یعنی business data processing، به طیف گسترده‌ای از use cases تعمیم یافتند. بخش زیادی از آنچه امروز در وب می‌بینید، هنوز توسط relational databases پشتیبانی می‌شود، چه online publishing، بحث، networking اجتماعی، ecom‐merce، games، software-as-a-service productivity applications یا موارد بسیار بیشتر.
    </p>
<h4>The Birth of NoSQL</h4>
<p>
        اکنون، در دهه 2010، NoSQL آخرین تلاش برای سرنگونی تسلط relational model است. نام "NoSQL" نامناسب است، زیرا در واقع به هیچ technology خاصی اشاره نمی‌کند - در اصل به عنوان یک hashtag جذاب Twitter برای یک meetup در مورد open source، distributed، nonrelational databases در سال 2009 در نظر گرفته شده بود [3]. با این وجود، این اصطلاح یک عصب را لمس کرد و به سرعت در سراسر community web startup و فراتر از آن گسترش یافت. تعدادی از سیستم‌های database جالب اکنون با #NoSQL hashtag مرتبط هستند و به صورت بازنگری شده به عنوان Not Only SQL [4] تفسیر شده است.
    </p>
<p>
        چندین نیروی محرکه در پشت پذیرش NoSQL databases وجود دارد، از جمله:
    </p>
<ul>
<li>یک نیاز برای scalability بیشتر از آنچه relational databases می‌تواند به راحتی به آن دست یابد، از جمله datasets بسیار بزرگ یا write throughput بسیار بالا</li>
<li>یک ترجیح گسترده برای software free و open source بر محصولات commercial database</li>
<li>operations query تخصصی که توسط relational model به خوبی پشتیبانی نمی‌شوند</li>
<li>Frustration با محدودیت‌های relational schemas و تمایل به یک data model پویا و رسا [5]</li>
</ul>
<p>
        applications مختلف، requirements متفاوتی دارند و بهترین انتخاب technology برای یک use case ممکن است با بهترین انتخاب برای یک use case دیگر متفاوت باشد. بنابراین به نظر می‌رسد که در آینده قابل پیش‌بینی، relational databases همچنان در کنار طیف وسیعی از datastores nonrelational مورد استفاده قرار خواهند گرفت - ایده‌ای که گاهی اوقات polyglot persistence [3] نامیده می‌شود.
    </p>
<h4>The Object-Relational Mismatch</h4>
<p>
        اکثر application development امروزی در زبان‌های object-oriented programming انجام می‌شود، که منجر به یک انتقاد رایج از SQL data model می‌شود: اگر data در relational tables ذخیره شود، یک layer ترجمه ناخوشایند بین objects در
    </p>
<p>
        Relational Model Versus Document Model | 29
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0051</div>
            </div>
        </div>
        <!-- Page 0052 -->
        <div class="chapter" id="page-0052">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        i.  یک اصطلاح وام گرفته شده از electronics. هر electric circuit دارای یک impedance خاص (مقاومت در برابر alternating current) در ورودی‌ها و خروجی‌های خود است. هنگامی که خروجی یک circuit را به ورودی circuit دیگری متصل می‌کنید، انتقال power در سراسر اتصال در صورتی به حداکثر می‌رسد که impedances خروجی و ورودی دو circuit با هم مطابقت داشته باشند. A impedance mismatch می‌تواند منجر به signal reflections و مشکلات دیگر شود.
    </p>
<p>
        application code و database model جداول، ردیف‌ها و ستون‌ها. این discon‐nect بین models گاهی اوقات یک impedance mismatch نامیده می‌شود.
    </p>
<p>
        فریم‌ورک‌های object-relational mapping (ORM) مانند ActiveRecord و Hibernate مقدار boilerplate code مورد نیاز برای این translation layer را کاهش می‌دهند، اما نمی‌توانند تفاوت‌های بین دو model را به طور کامل پنهان کنند.
    </p>
<p>
        به عنوان مثال، شکل 2-1 نشان می‌دهد که چگونه یک رزومه (یک پروفایل LinkedIn) می‌تواند در یک relational schema بیان شود. پروفایل به عنوان یک کل می‌تواند با یک unique identifier، user_id، شناسایی شود. فیلدهایی مانند first_name و last_name دقیقاً یک بار در هر user ظاهر می‌شوند، بنابراین می‌توانند به عنوان columns در جدول users مدل‌سازی شوند. با این حال، اکثر افراد در career خود (positions) بیش از یک شغل داشته‌اند و افراد ممکن است تعداد متفاوتی از دوره‌های تحصیلی و هر تعداد piece of contact information داشته باشند.
    </p>
<p>
        یک رابطه یک به چند از user به این آیتم‌ها وجود دارد که می‌تواند به روش‌های مختلف نشان داده شود:
    </p>
<ul>
<li>در traditional SQL model (قبل از SQL:1999)، رایج‌ترین نمایش normalized قرار دادن positions, education, و contact information در جداول جداگانه است، با یک foreign key reference به جدول users، همانطور که در شکل 2-1 نشان داده شده است.</li>
<li>نسخه‌های بعدی استاندارد SQL از data types ساختاری و XML data پشتیبانی می‌کردند. این به multi-valued data اجازه می‌دهد تا در یک ردیف واحد ذخیره شوند، با پشتیبانی از querying و indexing در داخل آن documents. این ویژگی‌ها تا درجات مختلفی توسط Oracle، IBM DB2، MS SQL Server و Post‐greSQL [6, 7] پشتیبانی می‌شوند. یک JSON datatype نیز توسط چندین database، از جمله IBM DB2، MySQL و PostgreSQL [8] پشتیبانی می‌شود.</li>
<li>گزینه سوم این است که مشاغل، آموزش و اطلاعات تماس را به عنوان یک document JSON یا XML رمزگذاری کنید، آن را در یک text column در database ذخیره کنید و به application اجازه دهید ساختار و محتوای آن را تفسیر کند. در این setup، معمولاً نمی‌توانید از database برای query برای values داخل آن encoded column استفاده کنید.</li>
</ul>
<p>
        30 | Chapter 2: Data Models and Query Languages
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0052</div>
            </div>
        </div>
        <!-- Page 0053 -->
        <div class="chapter" id="page-0053">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        شکل 2-1. نشان دادن یک پروفایل LinkedIn با استفاده از یک relational schema. عکس Bill Gates با اجازه از Wikimedia Commons، Ricardo Stuckert، Agência Brasil.
    </p>
<p>
        برای یک data structure مانند رزومه، که عمدتاً یک document خودکفا است، یک JSON representation می‌تواند کاملاً مناسب باشد: به Example 2-1 مراجعه کنید. JSON جذابیت بسیار ساده‌تری نسبت به XML دارد. databases مبتنی بر document مانند MongoDB [9]، RethinkDB [10]، CouchDB [11] و Espresso [12] از این data model پشتیبانی می‌کنند.
    </p>
<p>
        Example 2-1. نشان دادن یک پروفایل LinkedIn به عنوان یک document JSON
    </p>
<pre><code class="language-json">{
  "user_id":     251,
  "first_name":  "Bill",
  "last_name":   "Gates",
  "summary":     "Co-chair of the Bill &amp; Melinda Gates... Active blogger.",
  "region_id":   "us:91",
  "industry_id": 131,
  "photo_url":   "/p/7/000/253/05b/308dd6e.jpg",
}
</code></pre>
<p>
        Relational Model Versus Document Model | 31
    </p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 53" src="page_0053/image_1.png"/></div>
</div>
                <div class="page-number">صفحه 0053</div>
            </div>
        </div>
        <!-- Page 0054 -->
        <div class="chapter" id="page-0054">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<pre><code class="language-json">{
  "positions": [
    {"job_title": "Co-chair", "organization": "Bill &amp; Melinda Gates Foundation"},
    {"job_title": "Co-founder, Chairman", "organization": "Microsoft"}
  ],
  "education": [
    {"school_name": "Harvard University",       "start": 1973, "end": 1975},
    {"school_name": "Lakeside School, Seattle", "start": null, "end": null}
  ],
  "contact_info": {
    "blog":    "http://thegatesnotes.com",
    "twitter": "http://twitter.com/BillGates"
  }
}
</code></pre>
<p>
        برخی از developers احساس می‌کنند که model JSON، impedance mismatch بین application code و storage layer را کاهش می‌دهد. با این حال، همانطور که در فصل 4 خواهیم دید، مشکلاتی نیز با JSON به عنوان یک data encoding format وجود دارد. عدم وجود یک schema اغلب به عنوان یک مزیت ذکر می‌شود. ما این موضوع را در “Schema flexibility in the docu‐ment model” در صفحه 39 مورد بحث قرار خواهیم داد.
    </p>
<p>
        JSON representation locality بهتری نسبت به schema چند جدولی در شکل 2-1 دارد. اگر می‌خواهید یک profile را در مثال relational واکشی کنید، باید یا چندین query (query هر جدول توسط user_id) انجام دهید یا یک join چند طرفه نامرتب بین جدول users و جداول فرعی آن انجام دهید. در JSON representation، تمام اطلاعات مربوطه در یک مکان است و یک query کافی است.
    </p>
<p>
        روابط یک به چند از user profile به positions، history educational و contact information کاربر، یک ساختار درختی را در داده‌ها نشان می‌دهد و JSON representation این ساختار درختی را صریح می‌کند (به شکل 2-2 مراجعه کنید).
    </p>
<p>
        شکل 2-2. روابط یک به چند که یک ساختار درختی را تشکیل می‌دهند.
    </p>
<p>
        32 | Chapter 2: Data Models and Query Languages
    </p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 54" src="page_0054/image_1.png"/></div>
</div>
                <div class="page-number">صفحه 0054</div>
            </div>
        </div>
        <!-- Page 0055 -->
        <div class="chapter" id="page-0055">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        ii. Literature on the relational model چندین normal forms مختلف را متمایز می‌کند، اما تمایزها از نظر عملی، interest کمی دارند. به عنوان یک rule of thumb، اگر در حال تکرار values هستید که می‌توانستند فقط در یک مکان ذخیره شوند، schema نرمال‌سازی نشده است.
    </p>
<h4>Many-to-One و Many-to-Many Relationships</h4>
<p>
        در Example 2-1 در بخش قبلی، region_id و industry_id به عنوان IDs ارائه شده‌اند، نه به عنوان plain-text strings "Greater Seattle Area" و "Philanthropy". چرا؟
    </p>
<p>
        اگر user interface دارای fields free-text برای وارد کردن region و industry است، منطقی است که آن‌ها را به عنوان plain-text strings ذخیره کنید. اما مزایایی در داشتن lists استاندارد شده از geographic regions و industries و اجازه دادن به کاربران برای انتخاب از یک drop-down list یا autocompleter وجود دارد:
    </p>
<ul>
<li>سبک و املای سازگار در سراسر profiles</li>
<li>جلوگیری از ambiguity (به عنوان مثال، اگر چند شهر با نام یکسان وجود داشته باشد)</li>
<li>Ease of updating—نام فقط در یک مکان ذخیره می‌شود، بنابراین به راحتی می‌توان آن را در سراسر هیئت مدیره به‌روز کرد (به عنوان مثال، تغییر نام شهر به دلیل رویدادهای سیاسی)</li>
<li>پشتیبانی از Localization—هنگامی که سایت به زبان‌های دیگر ترجمه می‌شود، lists استانداردی شده می‌توانند localized شوند، بنابراین region و industry را می‌توان به زبان بیننده نمایش داد</li>
<li>Better search—به عنوان مثال، جستجو برای philanthropists در ایالت واشنگتن می‌تواند با این profile مطابقت داشته باشد، زیرا list of regions می‌تواند این واقعیت را رمزگذاری کند که Seattle در واشنگتن است (که از رشته "Greater Seattle Area" مشهود نیست)</li>
</ul>
<p>
        اینکه آیا شما یک ID یا یک text string را ذخیره می‌کنید، یک سوال تکراری است. هنگامی که از یک ID استفاده می‌کنید، اطلاعاتی که برای انسان‌ها معنی‌دار است (مانند کلمه Philanthropy) فقط در یک مکان ذخیره می‌شود و هر چیزی که به آن اشاره دارد از یک ID استفاده می‌کند (که فقط در داخل database معنا دارد). هنگامی که text را مستقیماً ذخیره می‌کنید، اطلاعات معنی‌دار برای انسان را در هر record که از آن استفاده می‌کند، تکرار می‌کنید.
    </p>
<p>
        مزیت استفاده از یک ID این است که چون برای انسان‌ها معنایی ندارد، هرگز نیازی به تغییر ندارد: ID می‌تواند یکسان باقی بماند، حتی اگر اطلاعاتی که شناسایی می‌کند تغییر کند. هر چیزی که برای انسان‌ها معنی‌دار است ممکن است در آینده‌ای نیاز به تغییر داشته باشد - و اگر آن اطلاعات تکرار شود، تمام کپی‌های redundant باید به‌روز شوند. این امر باعث write overheads می‌شود و خطر inconsistencies (جایی که برخی از کپی‌های اطلاعات به‌روز می‌شوند اما برخی دیگر نمی‌شوند) را دارد. حذف چنین تکراری، ایده اصلی پشت normalization در databases است.ii
    </p>
<p>
        Relational Model Versus Document Model | 33
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0055</div>
            </div>
        </div>
        <!-- Page 0056 -->
        <div class="chapter" id="page-0056">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        iii. At the time of writing, joins در RethinkDB پشتیبانی می‌شوند، در MongoDB پشتیبانی نمی‌شوند و فقط در views از قبل اعلام شده در CouchDB پشتیبانی می‌شوند.
    </p>
<p>
        Database administrators و developers عاشق بحث در مورد normalization و denormalization هستند، اما ما در حال حاضر قضاوت را به حالت تعلیق در می‌آوریم. در قسمت III این کتاب ما به این موضوع باز خواهیم گشت و راه‌های سیستماتیک برخورد با caching، denormalization و derived data را بررسی خواهیم کرد.
    </p>
<p>
        متأسفانه، نرمال‌سازی این data به relationships many-to-one نیاز دارد (افراد زیادی در یک منطقه خاص زندگی می‌کنند، افراد زیادی در یک صنعت خاص کار می‌کنند)، که به خوبی با document model مطابقت ندارند. در relational databases، ارجاع به ردیف‌ها در tables دیگر توسط ID، به دلیل آسان بودن joins، normal است. در document databases، joins برای ساختارهای درختی one-to-many مورد نیاز نیستند و پشتیبانی از joins اغلب ضعیف است.iii
    </p>
<p>
        اگر خود database از joins پشتیبانی نمی‌کند، باید یک join را در application code با انجام multiple queries به database شبیه‌سازی کنید. (در این مورد، lists of regions و industries احتمالاً به اندازه کافی کوچک و کند تغییر می‌کنند که application می‌تواند به سادگی آن‌ها را در memory نگه دارد. اما با این وجود، کار انجام join از database به application code منتقل می‌شود.)
    </p>
<p>
        علاوه بر این، حتی اگر نسخه اولیه یک application به خوبی در یک document model بدون join قرار گیرد، data تمایل به interconnectedتر شدن با اضافه شدن features به applications دارد. به عنوان مثال، تغییراتی را که می‌توانیم در مثال resume ایجاد کنیم، در نظر بگیرید:
    </p>
<ul>
<li>Organizations و schools به عنوان entities</li>
<li>در توضیحات قبلی، organization (شرکتی که user در آن کار می‌کرد) و school_name (جایی که آن‌ها تحصیل می‌کردند) فقط strings هستند. شاید آن‌ها باید به جای آن، به references به entities اشاره کنند؟ سپس هر organization، school یا university می‌تواند صفحه وب خود را داشته باشد (با logo، news feed و غیره). هر resume می‌تواند به organizations و schools که به آن اشاره می‌کند، link شود و شامل logos و اطلاعات دیگر آن‌ها باشد (به شکل 2-3 برای یک مثال از LinkedIn مراجعه کنید).</li>
<li>Recommendations</li>
<li>فرض کنید می‌خواهید یک feature جدید اضافه کنید: یک user می‌تواند یک recommendation برای user دیگری بنویسد. recommendation در resume از user که recommendation شده است، همراه با name و photo از user که recommendation را انجام می‌دهد، نمایش داده می‌شود. اگر recommender photo خود را به‌روزرسانی کند، هر recommendation که نوشته است باید photo جدید را منعکس کند. بنابراین، recommendation باید یک reference به profile نویسنده داشته باشد.</li>
</ul>
<p>
        34 | Chapter 2: Data Models and Query Languages
    </p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 56" src="page_0056/image_1.png"/></div>
</div>
                <div class="page-number">صفحه 0056</div>
            </div>
        </div>
        <!-- Page 0057 -->
        <div class="chapter" id="page-0057">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        شکل 2-3. نام شرکت فقط یک string نیست، بلکه یک link به یک company entity است. Screenshot از linkedin.com.
    </p>
<p>
        شکل 2-4 نشان می‌دهد که چگونه این features جدید به relationships many-to-many نیاز دارند.
    </p>
<p>
        data در داخل هر مستطیل نقطه‌چین می‌تواند در یک document گروه‌بندی شود، اما references به organizations، schools و سایر users باید به عنوان references نشان داده شوند و هنگام querying به joins نیاز دارند.
    </p>
<p>
        شکل 2-4. Extending résumés با relationships many-to-many.
    </p>
<p>
        Relational Model Versus Document Model | 35
    </p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 57" src="page_0057/image_1.png"/></div>
<div class="page-image"><img alt="Image from page 57" src="page_0057/image_2.png"/></div>
</div>
                <div class="page-number">صفحه 0057</div>
            </div>
        </div>
        <!-- Page 0058 -->
        <div class="chapter" id="page-0058">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<h4>آیا Document Databases در حال تکرار تاریخ هستند؟</h4>
<p>
        در حالی که relationships many-to-many و joins به طور معمول در relational databases استفاده می‌شوند، document databases و NoSQL بحث در مورد بهترین روش برای نشان دادن چنین relationships در یک database را دوباره باز کردند. این بحث بسیار قدیمی‌تر از NoSQL است - در واقع، به قدیمی‌ترین سیستم‌های database کامپیوتری شده برمی‌گردد.
    </p>
<p>
        محبوب‌ترین database برای business data processing در دهه 1970، Information Management System (IMS) از IBM بود که در اصل برای نگهداری سهام در برنامه فضایی Apollo توسعه داده شد و اولین بار در سال 1968 [13] به صورت تجاری منتشر شد. هنوز هم در حال استفاده و نگهداری است و امروزه بر روی OS/390 در IBM mainframes اجرا می‌شود [14].
    </p>
<p>
        طراحی IMS از یک data model نسبتاً ساده به نام hierarchical model استفاده می‌کرد که شباهت‌های قابل توجهی به JSON model که توسط document databases استفاده می‌شود، دارد [2]. این data همه داده‌ها را به عنوان یک tree of records که در داخل records قرار گرفته‌اند، نشان می‌داد، درست مانند ساختار JSON شکل 2-2.
    </p>
<p>
        مانند document databases، IMS برای relationships one-to-many عملکرد خوبی داشت، اما relationships many-to-many را دشوار می‌کرد و از joins پشتیبانی نمی‌کرد. developers مجبور بودند تصمیم بگیرند که آیا داده‌ها را تکرار (denormalize) کنند یا به صورت دستی references را از یک record به record دیگری حل کنند. این مشکلات دهه 1960 و 70، بسیار شبیه به مشکلاتی بود که developers امروزه با document databases با آن مواجه هستند [15].
    </p>
<p>
        راه حل‌های مختلفی برای حل محدودیت‌های hierarchical model پیشنهاد شد. دو مورد برجسته‌تر relational model (که به SQL تبدیل شد و جهان را در دست گرفت) و network model (که در ابتدا طرفداران زیادی داشت اما در نهایت به فراموشی سپرده شد) بودند. "بحث بزرگ" بین این دو camp بخش زیادی از دهه 1970 را به خود اختصاص داد [2].
    </p>
<p>
        از آنجایی که مشکلی که دو model در حال حل آن بودند، هنوز هم امروزه بسیار مرتبط است، ارزش دارد که به طور خلاصه این بحث را در نور امروز مرور کنیم.
    </p>
<h4>The network model</h4>
<p>
        network model توسط کمیته‌ای به نام Conference on Data Systems Languages (CODASYL) استاندارد شد و توسط چندین vendor database مختلف پیاده‌سازی شد. همچنین به عنوان CODASYL model [16] نیز شناخته می‌شود.
    </p>
<p>
        CODASYL model تعمیمی از hierarchical model بود. در tree structure از hierarchical model، هر record دقیقاً یک parent دارد. در network model، یک record می‌تواند multiple parents داشته باشد. به عنوان مثال، می‌توانست یک record برای "Greater Seattle Area" region وجود داشته باشد و هر user که در آن region زندگی می‌کند می‌تواند به آن link شود. این امر به relationships many-to-one و many-to-many اجازه می‌داد تا مدل‌سازی شوند.
    </p>
<p>
        36 | Chapter 2: Data Models and Query Languages
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0058</div>
            </div>
        </div>
        <!-- Page 0059 -->
        <div class="chapter" id="page-0059">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        iv. Foreign key constraints به شما اجازه می‌دهند تا modifications را محدود کنید، اما چنین constraints توسط relational model مورد نیاز نیستند. حتی با constraints، joins روی foreign keys در زمان query انجام می‌شوند، در حالی که در CODASYL، join عملاً در زمان insert انجام می‌شد.
    </p>
<p>
        links بین records در network model، foreign keys نبودند، بلکه بیشتر شبیه pointers در یک زبان برنامه‌نویسی (در حالی که هنوز روی دیسک ذخیره می‌شدند) بودند. تنها راه دسترسی به یک record، دنبال کردن یک مسیر از یک root record در امتداد این chains of links بود. این کار access path نامیده می‌شد.
    </p>
<p>
        در ساده‌ترین حالت، یک access path می‌تواند مانند traversal از یک linked list باشد: در head از list شروع کنید و یک record را در یک زمان بررسی کنید تا زمانی که مورد نظر خود را پیدا کنید. اما در دنیای relationships many-to-many، چندین مسیر مختلف می‌تواند به همان record منتهی شود و یک programmer که با network model کار می‌کند، باید این access paths مختلف را در ذهن خود دنبال کند.
    </p>
<p>
        یک query در CODASYL با جابجایی یک cursor از طریق database با تکرار lists of records و دنبال کردن access paths انجام می‌شد. اگر یک record چندین parent داشت (به عنوان مثال، چندین pointer ورودی از records دیگر)، application code باید تمام relationships مختلف را دنبال می‌کرد. حتی اعضای کمیته CODASYL اذعان داشتند که این کار مانند پیمایش در یک فضای داده n-dimensional است [17].
    </p>
<p>
        اگرچه انتخاب دستی access path قادر بود از قابلیت‌های سخت‌افزاری بسیار محدود در دهه 1970 (مانند tape drives که seeks آن‌ها بسیار کند است) استفاده بهینه را ببرد، اما مشکل این بود که آن‌ها کد را برای querying و updating database پیچیده و غیرقابل انعطاف می‌کردند. هم با hierarchical و هم با network model، اگر شما یک path به داده‌هایی که می‌خواستید نداشتید، در یک موقعیت دشوار قرار داشتید. شما می‌توانستید access paths را تغییر دهید، اما سپس مجبور بودید مقدار زیادی کد query database دست‌نویس را طی کنید و آن را دوباره بنویسید تا access paths جدید را مدیریت کند. ایجاد تغییرات در application’s data model دشوار بود.
    </p>
<h4>The relational model</h4>
<p>
        کاری که relational model در مقابل انجام داد این بود که همه data را در فضای باز قرار داد: یک relation (table) به سادگی یک collection از tuples (rows) است و همین. هیچ ساختارهای تو در توی پرپیچ و خم، هیچ access paths پیچیده‌ای برای دنبال کردن وجود ندارد، اگر می‌خواهید به data نگاه کنید. شما می‌توانید هر یا همه rows در یک table را بخوانید، آن‌هایی را که با یک condition دلخواه مطابقت دارند، انتخاب کنید. شما می‌توانید یک ردیف خاص را با تعیین برخی از columns به عنوان key و مطابقت با آن‌ها بخوانید. شما می‌توانید یک ردیف جدید را بدون نگرانی در مورد foreign key relationships به و از tables دیگر، وارد هر table کنید.iv
    </p>
<p>
        در یک relational database، query optimizer به طور خودکار تصمیم می‌گیرد که کدام بخش از query را به چه ترتیبی اجرا کند و از کدام indexes استفاده کند. این انتخاب‌ها در واقع همان "access path" هستند، اما تفاوت بزرگ این است که آن‌ها به طور خودکار توسط
    </p>
<p>
        Relational Model Versus Document Model | 37
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0059</div>
            </div>
        </div>
        <!-- Page 0060 -->
        <div class="chapter" id="page-0060">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        the query optimizer، نه توسط developer application، بنابراین ما به ندرت نیازی به فکر کردن در مورد آن‌ها داریم.
    </p>
<p>
        اگر می‌خواهید داده‌های خود را به روش‌های جدید query کنید، می‌توانید فقط یک index جدید را declare کنید و queries به طور خودکار از هر index که مناسب‌تر است استفاده خواهند کرد. شما نیازی به تغییر queries خود برای استفاده از یک index جدید ندارید. (همچنین به “Query Lan‐guages for Data” در صفحه 42 مراجعه کنید.) بنابراین relational model افزودن features جدید به applications را بسیار آسان‌تر کرد.
    </p>
<p>
        Query optimizers برای relational databases، beast های پیچیده‌ای هستند و سال‌های زیادی از تلاش‌های تحقیق و توسعه را مصرف کرده‌اند [18]. اما یک insight کلیدی از relational model این بود: شما فقط یک بار نیاز به ساختن query optimizer دارید و سپس همه applications که از database استفاده می‌کنند می‌توانند از آن بهره‌مند شوند. اگر شما یک query opti‐mizer ندارید، handcode کردن access paths برای یک query خاص آسان‌تر از نوشتن یک optimizer general-purpose است - اما راه‌حل general-purpose در درازمدت پیروز می‌شود.
    </p>
<h4>Comparison to document databases</h4>
<p>
        Document databases در یک جنبه به hierarchical model بازگشتند: ذخیره nested records (relationships one-to-many، مانند positions, education, و contact_info در شکل 2-1) در record parent خود به جای یک table جداگانه.
    </p>
<p>
        با این حال، هنگامی که به نشان دادن relationships many-to-one و many-to-many می‌رسد، relational و document databases اساساً متفاوت نیستند: در هر دو مورد، item مرتبط با یک unique identifier ارجاع داده می‌شود، که در relational model یک foreign key و در document model یک document reference نامیده می‌شود [9].
    </p>
<p>
        آن identifier در زمان خواندن با استفاده از یک join یا follow-up queries حل می‌شود. تا به امروز، document databases مسیر CODASYL را دنبال نکرده‌اند.
    </p>
<h4>Relational Versus Document Databases Today</h4>
<p>
        هنگام مقایسه relational databases با document databases، تفاوت‌های زیادی وجود دارد که باید در نظر گرفته شود، از جمله fault-tolerance properties آن‌ها (به فصل 5 مراجعه کنید) و handling of concurrency (به فصل 7 مراجعه کنید). در این فصل، ما فقط بر تفاوت‌های data model تمرکز خواهیم کرد.
    </p>
<p>
        دلایل اصلی به نفع document data model، schema flexibility، performance بهتر به دلیل locality و این است که برای برخی از applications به data structures که توسط application استفاده می‌شود، نزدیک‌تر است. relational model با ارائه پشتیبانی بهتر برای joins و relationships many-to-one و many-to-many، مقابله می‌کند.
    </p>
<p>
        کدام data model به ساده‌تر شدن application code منجر می‌شود؟
    </p>
<p>
        اگر data در application شما دارای یک structure document-like است (به عنوان مثال، یک tree از relationships one-to-many، که در آن معمولاً کل tree یکباره بارگذاری می‌شود)، در این صورت احتمالاً
    </p>
<p>
        38 | Chapter 2: Data Models and Query Languages
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0060</div>
            </div>
        </div>
        <!-- Page 0061 -->
        <div class="chapter" id="page-0061">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        bly a good idea برای استفاده از یک document model. تکنیک relational of shredding—تقسیم یک structure document-like به tables متعدد (مانند positions, education, و contact_info در شکل 2-1)—می‌تواند به schemas دست و پا گیر و application code بیش از حد پیچیده منجر شود.
    </p>
<p>
        document model محدودیت‌هایی دارد: به عنوان مثال، شما نمی‌توانید مستقیماً به یک item nested در یک document اشاره کنید، بلکه باید چیزی شبیه به "دومین item در list of positions برای user 251" (بسیار شبیه به یک access path در hierarchical model) بگویید. با این حال، تا زمانی که documents بیش از حد عمیق nested نشوند، معمولاً مشکلی نیست.
    </p>
<p>
        پشتیبانی ضعیف برای joins در document databases ممکن است یک مشکل باشد یا نباشد، که به application بستگی دارد. به عنوان مثال، relationships many-to-many ممکن است هرگز در یک analytics application که از یک document database برای ثبت events که در چه زمانی رخ داده‌اند [19]، مورد نیاز نباشد.
    </p>
<p>
        با این حال، اگر application شما از relationships many-to-many استفاده می‌کند، document model جذابیت کمتری پیدا می‌کند. امکان کاهش نیاز به joins با denormalizing وجود دارد، اما در این صورت application code نیاز به انجام کار اضافی برای حفظ consistency داده‌های denor‐malized دارد. Joins را می‌توان در application code با ایجاد multiple requests به database شبیه‌سازی کرد، اما این کار نیز پیچیدگی را به application منتقل می‌کند و معمولاً کندتر از یک join است که توسط code تخصصی در داخل database انجام می‌شود.
    </p>
<p>
        در چنین مواردی، استفاده از یک document model می‌تواند منجر به application code به طور قابل توجهی پیچیده‌تر و performance بدتر شود [15].
    </p>
<p>
        به طور کلی نمی‌توان گفت که کدام data model به application code ساده‌تری منجر می‌شود. به نوع relationships که بین data items وجود دارد، بستگی دارد. برای داده‌های بسیار interconnected، document model ناخوشایند است، relational model قابل قبول است و graph models (به "Graph-Like Data Models" در صفحه 49 مراجعه کنید) طبیعی‌ترین هستند.
    </p>
<h4>Schema flexibility in the document model</h4>
<p>
        اکثر document databases و پشتیبانی JSON در relational databases، هیچ schema را بر روی data در documents اعمال نمی‌کنند. پشتیبانی XML در relational databases معمولاً با schema validation اختیاری همراه است. بدون schema به این معنی است که کلیدها و values دلخواه را می‌توان به یک document اضافه کرد و هنگام خواندن، clients هیچ تضمینی در مورد فیلدهایی که documents ممکن است شامل شوند ندارند.
    </p>
<p>
        document databases گاهی اوقات schemaless نامیده می‌شوند، اما این گمراه‌کننده است، زیرا code که data را می‌خواند، معمولاً ساختاری را فرض می‌کند - یعنی، یک schema ضمنی وجود دارد، اما توسط database اعمال نمی‌شود [20]. یک عبارت دقیق‌تر schema-on-read است (ساختار داده ضمنی است و فقط زمانی تفسیر می‌شود که data خوانده شود)، در تضاد با schema-on-write (رویکرد سنتی relational
    </p>
<p>
        Relational Model Versus Document Model | 39
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0061</div>
            </div>
        </div>
        <!-- Page 0062 -->
        <div class="chapter" id="page-0062">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        databases، جایی که schema صریح است و database تضمین می‌کند که همه داده‌های نوشته شده با آن مطابقت دارند) [21].
    </p>
<p>
        Schema-on-read شبیه به dynamic (runtime) type checking در زبان‌های برنامه‌نویسی است، در حالی که schema-on-write شبیه به static (compile-time) type checking است.
    </p>
<p>
        درست همانطور که طرفداران static و dynamic type checking بحث‌های بزرگی در مورد شایستگی‌های نسبی خود دارند [22]، اجرای schemas در database یک موضوع بحث‌انگیز است و به طور کلی هیچ پاسخ درست یا غلطی وجود ندارد.
    </p>
<p>
        تفاوت بین رویکردها، به‌ویژه در موقعیت‌هایی که یک application می‌خواهد format داده‌های خود را تغییر دهد، قابل توجه است. به عنوان مثال، فرض کنید شما در حال حاضر نام کامل هر user را در یک فیلد ذخیره می‌کنید و در عوض می‌خواهید first name و last name را جداگانه ذخیره کنید [23]. در یک document database، شما فقط شروع به نوشتن documents جدید با فیلدهای جدید می‌کنید و کدی در application دارید که case را زمانی که documents قدیمی خوانده می‌شوند، مدیریت می‌کند. به عنوان مثال:
    </p>
<pre><code class="language-java">if (user &amp;&amp; user.name &amp;&amp; !user.first_name) {
    // Documents written before Dec 8, 2013 don't have first_name
    user.first_name = user.name.split(" ")[0];
}
</code></pre>
<p>
        از طرف دیگر، در یک schema database "statically typed"، شما معمولاً یک migration را در امتداد خطوط زیر انجام می‌دهید:
    </p>
<pre><code class="language-sql">ALTER TABLE users ADD COLUMN first_name text;
UPDATE users SET first_name = split_part(name, ' ', 1);      -- PostgreSQL
UPDATE users SET first_name = substring_index(name, ' ', 1);      -- MySQL
</code></pre>
<p>
        تغییرات Schema شهرت بدی برای slow بودن و نیاز به downtime دارند. این شهرت کاملاً سزاوار نیست: اکثر systems relational database دستور ALTER TABLE را در چند میلی‌ثانیه اجرا می‌کنند. MySQL یک استثنا قابل توجه است — این جدول کامل را در ALTER TABLE کپی می‌کند، که می‌تواند به معنای minutes یا حتی hours of downtime هنگام تغییر یک table بزرگ باشد—اگرچه ابزارهای مختلفی برای دور زدن این محدودیت وجود دارد [24, 25, 26].
    </p>
<p>
        اجرای دستور UPDATE بر روی یک table بزرگ احتمالاً در هر database کند خواهد بود، زیرا هر ردیف باید دوباره نوشته شود. اگر این قابل قبول نیست، application می‌تواند first_name را روی مقدار پیش‌فرض NULL خود بگذارد و آن را در زمان خواندن پر کند، مانند document database.
    </p>
<p>
        رویکرد schema-on-read در صورتی که items در collection به دلایلی ساختار یکسانی نداشته باشند (به عنوان مثال، داده‌ها ناهمگن هستند) مزیت دارد - به عنوان مثال، به دلیل:
    </p>
<ul>
<li>انواع مختلفی از objects وجود دارد و قرار دادن هر type of object در table خود عملی نیست.</li>
</ul>
<p>
        40 | Chapter 2: Data Models and Query Languages
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0062</div>
            </div>
        </div>
        <!-- Page 0063 -->
        <div class="chapter" id="page-0063">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<ul>
<li>The structure of the data is determined by external systems over which you have no control and which may change at any time.</li>
</ul>
<p>
        در موقعیت‌هایی مانند این‌ها، یک schema ممکن است بیشتر از اینکه کمک کند، آسیب برساند و documents schemaless می‌تواند یک data model بسیار طبیعی‌تر باشد. اما در مواردی که انتظار می‌رود همه records ساختار یکسانی داشته باشند، schemas یک مکانیزم مفید برای مستندسازی و اجرای آن structure هستند. ما در مورد schemas و schema evolution با جزئیات بیشتر در فصل 4 بحث خواهیم کرد.
    </p>
<h4>Data locality for queries</h4>
<p>
        یک document معمولاً به عنوان یک string پیوسته واحد ذخیره می‌شود که به صورت JSON, XML یا یک variant باینری از آن (مانند BSON از MongoDB) رمزگذاری شده است. اگر application شما اغلب نیاز به دسترسی به کل document دارد (به عنوان مثال، برای render کردن آن در یک صفحه وب)، یک مزیت performance برای این storage locality وجود دارد. اگر data در tables متعدد تقسیم شود، مانند شکل 2-1، به چندین index lookups برای بازیابی همه آن‌ها نیاز است، که ممکن است به disk seeks بیشتری نیاز داشته باشد و زمان بیشتری ببرد.
    </p>
<p>
        مزیت locality تنها در صورتی اعمال می‌شود که شما به بخش‌های بزرگی از document در همان زمان نیاز داشته باشید. database معمولاً نیاز به بارگذاری کل document دارد، حتی اگر شما فقط به یک بخش کوچکی از آن دسترسی داشته باشید، که می‌تواند در documents بزرگ هدر رفت باشد. در مورد updates به یک document، کل document معمولاً نیاز به بازنویسی دارد—فقط modifications که اندازه encoded یک document را تغییر نمی‌دهند، می‌توانند به راحتی در محل انجام شوند [19]. به همین دلایل، عموماً توصیه می‌شود که documents را نسبتاً کوچک نگه دارید و از write هایی که اندازه یک document را افزایش می‌دهند، اجتناب کنید [9].
    </p>
<p>
        این limitations performance به طور قابل توجهی مجموعه موقعیت‌هایی را که در آن‌ها document databases مفید هستند، کاهش می‌دهد.
    </p>
<p>
        شایان ذکر است که ایده گروه‌بندی داده‌های مرتبط با هم برای locality به document model محدود نمی‌شود. به عنوان مثال، database Spanner از Google همان properties locality را در یک relational data model ارائه می‌دهد و به schema اجازه می‌دهد اعلام کند که ردیف‌های یک جدول باید در داخل یک table parent interleaved (nested) شوند [27].
    </p>
<p>
        Oracle همین کار را با استفاده از یک ویژگی به نام multi-table index cluster tables [28] مجاز می‌کند.
    </p>
<p>
        مفهوم column-family در data model Bigtable (که در Cassandra و HBase استفاده می‌شود) هدف مشابهی از مدیریت locality دارد [29].
    </p>
<p>
        ما همچنین در فصل 3 اطلاعات بیشتری در مورد locality خواهیم دید.
    </p>
<h4>Convergence of document and relational databases</h4>
<p>
        اکثر relational database systems (به غیر از MySQL) از اواسط دهه 2000 از XML پشتیبانی می‌کنند. این شامل توابعی برای ایجاد modifications local به XML documents و توانایی index و query در داخل XML documents است که به applications اجازه می‌دهد از data models بسیار مشابه با آنچه هنگام استفاده از یک document data‐base انجام می‌دهند، استفاده کنند.
    </p>
<p>
        Relational Model Versus Document Model | 41
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0063</div>
            </div>
        </div>
        <!-- Page 0064 -->
        <div class="chapter" id="page-0064">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        v. Codd’s original description of the relational model [1] در واقع چیزی کاملاً مشابه با JSON documents را در یک relational schema مجاز می‌دانست. او آن را nonsimple domains نامید. ایده این بود که یک value در یک row نیازی نیست که فقط یک datatype اولیه مانند یک عدد یا یک رشته باشد، بلکه می‌تواند یک relation (table) nested نیز باشد — بنابراین شما می‌توانید یک ساختار درختی به صورت دلخواه nested را به عنوان یک value داشته باشید، درست شبیه پشتیبانی از JSON یا XML که بیش از 30 سال بعد به SQL اضافه شد.
    </p>
<p>
        PostgreSQL از نسخه 9.3 [8]، MySQL از نسخه 5.7 و IBM DB2 از نسخه 10.5 [30] نیز سطح مشابهی از پشتیبانی را برای JSON documents دارند. با توجه به محبوبیت JSON برای web APIs، احتمال دارد که سایر relational databases از این الگو پیروی کنند و پشتیبانی از JSON را اضافه کنند.
    </p>
<p>
        در سمت document database، RethinkDB از joins relational-like در زبان query خود پشتیبانی می‌کند و برخی از drivers MongoDB به طور خودکار database references را حل می‌کنند (به طور موثر انجام یک join client-side، اگرچه این احتمالاً کندتر از یک join است که در database انجام می‌شود، زیرا به round-trips شبکه اضافی نیاز دارد و کمتر بهینه شده است).
    </p>
<p>
        به نظر می‌رسد که relational و document databases با گذشت زمان به هم نزدیک‌تر می‌شوند و این یک چیز خوب است: data models یکدیگر را تکمیل می‌کنند.v اگر یک database بتواند data document-like را مدیریت کند و همچنین queries relational را روی آن انجام دهد، applications می‌توانند از ترکیب features که به بهترین وجه با نیازهایشان مطابقت دارد، استفاده کنند.
    </p>
<p>
        یک hybrid از relational و document models یک مسیر خوب برای databases است که در آینده طی شود.
    </p>
<h4>Query Languages for Data</h4>
<p>
        هنگامی که relational model معرفی شد، یک روش جدید برای querying data را شامل می‌شد:
    </p>
<p>
        SQL یک زبان query declarative است، در حالی که IMS و CODASYL database را با استفاده از imperative code query می‌کردند. این به چه معناست؟
    </p>
<p>
        بسیاری از زبان‌های برنامه‌نویسی که معمولاً استفاده می‌شوند، imperative هستند. به عنوان مثال، اگر شما یک list of animal species دارید، ممکن است چیزی شبیه این را برای return کردن فقط sharks در list بنویسید:
    </p>
<pre><code class="language-javascript">function getSharks() {
    var sharks = [];
    for (var i = 0; i &lt; animals.length; i++) {
        if (animals[i].family === "Sharks") {
            sharks.push(animals[i]);
        }
    }
    return sharks;
}
</code></pre>
<p>
        در relational algebra، شما به جای آن می‌نویسید:
    </p>
<p>
        sharks = σfamily = “Sharks” (animals)
    </p>
<p>
        42 | Chapter 2: Data Models and Query Languages
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0064</div>
            </div>
        </div>
        <!-- Page 0065 -->
        <div class="chapter" id="page-0065">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        where σ (حرف سیگمای یونانی) عملگر selection است و تنها آن ani‐mals را که با شرط family = “Sharks” مطابقت دارند، برمی‌گرداند.
    </p>
<p>
        هنگامی که SQL تعریف شد، ساختار relational algebra را بسیار نزدیک دنبال کرد:
    </p>
<pre><code class="language-sql">SELECT * FROM animals WHERE family = 'Sharks';
</code></pre>
<p>
        یک زبان imperative به computer می‌گوید که عملیات خاصی را به ترتیب خاصی انجام دهد. شما می‌توانید کد را خط به خط طی کنید، شرایط را ارزیابی کنید، متغیرها را به‌روزرسانی کنید و تصمیم بگیرید که آیا یک بار دیگر حلقه را طی کنید یا خیر.
    </p>
<p>
        در یک declarative query language، مانند SQL یا relational algebra، شما فقط الگوی داده‌هایی را که می‌خواهید مشخص می‌کنید—چه شرایطی باید نتایج را برآورده کند و چگونه می‌خواهید داده‌ها را transform (به عنوان مثال، sorted، grouped و aggregated) کنید—اما نه چگونگی رسیدن به آن هدف. این به query optimizer سیستم database بستگی دارد تا تصمیم بگیرد از کدام indexes و کدام join methods استفاده کند و به چه ترتیبی قسمت‌های مختلف query را اجرا کند.
    </p>
<p>
        یک declarative query language جذاب است زیرا معمولاً conciseتر و آسان‌تر از یک imperative API است. اما مهمتر از آن، جزئیات implementation از database engine را نیز پنهان می‌کند، که باعث می‌شود سیستم database، بهبودهای performance را بدون نیاز به هیچ تغییری در queries معرفی کند.
    </p>
<p>
        به عنوان مثال، در کد imperative که در ابتدای این بخش نشان داده شد، list of animals به ترتیب خاصی ظاهر می‌شود. اگر database می‌خواهد فضای دیسک استفاده نشده را در پشت صحنه بازیابی کند، ممکن است نیاز داشته باشد که records را جابجا کند و ترتیب ظاهر شدن animals را تغییر دهد. آیا database می‌تواند این کار را با خیال راحت انجام دهد، بدون اینکه queries را خراب کند؟
    </p>
<p>
        مثال SQL هیچ order خاصی را تضمین نمی‌کند و بنابراین اگر order تغییر کند، مشکلی ندارد. اما اگر query به عنوان imperative code نوشته شود، database هرگز نمی‌تواند مطمئن باشد که آیا کد به order وابسته است یا خیر. این واقعیت که SQL در عملکرد محدودتر است، به database فضای بیشتری برای optimizations خودکار می‌دهد.
    </p>
<p>
        در نهایت، declarative languages اغلب خود را به execution parallel می‌سپارند. امروزه، CPUs با افزودن cores بیشتر، سریع‌تر می‌شوند، نه با running در سرعت clock بسیار بالاتر از قبل [31]. Parallelize کردن imperative code در سراسر multiple cores و multiple machines بسیار دشوار است، زیرا دستورالعمل‌هایی را مشخص می‌کند که باید به ترتیب خاصی انجام شوند. declarative languages شانس بهتری برای سریع‌تر شدن در execution parallel دارند زیرا آن‌ها فقط الگوی نتایج را مشخص می‌کنند، نه الگوریتمی که برای تعیین نتایج استفاده می‌شود. database آزاد است که از یک پیاده‌سازی parallel از query language، در صورت لزوم، استفاده کند [32].
    </p>
<p>
        Query Languages for Data | 43
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0065</div>
            </div>
        </div>
        <!-- Page 0066 -->
        <div class="chapter" id="page-0066">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<h4>Declarative Queries on the Web</h4>
<p>
        مزایای declarative query languages فقط به databases محدود نمی‌شود. برای نشان دادن این نکته، بیایید رویکردهای declarative و imperative را در یک محیط کاملاً متفاوت مقایسه کنیم: یک web browser.
    </p>
<p>
        فرض کنید شما یک وب‌سایت در مورد حیوانات در اقیانوس دارید. user در حال حاضر صفحه مربوط به sharks را مشاهده می‌کند، بنابراین شما آیتم navigation “Sharks” را به عنوان انتخاب شده علامت‌گذاری می‌کنید، مانند این:
    </p>
<pre><code class="language-html">&lt;ul&gt;
    &lt;li class="selected"&gt; 
        &lt;p&gt;Sharks&lt;/p&gt; 
        &lt;ul&gt;
            &lt;li&gt;Great White Shark&lt;/li&gt;
            &lt;li&gt;Tiger Shark&lt;/li&gt;
            &lt;li&gt;Hammerhead Shark&lt;/li&gt;
        &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;
        &lt;p&gt;Whales&lt;/p&gt;
        &lt;ul&gt;
            &lt;li&gt;Blue Whale&lt;/li&gt;
            &lt;li&gt;Humpback Whale&lt;/li&gt;
            &lt;li&gt;Fin Whale&lt;/li&gt;
        &lt;/ul&gt;
    &lt;/li&gt;
&lt;/ul&gt;
</code></pre>
<p>
        آیتم selected با CSS class "selected" نشان داده شده است.
    </p>
<p>
        &lt;p&gt;Sharks&lt;/p&gt; عنوان صفحه انتخاب شده فعلی است.
    </p>
<p>
        اکنون فرض کنید می‌خواهید title صفحه انتخاب شده فعلی دارای پس‌زمینه آبی باشد تا بصری برجسته شود. این کار با استفاده از CSS آسان است:
    </p>
<pre><code class="language-css">li.selected &gt; p {
    background-color: blue;
}
</code></pre>
<p>
        در اینجا CSS selector li.selected &gt; p الگوی عناصری را که می‌خواهیم style آبی را به آن‌ها اعمال کنیم، اعلام می‌کند: یعنی، همه عناصر &lt;p&gt; که parent مستقیم آن‌ها یک عنصر &lt;li&gt; با یک CSS class از selected است. عنصر &lt;p&gt;Sharks&lt;/p&gt; در مثال با این الگو مطابقت دارد، اما &lt;p&gt;Whales&lt;/p&gt; مطابقت ندارد زیرا parent &lt;li&gt; آن فاقد class="selected" است.
    </p>
<p>
        44 | Chapter 2: Data Models and Query Languages
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0066</div>
            </div>
        </div>
        <!-- Page 0067 -->
        <div class="chapter" id="page-0067">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        If you were using XSL instead of CSS, you could do something similar:
    </p>
<pre><code class="language-xml">&lt;xsl:template match="li[@class='selected']/p"&gt;
    &lt;fo:block background-color="blue"&gt;
        &lt;xsl:apply-templates/&gt;
    &lt;/fo:block&gt;
&lt;/xsl:template&gt;
</code></pre>
<p>
        Here, the XPath expression li[@class='selected']/p is equivalent to the CSS selec‐tor li.selected &gt; p in the previous example. What CSS and XSL have in common is that they are both declarative languages for specifying the styling of a document.
    </p>
<p>
        تصور کنید اگر مجبور بودید از یک رویکرد imperative استفاده کنید، زندگی چگونه بود. در JavaScript، با استفاده از core Document Object Model (DOM) API، نتیجه ممکن است چیزی شبیه این باشد:
    </p>
<pre><code class="language-javascript">var liElements = document.getElementsByTagName("li");
for (var i = 0; i &lt; liElements.length; i++) {
    if (liElements[i].className === "selected") {
        var children = liElements[i].childNodes;
        for (var j = 0; j &lt; children.length; j++) {
            var child = children[j];
            if (child.nodeType === Node.ELEMENT_NODE &amp;&amp; child.tagName === "P") {
                child.setAttribute("style", "background-color: blue");
            }
        }
    }
}
</code></pre>
<p>
        این JavaScript به طور imperative عنصر &lt;p&gt;Sharks&lt;/p&gt; را تنظیم می‌کند تا دارای پس‌زمینه آبی باشد، اما کد وحشتناک است. نه تنها بسیار طولانی‌تر و دشوارتر از معادل‌های CSS و XSL است، بلکه مشکلات جدی نیز دارد:
    </p>
<ul>
<li>اگر selected class حذف شود (به عنوان مثال، به این دلیل که user روی صفحه دیگری کلیک می‌کند)، رنگ آبی حذف نمی‌شود، حتی اگر کد دوباره اجرا شود — و بنابراین item تا زمانی که کل صفحه دوباره بارگیری شود، برجسته باقی می‌ماند. با CSS، browser به طور خودکار تشخیص می‌دهد که چه زمانی rule li.selected &gt; p دیگر اعمال نمی‌شود و به محض حذف selected class، background آبی را حذف می‌کند.</li>
<li>اگر می‌خواهید از یک API جدید، مانند document.getElementsBy ClassName("selected") یا حتی document.evaluate()—که ممکن است performance را بهبود بخشد—استفاده کنید، باید کد را دوباره بنویسید. از سوی دیگر، vendors browser می‌توانند performance of CSS و XPath را بدون شکستن compatibility بهبود بخشند.</li>
</ul>
<p>
        Query Languages for Data | 45
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0067</div>
            </div>
        </div>
        <!-- Page 0068 -->
        <div class="chapter" id="page-0068">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        vi. IMS و CODASYL هر دو از imperative query APIs استفاده می‌کردند. Applications معمولاً از کد COBOL برای تکرار records در database، یک record در یک زمان استفاده می‌کردند [2, 16].
    </p>
<p>
        در یک web browser، استفاده از declarative CSS styling بسیار بهتر از دستکاری styles به صورت imperative در JavaScript است. به طور مشابه، در databases، declarative query languages مانند SQL بسیار بهتر از imperative query APIs عمل کردند.vi
    </p>
<h4>MapReduce Querying</h4>
<p>
        MapReduce یک programming model برای پردازش مقادیر زیادی از data به صورت bulk در سراسر machines است که توسط Google [33] محبوب شده است. یک فرم محدود از MapReduce توسط برخی از NoSQL datastores، از جمله MongoDB و CouchDB، به عنوان یک مکانیزم برای انجام queries read-only در سراسر documents پشتیبانی می‌شود.
    </p>
<p>
        MapReduce به طور کلی با جزئیات بیشتر در فصل 10 توضیح داده شده است. در حال حاضر، ما فقط به طور خلاصه در مورد استفاده MongoDB از این model بحث خواهیم کرد.
    </p>
<p>
        MapReduce نه یک declarative query language است و نه یک imperative query API کامل، بلکه چیزی در این بین است: منطق query با snippets of code بیان می‌شود که به طور مکرر توسط processing framework فراخوانی می‌شوند. این بر اساس توابع map (که همچنین با نام collect شناخته می‌شود) و reduce (که همچنین با نام fold یا inject شناخته می‌شود) است که در بسیاری از زبان‌های برنامه‌نویسی functional وجود دارند.
    </p>
<p>
        به عنوان مثال، تصور کنید شما یک زیست‌شناس دریایی هستید و هر بار که حیواناتی را در اقیانوس می‌بینید، یک record observation را به database خود اضافه می‌کنید. اکنون می‌خواهید گزارشی را تولید کنید که تعداد sharks که در هر ماه مشاهده کرده‌اید را بیان کند.
    </p>
<p>
        در PostgreSQL شما ممکن است آن query را به این صورت بیان کنید:
    </p>
<pre><code class="language-sql">SELECT date_trunc('month', observation_timestamp) AS observation_month, 
       sum(num_animals) AS total_animals
FROM observations
WHERE family = 'Sharks'
GROUP BY observation_month;
</code></pre>
<p>
        تابع date_trunc('month', timestamp) ماه تقویمی حاوی timestamp را تعیین می‌کند و یک timestamp دیگر را که نشان‌دهنده beginning of that month است، برمی‌گرداند. به عبارت دیگر، یک timestamp را به نزدیک‌ترین ماه گرد می‌کند.
    </p>
<p>
        این query ابتدا مشاهدات را فیلتر می‌کند تا فقط گونه‌هایی را در خانواده Sharks نشان دهد، سپس مشاهدات را بر اساس ماه تقویمی که در آن رخ داده‌اند، گروه‌بندی می‌کند و در نهایت تعداد حیواناتی را که در تمام مشاهدات در آن ماه دیده شده‌اند، جمع می‌کند.
    </p>
<p>
        همین را می‌توان با ویژگی MapReduce MongoDB به شرح زیر بیان کرد:
    </p>
<p>
        46 | Chapter 2: Data Models and Query Languages
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0068</div>
            </div>
        </div>
        <!-- Page 0069 -->
        <div class="chapter" id="page-0069">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<pre><code class="language-javascript">db.observations.mapReduce(
    function map() { 
        var year  = this.observationTimestamp.getFullYear();
        var month = this.observationTimestamp.getMonth() + 1;
        emit(year + "-" + month, this.numAnimals); 
    },
    function reduce(key, values) { 
        return Array.sum(values); 
    },
    {
        query: { family: "Sharks" }, 
        out: "monthlySharkReport" 
    }
);
</code></pre>
<p>
        فیلتر برای در نظر گرفتن فقط species sharks می‌تواند به صورت declarative مشخص شود (این یک extension MongoDB-specific به MapReduce است).
    </p>
<p>
        تابع JavaScript map یک بار برای هر document که با query مطابقت دارد، فراخوانی می‌شود، با این set به document object.
    </p>
<p>
        تابع map یک key (یک string متشکل از سال و ماه، مانند "2013-12" یا "2014-1") و یک value (تعداد حیوانات در آن observation) را emit می‌کند.
    </p>
<p>
        جفت‌های key-value که توسط map emit می‌شوند، توسط key گروه‌بندی می‌شوند. برای تمام جفت‌های key-value با همان key (یعنی همان ماه و سال)، تابع reduce یک بار فراخوانی می‌شود.
    </p>
<p>
        تابع reduce تعداد حیوانات را از تمام observations در یک ماه خاص جمع می‌کند.
    </p>
<p>
        خروجی نهایی به collection monthlySharkReport نوشته می‌شود.
    </p>
<p>
        به عنوان مثال، فرض کنید collection observations شامل این دو document است:
    </p>
<pre><code class="language-javascript">{
    observationTimestamp: Date.parse("Mon, 25 Dec 1995 12:34:56 GMT"),
    family:     "Sharks",
    species:    "Carcharodon carcharias",
    numAnimals: 3
}
{
    observationTimestamp: Date.parse("Tue, 12 Dec 1995 16:17:18 GMT"),
    family:     "Sharks",
    species:    "Carcharias taurus",
    numAnimals: 4
}
</code></pre>
<p>
        Query Languages for Data | 47
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0069</div>
            </div>
        </div>
        <!-- Page 0070 -->
        <div class="chapter" id="page-0070">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        تابع map یک بار برای هر document فراخوانی می‌شود، که منجر به emit("1995-12", 3) و emit("1995-12", 4) می‌شود. متعاقباً، تابع reduce با reduce("1995-12", [3, 4]) فراخوانی می‌شود که 7 را برمی‌گرداند.
    </p>
<p>
        توابع map و reduce تا حدودی در آنچه مجاز به انجام آن هستند، محدود شده‌اند. آن‌ها باید pure functions باشند، به این معنی که آن‌ها فقط از داده‌هایی استفاده می‌کنند که به عنوان ورودی به آن‌ها پاس داده می‌شود، نمی‌توانند queries database اضافی را انجام دهند و نباید هیچ side effects داشته باشند. این restrictions به database اجازه می‌دهد تا توابع را در هر جایی، به هر ترتیبی اجرا کند و آن‌ها را در صورت failure دوباره اجرا کند. با این حال، آن‌ها همچنان قدرتمند هستند: می‌توانند strings را parse کنند، توابع library را فراخوانی کنند، محاسبات را انجام دهند و موارد دیگر.
    </p>
<p>
        MapReduce یک programming model نسبتاً low-level برای execution distributed بر روی یک cluster of machines است. زبان‌های query high-level مانند SQL را می‌توان به عنوان یک pipeline از operations MapReduce پیاده‌سازی کرد (به فصل 10 مراجعه کنید)، اما همچنین پیاده‌سازی‌های distributed بسیاری از SQL وجود دارد که از MapReduce استفاده نمی‌کنند. توجه داشته باشید که هیچ چیز در SQL وجود ندارد که آن را به اجرا بر روی یک machine واحد محدود کند و MapReduce انحصار execution query distributed را ندارد.
    </p>
<p>
        توانایی استفاده از کد JavaScript در وسط یک query یک ویژگی عالی برای queries پیشرفته است، اما به MapReduce محدود نمی‌شود—برخی از SQL databases را می‌توان با توابع JavaScript نیز توسعه داد [34].
    </p>
<p>
        یک مشکل usability با MapReduce این است که شما باید دو تابع JavaScript با دقت هماهنگ شده بنویسید، که اغلب سخت‌تر از نوشتن یک query واحد است. علاوه بر این، یک declarative query language فرصت‌های بیشتری را برای یک query optimizer فراهم می‌کند تا performance یک query را بهبود بخشد. به همین دلایل، MongoDB 2.2 پشتیبانی از یک declarative query language به نام aggregation pipeline [9] را اضافه کرد. در این زبان، همان query shark-counting به این صورت است:
    </p>
<pre><code class="language-javascript">db.observations.aggregate([
    { $match: { family: "Sharks" } },
    { $group: {
        _id: {
            year:  { $year:  "$observationTimestamp" },
            month: { $month: "$observationTimestamp" }
        },
        totalAnimals: { $sum: "$numAnimals" }
    } }
]);
</code></pre>
<p>
        زبان aggregation pipeline از نظر expressiveness شبیه به یک subset از SQL است، اما از یک syntax مبتنی بر JSON به جای syntax جمله-style انگلیسی SQL استفاده می‌کند. این تفاوت شاید یک matter of taste باشد. نکته اخلاقی این داستان این است که یک سیستم NoSQL ممکن است خود را به طور تصادفی در حال بازآفرینی SQL بیابد، اگرچه در disguise.
    </p>
<p>
        48 | Chapter 2: Data Models and Query Languages
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0070</div>
            </div>
        </div>
        <!-- Page 0071 -->
        <div class="chapter" id="page-0071">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<h4>Graph-Like Data Models</h4>
<p>
        ما قبلاً دیدیم که relationships many-to-many یک distinguishing fea‐ture مهم بین data models مختلف هستند. اگر application شما عمدتاً دارای relationships one-to-many (داده‌های tree-structured) یا هیچ relationships بین records نیست، document model مناسب است.
    </p>
<p>
        اما اگر relationships many-to-many در داده‌های شما بسیار رایج باشد، چه؟ relational model می‌تواند موارد ساده relationships many-to-many را مدیریت کند، اما با پیچیده‌تر شدن connections در داده‌های شما، طبیعی‌تر است که شروع به مدل‌سازی داده‌های خود به عنوان یک graph کنید.
    </p>
<p>
        یک graph از دو نوع object تشکیل شده است: vertices (که به عنوان nodes یا entities نیز شناخته می‌شوند) و edges (که به عنوان relationships یا arcs نیز شناخته می‌شوند). بسیاری از انواع داده‌ها را می‌توان به عنوان یک graph مدل‌سازی کرد. نمونه‌های معمولی عبارتند از:
    </p>
<ul>
<li>Social graphs</li>
<li>Vertices افراد هستند و edges نشان می‌دهند که کدام افراد یکدیگر را می‌شناسند.</li>
<li>The web graph</li>
<li>Vertices صفحات وب هستند و edges نشان‌دهنده HTML links به صفحات دیگر هستند.</li>
<li>Road or rail networks</li>
<li>Vertices تقاطع‌ها هستند و edges نشان‌دهنده جاده‌ها یا خطوط راه‌آهن بین آن‌ها هستند.</li>
</ul>
<p>
        الگوریتم‌های well-known می‌توانند روی این graphs عمل کنند: به عنوان مثال، سیستم‌های car navigation به دنبال کوتاه‌ترین path بین دو نقطه در یک road network می‌گردند و PageRank می‌تواند در web graph برای تعیین محبوبیت یک web page و در نتیجه رتبه‌بندی آن در نتایج جستجو استفاده شود.
    </p>
<p>
        در مثال‌هایی که به‌تازگی ارائه شد، همه vertices در یک graph نشان‌دهنده همان نوع چیز (به ترتیب، افراد، صفحات وب یا تقاطع‌های جاده) هستند. با این حال، graphs به چنین داده‌های homogeneous محدود نمی‌شوند: استفاده به همان اندازه قدرتمند از graphs این است که یک راه سازگار برای ذخیره انواع کاملاً متفاوتی از objects در یک datastore واحد ارائه می‌دهد. به عنوان مثال، Facebook یک graph واحد را با انواع مختلفی از vertices و edges حفظ می‌کند: vertices نشان‌دهنده افراد، مکان‌ها، رویدادها، checkins و نظراتی هستند که توسط users ایجاد شده‌اند. edges نشان می‌دهند که کدام افراد با یکدیگر دوست هستند، کدام checkin در کدام location اتفاق افتاده است، چه کسی در مورد کدام post نظر داده است، چه کسی در کدام event شرکت کرده است و غیره [35].
    </p>
<p>
        در این بخش ما از مثال نشان داده شده در شکل 2-5 استفاده خواهیم کرد. این می‌تواند از یک social network یا یک database genealogical گرفته شود: دو نفر را نشان می‌دهد، Lucy از آیداهو و Alain از Beaune، France. آن‌ها ازدواج کرده‌اند و در لندن زندگی می‌کنند.
    </p>
<p>
        Graph-Like Data Models | 49
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0071</div>
            </div>
        </div>
        <!-- Page 0072 -->
        <div class="chapter" id="page-0072">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        شکل 2-5. نمونه‌ای از داده‌های graph-structured (boxes نشان‌دهنده vertices هستند، arrows نشان‌دهنده edges هستند).
    </p>
<p>
        راه‌های مختلف و مرتبط با هم برای structuring و querying data در graphs وجود دارد. در این بخش ما در مورد property graph model (که توسط Neo4j، Titan و InfiniteGraph پیاده‌سازی شده است) و triple-store model (که توسط Datomic، AllegroGraph و دیگران پیاده‌سازی شده است) بحث خواهیم کرد. ما به سه declarative query languages برای graphs نگاه خواهیم کرد: Cypher، SPARQL و Datalog. علاوه بر این‌ها، زبان‌های query graph imperative مانند Gremlin [36] و frameworks graph processing مانند Pregel (به فصل 10 مراجعه کنید) نیز وجود دارند.
    </p>
<h4>Property Graphs</h4>
<p>
        در property graph model، هر vertex شامل موارد زیر است:
    </p>
<ul>
<li>یک unique identifier</li>
<li>یک set از outgoing edges</li>
<li>یک set از incoming edges</li>
<li>یک collection از properties (جفت‌های key-value)</li>
</ul>
<p>
        هر edge شامل موارد زیر است:
    </p>
<ul>
<li>یک unique identifier</li>
<li>The vertex at which the edge starts (the tail vertex)</li>
</ul>
<p>
        50 | Chapter 2: Data Models and Query Languages
    </p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 72" src="page_0072/image_1.png"/></div>
</div>
                <div class="page-number">صفحه 0072</div>
            </div>
        </div>
        <!-- Page 0073 -->
        <div class="chapter" id="page-0073">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<ul>
<li>The vertex at which the edge ends (the head vertex)</li>
<li>A label to describe the kind of relationship between the two vertices</li>
<li>A collection of properties (key-value pairs)</li>
</ul>
<p>
        شما می‌توانید به یک graph store به عنوان متشکل از دو relational tables فکر کنید، یکی برای vertices و دیگری برای edges، همانطور که در Example 2-2 نشان داده شده است (این schema از PostgreSQL json datatype برای ذخیره properties از هر vertex یا edge استفاده می‌کند). head و tail vertex برای هر edge ذخیره می‌شوند. اگر شما set از incoming یا outgoing edges را برای یک vertex می‌خواهید، می‌توانید table edges را بر اساس head_vertex یا tail_vertex، به ترتیب query کنید.
    </p>
<p>
        Example 2-2. Representing a property graph using a relational schema
    </p>
<pre><code class="language-sql">CREATE TABLE vertices (
    vertex_id   integer PRIMARY KEY,
    properties  json
);
CREATE TABLE edges (
    edge_id     integer PRIMARY KEY,
    tail_vertex integer REFERENCES vertices (vertex_id),
    head_vertex integer REFERENCES vertices (vertex_id),
    label       text,
    properties  json
);
CREATE INDEX edges_tails ON edges (tail_vertex);
CREATE INDEX edges_heads ON edges (head_vertex);
</code></pre>
<p>
        Some important aspects of this model are:
    </p>
<ol>
<li>Any vertex can have an edge connecting it with any other vertex. There is no schema that restricts which kinds of things can or cannot be associated.</li>
<li>Given any vertex, you can efficiently find both its incoming and its outgoing edges, and thus traverse the graph—i.e., follow a path through a chain of vertices—both forward and backward. (That’s why Example 2-2 has indexes on both the tail_vertex and head_vertex columns.)</li>
<li>By using different labels for different kinds of relationships, you can store several different kinds of information in a single graph, while still maintaining a clean data model.</li>
</ol>
<p>
        These features give graphs a great deal of flexibility for data modeling, as illustrated in Figure 2-5. The figure shows a few things that would be difficult to express in a traditional relational schema, such as different kinds of regional structures in differ‐ent countries (France has départements and régions, whereas the US has counties and states), quirks of history such as a country within a country (ignoring for now the
    </p>
<p>
        Graph-Like Data Models | 51
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0073</div>
            </div>
        </div>
        <!-- Page 0074 -->
        <div class="chapter" id="page-0074">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        intricacies of sovereign states و nations)، و varying granularity of data (اقامتگاه فعلی Lucy به عنوان یک شهر مشخص شده است، در حالی که محل تولد او فقط در سطح یک state مشخص شده است).
    </p>
<p>
        شما می‌توانید تصور کنید که graph را گسترش دهید تا شامل بسیاری از حقایق دیگر در مورد Lucy و Alain، یا افراد دیگر نیز بشود. به عنوان مثال، شما می‌توانید از آن برای نشان دادن هر گونه food aller‐gies که آن‌ها دارند (با معرفی یک vertex برای هر allergen و یک edge بین یک person و یک allergen برای نشان دادن یک allergy) استفاده کنید و allergens را با مجموعه‌ای از vertices مرتبط کنید که نشان می‌دهند کدام foods حاوی کدام substances هستند. سپس می‌توانید یک query بنویسید تا بفهمید خوردن چه چیزی برای هر فرد ایمن است. Graphs برای evolvability خوب هستند: همانطور که شما features را به application خود اضافه می‌کنید، یک graph می‌تواند به راحتی برای accommodation تغییرات در data structures application شما گسترش یابد.
    </p>
<h4>The Cypher Query Language</h4>
<p>
        Cypher یک declarative query language برای property graphs است که برای database graph Neo4j ایجاد شده است [37]. (این نام از یک شخصیت در فیلم The Matrix گرفته شده است و با ciphers در رمزنگاری مرتبط نیست [38].)
    </p>
<p>
        Example 2-3 نشان می‌دهد که query Cypher برای درج بخش lefthand از شکل 2-5 در یک database graph. بقیه graph را می‌توان به طور مشابه اضافه کرد و برای خوانایی حذف شده است. به هر vertex یک نام نمادین مانند USA یا Idaho داده می‌شود و سایر قسمت‌های query می‌توانند از آن نام‌ها برای ایجاد edges بین vertices، با استفاده از یک arrow notation استفاده کنند: (Idaho) -[:WITHIN]-&gt; (USA) یک edge با برچسب WITHIN، با Idaho به عنوان tail node و USA به عنوان head node ایجاد می‌کند.
    </p>
<p>
        Example 2-3. A subset of the data in Figure 2-5, represented as a Cypher query
    </p>
<pre><code class="language-cypher">CREATE
  (NAmerica:Location {name:'North America', type:'continent'}),
  (USA:Location      {name:'United States', type:'country'  }),
  (Idaho:Location    {name:'Idaho',         type:'state'    }),
  (Lucy:Person       {name:'Lucy' }),
  (Idaho) -[:WITHIN]-&gt;  (USA)  -[:WITHIN]-&gt; (NAmerica),
  (Lucy)  -[:BORN_IN]-&gt; (Idaho)
</code></pre>
<p>
        هنگامی که تمام vertices و edges از شکل 2-5 به database اضافه می‌شوند، ما می‌توانیم شروع به پرسیدن سوالات جالب کنیم: به عنوان مثال، نام همه افرادی را که از ایالات متحده به اروپا مهاجرت کرده‌اند، پیدا کنید. برای دقیق‌تر شدن، در اینجا می‌خواهیم تمام vertices را پیدا کنیم که یک edge BORN_IN به یک location در ایالات متحده دارند و همچنین یک edge LIVING_IN به یک location در اروپا دارند و property name هر یک از آن vertices را برمی‌گردانیم.
    </p>
<p>
        Example 2-4 نشان می‌دهد که چگونه می‌توان آن query را در Cypher بیان کرد. از همان arrow notation در یک clause MATCH برای یافتن الگوها در graph استفاده می‌شود: (person) -[:BORN_IN]-&gt; ()
    </p>
<p>
        52 | Chapter 2: Data Models and Query Languages
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0074</div>
            </div>
        </div>
        <!-- Page 0075 -->
        <div class="chapter" id="page-0075">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        matches هر دو vertex که توسط یک edge با برچسب BORN_IN مرتبط هستند. The tail vertex از آن edge به متغیر person متصل است و the head vertex بدون نام باقی مانده است.
    </p>
<p>
        Example 2-4. Cypher query برای یافتن افرادی که از ایالات متحده به اروپا مهاجرت کرده‌اند
    </p>
<pre><code class="language-cypher">MATCH
  (person) -[:BORN_IN]-&gt;  () -[:WITHIN*0..]-&gt; (us:Location {name:'United States'}),
  (person) -[:LIVES_IN]-&gt; () -[:WITHIN*0..]-&gt; (eu:Location {name:'Europe'})
RETURN person.name
</code></pre>
<p>
        این query را می‌توان به این صورت خواند:
    </p>
<p>
        Find any vertex (call it person) که هر دو شرایط زیر را برآورده می‌کند:
    </p>
<ol>
<li>person دارای یک edge BORN_IN outgoing به یک vertex است. از آن vertex، شما می‌توانید یک chain از outgoing WITHIN edges را دنبال کنید تا در نهایت به یک vertex از type Location برسید که name property آن برابر با "United States" است.</li>
<li>همین person vertex همچنین دارای یک edge LIVES_IN outgoing است. با دنبال کردن آن edge و سپس یک chain از outgoing WITHIN edges، در نهایت به یک vertex از type Location می‌رسید که name property آن برابر با "Europe" است.</li>
</ol>
<p>
        For each such person vertex، property name را برمی‌گردانید.
    </p>
<p>
        راه‌های ممکن زیادی برای اجرای query وجود دارد. شرح ارائه شده در اینجا نشان می‌دهد که شما با scanning همه افراد در database شروع می‌کنید، birthplace و residence هر person را بررسی می‌کنید و فقط آن افرادی را که معیارهای مورد نظر را دارند برمی‌گردانید.
    </p>
<p>
        اما به طور معادل، شما می‌توانید با دو vertex Location شروع کنید و به عقب برگردید. اگر یک index بر روی name property وجود داشته باشد، احتمالاً می‌توانید دو vertices را که نشان‌دهنده ایالات متحده و اروپا هستند، به طور موثر پیدا کنید. سپس می‌توانید با دنبال کردن همه incoming WITHIN edges، به ترتیب، به دنبال تمام locations (states, regions, cities و غیره) در ایالات متحده و اروپا باشید. در نهایت، شما می‌توانید به دنبال افرادی باشید که می‌توانند از طریق یک edge BORN_IN یا LIVES_IN incoming در یکی از vertices location پیدا شوند.
    </p>
<p>
        همانطور که برای یک declarative query language معمول است، شما نیازی به مشخص کردن چنین execution details هنگام نوشتن query ندارید: query optimizer به طور خودکار strategy را انتخاب می‌کند که پیش‌بینی می‌شود کارآمدترین باشد، بنابراین شما می‌توانید بقیه application خود را بنویسید.
    </p>
<h4>Graph Queries in SQL</h4>
<p>
        Example 2-2 نشان داد که داده‌های graph را می‌توان در یک relational database نشان داد.
    </p>
<p>
        اما اگر ما data graph را در یک structure relational قرار دهیم، آیا می‌توانیم آن را با استفاده از SQL نیز query کنیم؟
    </p>
<p>
        پاسخ مثبت است، اما با کمی مشکل. در یک relational database، شما معمولاً از قبل می‌دانید که کدام joins را در query خود نیاز دارید. در یک graph query، شما ممکن است نیاز داشته باشید
    </p>
<p>
        Graph-Like Data Models | 53
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0075</div>
            </div>
        </div>
        <!-- Page 0076 -->
        <div class="chapter" id="page-0076">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        traverse a variable number of edges قبل از اینکه vertex مورد نظر خود را پیدا کنید—یعنی، تعداد joins از قبل ثابت نیست.
    </p>
<p>
        در مثال ما، این در rule () -[:WITHIN*0..]-&gt; () در query Cypher اتفاق می‌افتد. The LIVES_IN edge یک فرد ممکن است به هر نوع location اشاره کند: یک خیابان، یک شهر، یک district، یک region، یک state و غیره. یک شهر ممکن است WITHIN یک region باشد، یک region WITHIN یک state باشد، یک state WITHIN یک country و غیره. The LIVES_IN edge ممکن است مستقیماً به location ver‐tex که شما به دنبال آن هستید اشاره کند، یا ممکن است چندین سطح در hierarchy location حذف شود.
    </p>
<p>
        در Cypher، :WITHIN*0.. این واقعیت را بسیار مختصر بیان می‌کند: به این معنی است "follow a WITHIN edge، zero or more times." این مانند عملگر * در یک regular expression است.
    </p>
<p>
        از زمان SQL:1999، این ایده از variable-length traversal paths در یک query می‌تواند با استفاده از چیزی به نام recursive common table expressions (syntax WITH RECURSIVE) بیان شود. Example 2-5 همان query—یافتن نام افرادی که از ایالات متحده به اروپا مهاجرت کرده‌اند—را نشان می‌دهد که با استفاده از این تکنیک در SQL بیان شده است (که در PostgreSQL، IBM DB2، Oracle و SQL Server پشتیبانی می‌شود). با این حال، syntax در مقایسه با Cypher بسیار دست و پا چلفتی است.
    </p>
<p>
        Example 2-5. The same query as Example 2-4, expressed in SQL using recursive common table expressions
    </p>
<pre><code class="language-sql">WITH RECURSIVE
  -- in_usa is the set of vertex IDs of all locations within the United States
  in_usa(vertex_id) AS (
      SELECT vertex_id FROM vertices WHERE properties-&gt;&gt;'name' = 'United States' 
    UNION
      SELECT edges.tail_vertex FROM edges 
        JOIN in_usa ON edges.head_vertex = in_usa.vertex_id
        WHERE edges.label = 'within'
  ),
  -- in_europe is the set of vertex IDs of all locations within Europe
  in_europe(vertex_id) AS (
      SELECT vertex_id FROM vertices WHERE properties-&gt;&gt;'name' = 'Europe' 
    UNION
      SELECT edges.tail_vertex FROM edges
        JOIN in_europe ON edges.head_vertex = in_europe.vertex_id
        WHERE edges.label = 'within'
  ),
  -- born_in_usa is the set of vertex IDs of all people born in the US
  born_in_usa(vertex_id) AS ( 
    SELECT edges.tail_vertex FROM edges
      JOIN in_usa ON edges.head_vertex = in_usa.vertex_id
      WHERE edges.label = 'born_in'
  ),
</code></pre>
<p>
        54 | Chapter 2: Data Models and Query Languages
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0076</div>
            </div>
        </div>
        <!-- Page 0077 -->
        <div class="chapter" id="page-0077">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<pre><code class="language-sql"> -- lives_in_europe is the set of vertex IDs of all people living in Europe
  lives_in_europe(vertex_id) AS ( 
    SELECT edges.tail_vertex FROM edges
      JOIN in_europe ON edges.head_vertex = in_europe.vertex_id
      WHERE edges.label = 'lives_in'
  )
SELECT vertices.properties-&gt;&gt;'name'
FROM vertices
-- join to find those people who were both born in the US *and* live in Europe
JOIN born_in_usa     ON vertices.vertex_id = born_in_usa.vertex_id 
JOIN lives_in_europe ON vertices.vertex_id = lives_in_europe.vertex_id;
</code></pre>
<p>
        ابتدا vertex را پیدا کنید که name property آن دارای مقدار "United States" است و آن را به عنوان اولین عنصر از set of vertices in_usa قرار دهید.
    </p>
<p>
        تمام incoming within edges را از vertices در set in_usa دنبال کنید و آن‌ها را به همان set اضافه کنید، تا زمانی که از همه incoming within edges بازدید شود.
    </p>
<p>
        همین کار را با شروع از vertex که name property آن دارای مقدار "Europe" است، انجام دهید و set of vertices in_europe را بسازید.
    </p>
<p>
        برای هر یک از vertices در set in_usa، incoming born_in edges را دنبال کنید تا افرادی را که در مکانی در ایالات متحده متولد شده‌اند، پیدا کنید.
    </p>
<p>
        به طور مشابه، برای هر یک از vertices در set in_europe، incoming lives_in edges را دنبال کنید تا افرادی را که در اروپا زندگی می‌کنند، پیدا کنید.
    </p>
<p>
        در نهایت، set of people born in the USA را با set of people living in Europe با پیوستن به آن‌ها، intersect کنید.
    </p>
<p>
        اگر همان query را می‌توان در 4 خط در یک query language نوشت، اما به 29 خط در زبان دیگر نیاز دارد، این فقط نشان می‌دهد که data models مختلف برای پاسخگویی به use cases مختلف طراحی شده‌اند. انتخاب یک data model که برای application شما مناسب است، مهم است.
    </p>
<h4>Triple-Stores and SPARQL</h4>
<p>
        The triple-store model تقریباً معادل property graph model است و از کلمات مختلف برای توصیف ایده‌های یکسان استفاده می‌کند. با این وجود، ارزش بحث دارد، زیرا ابزارها و زبان‌های مختلفی برای triple-stores وجود دارد که می‌تواند additions ارزشمندی برای toolbox شما برای ساخت applications باشد.
    </p>
<p>
        در یک triple-store، تمام اطلاعات به شکل statements سه قسمتی بسیار ساده ذخیره می‌شوند: (subject, predicate, object). به عنوان مثال، در triple (Jim, likes, bananas)، Jim subject، likes predicate (فعل) و bananas object است.
    </p>
<p>
        Graph-Like Data Models | 55
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0077</div>
            </div>
        </div>
        <!-- Page 0078 -->
        <div class="chapter" id="page-0078">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        The subject of a triple معادل یک vertex در یک graph است. The object یکی از دو چیز است:
    </p>
<ol>
<li>یک value در یک datatype اولیه، مانند یک string یا یک عدد. در این صورت، predicate و object از triple معادل key و value از یک property روی subject vertex هستند. به عنوان مثال، (lucy, age, 33) مانند یک vertex lucy با properties {"age":33} است.</li>
<li>یک vertex دیگر در graph. در این صورت، predicate یک edge در graph است، subject the tail vertex است و object the head vertex است. به عنوان مثال، در (lucy, marriedTo, alain) subject و object lucy و alain هر دو vertices هستند و the predicate marriedTo برچسب edge است که آن‌ها را به هم متصل می‌کند.</li>
</ol>
<p>
        Example 2-6 همان data را به عنوان Example 2-3 نشان می‌دهد، که به عنوان triples در یک format به نام Turtle، یک subset از Notation3 (N3) [39] نوشته شده است.
    </p>
<p>
        Example 2-6. A subset of the data in Figure 2-5, represented as Turtle triples
    </p>
<pre><code class="language-turtle">@prefix : &lt;urn:example:&gt;.
_:lucy     a       :Person.
_:lucy     :name   "Lucy".
_:lucy     :bornIn _:idaho.
_:idaho    a       :Location.
_:idaho    :name   "Idaho".
_:idaho    :type   "state".
_:idaho    :within _:usa.
_:usa      a       :Location.
_:usa      :name   "United States".
_:usa      :type   "country".
_:usa      :within _:namerica.
_:namerica a       :Location.
_:namerica :name   "North America".
_:namerica :type   "continent".
</code></pre>
<p>
        در این مثال، vertices از graph به صورت _:someName نوشته می‌شوند. نام در خارج از این فایل معنایی ندارد. فقط وجود دارد زیرا در غیر این صورت ما نمی‌دانیم کدام triples به همان vertex اشاره دارند. هنگامی که predicate یک edge را نشان می‌دهد، object یک vertex است، مانند _:idaho :within _:usa. هنگامی که predicate یک property است، object یک string literal است، مانند _:usa :name "United States".
    </p>
<p>
        تکرار مکرر subject یکسان بسیار تکراری است، اما خوشبختانه شما می‌توانید از semicolons برای گفتن چندین چیز در مورد همان subject استفاده کنید. این کار format Turtle را بسیار خوب و خوانا می‌کند: به Example 2-7 مراجعه کنید.
    </p>
<p>
        56 | Chapter 2: Data Models and Query Languages
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0078</div>
            </div>
        </div>
        <!-- Page 0079 -->
        <div class="chapter" id="page-0079">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        vii. Technically، Datomic از 5-tuples به جای triples استفاده می‌کند. دو فیلد اضافی metadata برای version‐ing هستند.
    </p>
<p>
        Example 2-7. A more concise way of writing the data in Example 2-6
    </p>
<pre><code class="language-turtle">@prefix : &lt;urn:example:&gt;.
_:lucy     a :Person;   :name "Lucy";          :bornIn _:idaho.
_:idaho    a :Location; :name "Idaho";         :type "state";   :within _:usa.
_:usa      a :Location; :name "United States"; :type "country"; :within _:namerica.
_:namerica a :Location; :name "North America"; :type "continent".
</code></pre>
<h4>The semantic web</h4>
<p>
        اگر شما در مورد triple-stores بیشتر بخوانید، ممکن است وارد یک maelstrom از مقالات نوشته شده در مورد the semantic web شوید. The triple-store data model کاملاً مستقل از the semantic web است—به عنوان مثال، Datomic [40] یک triple-store است که ادعا نمی‌کند که هیچ ارتباطی با آن دارد.vii اما از آنجایی که این دو در ذهن بسیاری از مردم بسیار نزدیک به هم هستند، ما باید آن‌ها را به طور خلاصه مورد بحث قرار دهیم.
    </p>
<p>
        The semantic web اساساً یک ایده ساده و معقول است: وب‌سایت‌ها در حال حاضر اطلاعات را به عنوان متن و تصاویر برای خواندن توسط انسان‌ها منتشر می‌کنند، پس چرا آن‌ها اطلاعات را به عنوان داده‌های machine-readable برای خواندن توسط computers منتشر نمی‌کنند؟ The Resource Description Framework (RDF) [41] به عنوان یک مکانیزم برای وب‌سایت‌های مختلف در نظر گرفته شده بود تا data را در یک format سازگار منتشر کنند و به داده‌ها از وب‌سایت‌های مختلف اجازه دهد تا به طور خودکار در یک وب data—نوعی "database of everything" در سراسر اینترنت—ترکیب شوند.
    </p>
<p>
        متاسفانه، the semantic web در اوایل دهه 2000 overhyped شد، اما تاکنون هیچ نشانه‌ای از تحقق یافتن در عمل نشان نداده است، که باعث شده است بسیاری از مردم نسبت به آن بدبین شوند. همچنین از انبوهی از acronyms، پیشنهادهای استانداردهای بیش از حد پیچیده و hubris رنج برده است.
    </p>
<p>
        با این حال، اگر شما از آن شکست‌ها عبور کنید، کارهای خوب زیادی نیز از project the semantic web بیرون آمده است. Triples می‌توانند یک data model داخلی خوب برای applications باشند، حتی اگر شما هیچ علاقه‌ای به انتشار data RDF در the semantic web نداشته باشید.
    </p>
<h4>The RDF data model</h4>
<p>
        The Turtle language که ما در Example 2-7 استفاده کردیم، یک format human-readable برای data RDF است. گاهی اوقات RDF نیز در یک format XML نوشته می‌شود، که همان کار را بسیار verbosely انجام می‌دهد—به Example 2-8 مراجعه کنید. Turtle/N3 ترجیح داده می‌شود زیرا چشم‌نوازتر است و ابزارهایی مانند Apache Jena [42] می‌توانند در صورت لزوم، به طور خودکار بین formats RDF مختلف تبدیل کنند.
    </p>
<p>
        Graph-Like Data Models | 57
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0079</div>
            </div>
        </div>
        <!-- Page 0080 -->
        <div class="chapter" id="page-0080">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        Example 2-8. The data of Example 2-7, expressed using RDF/XML syntax
    </p>
<pre><code class="language-xml">&lt;rdf:RDF xmlns="urn:example:"
    xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"&gt;
  &lt;Location rdf:nodeID="idaho"&gt;
    &lt;name&gt;Idaho&lt;/name&gt;
    &lt;type&gt;state&lt;/type&gt;
    &lt;within&gt;
      &lt;Location rdf:nodeID="usa"&gt;
        &lt;name&gt;United States&lt;/name&gt;
        &lt;type&gt;country&lt;/type&gt;
        &lt;within&gt;
          &lt;Location rdf:nodeID="namerica"&gt;
            &lt;name&gt;North America&lt;/name&gt;
            &lt;type&gt;continent&lt;/type&gt;
          &lt;/Location&gt;
        &lt;/within&gt;
      &lt;/Location&gt;
    &lt;/within&gt;
  &lt;/Location&gt;
  &lt;Person rdf:nodeID="lucy"&gt;
    &lt;name&gt;Lucy&lt;/name&gt;
    &lt;bornIn rdf:nodeID="idaho"/&gt;
  &lt;/Person&gt;
&lt;/rdf:RDF&gt;
</code></pre>
<p>
        RDF به دلیل این واقعیت که برای internet-wide data exchange طراحی شده است، چند quirks دارد. The subject, predicate و object از یک triple اغلب URIs هستند. به عنوان مثال، یک predicate ممکن است یک URI مانند &lt;http://my-company.com/namespace#within&gt; یا &lt;http://my-company.com/namespace#lives_in&gt; باشد، به جای فقط WITHIN یا LIVES_IN. دلیل این طراحی این است که شما باید بتوانید data خود را با data شخص دیگری ترکیب کنید و اگر آن‌ها یک معنی متفاوت را به کلمه within یا lives_in متصل کنند، شما دچار conflict نخواهید شد زیرا predicates آن‌ها در واقع &lt;http://other.org/foo#within&gt; و &lt;http://other.org/foo#lives_in&gt; هستند.
    </p>
<p>
        URL &lt;http://my-company.com/namespace&gt; لزوماً نیازی به resolve شدن به چیزی ندارد—از دیدگاه RDF، این به سادگی یک namespace است. برای جلوگیری از سردرگمی احتمالی با URLs http://، مثال‌های این بخش از URIs غیر قابل حل مانند urn:example:within استفاده می‌کنند. خوشبختانه، شما فقط می‌توانید این prefix را یک بار در بالای فایل مشخص کنید و سپس آن را فراموش کنید.
    </p>
<p>
        58 | Chapter 2: Data Models and Query Languages
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0080</div>
            </div>
        </div>
        <!-- Page 0081 -->
        <div class="chapter" id="page-0081">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<h4>The SPARQL query language</h4>
<p>
        SPARQL یک query language برای triple-stores با استفاده از the RDF data model است [43]. (این یک acronym برای SPARQL Protocol and RDF Query Language است که "sparkle" تلفظ می‌شود.) قبل از Cypher است و از آنجایی که pattern matching از Cypher از SPARQL قرض گرفته شده است، آن‌ها بسیار شبیه به هم هستند [37].
    </p>
<p>
        The same query as before—finding people who have moved from the US to Europe—در SPARQL حتی conciseتر از Cypher است (به Example 2-9 مراجعه کنید).
    </p>
<p>
        Example 2-9. The same query as Example 2-4, expressed in SPARQL
    </p>
<pre><code class="language-sparql">PREFIX : &lt;urn:example:&gt;
SELECT ?personName WHERE {
  ?person :name ?personName.
  ?person :bornIn  / :within* / :name "United States".
  ?person :livesIn / :within* / :name "Europe".
}
</code></pre>
<p>
        ساختار بسیار شبیه است. دو عبارت زیر معادل هستند (متغیرها با یک علامت سوال در SPARQL شروع می‌شوند):
    </p>
<pre><code class="language-cypher">(person) -[:BORN_IN]-&gt; () -[:WITHIN*0..]-&gt; (location)   # Cypher
?person :bornIn / :within* ?location.                   # SPARQL
</code></pre>
<p>
        از آنجایی که RDF بین properties و edges تمایز قائل نمی‌شود، بلکه فقط از predicates برای هر دو استفاده می‌کند، شما می‌توانید از همان syntax برای matching properties استفاده کنید. در عبارت زیر، متغیر usa به هر vertex که دارای یک name property است که value آن string "United States" است، متصل است:
    </p>
<pre><code class="language-cypher">(usa {name:'United States'})   # Cypher
?usa :name "United States".    # SPARQL
</code></pre>
<p>
        SPARQL یک query language خوب است—حتی اگر the semantic web هرگز اتفاق نیفتد، می‌تواند یک ابزار قدرتمند برای استفاده applications به صورت داخلی باشد.
    </p>
<p>
        Graph-Like Data Models | 59
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0081</div>
            </div>
        </div>
        <!-- Page 0082 -->
        <div class="chapter" id="page-0082">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        viii. Datomic و Cascalog از یک syntax Clojure S-expression برای Datalog استفاده می‌کنند. در مثال‌های زیر ما از یک syntax Prolog استفاده می‌کنیم، که خواندن آن کمی آسان‌تر است، اما این هیچ تفاوت عملکردی ایجاد نمی‌کند.
    </p>
<h4>Graph Databases Compared to the Network Model</h4>
<p>
        در "Are Document Databases Repeating History?" در صفحه 36 ما در مورد اینکه چگونه CODASYL و relational model برای حل مشکل relationships many-to-many در IMS رقابت کردند، بحث کردیم. در نگاه اول، network model از CODASYL شبیه به graph model به نظر می‌رسد. آیا graph databases دومین ظهور CODASYL در disguise هستند؟
    </p>
<p>
        خیر. آن‌ها از چند جهت مهم با هم تفاوت دارند:
    </p>
<ul>
<li>در CODASYL، یک database دارای یک schema بود که مشخص می‌کرد کدام record type می‌تواند در کدام record type دیگر nested شود. در یک graph database، هیچ محدودیتی وجود ندارد: هر vertex می‌تواند یک edge به هر vertex دیگری داشته باشد. این امر انعطاف‌پذیری بیشتری را برای applications برای انطباق با تغییر requirements فراهم می‌کند.</li>
<li>در CODASYL، تنها راه رسیدن به یک record خاص، پیمایش یکی از access paths به آن بود. در یک graph database، شما می‌توانید مستقیماً با unique ID به هر vertex اشاره کنید، یا می‌توانید از یک index برای یافتن vertices با یک value خاص استفاده کنید.</li>
<li>در CODASYL، children از یک record یک set مرتب شده بودند، بنابراین database مجبور بود آن ordering را حفظ کند (که عواقبی برای storage layout داشت) و applications که records جدید را در database درج می‌کردند، باید در مورد positions از records جدید در این sets نگران می‌بودند. در یک graph database، vertices و edges مرتب نشده‌اند (شما فقط می‌توانید نتایج را هنگام انجام یک query مرتب کنید).</li>
<li>در CODASYL، تمام queries imperative بودند، نوشتن آن‌ها دشوار بود و به راحتی با تغییرات در schema شکسته می‌شدند. در یک graph database، شما می‌توانید traversal خود را در imperative code بنویسید اگر بخواهید، اما اکثر graph databases همچنین از high-level, declarative query languages مانند Cypher یا SPARQL پشتیبانی می‌کنند.</li>
</ul>
<h4>The Foundation: Datalog</h4>
<p>
        Datalog یک زبان بسیار قدیمی‌تر از SPARQL یا Cypher است که توسط محققان در دهه 1980 به طور گسترده مورد مطالعه قرار گرفته است [44, 45, 46]. در بین software engineers کمتر شناخته شده است، اما با این وجود مهم است، زیرا این پایه را فراهم می‌کند که later query languages بر روی آن ساخته می‌شوند.
    </p>
<p>
        در عمل، Datalog در چند data systems استفاده می‌شود: به عنوان مثال، این زبان query از Datomic [40] است و Cascalog [47] یک پیاده‌سازی Datalog برای querying large datasets در Hadoop است.viii
    </p>
<p>
        60 | Chapter 2: Data Models and Query Languages
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0082</div>
            </div>
        </div>
        <!-- Page 0083 -->
        <div class="chapter" id="page-0083">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        Datalog’s data model شبیه به triple-store model است، که کمی generalize شده است. به جای نوشتن یک triple به صورت (subject, predicate, object)، ما آن را به صورت predicate(subject, object) می‌نویسیم.
    </p>
<p>
        Example 2-10 نشان می‌دهد که چگونه داده‌ها را از مثال ما در Datalog بنویسیم.
    </p>
<p>
        Example 2-10. A subset of the data in Figure 2-5, represented as Datalog facts
    </p>
<pre><code class="language-prolog">name(namerica, 'North America').
type(namerica, continent).
name(usa, 'United States').
type(usa, country).
within(usa, namerica).
name(idaho, 'Idaho').
type(idaho, state).
within(idaho, usa).
name(lucy, 'Lucy').
born_in(lucy, idaho).
</code></pre>
<p>
        اکنون که data را تعریف کردیم، می‌توانیم همان query را مانند قبل بنویسیم، همانطور که در Example 2-11 نشان داده شده است. این کمی متفاوت از معادل آن در Cypher یا SPARQL به نظر می‌رسد، اما اجازه ندهید که شما را منصرف کند. Datalog یک subset از Prolog است، که اگر علوم کامپیوتر را مطالعه کرده باشید، ممکن است قبلاً آن را دیده باشید.
    </p>
<p>
        Example 2-11. The same query as Example 2-4, expressed in Datalog
    </p>
<pre><code class="language-prolog">within_recursive(Location, Name) :- name(Location, Name).     /* Rule 1 */
within_recursive(Location, Name) :- within(Location, Via),    /* Rule 2 */
                                    within_recursive(Via, Name).
migrated(Name, BornIn, LivingIn) :- name(Person, Name),       /* Rule 3 */
                                    born_in(Person, BornLoc),
                                    within_recursive(BornLoc, BornIn),
                                    lives_in(Person, LivingLoc),
                                    within_recursive(LivingLoc, LivingIn).
?- migrated(Who, 'United States', 'Europe').
/* Who = 'Lucy'. */
</code></pre>
<p>
        Cypher و SPARQL بلافاصله با SELECT وارد می‌شوند، اما Datalog گام به گام پیش می‌رود. ما قوانینی را تعریف می‌کنیم که در مورد predicates جدید به database می‌گویند: در اینجا، ما دو predicate جدید، within_recursive و migrated را تعریف می‌کنیم. این predicates triples نیستند که در database ذخیره شده‌اند، بلکه از داده‌ها یا از other rules مشتق شده‌اند.
    </p>
<p>
        Rules می‌توانند به other rules، درست مانند توابعی که می‌توانند توابع دیگر را فراخوانی کنند یا خود را به صورت recursive فراخوانی کنند، اشاره کنند. مانند این، queries پیچیده را می‌توان یک قطعه کوچک در یک زمان ساخت.
    </p>
<p>
        Graph-Like Data Models | 61
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0083</div>
            </div>
        </div>
        <!-- Page 0084 -->
        <div class="chapter" id="page-0084">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        در rules، کلماتی که با حرف بزرگ شروع می‌شوند متغیر هستند و predicates مانند Cypher و SPARQL مطابقت دارند. به عنوان مثال، name(Location, Name) با triple name(namerica, 'North America') با variable bindings Location = namerica و Name = 'North America' مطابقت دارد.
    </p>
<p>
        یک rule اعمال می‌شود اگر سیستم بتواند یک match برای تمام predicates در سمت راست عملگر :- پیدا کند. وقتی rule اعمال می‌شود، به این صورت است که انگار سمت چپ از :- به database اضافه شده است (با متغیرهایی که با values که با آن‌ها مطابقت داشتند، جایگزین شده‌اند).
    </p>
<p>
        یک راه ممکن برای اعمال rules به این صورت است:
    </p>
<ol>
<li>name(namerica, 'North America') در database وجود دارد، بنابراین rule 1 اعمال می‌شود. این within_recursive(namerica, 'North America') را تولید می‌کند.</li>
<li>within(usa, namerica) در database وجود دارد و گام قبل within_recursive(namerica, 'North America') را تولید کرد، بنابراین rule 2 اعمال می‌شود. این within_recursive(usa, 'North America') را تولید می‌کند.</li>
<li>within(idaho, usa) در database وجود دارد و گام قبل within_recursive(usa, 'North America') را تولید کرد، بنابراین rule 2 اعمال می‌شود. این within_recursive(idaho, 'North America') را تولید می‌کند.</li>
</ol>
<p>
        با اعمال مکرر rules 1 و 2، predicate within_recursive می‌تواند تمام locations در North America (یا هر نام location دیگری) را که در database ما وجود دارد، به ما بگوید. این فرآیند در شکل 2-6 نشان داده شده است.
    </p>
<p>
        شکل 2-6. Determining که Idaho در North America است، با استفاده از Datalog rules از Example 2-11.
    </p>
<p>
        اکنون rule 3 می‌تواند افرادی را که در مکانی BornIn متولد شده‌اند و در مکانی LivingIn زندگی می‌کنند، پیدا کند. با querying با BornIn = 'United States' و LivingIn = 'Europe' و رها کردن person به عنوان یک متغیر Who، ما از سیستم Datalog می‌خواهیم بفهمد چه values می‌توانند برای متغیر Who ظاهر شوند. بنابراین، در نهایت ما همان پاسخ را در queries قبلی Cypher و SPARQL دریافت می‌کنیم.
    </p>
<p>
        62 | Chapter 2: Data Models and Query Languages
    </p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 84" src="page_0084/image_1.png"/></div>
</div>
                <div class="page-number">صفحه 0084</div>
            </div>
        </div>
        <!-- Page 0085 -->
        <div class="chapter" id="page-0085">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        The Datalog approach به یک نوع تفکر متفاوت با سایر query lan‐guages که در این فصل مورد بحث قرار گرفت، نیاز دارد، اما یک رویکرد بسیار قدرتمند است، زیرا rules را می‌توان در queries مختلف ترکیب و استفاده مجدد کرد. این برای simple one-off queries مناسب نیست، اما اگر data شما complex باشد، می‌تواند بهتر از عهده آن برآید.
    </p>
<h4>Summary</h4>
<p>
        Data models یک موضوع بزرگ هستند و در این فصل ما به سرعت به طیف گسترده‌ای از models مختلف نگاهی انداختیم. ما فضای کافی برای پرداختن به تمام جزئیات هر model را نداشتیم، اما امیدواریم که این overview برای اینکه شما را به پیدا کردن اطلاعات بیشتر در مورد model که به بهترین وجه با requirements application شما مطابقت دارد، ترغیب کند، کافی بوده باشد.
    </p>
<p>
        از نظر تاریخی، data ابتدا به عنوان یک tree بزرگ (the hierarchical model) نشان داده می‌شد، اما برای نشان دادن relationships many-to-many خوب نبود، بنابراین relational model برای حل این مشکل اختراع شد. اخیراً، developers دریافتند که برخی از applications نیز به خوبی در relational model قرار نمی‌گیرند. New nonrelational "NoSQL" datastores در دو جهت اصلی واگرا شده‌اند:
    </p>
<ol>
<li>Document databases use cases را هدف قرار می‌دهند که data در documents خودکفا وارد می‌شود و relationships بین یک document و دیگری نادر است.</li>
<li>Graph databases در جهت مخالف حرکت می‌کنند و use cases را هدف قرار می‌دهند که در آن‌ها هر چیزی بالقوه به همه چیز مرتبط است.</li>
</ol>
<p>
        هر سه model (document, relational و graph) امروزه به طور گسترده مورد استفاده قرار می‌گیرند و هر کدام در دامنه مربوطه خود خوب هستند. یک model را می‌توان از نظر یک model دیگر شبیه‌سازی کرد—به عنوان مثال، data graph را می‌توان در یک relational database نشان داد—اما نتیجه اغلب ناخوشایند است. به همین دلیل است که ما systems مختلفی برای اهداف مختلف داریم، نه یک راه‌حل واحد.
    </p>
<p>
        یک چیزی که document و graph databases مشترک دارند این است که آن‌ها معمولاً یک schema را برای داده‌هایی که ذخیره می‌کنند، اعمال نمی‌کنند، که می‌تواند انطباق applications با تغییر requirements را آسان‌تر کند. با این حال، application شما به احتمال زیاد هنوز فرض می‌کند که داده‌ها ساختار خاصی دارند. این فقط یک سوال است که آیا schema صریح است (در زمان write اعمال می‌شود) یا ضمنی (در زمان read مدیریت می‌شود).
    </p>
<p>
        هر data model همراه با query language یا framework خود است و ما چندین مثال را مورد بحث قرار دادیم: SQL, MapReduce, MongoDB’s aggregation pipeline, Cypher, SPARQL و Datalog. ما همچنین به CSS و XSL/XPath اشاره کردیم، که query languages database نیستند اما شباهت‌های جالبی دارند.
    </p>
<p>
        اگرچه ما زمین‌های زیادی را پوشش داده‌ایم، اما هنوز هم بسیاری از data models ذکر نشده‌اند. برای ارائه فقط چند نمونه مختصر:
    </p>
<ul>
<li>Researchers که با data genome کار می‌کنند، اغلب نیاز به انجام searches sequence-similarity دارند، به این معنی که یک string بسیار طولانی (نشان‌دهنده a</li>
</ul>
<p>
        Summary | 63
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0085</div>
            </div>
        </div>
        <!-- Page 0086 -->
        <div class="chapter" id="page-0086">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<ul>
<li>Researchers که با data genome کار می‌کنند، اغلب نیاز به انجام searches sequence-similarity دارند، به این معنی که یک string بسیار طولانی (نشان‌دهنده یک مولکول DNA) را می‌گیرند و آن را با یک database بزرگ از strings که similar هستند، اما یکسان نیستند، مطابقت می‌دهند. هیچ یک از databases که در اینجا توضیح داده شد، نمی‌توانند این نوع usage را مدیریت کنند، به همین دلیل است که researchers نرم‌افزار database genome تخصصی مانند GenBank [48] را نوشته‌اند.</li>
<li>فیزیکدانان ذرات، دهه‌هاست که در حال انجام data analysis به سبک Big Data-style در مقیاس بزرگ هستند و پروژه‌هایی مانند Large Hadron Collider (LHC) اکنون با صدها پتابایت کار می‌کنند! در چنین مقیاسی، راه‌حل‌های سفارشی مورد نیاز هستند تا از خارج شدن hardware cost از کنترل جلوگیری شود [49].</li>
<li>Full-text search مسلماً یک نوع data model است که اغلب در کنار databases استفاده می‌شود. Information retrieval یک موضوع تخصصی بزرگ است که ما در این کتاب با جزئیات زیاد پوشش نخواهیم داد، اما ما به search indexes در فصل 3 و قسمت III اشاره خواهیم کرد.</li>
</ul>
<p>
        ما باید فعلاً به همین‌جا اکتفا کنیم. در فصل بعد، ما در مورد برخی از trade-offs که هنگام پیاده‌سازی data models توضیح داده شده در این فصل مطرح می‌شوند، بحث خواهیم کرد.
    </p>
<h4>References</h4>
<p>
        [1] Edgar F. Codd: “A Relational Model of Data for Large Shared Data Banks,” Communications of the ACM, volume 13, number 6, pages 377–387, June 1970. doi: 10.1145/362384.362685
    </p>
<p>
        [2] Michael Stonebraker and Joseph M. Hellerstein: “What Goes Around Comes Around,” in Readings in Database Systems, 4th edition, MIT Press, pages 2–41, 2005. ISBN: 978-0-262-69314-1
    </p>
<p>
        [3] Pramod J. Sadalage and Martin Fowler: NoSQL Distilled. Addison-Wesley, August 2012. ISBN: 978-0-321-82662-6
    </p>
<p>
        [4] Eric Evans: “NoSQL: What’s in a Name?,” blog.sym-link.com, October 30, 2009.
    </p>
<p>
        [5] James Phillips: “Surprises in Our NoSQL Adoption Survey,” blog.couchbase.com, February 8, 2012.
    </p>
<p>
        [6] Michael Wagner: SQL/XML:2006 – Evaluierung der Standardkonformität ausgewählter Datenbanksysteme. Diplomica Verlag, Hamburg, 2010. ISBN: 978-3-836-64609-3
    </p>
<p>
        [7] “XML Data in SQL Server,” SQL Server 2012 documentation, technet.microsoft.com, 2013.
    </p>
<p>
        [8] “PostgreSQL 9.3.1 Documentation,” The PostgreSQL Global Development Group, 2013.
    </p>
<p>
        [9] “The MongoDB 2.4 Manual,” MongoDB, Inc., 2013.
    </p>
<p>
        64 | Chapter 2: Data Models and Query Languages
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0086</div>
            </div>
        </div>
        <!-- Page 0087 -->
        <div class="chapter" id="page-0087">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        [10] “RethinkDB 1.11 Documentation,” rethinkdb.com, 2013.
    </p>
<p>
        [11] “Apache CouchDB 1.6 Documentation,” docs.couchdb.org, 2014.
    </p>
<p>
        [12] Lin Qiao, Kapil Surlaker, Shirshanka Das, et al.: “On Brewing Fresh Espresso: LinkedIn’s Distributed Data Serving Platform,” at ACM International Conference on Management of Data (SIGMOD), June 2013.
    </p>
<p>
        [13] Rick Long, Mark Harrington, Robert Hain, and Geoff Nicholls: IMS Primer. IBM Redbook SG24-5352-00, IBM International Technical Support Organization, January 2000.
    </p>
<p>
        [14] Stephen D. Bartlett: “IBM’s IMS—Myths, Realities, and Opportunities,” The Clipper Group Navigator, TCG2013015LI, July 2013.
    </p>
<p>
        [15] Sarah Mei: “Why You Should Never Use MongoDB,” sarahmei.com, November 11, 2013.
    </p>
<p>
        [16] J. S. Knowles and D. M. R. Bell: “The CODASYL Model,” in Databases—Role and Structure: An Advanced Course, edited by P. M. Stocker, P. M. D. Gray, and M. P. Atkinson, pages 19–56, Cambridge University Press, 1984. ISBN: 978-0-521-25430-4
    </p>
<p>
        [17] Charles W. Bachman: “The Programmer as Navigator,” Communications of the ACM, volume 16, number 11, pages 653–658, November 1973. doi: 10.1145/355611.362534
    </p>
<p>
        [18] Joseph M. Hellerstein, Michael Stonebraker, and James Hamilton: “Architecture of a Database System,” Foundations and Trends in Databases, volume 1, number 2, pages 141–259, November 2007. doi:10.1561/1900000002
    </p>
<p>
        [19] Sandeep Parikh and Kelly Stirman: “Schema Design for Time Series Data in MongoDB,” blog.mongodb.org, October 30, 2013.
    </p>
<p>
        [20] Martin Fowler: “Schemaless Data Structures,” martinfowler.com, January 7, 2013.
    </p>
<p>
        [21] Amr Awadallah: “Schema-on-Read vs. Schema-on-Write,” at Berkeley EECS RAD Lab Retreat, Santa Cruz, CA, May 2009.
    </p>
<p>
        [22] Martin Odersky: “The Trouble with Types,” at Strange Loop, September 2013.
    </p>
<p>
        [23] Conrad Irwin: “MongoDB—Confessions of a PostgreSQL Lover,” at HTML5DevConf, October 2013.
    </p>
<p>
        [24] “Percona Toolkit Documentation: pt-online-schema-change,” Percona Ireland Ltd., 2013.
    </p>
<p>
        [25] Rany Keddo, Tobias Bielohlawek, and Tobias Schmidt: “Large Hadron Migra‐tor,” SoundCloud, 2013.
    </p>
<p>
        Summary | 65
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0087</div>
            </div>
        </div>
        <!-- Page 0088 -->
        <div class="chapter" id="page-0088">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        [26] Shlomi Noach: “gh-ost: GitHub’s Online Schema Migration Tool for MySQL,” githubengineering.com, August 1, 2016.
    </p>
<p>
        [27] James C. Corbett, Jeffrey Dean, Michael Epstein, et al.: “Spanner: Google’s Globally-Distributed Database,” at 10th USENIX Symposium on Operating System Design and Implementation (OSDI), October 2012.
    </p>
<p>
        [28] Donald K. Burleson: “Reduce I/O with Oracle Cluster Tables,” dba-oracle.com.
    </p>
<p>
        [29] Fay Chang, Jeffrey Dean, Sanjay Ghemawat, et al.: “Bigtable: A Distributed Storage System for Structured Data,” at 7th USENIX Symposium on Operating System Design and Implementation (OSDI), November 2006.
    </p>
<p>
        [30] Bobbie J. Cochrane and Kathy A. McKnight: “DB2 JSON Capabilities, Part 1: Introduction to DB2 JSON,” IBM developerWorks, June 20, 2013.
    </p>
<p>
        [31] Herb Sutter: “The Free Lunch Is Over: A Fundamental Turn Toward Concurrency in Software,” Dr. Dobb’s Journal, volume 30, number 3, pages 202-210, March 2005.
    </p>
<p>
        [32] Joseph M. Hellerstein: “The Declarative Imperative: Experiences and Conjectures in Distributed Logic,” Electrical Engineering and Computer Sciences, University of California at Berkeley, Tech report UCB/EECS-2010-90, June 2010.
    </p>
<p>
        [33] Jeffrey Dean and Sanjay Ghemawat: “MapReduce: Simplified Data Processing on Large Clusters,” at 6th USENIX Symposium on Operating System Design and Implementation (OSDI), December 2004.
    </p>
<p>
        [34] Craig Kerstiens: “JavaScript in Your Postgres,” blog.heroku.com, June 5, 2013.
    </p>
<p>
        [35] Nathan Bronson, Zach Amsden, George Cabrera, et al.: “TAO: Facebook’s Distributed Data Store for the Social Graph,” at USENIX Annual Technical Conference (USENIX ATC), June 2013.
    </p>
<p>
        [36] “Apache TinkerPop3.2.3 Documentation,” tinkerpop.apache.org, October 2016.
    </p>
<p>
        [37] “The Neo4j Manual v2.0.0,” Neo Technology, 2013.
    </p>
<p>
        [38] Emil Eifrem: Twitter correspondence, January 3, 2014.
    </p>
<p>
        [39] David Beckett and Tim Berners-Lee: “Turtle – Terse RDF Triple Language,” W3C Team Submission, March 28, 2011.
    </p>
<p>
        [40] “Datomic Development Resources,” Metadata Partners, LLC, 2013.
    </p>
<p>
        [41] W3C RDF Working Group: “Resource Description Framework (RDF),” w3.org, 10 February 2004.
    </p>
<p>
        [42] “Apache Jena,” Apache Software Foundation.
    </p>
<p>
        66 | Chapter 2: Data Models and Query Languages
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0088</div>
            </div>
        </div>
        <!-- Page 0089 -->
        <div class="chapter" id="page-0089">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        [43] Steve Harris, Andy Seaborne, and Eric Prud’hommeaux: “SPARQL 1.1 Query Language,” W3C Recommendation, March 2013.
    </p>
<p>
        [44] Todd J. Green, Shan Shan Huang, Boon Thau Loo, and Wenchao Zhou: “Datalog and Recursive Query Processing,” Foundations and Trends in Databases, volume 5, number 2, pages 105–195, November 2013. doi:10.1561/1900000017
    </p>
<p>
        [45] Stefano Ceri, Georg Gottlob, and Letizia Tanca: “What You Always Wanted to Know About Datalog (And Never Dared to Ask),” IEEE Transactions on Knowledge and Data Engineering, volume 1, number 1, pages 146–166, March 1989. doi: 10.1109/69.43410
    </p>
<p>
        [46] Serge Abiteboul, Richard Hull, and Victor Vianu: Foundations of Databases. Addison-Wesley, 1995. ISBN: 978-0-201-53771-0, available online at web‐dam.inria.fr/Alice
    </p>
<p>
        [47] Nathan Marz: “Cascalog,” cascalog.org.
    </p>
<p>
        [48] Dennis A. Benson, Ilene Karsch-Mizrachi, David J. Lipman, et al.: “GenBank,” Nucleic Acids Research, volume 36, Database issue, pages D25–D30, December 2007. doi:10.1093/nar/gkm929
    </p>
<p>
        [49] Fons Rademakers: “ROOT for Big Data Analysis,” at Workshop on the Future of Big Data Management, London, UK, June 2013.
    </p>
<p>
        Summary | 67
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0089</div>
            </div>
        </div>
        <!-- Page 0091 -->
        <div class="chapter" id="page-0091">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<h3>فصل 3</h3>
<h4>Storage و Retrieval</h4>
<p>
        Wer Ordnung hält, ist nur zu faul zum Suchen.
        (If you keep things tidily ordered, you’re just too lazy to go searching.)
        —German proverb
    </p>
<p>
        در اساسی‌ترین سطح، یک database باید دو کار را انجام دهد: وقتی شما به آن مقداری data می‌دهید، باید data را ذخیره کند و وقتی بعداً دوباره از آن درخواست می‌کنید، باید data را به شما برگرداند.
    </p>
<p>
        در فصل 2 ما در مورد data models و query languages بحث کردیم—یعنی، format که در آن شما (developer application) data خود را به database می‌دهید و مکانیزمی که به وسیله آن می‌توانید بعداً دوباره آن را درخواست کنید. در این فصل ما از دیدگاه database در مورد همین موضوع بحث می‌کنیم: چگونه می‌توانیم data را که به ما داده شده است، ذخیره کنیم و چگونه می‌توانیم دوباره آن را پیدا کنیم وقتی از ما درخواست می‌شود.
    </p>
<p>
        چرا شما، به عنوان یک developer application، باید به نحوه مدیریت internal storage و retrieval توسط database اهمیت دهید؟ شما احتمالاً موتور storage خود را از ابتدا پیاده‌سازی نخواهید کرد، اما شما نیاز دارید یک storage engine را انتخاب کنید که برای application شما مناسب باشد، از بین بسیاری از مواردی که در دسترس هستند. به منظور تنظیم یک storage engine برای عملکرد خوب در workload شما، شما باید یک ایده تقریبی از آنچه که storage engine در حال انجام آن است، داشته باشید.
    </p>
<p>
        به طور خاص، یک تفاوت بزرگ بین storage engines که برای transactional workloads بهینه شده‌اند و آن‌هایی که برای analytics بهینه شده‌اند، وجود دارد. ما در ادامه در "Transaction Processing or Analytics?" در صفحه 90، این تمایز را بررسی خواهیم کرد و در "Column-Oriented Storage" در صفحه 95 ما یک family از storage engines را که برای analytics بهینه شده است، مورد بحث قرار خواهیم داد.
    </p>
<p>
        با این حال، ابتدا این فصل را با صحبت در مورد storage engines که در انواع databases استفاده می‌شوند که شما احتمالاً با آن‌ها آشنا هستید، شروع خواهیم کرد: traditional relational data‐bases و همچنین اکثر databases به اصطلاح NoSQL. ما دو خانواده از
    </p>
<p>
        69
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0091</div>
            </div>
        </div>
        <!-- Page 0092 -->
        <div class="chapter" id="page-0092">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        storage engines: log-structured storage engines و page-oriented storage engines مانند B-trees.
    </p>
<h4>Data Structures That Power Your Database</h4>
<p>
        ساده‌ترین database جهان را در نظر بگیرید که به عنوان دو تابع Bash پیاده‌سازی شده است:
    </p>
<pre><code class="language-bash">#!/bin/bash
db_set () {
    echo "$1,$2" &gt;&gt; database
}
db_get () {
    grep "^$1," database | sed -e "s/^$1,//" | tail -n 1
}
</code></pre>
<p>
        این دو تابع یک key-value store را پیاده‌سازی می‌کنند. شما می‌توانید db_set key value را فراخوانی کنید، که key و value را در database ذخیره می‌کند. key و value می‌توانند (تقریباً) هر چیزی که دوست دارید باشند—به عنوان مثال، value می‌تواند یک document JSON باشد. سپس می‌توانید db_get key را فراخوانی کنید، که آخرین value مرتبط با آن key خاص را جستجو می‌کند و آن را برمی‌گرداند.
    </p>
<p>
        و کار می‌کند:
    </p>
<pre><code class="language-bash">$ db_set 123456 '{"name":"London","attractions":["Big Ben","London Eye"]}'
$ db_set 42 '{"name":"San Francisco","attractions":["Golden Gate Bridge"]}'
$ db_get 42
{"name":"San Francisco","attractions":["Golden Gate Bridge"]}
</code></pre>
<p>
        The underlying storage format بسیار ساده است: یک فایل متنی که هر خط آن شامل یک key-value pair است که با یک کاما از هم جدا شده‌اند (تقریباً مانند یک فایل CSV، با نادیده گرفتن مسائل مربوط به escaping). هر فراخوانی به db_set به انتهای فایل اضافه می‌شود، بنابراین اگر شما یک key را چندین بار به‌روزرسانی کنید، نسخه‌های قدیمی value بازنویسی نمی‌شوند—شما باید به آخرین occurrence یک key در یک فایل نگاه کنید تا آخرین value را پیدا کنید (از این رو tail -n 1 در db_get):
    </p>
<pre><code class="language-bash">$ db_set 42 '{"name":"San Francisco","attractions":["Exploratorium"]}'
$ db_get 42
{"name":"San Francisco","attractions":["Exploratorium"]}
$ cat database
123456,{"name":"London","attractions":["Big Ben","London Eye"]}
42,{"name":"San Francisco","attractions":["Golden Gate Bridge"]}
42,{"name":"San Francisco","attractions":["Exploratorium"]}
</code></pre>
<p>
        70 | Chapter 3: Storage and Retrieval
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0092</div>
            </div>
        </div>
        <!-- Page 0093 -->
        <div class="chapter" id="page-0093">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        در واقع تابع db_set ما برای چیزی که اینقدر ساده است، performance بسیار خوبی دارد، زیرا اضافه کردن به یک فایل عموماً بسیار کارآمد است. به طور مشابه با آنچه db_set انجام می‌دهد، بسیاری از databases به صورت داخلی از یک log استفاده می‌کنند که یک فایل داده append-only است. databases واقعی مشکلات بیشتری برای مقابله با آن‌ها دارند (مانند concurrency control، بازیابی فضای دیسک به طوری که log برای همیشه رشد نکند و handling errors و records که به طور جزئی نوشته شده‌اند)، اما اصل اساسی یکسان است. Logs باورنکردنی مفید هستند و ما آن‌ها را چندین بار در بقیه این کتاب مشاهده خواهیم کرد.
    </p>
<p>
        کلمه log اغلب برای اشاره به application logs استفاده می‌شود، جایی که یک application متنی را خروجی می‌دهد که آنچه را که در حال رخ دادن است، توضیح می‌دهد. در این کتاب، log در معنای general‌تر استفاده می‌شود: یک دنباله append-only از records. نیازی نیست که انسان-readable باشد. ممکن است باینری باشد و فقط برای خواندن توسط برنامه‌های دیگر در نظر گرفته شده باشد.
    </p>
<p>
        از طرف دیگر، تابع db_get ما اگر شما تعداد زیادی record در database خود داشته باشید، performance وحشتناکی دارد. هر بار که می‌خواهید یک key را جستجو کنید، db_get باید کل فایل database را از ابتدا تا انتها scan کند و به دنبال occurrences of the key باشد. از نظر الگوریتمی، هزینه یک lookup O(n) است: اگر شما تعداد records n را در database خود دو برابر کنید، یک lookup دو برابر طول می‌کشد. این خوب نیست.
    </p>
<p>
        به منظور یافتن کارآمد value برای یک key خاص در database، ما به یک data structure متفاوت نیاز داریم: یک index. در این فصل ما به طیف وسیعی از indexing structures نگاه خواهیم کرد و خواهیم دید که چگونه با هم مقایسه می‌شوند. ایده کلی پشت آن‌ها این است که مقداری metadata اضافی را در کنار خود نگه دارید، که به عنوان یک signpost عمل می‌کند و به شما کمک می‌کند داده‌های مورد نظر خود را پیدا کنید. اگر شما می‌خواهید data یکسان را به روش‌های مختلف جستجو کنید، ممکن است به چندین index متفاوت در قسمت‌های مختلف data نیاز داشته باشید.
    </p>
<p>
        یک index یک ساختار اضافی است که از داده‌های اولیه مشتق شده است. بسیاری از databases به شما اجازه می‌دهند تا indexes را اضافه و حذف کنید و این بر محتویات database تأثیری ندارد. این فقط بر performance of queries تأثیر می‌گذارد. حفظ ساختارهای اضافی، overhead ایجاد می‌کند، به خصوص در writes. برای writes، غلبه بر performance از append کردن ساده به یک فایل سخت است، زیرا این ساده‌ترین عمل write ممکن است. هر نوع index معمولاً سرعت writes را کاهش می‌دهد، زیرا index نیز باید هر بار که داده‌ها نوشته می‌شود، به‌روزرسانی شود.
    </p>
<p>
        این یک trade-off مهم در storage systems است: indexes که به خوبی انتخاب شده‌اند، queries read را سرعت می‌بخشند، اما هر index سرعت writes را کاهش می‌دهد. به همین دلیل، databases معمولاً به طور پیش‌فرض همه چیز را index نمی‌کنند، اما از شما—developer application یا database administrator—می‌خواهند که indexes را به صورت دستی، با استفاده از دانش شما از الگوهای query معمولی application، انتخاب کنید. سپس می‌توانید indexes را انتخاب کنید که بیشترین سود را برای application شما به ارمغان می‌آورند، بدون اینکه overhead بیشتری نسبت به آنچه لازم است، معرفی کنید.
    </p>
<p>
        Data Structures That Power Your Database | 71
    </p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 93" src="page_0093/image_1.png"/></div>
</div>
                <div class="page-number">صفحه 0093</div>
            </div>
        </div>
        <!-- Page 0094 -->
        <div class="chapter" id="page-0094">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<h4>Hash Indexes</h4>
<p>
        بیایید با indexes برای key-value data شروع کنیم. این تنها نوع data نیست که می‌توانید index کنید، اما بسیار رایج است و یک building block مفید برای indexes پیچیده‌تر است.
    </p>
<p>
        Key-value stores کاملاً شبیه به type dictionary هستند که می‌توانید در اکثر زبان‌های برنامه‌نویسی پیدا کنید و معمولاً به عنوان یک hash map (hash table) پیاده‌سازی می‌شوند. Hash maps در بسیاری از کتاب‌های درسی الگوریتم‌ها توضیح داده شده‌اند [1, 2]، بنابراین ما در اینجا به جزئیات نحوه عملکرد آن‌ها نمی‌پردازیم. از آنجایی که ما قبلاً hash maps را برای in-memory data structures خود داریم، چرا از آن‌ها برای index کردن data خود روی دیسک استفاده نکنیم؟
    </p>
<p>
        بگذارید بگوییم data storage ما فقط شامل اضافه کردن به یک فایل است، همانطور که در مثال قبلی بود. سپس ساده‌ترین strategy indexing ممکن این است: یک in-memory hash map را نگه دارید که در آن هر key به یک byte offset در فایل داده‌ها نگاشت می‌شود—مکانی که در آن value را می‌توان یافت، همانطور که در شکل 3-1 نشان داده شده است. هر زمان که شما یک key-value pair جدید را به فایل اضافه می‌کنید، شما همچنین hash map را به‌روزرسانی می‌کنید تا offset از data که تازه نوشته‌اید را منعکس کند (این هم برای درج keys جدید و هم برای به‌روزرسانی keys موجود کار می‌کند). وقتی می‌خواهید یک value را جستجو کنید، از hash map برای یافتن offset در فایل داده‌ها استفاده کنید، به آن location بروید و value را بخوانید.
    </p>
<p>
        شکل 3-1. ذخیره یک log از key-value pairs در یک format CSV-like، که با یک in-memory hash map index شده است.
    </p>
<p>
        این ممکن است ساده‌لوحانه به نظر برسد، اما یک رویکرد مناسب است. در واقع، این اساساً همان کاری است که Bitcask (storage engine پیش‌فرض در Riak) انجام می‌دهد [3]. Bitcask خواندن و نوشتن با performance بالا را ارائه می‌دهد، مشروط بر اینکه همه keys در RAM موجود قرار بگیرند، زیرا hash map کاملاً در memory نگهداری می‌شود. The values می‌توانند از فضای بیشتری نسبت به حافظه موجود استفاده کنند، زیرا می‌توانند از دیسک با فقط یک disk
    </p>
<p>
        72 | Chapter 3: Storage and Retrieval
    </p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 94" src="page_0094/image_1.png"/></div>
</div>
                <div class="page-number">صفحه 0094</div>
            </div>
        </div>
        <!-- Page 0095 -->
        <div class="chapter" id="page-0095">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        seek. If that part of the data file is already in the filesystem cache, a read doesn’t require any disk I/O at all.
    </p>
<p>
        یک storage engine مانند Bitcask برای موقعیت‌هایی که value برای هر key اغلب به‌روزرسانی می‌شود، مناسب است. به عنوان مثال، key ممکن است URL یک ویدیو گربه باشد و value ممکن است تعداد دفعاتی باشد که پخش شده است (هر بار که کسی دکمه play را فشار می‌دهد، افزایش می‌یابد). در این نوع workload، تعداد زیادی write وجود دارد، اما keys خیلی زیادی وجود ندارد—شما تعداد زیادی write در هر key دارید، اما نگه‌داشتن همه keys در memory امکان‌پذیر است.
    </p>
<p>
        همانطور که تا کنون توضیح داده شد، ما فقط به یک فایل اضافه می‌کنیم—بنابراین چگونه از تمام شدن فضای دیسک در نهایت جلوگیری می‌کنیم؟ یک راه‌حل خوب این است که log را به segmentهایی با اندازه مشخص تقسیم کنیم، با بستن یک فایل segment وقتی به اندازه مشخصی می‌رسد و انجام writes متعاقب به یک فایل segment جدید. سپس می‌توانیم compaction را بر روی این segments انجام دهیم، همانطور که در شکل 3-2 نشان داده شده است. Compaction به معنای دور انداختن keys duplicate در log و نگه‌داشتن فقط جدیدترین update برای هر key است.
    </p>
<p>
        شکل 3-2. Compaction از یک key-value update log (شمارش تعداد دفعاتی که هر ویدیو گربه پخش شده است)، فقط نگه‌داشتن most recent value برای هر key.
    </p>
<p>
        علاوه بر این، از آنجایی که compaction اغلب segments را بسیار کوچک‌تر می‌کند (با فرض اینکه یک key به طور متوسط چندین بار در یک segment بازنویسی می‌شود)، ما همچنین می‌توانیم چندین segments را همزمان با انجام compaction، ادغام کنیم، همانطور که در شکل 3-3 نشان داده شده است. Segments هرگز پس از نوشته شدن، اصلاح نمی‌شوند، بنابراین the merged segment به یک فایل جدید نوشته می‌شود. ادغام و compaction از frozen seg‐ments را می‌توان در یک background thread انجام داد و در حالی که در حال انجام است، ما هنوز هم می‌توانیم درخواست‌های read و write را به طور معمول، با استفاده از فایل‌های segment قدیمی، انجام دهیم. پس از completion process merging، ما درخواست‌های read را به استفاده از the new merged seg‐ment به جای segments قدیمی تغییر می‌دهیم—و سپس فایل‌های segment قدیمی را می‌توان به سادگی حذف کرد.
    </p>
<p>
        Data Structures That Power Your Database | 73
    </p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 95" src="page_0095/image_1.png"/></div>
</div>
                <div class="page-number">صفحه 0095</div>
            </div>
        </div>
        <!-- Page 0096 -->
        <div class="chapter" id="page-0096">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        شکل 3-3. انجام compaction و segment merging به طور همزمان.
    </p>
<p>
        هر segment اکنون hash table in-memory خود را دارد که keys را به file offsets نگاشت می‌کند. به منظور یافتن value برای یک key، ما ابتدا hash map جدیدترین segment را بررسی می‌کنیم. اگر key وجود نداشته باشد، ما دومین segment جدیدتر را بررسی می‌کنیم و به همین ترتیب. The merging process تعداد segments را کم نگه می‌دارد، بنابراین lookups نیازی به بررسی hash maps زیادی ندارند.
    </p>
<p>
        جزئیات زیادی برای عملی کردن این ایده ساده در عمل وجود دارد. به طور خلاصه، برخی از issues که در یک پیاده‌سازی واقعی مهم هستند، عبارتند از:
    </p>
<ul>
<li>File format</li>
<li>CSV بهترین format برای یک log نیست. استفاده از یک format باینری که ابتدا طول یک string را بر حسب بایت رمزگذاری می‌کند، و پس از آن string خام (بدون نیاز به escaping) سریع‌تر و ساده‌تر است.</li>
<li>Deleting records</li>
<li>اگر شما می‌خواهید یک key و value مرتبط با آن را حذف کنید، باید یک record deletion ویژه (که گاهی اوقات tombstone نامیده می‌شود) را به فایل data اضافه کنید. هنگامی که log seg‐ments ادغام می‌شوند، tombstone به process merging می‌گوید که هرگونه value قبلی را برای key حذف شده دور بریزد.</li>
<li>Crash recovery</li>
<li>اگر database دوباره راه‌اندازی شود، hash maps in-memory از دست می‌روند. در اصل، شما می‌توانید hash map هر segment را با خواندن کل فایل segment از ابتدا تا انتها و یادداشت offset از most recent value برای هر key در حین انجام این کار، بازیابی کنید. با این حال، اگر فایل‌های segment بزرگ باشند، این کار ممکن است زمان زیادی ببرد، که باعث می‌شود server restarts دردناک باشد. Bitcask recovery را با ذخیره کردن</li>
</ul>
<p>
        74 | Chapter 3: Storage and Retrieval
    </p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 96" src="page_0096/image_1.png"/></div>
</div>
                <div class="page-number">صفحه 0096</div>
            </div>
        </div>
        <!-- Page 0097 -->
        <div class="chapter" id="page-0097">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        a snapshot از hash map هر segment روی دیسک، که می‌تواند سریع‌تر در memory بارگذاری شود.
    </p>
<ul>
<li>Partially written records</li>
<li>The database ممکن است در هر زمانی crash کند، از جمله در نیمه راه اضافه کردن یک record به log. فایل‌های Bitcask شامل checksums هستند و اجازه می‌دهند تا چنین بخش‌های corrupted از log شناسایی و نادیده گرفته شوند.</li>
<li>Concurrency control</li>
<li>As writes به log به ترتیب کاملاً sequential اضافه می‌شوند، یک انتخاب common implementation این است که فقط یک writer thread داشته باشید. Data file segments append-only و در غیر این صورت immutable هستند، بنابراین می‌توانند به طور همزمان توسط multiple threads خوانده شوند.</li>
</ul>
<p>
        یک log append-only در نگاه اول هدر رفته به نظر می‌رسد: چرا شما فایل را در جای خود update نمی‌کنید، value قدیمی را با value جدید overwrite نمی‌کنید؟ اما یک طراحی append-only به چند دلیل خوب است:
    </p>
<ul>
<li>Appending و segment merging عملیات write sequential هستند، که عموماً بسیار سریع‌تر از random writes هستند، به خصوص در هارد دیسک‌های مغناطیسی spinning-disk. تا حدودی، writes sequential نیز در solid state drives (SSDs) مبتنی بر flash ترجیح داده می‌شوند [4]. ما این موضوع را در "Comparing B-Trees and LSM-Trees" در صفحه 83 بیشتر مورد بحث قرار خواهیم داد.</li>
<li>Concurrency و crash recovery بسیار ساده‌تر هستند اگر فایل‌های segment append-only یا immutable باشند. به عنوان مثال، شما نیازی به نگرانی در مورد موردی ندارید که در آن یک crash در حین overwrite شدن value رخ داده است، که شما را با یک فایل حاوی بخشی از old و بخشی از new value متصل شده، رها می‌کند.</li>
<li>Merging segments قدیمی از مشکل fragmented شدن فایل‌های داده در طول زمان جلوگیری می‌کند.</li>
</ul>
<p>
        با این حال، index hash table همچنین محدودیت‌هایی دارد:
    </p>
<ul>
<li>Hash table باید در memory جا شود، بنابراین اگر شما تعداد بسیار زیادی از keys دارید، شما شانسی ندارید. در اصل، شما می‌توانید یک hash map را روی دیسک نگهداری کنید، اما متأسفانه عملکرد خوب یک hash map روی دیسک دشوار است. این نیاز به مقدار زیادی از random access I/O دارد، رشد آن زمانی که پر می‌شود، گران است و hash collisions به منطق fiddly نیاز دارند [5].</li>
<li>Range queries کارآمد نیستند. به عنوان مثال، شما نمی‌توانید به راحتی همه keys بین kitty00000 و kitty99999 را scan کنید—شما باید هر key را به صورت جداگانه در hash maps جستجو کنید.</li>
</ul>
<p>
        در بخش بعد ما به یک structure indexing نگاه خواهیم کرد که آن limitations را ندارد.
    </p>
<p>
        Data Structures That Power Your Database | 75
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0097</div>
            </div>
        </div>
        <!-- Page 0098 -->
        <div class="chapter" id="page-0098">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<h4>SSTables و LSM-Trees</h4>
<p>
        در شکل 3-3، هر log-structured storage segment یک دنباله از key-value pairs است.
        این pairs به ترتیبی که نوشته شده‌اند ظاهر می‌شوند و values در log بعدی بر values برای همان key در log قبلی مقدم هستند. جدا از این، ترتیب key-value pairs در فایل مهم نیست.
    </p>
<p>
        اکنون می‌توانیم یک تغییر ساده در format از فایل‌های segment خود ایجاد کنیم: ما نیاز داریم که دنباله key-value pairs بر اساس key مرتب شود. در نگاه اول، به نظر می‌رسد که این requirement توانایی ما را برای استفاده از writes sequential از بین می‌برد، اما ما در یک لحظه به آن خواهیم رسید.
    </p>
<p>
        ما این format را Sorted String Table یا به اختصار SSTable می‌نامیم. ما همچنین نیاز داریم که هر key فقط یک بار در هر فایل segment merged ظاهر شود (the compaction process از قبل این را تضمین می‌کند). SSTables چندین مزیت بزرگ نسبت به log segments با hash indexes دارند:
    </p>
<ol>
<li>ادغام segments ساده و کارآمد است، حتی اگر فایل‌ها بزرگ‌تر از memory موجود باشند. این رویکرد مانند رویکردی است که در الگوریتم mergesort استفاده می‌شود و در شکل 3-4 نشان داده شده است: شما شروع به خواندن فایل‌های ورودی در کنار هم می‌کنید، به اولین key در هر فایل نگاه می‌کنید، کمترین key را (با توجه به sort order) به فایل خروجی کپی می‌کنید و تکرار می‌کنید. این یک فایل segment merged جدید تولید می‌کند، که همچنین بر اساس key مرتب شده است.</li>
</ol>
<p>
        شکل 3-4. Merging چندین segment SSTable، نگه‌داشتن فقط most recent value برای هر key.
    </p>
<p>
        76 | Chapter 3: Storage and Retrieval
    </p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 98" src="page_0098/image_1.png"/></div>
</div>
                <div class="page-number">صفحه 0098</div>
            </div>
        </div>
        <!-- Page 0099 -->
        <div class="chapter" id="page-0099">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        i. If all keys and values had a fixed size, you could use binary search on a segment file and avoid the in-memory index entirely. However, they are usually variable-length in practice, which makes it difficult to tell where one record ends and the next one starts if you don’t have an index.
    </p>
<p>
        What if the same key appears in several input segments? Remember that each segment contains all the values written to the database during some period of time. This means that all the values in one input segment must be more recent than all the values in the other segment (assuming that we always merge adjacent segments). When multiple segments contain the same key, we can keep the value from the most recent segment and discard the values in older segments.
    </p>
<ol>
<li>به منظور یافتن یک key خاص در فایل، شما دیگر نیازی به نگه‌داشتن یک index از همه keys در memory ندارید. به شکل 3-5 برای یک مثال مراجعه کنید: فرض کنید شما به دنبال key handiwork هستید، اما شما offset دقیق آن key را در فایل segment نمی‌دانید. با این حال، شما offsets را برای keys handbag و handsome می‌دانید و به دلیل sorting شما می‌دانید که handiwork باید بین آن دو ظاهر شود. این بدان معنی است که شما می‌توانید به offset برای handbag بروید و از آنجا تا زمانی که handiwork را پیدا می‌کنید، scan کنید (یا نه، اگر key در فایل وجود نداشته باشد).</li>
</ol>
<p>
        شکل 3-5. An SSTable با یک index in-memory.
    </p>
<p>
        شما هنوز به یک index in-memory نیاز دارید تا offsets را برای برخی از keys به شما بگوید، اما می‌تواند sparse باشد: یک key برای هر چند کیلوبایت از فایل segment کافی است، زیرا چند کیلوبایت را می‌توان بسیار سریع scan کرد.i
    </p>
<ol start="3">
<li>از آنجایی که درخواست‌های read در هر صورت نیاز به scan بر روی چندین key-value pairs در range درخواستی دارند، امکان گروه‌بندی آن records در یک block و compress کردن آن قبل از نوشتن آن روی دیسک وجود دارد (که توسط ناحیه سایه‌دار در شکل 3-5 نشان داده شده است). سپس هر ورودی از index in-memory sparse به ابتدای یک block compressed اشاره می‌کند.</li>
</ol>
<p>
        علاوه بر صرفه‌جویی در فضای دیسک، compression همچنین استفاده از پهنای باند I/O را کاهش می‌دهد.
    </p>
<p>
        Data Structures That Power Your Database | 77
    </p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 99" src="page_0099/image_1.png"/></div>
</div>
                <div class="page-number">صفحه 0099</div>
            </div>
        </div>
        <!-- Page 0100 -->
        <div class="chapter" id="page-0100">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<h4>Constructing and maintaining SSTables</h4>
<p>
        خوب تا اینجا—اما چگونه data شما را به ترتیب key در وهله اول مرتب می‌کنید؟ writes ورودی ما می‌توانند به هر ترتیبی رخ دهند.
    </p>
<p>
        حفظ یک structure مرتب شده روی دیسک امکان‌پذیر است ("B-Trees" در صفحه 79 را ببینید)، اما حفظ آن در memory بسیار آسان‌تر است. ساختارهای data tree زیادی وجود دارند که شما می‌توانید از آن‌ها استفاده کنید، مانند red-black trees یا AVL trees [2]. با این data structures، شما می‌توانید keys را به هر ترتیبی درج کنید و آن‌ها را به ترتیب مرتب شده بخوانید.
    </p>
<p>
        اکنون می‌توانیم storage engine خود را به صورت زیر کار کنیم:
    </p>
<ul>
<li>وقتی یک write وارد می‌شود، آن را به یک data structure tree متوازن in-memory (به عنوان مثال، یک red-black tree) اضافه کنید. این tree in-memory گاهی memtable نامیده می‌شود.</li>
<li>وقتی memtable بزرگتر از یک threshold می‌شود—معمولاً چند مگابایت—آن را به عنوان یک فایل SSTable به دیسک write کنید. این کار را می‌توان به طور کارآمد انجام داد زیرا tree در حال حاضر key-value pairs را بر اساس key مرتب نگه می‌دارد. فایل SSTable جدید به جدیدترین segment از database تبدیل می‌شود. در حالی که SSTable در حال write شدن به دیسک است، writes می‌توانند به یک نمونه memtable جدید ادامه دهند.</li>
<li>به منظور ارائه یک درخواست read، ابتدا سعی کنید key را در memtable پیدا کنید، سپس در جدیدترین segment on-disk، سپس در segment بعدی قدیمی‌تر و غیره.</li>
<li>هر از چند گاهی، یک فرآیند merging و compaction را در background اجرا کنید تا فایل‌های segment را ترکیب کنید و values overwritten یا deleted شده را دور بریزید.</li>
</ul>
<p>
        این طرح بسیار خوب کار می‌کند. این فقط از یک مشکل رنج می‌برد: اگر database crash کند، جدیدترین writes (که در memtable هستند اما هنوز روی دیسک نوشته نشده‌اند) از بین می‌روند. به منظور جلوگیری از آن مشکل، ما می‌توانیم یک log جداگانه روی دیسک نگه داریم که هر write بلافاصله به آن اضافه می‌شود، درست مانند بخش قبل. آن log به ترتیب مرتب نشده است، اما این مهم نیست، زیرا تنها هدف آن بازیابی memtable پس از یک crash است. هر بار که memtable به یک SSTable نوشته می‌شود، log مربوطه را می‌توان دور انداخت.
    </p>
<h4>Making an LSM-tree out of SSTables</h4>
<p>
        الگوریتم توضیح داده شده در اینجا اساساً همان چیزی است که در LevelDB [6] و RocksDB [7] استفاده می‌شود، کتابخانه‌های storage engine key-value که برای embedded شدن در applications دیگر طراحی شده‌اند. از جمله موارد دیگر، LevelDB می‌تواند در Riak به عنوان جایگزینی برای Bitcask استفاده شود. storage engines مشابه در Cassandra و HBase [8] استفاده می‌شوند، که هر دو از مقاله Bigtable از Google [9] الهام گرفته‌اند (که اصطلاحات SSTable و memtable را معرفی کرد).
    </p>
<p>
        در اصل، این structure indexing توسط Patrick O’Neil و همکارانش تحت نام Log-Structured Merge-Tree (یا LSM-Tree) [10]، بر اساس کار قبلی در
    </p>
<p>
        78 | Chapter 3: Storage and Retrieval
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0100</div>
            </div>
        </div>
        <!-- Page 0101 -->
        <div class="chapter" id="page-0101">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        log-structured filesystems [11]. Storage engines که بر اساس این اصل از merging و compacting sorted files هستند، اغلب LSM storage engines نامیده می‌شوند.
    </p>
<p>
        Lucene، یک indexing engine برای full-text search که توسط Elasticsearch و Solr استفاده می‌شود، از یک روش مشابه برای ذخیره term dictionary خود استفاده می‌کند [12, 13]. A full-text index بسیار پیچیده‌تر از یک key-value index است اما بر اساس یک ایده مشابه است: با توجه به یک کلمه در یک query search، تمام documents (صفحات وب، توضیحات محصول و غیره) را پیدا کنید که به آن کلمه اشاره می‌کنند. این با یک ساختار key-value پیاده‌سازی می‌شود که در آن key یک کلمه (یک term) و value list of IDs از تمام documents است که حاوی کلمه (postings list) هستند. در Lucene، این mapping از term به postings list در فایل‌های sorted شبیه به SSTable نگهداری می‌شود، که در صورت نیاز در background merge می‌شوند [14].
    </p>
<h4>Performance optimizations</h4>
<p>
        همانطور که همیشه، جزئیات زیادی برای کارآمد کردن یک storage engine در عمل وجود دارد.
    </p>
<p>
        به عنوان مثال، الگوریتم LSM-tree می‌تواند هنگام جستجوی keys که در database وجود ندارند، کند باشد: شما باید memtable را بررسی کنید، سپس segments را تا قدیمی‌ترین (احتمالاً مجبور به خواندن از دیسک برای هر کدام) بررسی کنید، قبل از اینکه مطمئن شوید که key وجود ندارد. به منظور بهینه‌سازی این نوع دسترسی، storage engines اغلب از Bloom filters اضافی استفاده می‌کنند [15]. (A Bloom filter یک data structure با حافظه کارآمد برای تخمین محتویات یک set است. این می‌تواند به شما بگوید که آیا یک key در database ظاهر نمی‌شود و بنابراین بسیاری از disk reads غیرضروری را برای keys nonexistent ذخیره می‌کند.)
    </p>
<p>
        همچنین استراتژی‌های مختلفی برای تعیین ترتیب و زمان‌بندی چگونگی compacted و merged شدن SSTables وجود دارد. رایج‌ترین گزینه‌ها compaction size-tiered و leveled compaction هستند. LevelDB و RocksDB از leveled compaction استفاده می‌کنند (از این رو نام Lev‐elDB)، HBase از size-tiered استفاده می‌کند و Cassandra از هر دو پشتیبانی می‌کند [16]. در compaction size-tiered، SSTables جدیدتر و کوچکتر به طور متوالی در SSTables قدیمی‌تر و بزرگتر merge می‌شوند. در leveled compaction، key range به SSTables کوچکتر تقسیم می‌شود و داده‌های قدیمی‌تر به "levels" جداگانه منتقل می‌شوند، که به compaction اجازه می‌دهد تا به صورت افزایشی‌تری پیش برود و از فضای دیسک کمتری استفاده کند.
    </p>
<p>
        حتی اگر ظرافت‌های زیادی وجود داشته باشد، ایده اصلی LSM-trees—نگه‌داشتن یک cas‐cade از SSTables که در background merge می‌شوند—ساده و موثر است. حتی زمانی که dataset بسیار بزرگتر از memory موجود است، همچنان به خوبی کار می‌کند.
    </p>
<p>
        از آنجایی که داده‌ها به ترتیب مرتب شده ذخیره می‌شوند، شما می‌توانید queries range را به طور کارآمد انجام دهید (scanning تمام keys بالاتر از حداقل و تا حداکثر) و از آنجایی که disk writes sequential هستند، LSM-tree می‌تواند throughput write بسیار بالایی را پشتیبانی کند.
    </p>
<h4>B-Trees</h4>
<p>
        Indexes log-structured که ما تا کنون در مورد آن‌ها بحث کردیم، در حال جلب پذیرش هستند، اما آن‌ها رایج‌ترین نوع index نیستند. پرکاربردترین structure indexing کاملاً متفاوت است: the B-tree.
    </p>
<p>
        Data Structures That Power Your Database | 79
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0101</div>
            </div>
        </div>
        <!-- Page 0102 -->
        <div class="chapter" id="page-0102">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        معرفی شده در سال 1970 [17] و کمتر از 10 سال بعد "ubiquitous" نامیده شد [18]، B-trees امتحان زمان را بسیار خوب پس داده‌اند. آن‌ها پیاده‌سازی index استاندارد را تقریباً در همه relational databases حفظ می‌کنند و بسیاری از databases nonrelational نیز از آن‌ها استفاده می‌کنند.
    </p>
<p>
        مانند SSTables، B-trees key-value pairs را بر اساس key مرتب نگه می‌دارند، که این امکان را برای lookups key-value و queries range کارآمد فراهم می‌کند. اما اینجاست که شباهت به پایان می‌رسد: B-trees یک فلسفه طراحی بسیار متفاوت دارند.
    </p>
<p>
        Indexes log-structured که قبلاً دیدیم، database را به segments با اندازه متغیر، معمولاً چند مگابایت یا بیشتر در اندازه، تقسیم می‌کنند و همیشه یک segment را به صورت sequential می‌نویسند. در مقابل، B-trees database را به blocks یا pages با اندازه ثابت تقسیم می‌کنند، که به طور سنتی 4 کیلوبایت اندازه دارند (گاهی بزرگتر)، و یک صفحه را در یک زمان می‌خوانند یا می‌نویسند. این طراحی بیشتر با سخت‌افزار اساسی مطابقت دارد، زیرا دیسک‌ها نیز در blocks با اندازه ثابت چیده شده‌اند.
    </p>
<p>
        هر صفحه را می‌توان با استفاده از یک address یا location شناسایی کرد، که به یک صفحه اجازه می‌دهد به صفحه دیگری اشاره کند—مشابه یک pointer، اما روی دیسک به جای memory. ما می‌توانیم از این page references برای ساختن یک tree of pages استفاده کنیم، همانطور که در شکل 3-6 نشان داده شده است.
    </p>
<p>
        شکل 3-6. Looking up یک key با استفاده از یک B-tree index.
    </p>
<p>
        یک صفحه به عنوان root of the B-tree تعیین شده است. هر زمان که شما می‌خواهید یک key را در index جستجو کنید، از اینجا شروع می‌کنید. صفحه شامل چندین key و references به child pages است. هر child مسئول یک range پیوسته از keys است و keys بین references نشان می‌دهند که مرزها بین آن ranges در کجا قرار دارند.
    </p>
<p>
        در مثال در شکل 3-6، ما به دنبال key 251 هستیم، بنابراین ما می‌دانیم که باید page reference را بین مرزهای 200 و 300 دنبال کنیم. این ما را به یک صفحه با ظاهری مشابه می‌برد که range 200–300 را بیشتر به subranges تقسیم می‌کند.
    </p>
<p>
        80 | Chapter 3: Storage and Retrieval
    </p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 102" src="page_0102/image_1.png"/></div>
</div>
                <div class="page-number">صفحه 0102</div>
            </div>
        </div>
        <!-- Page 0103 -->
        <div class="chapter" id="page-0103">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        ii. Inserting یک key جدید در یک B-tree تا حدودی intuitive است، اما حذف کردن یکی (در حالی که tree متعادل باقی می‌ماند) تا حدودی پیچیده‌تر است [2].
    </p>
<p>
        در نهایت ما به یک صفحه می‌رسیم که شامل keys مجزا است (یک leaf page)، که یا شامل value برای هر key inline است یا شامل references به صفحاتی است که در آنجا می‌توان values را یافت.
    </p>
<p>
        تعداد references به child pages در یک صفحه از B-tree را the branching factor می‌نامند. به عنوان مثال، در شکل 3-6، the branching factor شش است. در عمل، the branching factor به مقدار فضای مورد نیاز برای ذخیره page refer‐ences و مرزهای range بستگی دارد، اما معمولاً چند صد است.
    </p>
<p>
        اگر شما می‌خواهید value را برای یک key موجود در یک B-tree به‌روزرسانی کنید، شما page leaf را که حاوی آن key است، جستجو می‌کنید، value را در آن صفحه تغییر می‌دهید و صفحه را به دیسک می‌نویسید (هر references به آن صفحه معتبر باقی می‌مانند). اگر شما می‌خواهید یک key جدید اضافه کنید، شما باید صفحه‌ای را پیدا کنید که range آن شامل key جدید است و آن را به آن صفحه اضافه کنید.
    </p>
<p>
        اگر فضای آزاد کافی در صفحه برای accommodation key جدید وجود نداشته باشد، آن را به دو صفحه نیمه‌پر تقسیم می‌کنید و صفحه parent برای در نظر گرفتن subdivision جدید از key ranges به‌روزرسانی می‌شود—شکل 3-7 را ببینید.ii
    </p>
<p>
        شکل 3-7. Growing یک B-tree با تقسیم یک صفحه.
    </p>
<p>
        این الگوریتم تضمین می‌کند که tree متعادل باقی می‌ماند: یک B-tree با n keys همیشه یک depth از O(log n) دارد. اکثر databases می‌توانند در یک B-tree که سه یا چهار level deep است، جا شوند، بنابراین شما نیازی به دنبال کردن page references زیادی برای یافتن صفحه‌ای که به دنبال آن هستید، ندارید. (یک tree چهار سطحی از صفحات 4 کیلوبایتی با a branching factor از 500 می‌تواند تا 256 ترابایت را ذخیره کند.)
    </p>
<p>
        Data Structures That Power Your Database | 81
    </p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 103" src="page_0103/image_1.png"/></div>
</div>
                <div class="page-number">صفحه 0103</div>
            </div>
        </div>
        <!-- Page 0104 -->
        <div class="chapter" id="page-0104">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<h4>Making B-trees reliable</h4>
<p>
        The basic underlying write operation از یک B-tree، overwriting یک صفحه روی دیسک با data جدید است. فرض بر این است که overwrite location صفحه را تغییر نمی‌دهد. یعنی، همه references به آن صفحه، هنگامی که صفحه overwrite می‌شود، دست نخورده باقی می‌مانند. این در تضاد آشکار با indexes log-structured مانند LSM-trees است، که فقط به فایل‌ها اضافه می‌شوند (و در نهایت فایل‌های منسوخ شده را حذف می‌کنند) اما هرگز فایل‌ها را در جای خود اصلاح نمی‌کنند.
    </p>
<p>
        شما می‌توانید به overwrite کردن یک صفحه روی دیسک به عنوان یک operation سخت‌افزاری واقعی فکر کنید. در یک هارد دیسک مغناطیسی، این به معنای حرکت دادن سر دیسک به مکان مناسب، انتظار برای رسیدن موقعیت مناسب بر روی صفحه چرخان و سپس overwrite کردن sector مناسب با data جدید است. در SSDs، آنچه اتفاق می‌افتد تا حدودی پیچیده‌تر است، به دلیل این واقعیت که یک SSD باید بلوک‌های نسبتاً بزرگی از یک storage chip را در یک زمان erase و rewrite کند [19].
    </p>
<p>
        علاوه بر این، برخی از operations نیاز به overwrite کردن چندین صفحه مختلف دارند. به عنوان مثال، اگر شما یک صفحه را تقسیم می‌کنید زیرا درج باعث شد که overfull شود، شما نیاز دارید دو صفحه‌ای که تقسیم شده‌اند را بنویسید، و همچنین صفحه parent آن‌ها را overwrite کنید تا references به دو child pages را به‌روزرسانی کنید. این یک operation خطرناک است، زیرا اگر database پس از نوشته شدن فقط برخی از صفحات crash کند، شما به یک index corrupted (به عنوان مثال، ممکن است یک orphan page وجود داشته باشد که child هیچ parent نیست) می‌رسید.
    </p>
<p>
        به منظور مقاوم کردن database در برابر crashes، معمول است که پیاده‌سازی‌های B-tree شامل یک data structure اضافی روی دیسک باشند: a write-ahead log (WAL، همچنین به عنوان a redo log شناخته می‌شود). این یک فایل append-only است که هر B-tree modification باید قبل از اینکه بتواند به صفحات خود tree اعمال شود، به آن نوشته شود. وقتی database پس از یک crash دوباره بالا می‌آید، از این log برای بازیابی B-tree به یک state consistent استفاده می‌شود [5, 20].
    </p>
<p>
        یک complication اضافی از updating pages in place این است که concurrency control دقیق مورد نیاز است اگر چندین thread قرار است به B-tree در همان زمان دسترسی داشته باشند—در غیر این صورت یک thread ممکن است tree را در یک state inconsistent ببیند. این معمولاً با محافظت از data structures tree با latches (قفل‌های سبک وزن) انجام می‌شود. رویکردهای log-structured از این نظر ساده‌تر هستند، زیرا آن‌ها همه merging را در background بدون تداخل با queries ورودی انجام می‌دهند و به صورت اتمی segments قدیمی را هر از چند گاهی برای segments جدید swap می‌کنند.
    </p>
<h4>B-tree optimizations</h4>
<p>
        از آنجایی که B-trees برای مدت طولانی وجود داشته‌اند، تعجب‌آور نیست که بسیاری از optimizations در طول سال‌ها توسعه یافته‌اند. برای اشاره فقط به موارد معدودی:
    </p>
<ul>
<li>به جای overwriting صفحات و حفظ یک WAL برای crash recovery، برخی از databases (مانند LMDB) از یک طرح copy-on-write استفاده می‌کنند [21]. یک صفحه اصلاح شده به یک location متفاوت نوشته می‌شود و یک نسخه جدید از صفحات parent در tree ایجاد می‌شود که به location جدید اشاره می‌کند. این رویکرد همچنین برای concur‐</li>
</ul>
<p>
        82 | Chapter 3: Storage and Retrieval
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0104</div>
            </div>
        </div>
        <!-- Page 0105 -->
        <div class="chapter" id="page-0105">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        iii. This variant is sometimes known as a B+ tree, although the optimization is so common that it often isn’t distinguished from other B-tree variants.
    </p>
<ul>
<li>rency control، همانطور که در "Snapshot Isolation and Repeatable Read" در صفحه 237 خواهیم دید.</li>
<li>ما می‌توانیم با ذخیره نکردن کل key، فضای زیادی در صفحات ذخیره کنیم، اما آن را مختصر کنیم. به خصوص در صفحات داخلی tree، keys فقط باید اطلاعات کافی را برای عمل به عنوان مرز بین key ranges ارائه دهند. Packing keys بیشتر در یک صفحه به tree اجازه می‌دهد تا a branching factor بالاتری داشته باشد و بنابراین سطوح کمتری داشته باشد.iii</li>
<li>به طور کلی، صفحات را می‌توان در هر جایی از دیسک قرار داد. هیچ چیز نیازی به نزدیکی صفحات با key ranges مجاور در دیسک ندارد. اگر یک query نیاز به scan بر روی بخش بزرگی از key range به ترتیب مرتب شده داشته باشد، این page-by-page layout می‌تواند ineffi‐cient باشد، زیرا یک disk seek ممکن است برای هر صفحه ای که خوانده می‌شود، مورد نیاز باشد. بنابراین بسیاری از پیاده‌سازی‌های B-tree سعی می‌کنند tree را طوری lay out کنند که leaf pages به ترتیب sequential در دیسک ظاهر شوند. با این حال، حفظ این order با رشد tree دشوار است. در مقابل، از آنجایی که LSM-trees segments بزرگ storage را در یک go در حین merging، دوباره می‌نویسند، حفظ sequential keys نزدیک به یکدیگر روی دیسک برای آن‌ها آسان‌تر است.</li>
<li>Additional pointers به tree اضافه شده‌اند. به عنوان مثال، هر leaf page ممکن است references به صفحات sibling خود در سمت چپ و راست داشته باشد، که به scanning keys به ترتیب بدون پرش به عقب به parent pages اجازه می‌دهد.</li>
<li>B-tree variants مانند fractal trees [22] برخی از ایده‌های log-structured را برای کاهش disk seeks قرض می‌گیرند (و آن‌ها هیچ ارتباطی با fractals ندارند).</li>
</ul>
<h4>Comparing B-Trees and LSM-Trees</h4>
<p>
        حتی اگر پیاده‌سازی‌های B-tree عموماً بالغ‌تر از پیاده‌سازی‌های LSM-tree هستند، LSM-trees نیز به دلیل ویژگی‌های performance خود جالب هستند. به عنوان یک rule of thumb، LSM-trees معمولاً برای writes سریع‌تر هستند، در حالی که B-trees برای reads سریع‌تر در نظر گرفته می‌شوند [23]. Reads معمولاً در LSM-trees کندتر هستند زیرا آن‌ها باید چندین data structures و SSTables مختلف را در مراحل مختلف compaction بررسی کنند.
    </p>
<p>
        با این حال، benchmarks اغلب بی‌نتیجه هستند و به جزئیات workload حساس هستند. شما نیاز دارید systems را با workload خاص خود تست کنید تا یک مقایسه معتبر انجام دهید. در این بخش ما به طور خلاصه در مورد چند چیزی که هنگام اندازه‌گیری performance از یک storage engine، ارزش در نظر گرفتن را دارند، بحث خواهیم کرد.
    </p>
<p>
        Data Structures That Power Your Database | 83
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0105</div>
            </div>
        </div>
        <!-- Page 0106 -->
        <div class="chapter" id="page-0106">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<h4>Advantages of LSM-trees</h4>
<p>
        یک B-tree index باید هر قطعه از داده را حداقل دو بار بنویسد: یک بار به write-ahead log و یک بار به خود صفحه tree (و شاید دوباره در حالی که صفحات تقسیم می‌شوند). همچنین overhead از نوشتن یک صفحه کامل در یک زمان وجود دارد، حتی اگر فقط چند بایت در آن صفحه تغییر کند. برخی از storage engines حتی یک صفحه را دو بار overwrite می‌کنند تا از پایان یافتن با یک صفحه تا حدودی به‌روزرسانی شده در صورت خرابی power جلوگیری کنند [24, 25].
    </p>
<p>
        Indexes log-structured نیز داده‌ها را چندین بار به دلیل compaction و merging تکراری از SSTables دوباره می‌نویسند. این effect—یک write به database که منجر به multiple writes به دیسک در طول عمر database می‌شود—به عنوان write amplification شناخته می‌شود. این موضوع به خصوص در SSDs که فقط می‌توانند بلوک‌ها را به تعداد محدودی بار قبل از فرسودگی، overwrite کنند، نگران‌کننده است.
    </p>
<p>
        در applications با write-heavy، bottleneck performance ممکن است rate که database می‌تواند به دیسک بنویسد باشد. در این مورد، write amplification یک performance مستقیم دارد: هرچه یک storage engine بیشتر به دیسک می‌نویسد، writes کمتری در ثانیه می‌تواند در پهنای باند دیسک موجود، مدیریت کند.
    </p>
<p>
        علاوه بر این، LSM-trees معمولاً قادر به حفظ throughput write بالاتری نسبت به B-trees هستند، تا حدی به این دلیل که آن‌ها گاهی اوقات write amplification کمتری دارند (اگرچه این به configuration storage engine و workload بستگی دارد) و تا حدی به این دلیل که آن‌ها به صورت sequential فایل‌های SSTable فشرده را می‌نویسند تا اینکه مجبور به overwrite کردن چندین صفحه در tree باشند [26]. این تفاوت به ویژه در هارد دیسک‌های مغناطیسی مهم است، جایی که writes sequential بسیار سریع‌تر از random writes هستند.
    </p>
<p>
        LSM-trees را می‌توان بهتر compressed کرد و بنابراین اغلب فایل‌های کوچکتری را روی دیسک نسبت به B-trees تولید می‌کنند. storage engines B-tree مقداری فضای دیسک را به دلیل fragmentation استفاده نشده رها می‌کنند: وقتی یک صفحه تقسیم می‌شود یا وقتی یک ردیف نمی‌تواند در یک صفحه موجود قرار گیرد، مقداری فضا در یک صفحه بدون استفاده باقی می‌ماند. از آنجایی که LSM-trees page-oriented نیستند و دوره‌ای SSTables را دوباره می‌نویسند تا fragmentation را حذف کنند، آن‌ها overheads storage کمتری دارند، به خصوص هنگام استفاده از leveled compaction [27].
    </p>
<p>
        در بسیاری از SSDs، firmware به صورت داخلی از یک الگوریتم log-structured برای تبدیل random writes به sequential writes روی storage chips اساسی استفاده می‌کند، بنابراین تأثیر الگوی write storage engine کمتر مشخص است [19]. با این حال، write amplification کمتر و کاهش fragmentation هنوز هم در SSDs مفید است: نشان دادن داده‌ها به طور فشرده‌تر به درخواست‌های read و write بیشتر در پهنای باند I/O موجود اجازه می‌دهد.
    </p>
<h4>Downsides of LSM-trees</h4>
<p>
        یک downside از storage log-structured این است که process compaction گاهی اوقات می‌تواند با performance reads و writes در حال انجام تداخل داشته باشد. حتی اگر storage engines سعی می‌کنند compaction را به صورت افزایشی و بدون تأثیر بر concurrency انجام دهند
    </p>
<p>
        84 | Chapter 3: Storage and Retrieval
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0106</div>
            </div>
        </div>
        <!-- Page 0107 -->
        <div class="chapter" id="page-0107">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        access، دیسک‌ها منابع محدودی دارند، بنابراین به راحتی ممکن است در حالی که دیسک عملیات compaction گران‌قیمتی را به پایان می‌رساند، یک درخواست نیاز به انتظار داشته باشد. تأثیر بر throughput و متوسط ​​زمان پاسخ معمولاً کم است، اما در percentiles بالاتر (به "Describing Performance" در صفحه 13 مراجعه کنید) زمان پاسخ queries به storage engines log-structured گاهی اوقات می‌تواند کاملاً زیاد باشد و B-trees می‌توانند قابل پیش‌بینی‌تر باشند [28].
    </p>
<p>
        یکی دیگر از مسائل با compaction در throughput write بالا ایجاد می‌شود: پهنای باند write محدود دیسک باید بین write اولیه (logging و flushing a memtable به دیسک) و threads compaction که در background در حال اجرا هستند، به اشتراک گذاشته شود. هنگام نوشتن در یک database خالی، از full disk bandwidth می‌توان برای write اولیه استفاده کرد، اما هر چه database بزرگتر می‌شود، پهنای باند دیسک بیشتری برای compaction مورد نیاز است.
    </p>
<p>
        اگر throughput write بالا باشد و compaction با دقت پیکربندی نشده باشد، ممکن است اتفاق بیفتد که compaction نتواند با نرخ incoming writes همگام شود. در این صورت، تعداد segments unmerged روی دیسک همچنان در حال رشد است تا اینکه شما فضای دیسک را تمام کنید، و reads نیز کند می‌شوند زیرا آن‌ها نیاز به بررسی فایل‌های segment بیشتری دارند. Typ‐ically، storage engines مبتنی بر SSTable نرخ incoming writes را محدود نمی‌کنند، حتی اگر compaction نتواند همگام شود، بنابراین شما نیاز به نظارت صریح برای تشخیص این موقعیت دارید [29, 30].
    </p>
<p>
        یک مزیت B-trees این است که هر key دقیقاً در یک مکان در index وجود دارد، در حالی که یک storage engine log-structured ممکن است چندین کپی از یک key یکسان در segments مختلف داشته باشد. این جنبه باعث می‌شود B-trees در databases که می‌خواهند strong transactional semantics را ارائه دهند، جذاب باشند: در بسیاری از relational databases، transaction isola‐tion با استفاده از locks روی ranges of keys پیاده‌سازی می‌شود و در یک B-tree index، آن locks می‌توانند مستقیماً به tree متصل شوند [5]. در فصل 7 ما در مورد این موضوع با جزئیات بیشتر بحث خواهیم کرد.
    </p>
<p>
        B-trees بسیار در architecture of databases ریشه‌دار هستند و performance خوب و مداومی را برای بسیاری از workloads فراهم می‌کنند، بنابراین بعید است که آن‌ها به این زودی‌ها از بین بروند. در new datastores، indexes log-structured به طور فزاینده‌ای محبوب می‌شوند.
    </p>
<p>
        هیچ قانون سریع و آسانی برای تعیین اینکه کدام نوع storage engine برای use case شما بهتر است وجود ندارد، بنابراین ارزش دارد که به صورت تجربی تست کنید.
    </p>
<h4>Other Indexing Structures</h4>
<p>
        تا کنون ما فقط در مورد key-value indexes بحث کرده‌ایم، که مانند یک primary key index در relational model هستند. A primary key به طور منحصر به فرد یک ردیف را در یک table relational، یا یک document را در یک document database یا یک vertex را در یک graph database شناسایی می‌کند. سایر records در database می‌توانند به آن row/document/vertex با primary key (یا ID) اشاره کنند و index برای حل چنین references استفاده می‌شود.
    </p>
<p>
        همچنین داشتن secondary indexes بسیار رایج است. در relational databases، شما می‌توانید چندین secondary indexes را بر روی همان table با استفاده از CREATE INDEX com‐
    </p>
<p>
        Data Structures That Power Your Database | 85
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0107</div>
            </div>
        </div>
        <!-- Page 0108 -->
        <div class="chapter" id="page-0108">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        mand، و آن‌ها اغلب برای انجام joins به طور کارآمد حیاتی هستند. به عنوان مثال، در شکل 2-1 در فصل 2 شما احتمالاً یک secondary index روی columns user_id خواهید داشت تا بتوانید تمام ردیف‌های متعلق به همان user را در هر یک از tables پیدا کنید.
    </p>
<p>
        یک secondary index را می‌توان به راحتی از یک key-value index ساخت. تفاوت اصلی این است که keys یکتا نیستند. یعنی، ممکن است ردیف‌های (documents, vertices) زیادی با همان key وجود داشته باشند. این را می‌توان به دو روش حل کرد: یا با ساختن هر value در index یک list of matching row identifiers (مانند یک postings list در یک full-text index) یا با ساختن هر key یکتا با اضافه کردن یک row identifier به آن. به هر حال، هم B-trees و هم indexes log-structured می‌توانند به عنوان secondary indexes استفاده شوند.
    </p>
<h4>Storing values within the index</h4>
<p>
        The key in an index چیزی است که queries به دنبال آن هستند، اما value می‌تواند یکی از دو چیز باشد: می‌تواند row (document, vertex) واقعی مورد نظر باشد، یا می‌تواند یک reference به ردیف ذخیره شده در جای دیگر باشد. در مورد دوم، مکانی که ردیف‌ها در آن ذخیره می‌شوند، به عنوان a heap file شناخته می‌شود و داده‌ها را بدون ترتیب خاصی ذخیره می‌کند (ممکن است append-only باشد، یا ممکن است ردیف‌های حذف شده را ردیابی کند تا بعداً آن‌ها را با data جدید overwrite کند). رویکرد heap file رایج است زیرا از تکرار data در صورت وجود multiple secondary indexes اجتناب می‌کند: هر index فقط به یک location در heap file اشاره می‌کند و data واقعی در یک مکان نگهداری می‌شود.
    </p>
<p>
        هنگام به‌روزرسانی یک value بدون تغییر key، رویکرد heap file می‌تواند بسیار کارآمد باشد: record را می‌توان در محل overwrite کرد، به شرطی که value جدید بزرگتر از value قدیمی نباشد. اگر value جدید بزرگتر باشد، وضعیت پیچیده‌تر است، زیرا احتمالاً نیاز به انتقال آن به یک location جدید در heap است که فضای کافی وجود دارد. در این صورت، یا همه indexes نیاز به به‌روزرسانی دارند تا به location heap جدید از record اشاره کنند، یا یک forwarding pointer در location heap قدیمی باقی می‌ماند [5].
    </p>
<p>
        در برخی موارد، جهش اضافی از index به heap file یک penalty performance بیش از حد برای reads است، بنابراین ممکن است ذخیره row indexed مستقیماً در یک index مطلوب باشد. این به عنوان a clustered index شناخته می‌شود. به عنوان مثال، در storage engine InnoDB از MySQL، primary key از یک table همیشه یک clustered index است و secondary indexes به primary key (به جای یک location heap file) اشاره می‌کنند [31]. در SQL Server، شما می‌توانید یک clustered index را برای هر table مشخص کنید [32].
    </p>
<p>
        یک compromise بین a clustered index (ذخیره تمام data row در index) و یک nonclustered index (ذخیره فقط references به data در index) به عنوان یک covering index یا index with included columns شناخته می‌شود، که برخی از columns یک جدول را در index ذخیره می‌کند [33]. این به برخی از queries اجازه می‌دهد تا با استفاده از index به تنهایی پاسخ داده شوند (در این صورت، گفته می‌شود index query را پوشش می‌دهد) [32].
    </p>
<p>
        Data Structures That Power Your Database | 86
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0108</div>
            </div>
        </div>
        <!-- Page 0109 -->
        <div class="chapter" id="page-0109">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        As with any kind of duplication of data, clustered و covering indexes می‌توانند سرعت reads را افزایش دهند، اما آن‌ها به storage اضافی نیاز دارند و می‌توانند overhead را در writes اضافه کنند. Databases همچنین نیاز به تلاش‌های اضافی برای اعمال transactional guarantees دارند، زیرا appli‐cations نباید inconsistencies را به دلیل duplication ببینند.
    </p>
<h4>Multi-column indexes</h4>
<p>
        Indexes که تاکنون مورد بحث قرار گرفتند، فقط یک key را به یک value نگاشت می‌کنند. این کافی نیست اگر ما نیاز به query کردن multiple columns از یک جدول (یا multiple fields در یک document) به طور همزمان داشته باشیم.
    </p>
<p>
        متداول‌ترین نوع multi-column index، یک concatenated index نامیده می‌شود که به سادگی چندین فیلد را با اضافه کردن یک column به دیگری در یک key ترکیب می‌کند (تعریف index مشخص می‌کند که فیلدها به چه ترتیبی concatenated شوند). این مانند یک دفترچه تلفن کاغذی قدیمی است که یک index از (lastname, first‐name) به شماره تلفن ارائه می‌دهد. به دلیل sort order، index می‌تواند برای یافتن همه افرادی که دارای lastname خاصی هستند، یا همه افرادی که دارای ترکیب lastname-firstname خاصی هستند، استفاده شود. با این حال، اگر شما می‌خواهید همه افرادی را که دارای first name خاصی هستند، پیدا کنید، index بی‌فایده است.
    </p>
<p>
        Multi-dimensional indexes یک روش عمومی‌تر برای querying چندین columns در یک زمان است که به ویژه برای داده‌های geospatial مهم است. به عنوان مثال، یک وب‌سایت restaurant-search ممکن است یک database داشته باشد که شامل latitude و longitude هر رستوران است. هنگامی که یک user در حال مشاهده رستوران‌ها روی یک نقشه است، وب‌سایت نیاز به جستجوی تمام رستوران‌ها در area map مستطیلی دارد که user در حال حاضر در حال مشاهده آن است. این نیاز به یک query range دو بعدی مانند موارد زیر دارد:
    </p>
<pre><code class="language-sql">SELECT * FROM restaurants WHERE latitude  &gt; 51.4946 AND latitude  &lt; 51.5079
                            AND longitude &gt; -0.1162 AND longitude &lt; -0.1004;
</code></pre>
<p>
        یک B-tree یا LSM-tree index استاندارد قادر به پاسخگویی کارآمد به این نوع query نیست: می‌تواند یا تمام رستوران‌ها را در یک range از latitudes (اما در هر longitude) یا تمام رستوران‌ها را در یک range از longitudes (اما در هر جایی بین قطب شمال و جنوب) به شما بدهد، اما نه هر دو به طور همزمان.
    </p>
<p>
        یک گزینه این است که یک location دو بعدی را با استفاده از یک space-filling curve به یک عدد واحد ترجمه کنید و سپس از یک B-tree index معمولی استفاده کنید [34]. به طور معمول، indexes spatial تخصصی مانند R-trees استفاده می‌شوند. به عنوان مثال، PostGIS indexes geospatial را به عنوان R-trees با استفاده از تسهیلات indexing Generalized Search Tree از PostgreSQL پیاده‌سازی می‌کند [35]. ما فضا برای توصیف R-trees با جزئیات در اینجا نداریم، اما مطالب زیادی در مورد آن‌ها وجود دارد.
    </p>
<p>
        یک ایده جالب این است که multi-dimensional indexes فقط برای geographic locations نیستند. به عنوان مثال، در یک وب‌سایت ecommerce شما می‌توانید از یک index سه بعدی در dimensions (red, green, blue) برای جستجوی محصولات در یک range خاص از colors استفاده کنید، یا در یک database از weather observations شما می‌توانید a two-dimensional
    </p>
<p>
        Data Structures That Power Your Database | 87
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0109</div>
            </div>
        </div>
        <!-- Page 0110 -->
        <div class="chapter" id="page-0110">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        index روی (date, temperature) به منظور جستجوی کارآمد برای تمام observations در طول سال 2013 که در آن دما بین 25 و 30 درجه سانتی‌گراد بود. با یک index یک‌بعدی، شما یا باید تمام records از سال 2013 (صرف نظر از دما) را scan کنید و سپس آن‌ها را بر اساس دما فیلتر کنید، یا بالعکس. یک index 2D می‌تواند به طور همزمان بر اساس timestamp و temperature محدود شود. این tech‐nique توسط HyperDex [36] استفاده می‌شود.
    </p>
<h4>Full-text search و fuzzy indexes</h4>
<p>
        همه indexes که تاکنون مورد بحث قرار گرفتند، فرض می‌کنند که شما data دقیق دارید و به شما اجازه می‌دهند که برای exact values از یک key، یا یک range از values از یک key با یک sort order query کنید. آنچه که آن‌ها به شما اجازه نمی‌دهند این است که به دنبال keys مشابه، مانند کلمات املایی اشتباه، باشید. چنین fuzzy querying نیاز به تکنیک‌های متفاوتی دارد.
    </p>
<p>
        به عنوان مثال، full-text search engines معمولاً به جستجوی یک کلمه اجازه می‌دهند تا شامل مترادف‌های کلمه شود، variations گرامری از کلمات را نادیده بگیرد، و به دنبال occurrences of words در نزدیکی یکدیگر در همان document باشد و از ویژگی‌های مختلف دیگری پشتیبانی کند که به تجزیه و تحلیل زبانی متن بستگی دارد. برای مقابله با typos در documents یا queries، Lucene قادر است text را برای کلمات در یک edit distance خاص (یک edit distance از 1 به این معنی است که یک حرف اضافه، حذف یا جایگزین شده است) جستجو کند [37].
    </p>
<p>
        همانطور که در "Making an LSM-tree out of SSTables" در صفحه 78 اشاره شد، Lucene از یک ساختار شبیه به SSTable برای term dictionary خود استفاده می‌کند. این structure به یک in-memory index کوچک نیاز دارد که به queries می‌گوید که در کدام offset در فایل مرتب شده، باید به دنبال یک key باشند. در LevelDB، این in-memory index یک collection sparse از برخی از keys است، اما در Lucene، the in-memory index یک finite state automaton بر روی کاراکترهای در keys است، شبیه به یک trie [38]. این automaton را می‌توان به یک Levenshtein automaton تبدیل کرد، که از search کارآمد برای کلمات در یک edit distance داده شده پشتیبانی می‌کند [39].
    </p>
<p>
        سایر تکنیک‌های fuzzy search به سمت document classification و machine learning می‌روند. برای اطلاعات بیشتر به یک کتاب درسی information retrieval مراجعه کنید [به عنوان مثال، 40].
    </p>
<h4>Keeping everything in memory</h4>
<p>
        Data structures که در این فصل مورد بحث قرار گرفتند، همگی پاسخ‌هایی به limitations of disks بوده‌اند. در مقایسه با main memory، مقابله با دیسک‌ها دشوار است. هم با magnetic disks و هم با SSDs، داده‌ها روی دیسک باید با دقت lay out شوند اگر شما می‌خواهید performance خوبی در reads و writes داشته باشید. با این حال، ما این awkwardness را تحمل می‌کنیم زیرا دیسک‌ها دو مزیت مهم دارند: آن‌ها با دوام هستند (محتوای آن‌ها در صورت قطع برق از بین نمی‌رود) و هزینه کمتری به ازای هر گیگابایت نسبت به RAM دارند.
    </p>
<p>
        از آنجایی که RAM ارزان‌تر می‌شود، argument cost-per-gigabyte فرسوده می‌شود. بسیاری از datasets به سادگی به آن بزرگی نیستند، بنابراین کاملاً امکان‌پذیر است که آن‌ها را به طور کامل در memory نگه داریم، poten‐
    </p>
<p>
        88 | Chapter 3: Storage and Retrieval
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0110</div>
            </div>
        </div>
        <!-- Page 0111 -->
        <div class="chapter" id="page-0111">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        tially distributed در سراسر چندین machine. این امر منجر به توسعه in-memory databases شده است.
    </p>
<p>
        برخی از key-value stores in-memory، مانند Memcached، فقط برای استفاده از caching در نظر گرفته شده‌اند، جایی که از دست رفتن data در صورت راه‌اندازی مجدد یک machine قابل قبول است. اما other in-memory databases برای durability هدف دارند، که می‌توان با سخت‌افزار ویژه (مانند RAM باتری‌دار)، با نوشتن یک log از تغییرات در دیسک، با نوشتن snapshots periodic به دیسک، یا با تکرار state in-memory به سایر machines به دست آورد.
    </p>
<p>
        هنگامی که یک in-memory database دوباره راه‌اندازی می‌شود، باید state خود را، یا از دیسک یا از طریق شبکه از یک replica (مگر اینکه از سخت‌افزار ویژه استفاده شود)، دوباره بارگیری کند. علیرغم نوشتن به دیسک، هنوز یک in-memory database است، زیرا دیسک صرفاً به عنوان یک log append-only برای durability استفاده می‌شود و reads به طور کامل از memory ارائه می‌شوند. نوشتن به دیسک نیز مزایای operational دارد: فایل‌ها روی دیسک را می‌توان به راحتی توسط ابزارهای خارجی، پشتیبان‌گیری، بازرسی و تجزیه و تحلیل کرد.
    </p>
<p>
        محصولاتی مانند VoltDB، MemSQL و Oracle TimesTen، in-memory databases با یک relational model هستند و vendors ادعا می‌کنند که می‌توانند با حذف تمام overheads مرتبط با مدیریت on-disk data structures، بهبودهای performance بزرگی را ارائه دهند [41, 42]. RAMCloud یک open source, in-memory key-value store با durability است (با استفاده از یک رویکرد log-structured برای data در memory و همچنین data روی دیسک) [43]. Redis و Couchbase با نوشتن به صورت asyn‐chronously، durability ضعیفی را ارائه می‌دهند.
    </p>
<p>
        به طور غیرمنتظره، مزیت performance از in-memory databases به این دلیل نیست که آن‌ها نیازی به خواندن از دیسک ندارند. حتی یک storage engine مبتنی بر دیسک ممکن است هرگز نیازی به خواندن از دیسک نداشته باشد اگر شما memory کافی داشته باشید، زیرا operating sys‐tem به هر حال بلوک‌های دیسک اخیراً استفاده شده را در memory cache می‌کند. بلکه، آن‌ها می‌توانند سریع‌تر باشند زیرا می‌توانند از overheads of encoding in-memory data structures در یک form که می‌تواند به دیسک نوشته شود، اجتناب کنند [44].
    </p>
<p>
        علاوه بر performance، یک حوزه جالب دیگر برای in-memory databases ارائه data models است که پیاده‌سازی آن‌ها با indexes disk-based دشوار است. به عنوان مثال، Redis یک interface شبیه به database را به data structures مختلف مانند priority queues و sets ارائه می‌دهد. از آنجایی که همه data را در memory نگه می‌دارد، پیاده‌سازی آن نسبتاً ساده است.
    </p>
<p>
        تحقیقات اخیر نشان می‌دهد که یک architecture in-memory database می‌تواند برای پشتیبانی از datasets بزرگتر از memory موجود، بدون بازگشت over‐heads of a disk-centric architecture گسترش یابد [45]. رویکرد به اصطلاح anti-caching با evicting داده‌های اخیراً استفاده‌شده از memory به دیسک، زمانی که memory کافی وجود ندارد، کار می‌کند و دوباره آن را در آینده، زمانی که دوباره به آن دسترسی پیدا شود، در memory بارگذاری می‌کند. این شبیه به کاری است که operating systems با virtual memory و swap files انجام می‌دهند، اما database می‌تواند memory را کارآمدتر از OS مدیریت کند، زیرا می‌تواند در granularity از records مجزا به جای کل صفحات memory کار کند. این
    </p>
<p>
        Data Structures That Power Your Database | 89
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0111</div>
            </div>
        </div>
        <!-- Page 0112 -->
        <div class="chapter" id="page-0112">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        approach همچنان نیاز به indexes دارد که کاملاً در memory جا شوند، اگرچه (مانند مثال Bitcask در ابتدای فصل).
    </p>
<p>
        تغییرات بیشتر در طراحی storage engine احتمالاً مورد نیاز خواهد بود اگر فناوری‌های non-volatile memory (NVM) بیشتر مورد استفاده قرار گیرند [46]. در حال حاضر، این یک حوزه جدید تحقیقاتی است، اما ارزش دارد که در آینده آن را زیر نظر داشته باشید.
    </p>
<h4>Transaction Processing or Analytics?</h4>
<p>
        در روزهای اولیه پردازش داده‌های کسب‌وکار، یک write به database معمولاً با یک transaction تجاری که در حال انجام است، مطابقت داشت: انجام یک فروش، ثبت سفارش با یک تأمین‌کننده، پرداخت حقوق یک کارمند و غیره. همانطور که databases به مناطقی که شامل تبادل پول نمی‌شدند، گسترش یافتند، اصطلاح transaction با این وجود باقی ماند و به گروهی از reads و writes اشاره دارد که یک واحد منطقی را تشکیل می‌دهند.
    </p>
<p>
        یک transaction لزوماً نباید دارای ویژگی‌های ACID (atomicity, consis‐tency, isolation و durability) باشد. Transaction processing فقط به معنای اجازه دادن به clients برای انجام reads و writes با low-latency است—برخلاف jobs batch processing، که فقط به صورت دوره‌ای اجرا می‌شوند (به عنوان مثال، یک بار در روز). ما ویژگی‌های ACID را در فصل 7 و batch processing را در فصل 10 مورد بحث قرار می‌دهیم.
    </p>
<p>
        حتی اگر databases شروع به استفاده برای انواع مختلفی از داده‌ها کردند—نظرات در مورد blog posts، اقدامات در یک بازی، مخاطبین در یک address book و غیره—الگوی دسترسی اساسی مشابه پردازش معاملات تجاری باقی ماند. یک application معمولاً تعداد کمی از records را بر اساس یک key با استفاده از یک index جستجو می‌کند. Records بر اساس ورودی user درج یا به‌روزرسانی می‌شوند. از آنجایی که این applications تعاملی هستند، الگوی دسترسی به عنوان online transaction processing (OLTP) شناخته شد.
    </p>
<p>
        با این حال، databases همچنین شروع به استفاده فزاینده‌ای برای data analytics کردند، که الگوهای دسترسی بسیار متفاوتی دارد. معمولاً یک query analytic نیاز به scan بر روی تعداد زیادی از records دارد، فقط چند column در هر record را می‌خواند و آمار aggregate (مانند count, sum یا average) را محاسبه می‌کند، به جای بازگرداندن data خام به user. به عنوان مثال، اگر data شما یک جدول از sales transactions باشد، سپس queries analytic ممکن است:
    </p>
<ul>
<li>درآمد کل هر یک از فروشگاه‌های ما در ماه ژانویه چقدر بود؟</li>
<li>چند موز بیشتر از حد معمول در طول آخرین promotion خود فروختیم؟</li>
<li>کدام برند غذای کودک اغلب با پوشک برند X خریداری می‌شود؟</li>
</ul>
<p>
        90 | Chapter 3: Storage and Retrieval
    </p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 112" src="page_0112/image_1.png"/></div>
</div>
                <div class="page-number">صفحه 0112</div>
            </div>
        </div>
        <!-- Page 0113 -->
        <div class="chapter" id="page-0113">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        iv. The meaning of online in OLAP نامشخص است. این احتمالاً به این واقعیت اشاره دارد که queries فقط برای pre‐defined reports نیستند، بلکه analysts از سیستم OLAP به صورت تعاملی برای queries explorative استفاده می‌کنند.
    </p>
<p>
        این queries اغلب توسط business analysts نوشته می‌شوند و به گزارش‌هایی منتهی می‌شوند که به مدیریت یک شرکت در تصمیم‌گیری‌های بهتر کمک می‌کنند (business intelligence). به منظور تمایز این الگو از استفاده از databases از transaction processing، به آن online analytic processing (OLAP) [47] گفته شده است.iv تفاوت بین OLTP و OLAP همیشه مشخص نیست، اما برخی از ویژگی‌های معمولی در جدول 3-1 فهرست شده‌اند.
    </p>
<p>
        Table 3-1. Comparing characteristics of transaction processing versus analytic systems
    </p>
<table>
<thead>
<tr>
<th>Property</th>
<th>Transaction processing systems (OLTP)</th>
<th>Analytic systems (OLAP)</th>
</tr>
</thead>
<tbody>
<tr>
<td>Main read pattern</td>
<td>Small number of records per query, fetched by key</td>
<td>Aggregate over large number of records</td>
</tr>
<tr>
<td>Main write pattern</td>
<td>Random-access, low-latency writes from user input</td>
<td>Bulk import (ETL) or event stream</td>
</tr>
<tr>
<td>Primarily used by</td>
<td>End user/customer, via web application</td>
<td>Internal analyst, for decision support</td>
</tr>
<tr>
<td>What data represents</td>
<td>Latest state of data (current point in time)</td>
<td>History of events that happened over time</td>
</tr>
<tr>
<td>Dataset size</td>
<td>Gigabytes to terabytes</td>
<td>Terabytes to petabytes</td>
</tr>
</tbody>
</table>
<p>
        در ابتدا، از همان databases برای هر دو transaction processing و analytic queries استفاده می‌شد. SQL در این زمینه کاملاً انعطاف‌پذیر ظاهر شد: هم برای queries نوع OLTP و هم برای queries نوع OLAP به خوبی کار می‌کند. با این وجود، در اواخر دهه 1980 و اوایل دهه 1990، یک روند برای شرکت‌ها وجود داشت که از استفاده از systems OLTP خود برای اهداف analytics دست بردارند و analytics را به جای آن روی یک database جداگانه اجرا کنند. به این database جداگانه یک data warehouse گفته می‌شد.
    </p>
<h4>Data Warehousing</h4>
<p>
        یک enterprise ممکن است ده‌ها system transaction processing مختلف داشته باشد: سیستم‌هایی که وب‌سایت مشتری‌محور را پشتیبانی می‌کنند، سیستم‌های point of sale (checkout) را در فروشگاه‌های فیزیکی کنترل می‌کنند، موجودی را در انبارها ردیابی می‌کنند، مسیرها را برای وسایل نقلیه برنامه‌ریزی می‌کنند، کارمندان را مدیریت می‌کنند، و غیره. هر یک از این systems پیچیده است و نیاز به تیمی از افراد برای نگهداری آن دارد، بنابراین systems در نهایت عمدتاً به طور autonomous از یکدیگر عمل می‌کنند.
    </p>
<p>
        از این systems OLTP معمولاً انتظار می‌رود که بسیار در دسترس باشند و تراکنش‌ها را با low latency پردازش کنند، زیرا آن‌ها اغلب برای عملیات کسب‌وکار حیاتی هستند. بنابراین database administrators از databases OLTP خود به شدت محافظت می‌کنند. آن‌ها معمولاً تمایلی ندارند که به business analysts اجازه دهند queries ad hoc analytic را روی یک database OLTP اجرا کنند، زیرا این queries اغلب گران هستند و بخش‌های بزرگی از dataset را scan می‌کنند، که می‌تواند به performance تراکنش‌های همزمان اجرا شده آسیب برساند.
    </p>
<p>
        Transaction Processing or Analytics? | 91
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0113</div>
            </div>
        </div>
        <!-- Page 0114 -->
        <div class="chapter" id="page-0114">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        یک data warehouse، در مقابل، یک database جداگانه است که analysts می‌توانند به content دلخواه خود query کنند، بدون تأثیر بر operations OLTP [48]. The data warehouse شامل یک کپی read-only از داده‌ها در تمام systems OLTP مختلف در شرکت است.
    </p>
<p>
        Data از databases OLTP استخراج می‌شود (با استفاده از data dump periodic یا یک جریان پیوسته از updates)، به یک schema analysis-friendly تبدیل می‌شود، تمیز می‌شود و سپس در data warehouse بارگذاری می‌شود. این فرآیند وارد کردن داده‌ها به warehouse به عنوان Extract–Transform–Load (ETL) شناخته می‌شود و در شکل 3-8 نشان داده شده است.
    </p>
<p>
        شکل 3-8. Simplified outline از ETL به یک data warehouse.
    </p>
<p>
        Data warehouses در حال حاضر تقریباً در تمام enterprises بزرگ وجود دارند، اما در شرکت‌های کوچک تقریباً ناشناخته هستند. این احتمالاً به این دلیل است که اکثر شرکت‌های کوچک دارای سیستم‌های OLTP متفاوت زیادی نیستند و اکثر شرکت‌های کوچک حجم کمی از data دارند—به اندازه کافی کوچک است که می‌توان آن را در یک database SQL معمولی query کرد، یا حتی در یک spreadsheet تجزیه و تحلیل کرد. در یک شرکت بزرگ، کارهای زیادی برای انجام چیزی که در یک شرکت کوچک ساده است، مورد نیاز است.
    </p>
<p>
        یک مزیت بزرگ از استفاده از یک data warehouse جداگانه، به جای querying systems OLTP به طور مستقیم برای analytics، این است که data warehouse را می‌توان برای analytic access patterns بهینه کرد. مشخص می‌شود که الگوریتم‌های indexing که در نیمه اول این فصل مورد بحث قرار گرفت، برای OLTP خوب عمل می‌کنند، اما برای پاسخ دادن به queries analytic بسیار خوب نیستند.
    </p>
<p>
        92 | Chapter 3: Storage and Retrieval
    </p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 114" src="page_0114/image_1.png"/></div>
</div>
                <div class="page-number">صفحه 0114</div>
            </div>
        </div>
        <!-- Page 0115 -->
        <div class="chapter" id="page-0115">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        در بقیه این فصل ما به storage engines نگاه خواهیم کرد که برای ana‐lytics بهینه شده‌اند.
    </p>
<h4>The divergence بین databases OLTP و data warehouses</h4>
<p>
        The data model از یک data warehouse معمولاً relational است، زیرا SQL به طور کلی برای queries analytic مناسب است. ابزارهای تجزیه و تحلیل داده‌های گرافیکی زیادی وجود دارد که queries SQL را تولید می‌کنند، نتایج را تجسم می‌کنند و به analysts اجازه می‌دهند تا داده‌ها را (از طریق عملیاتی مانند drill-down و slicing and dicing) بررسی کنند.
    </p>
<p>
        در ظاهر، یک data warehouse و یک database relational OLTP شبیه به هم هستند، زیرا هر دو دارای یک interface SQL query هستند. با این حال، internals از systems می‌تواند کاملاً متفاوت به نظر برسد، زیرا آن‌ها برای الگوهای query بسیار متفاوت بهینه شده‌اند.
    </p>
<p>
        بسیاری از database vendors اکنون بر پشتیبانی از transaction processing یا workloads analytics متمرکز هستند، اما نه هر دو.
    </p>
<p>
        برخی از databases، مانند Microsoft SQL Server و SAP HANA، از transaction processing و data warehousing در همان product پشتیبانی می‌کنند. با این حال، آن‌ها به طور فزاینده‌ای به دو storage و query engines جداگانه تبدیل می‌شوند، که از طریق یک interface SQL common قابل دسترسی هستند [49, 50, 51].
    </p>
<p>
        Data warehouse vendors مانند Teradata، Vertica، SAP HANA و ParAccel معمولاً systems خود را تحت مجوزهای تجاری گران قیمت می‌فروشند. Amazon RedShift یک نسخه hosted از ParAccel است. اخیراً، تعداد زیادی از پروژه‌های open source SQL-on-Hadoop پدیدار شده‌اند. آن‌ها جوان هستند اما قصد دارند با systems commercial data warehouse رقابت کنند. این‌ها شامل Apache Hive، Spark SQL، Cloudera Impala، Facebook Presto، Apache Tajo و Apache Drill [52, 53] می‌شوند. برخی از آن‌ها بر اساس ایده‌های Dremel از Google [54] هستند.
    </p>
<h4>Stars and Snowflakes: Schemas for Analytics</h4>
<p>
        همانطور که در فصل 2 بررسی شد، طیف گسترده‌ای از data models مختلف در حوزه transaction processing استفاده می‌شود، بسته به نیازهای application. از سوی دیگر، در analytics، تنوع data models بسیار کمتر است. بسیاری از data warehouses در یک style نسبتاً formulaic استفاده می‌شوند، که به عنوان star schema (همچنین به عنوان dimen‐sional modeling [55] شناخته می‌شود) شناخته می‌شود.
    </p>
<p>
        The example schema در شکل 3-9 یک data warehouse را نشان می‌دهد که ممکن است در یک خرده‌فروش مواد غذایی یافت شود. در مرکز schema یک fact table به اصطلاح (در این مثال، fact_sales نامیده می‌شود) است. هر ردیف از fact table نشان‌دهنده یک event است که در یک زمان خاص رخ داده است (در اینجا، هر ردیف نشان‌دهنده خرید یک محصول توسط یک مشتری است). اگر ما در حال تجزیه و تحلیل traffic وب‌سایت به جای retail sales بودیم، هر ردیف ممکن است نمای یک صفحه یا کلیک توسط یک user را نشان دهد.
    </p>
<p>
        Transaction Processing or Analytics? | 93
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0115</div>
            </div>
        </div>
        <!-- Page 0116 -->
        <div class="chapter" id="page-0116">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        شکل 3-9. نمونه‌ای از یک star schema برای استفاده در یک data warehouse.
    </p>
<p>
        معمولاً، facts به عنوان events مجزا ثبت می‌شوند، زیرا این به حداکثر انعطاف‌پذیری در تجزیه و تحلیل در آینده اجازه می‌دهد. با این حال، این بدان معناست که fact table می‌تواند بسیار بزرگ شود. یک enterprise بزرگ مانند Apple، Walmart یا eBay ممکن است ده‌ها پتابایت از transaction history را در data warehouse خود داشته باشد، که بیشتر آن در واقع در fact tables است [56].
    </p>
<p>
        برخی از columns در fact table attributes هستند، مانند قیمتی که محصول فروخته شد و هزینه خرید آن از تأمین‌کننده (اجازه دادن به محاسبه profit mar‐gin). سایر columns در fact table foreign key references به tables دیگر هستند که dimension tables نامیده می‌شوند. از آنجایی که هر ردیف در fact table یک event را نشان می‌دهد، dimensions نشان‌دهنده who, what, where, when, how و why از event هستند.
    </p>
<p>
        به عنوان مثال، در شکل 3-9، یکی از dimensions، محصولی است که فروخته شده است. هر ردیف در جدول dim_product یک نوع محصول را نشان می‌دهد که برای فروش است، از جمله
    </p>
<p>
        94 | Chapter 3: Storage and Retrieval
    </p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 116" src="page_0116/image_1.png"/></div>
</div>
                <div class="page-number">صفحه 0116</div>
            </div>
        </div>
        <!-- Page 0117 -->
        <div class="chapter" id="page-0117">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        the stock-keeping unit (SKU) آن، description، brand name، category، fat content، package size و غیره. هر ردیف در fact_sales table از یک foreign key برای نشان دادن اینکه کدام prod‐uct در آن transaction خاص فروخته شده است، استفاده می‌کند. (برای سادگی، اگر مشتری چندین محصول مختلف را به طور همزمان خریداری کند، آن‌ها به عنوان ردیف‌های جداگانه در fact table نشان داده می‌شوند.)
    </p>
<p>
        حتی تاریخ و زمان اغلب با استفاده از dimension tables نشان داده می‌شوند، زیرا این به اطلاعات اضافی در مورد تاریخ‌ها (مانند تعطیلات عمومی) اجازه می‌دهد تا رمزگذاری شوند، که به queries اجازه می‌دهد بین فروش در تعطیلات و غیر تعطیلات تمایز قائل شوند.
    </p>
<p>
        The name “star schema” از این واقعیت ناشی می‌شود که وقتی relationships table تجسم می‌شوند، fact table در وسط قرار دارد، که توسط dimension tables احاطه شده است. connections به این جداول مانند پرتوهای یک ستاره هستند.
    </p>
<p>
        A variation از این template به عنوان snowflake schema شناخته می‌شود، که در آن dimensions بیشتر به subdimensions تقسیم می‌شوند. به عنوان مثال، می‌تواند tables جداگانه‌ای برای brands و product categories وجود داشته باشد، و هر ردیف در dim_product table می‌تواند به brand و category به عنوان foreign keys اشاره کند، به جای ذخیره آن‌ها به عنوان strings در جدول dim_product. Snowflake schemas بیشتر از star schemas نرمال‌سازی شده‌اند، اما star schemas اغلب ترجیح داده می‌شوند زیرا کار با آن‌ها برای analysts ساده‌تر است [55].
    </p>
<p>
        در یک data warehouse معمولی، tables اغلب بسیار wide هستند: fact tables اغلب بیش از 100 column دارند، گاهی اوقات چند صد [51]. Dimension tables نیز می‌توانند بسیار wide باشند، زیرا آن‌ها شامل تمام metadata هستند که ممکن است برای تجزیه و تحلیل مرتبط باشد—به عنوان مثال، the dim_store table ممکن است شامل جزئیاتی از اینکه کدام services در هر فروشگاه ارائه می‌شوند، آیا یک in-store bakery دارد، square footage، تاریخ افتتاح فروشگاه، آخرین تاریخ بازسازی آن، فاصله آن تا نزدیکترین بزرگراه و غیره.
    </p>
<h4>Column-Oriented Storage</h4>
<p>
        اگر شما trillions of rows و petabytes of data در fact tables خود دارید، ذخیره و querying آن‌ها به طور کارآمد به یک مشکل چالش‌برانگیز تبدیل می‌شود. Dimension tables معمولاً بسیار کوچکتر هستند (میلیون‌ها ردیف)، بنابراین در این بخش ما در درجه اول بر storage of facts تمرکز خواهیم کرد.
    </p>
<p>
        اگرچه fact tables اغلب بیش از 100 columns wide هستند، یک query data warehouse معمولی فقط به 4 یا 5 مورد از آن‌ها در یک زمان دسترسی دارد ("SELECT *" queries به ندرت برای analytics مورد نیاز هستند) [51]. query در Example 3-1 را در نظر بگیرید: این به تعداد زیادی از rows (هر occurrence از کسی که در طول سال تقویمی 2013 میوه یا آب نبات می‌خرد) دسترسی دارد، اما فقط نیاز به دسترسی به سه columns از fact_sales table دارد: date_key, product_sk و quantity. query تمام columns دیگر را نادیده می‌گیرد.
    </p>
<p>
        Column-Oriented Storage | 95
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0117</div>
            </div>
        </div>
        <!-- Page 0118 -->
        <div class="chapter" id="page-0118">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        Example 3-1. Analyzing whether people are more inclined to buy fresh fruit or candy, depending on the day of the week
    </p>
<pre><code class="language-sql">SELECT
  dim_date.weekday, dim_product.category,
  SUM(fact_sales.quantity) AS quantity_sold
FROM fact_sales
  JOIN dim_date    ON fact_sales.date_key   = dim_date.date_key
  JOIN dim_product ON fact_sales.product_sk = dim_product.product_sk
WHERE
  dim_date.year = 2013 AND
  dim_product.category IN ('Fresh fruit', 'Candy')
GROUP BY
  dim_date.weekday, dim_product.category;
</code></pre>
<p>
        چگونه می‌توانیم این query را به طور کارآمد اجرا کنیم؟
    </p>
<p>
        در اکثر databases OLTP، storage به صورت row-oriented چیده شده است: تمام values از یک ردیف از یک جدول در کنار یکدیگر ذخیره می‌شوند. Document databases similar هستند: یک document کامل معمولاً به عنوان یک sequence پیوسته از bytes ذخیره می‌شود. شما می‌توانید این را در مثال CSV در شکل 3-1 مشاهده کنید.
    </p>
<p>
        به منظور پردازش یک query مانند Example 3-1، شما ممکن است indexes را روی fact_sales.date_key و/یا fact_sales.product_sk داشته باشید که به storage engine می‌گوید که در کجا تمام فروش‌ها را برای یک تاریخ خاص یا برای یک محصول خاص پیدا کند. اما پس از آن، یک storage engine row-oriented هنوز نیاز دارد که همه آن rows (که هر کدام شامل بیش از 100 attribute هستند) را از دیسک به memory بارگذاری کند، آن‌ها را parse کند و آن‌هایی را که شرایط مورد نیاز را برآورده نمی‌کنند، فیلتر کند. این می‌تواند زمان زیادی ببرد.
    </p>
<p>
        ایده پشت column-oriented storage ساده است: همه values از یک row را با هم ذخیره نکنید، بلکه به جای آن، تمام values از هر column را با هم ذخیره کنید. اگر هر column در یک فایل جداگانه ذخیره شود، یک query فقط نیاز به خواندن و parse کردن آن columns دارد که در آن query استفاده می‌شوند، که می‌تواند کار زیادی را ذخیره کند. این اصل در شکل 3-10 نشان داده شده است. Column storage ساده‌ترین درک در یک relational data model است، اما به طور مساوی برای داده‌های nonrelational اعمال می‌شود. به عنوان مثال، Parquet [57] یک format storage columnar است که از یک document data model پشتیبانی می‌کند که بر اساس Dremel از Google [54] است.
    </p>
<p>
        96 | Chapter 3: Storage and Retrieval
    </p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 118" src="page_0118/image_1.png"/></div>
</div>
                <div class="page-number">صفحه 0118</div>
            </div>
        </div>
        <!-- Page 0119 -->
        <div class="chapter" id="page-0119">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        شکل 3-10. ذخیره data relational by column، به جای by row.
    </p>
<p>
        The column-oriented storage layout بر این واقعیت متکی است که هر فایل column شامل rows به همان ترتیب است. بنابراین، اگر شما نیاز به reassemble یک ردیف کامل دارید، شما می‌توانید entry 23rd را از هر یک از فایل‌های column مجزا بردارید و آن‌ها را کنار هم قرار دهید تا ردیف 23rd جدول را تشکیل دهید.
    </p>
<h4>Column Compression</h4>
<p>
        علاوه بر فقط loading آن columns از دیسک که برای یک query مورد نیاز هستند، ما می‌توانیم با compression داده‌ها، تقاضا برای دیسک throughput را بیشتر کاهش دهیم. خوشبختانه، column-oriented storage اغلب به خوبی با compression سازگار است.
    </p>
<p>
        به sequences of values برای هر column در شکل 3-10 نگاهی بیندازید: آن‌ها اغلب بسیار تکراری به نظر می‌رسند، که یک نشانه خوب برای compression است. بسته به داده‌های موجود در column، تکنیک‌های compression مختلفی می‌توانند استفاده شوند. یک تکنیک که به ویژه در data warehouses مؤثر است، bitmap encoding است که در شکل 3-11 نشان داده شده است.
    </p>
<p>
        Column-Oriented Storage | 97
    </p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 119" src="page_0119/image_1.png"/></div>
</div>
                <div class="page-number">صفحه 0119</div>
            </div>
        </div>
        <!-- Page 0120 -->
        <div class="chapter" id="page-0120">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        شکل 3-11. ذخیره شده، bitmap-indexed از یک column واحد.
    </p>
<p>
        اغلب، تعداد distinct values در یک column در مقایسه با تعداد rows کوچک است (به عنوان مثال، یک خرده‌فروش ممکن است میلیاردها sales transactions داشته باشد، اما فقط 100000 محصول distinct). اکنون ما می‌توانیم یک column با n distinct values را بگیریم و آن را به n bitmaps جداگانه تبدیل کنیم: یک bitmap برای هر value distinct، با یک bit برای هر row. The bit برابر 1 است اگر ردیف آن value را داشته باشد، و 0 در غیر این صورت.
    </p>
<p>
        اگر n بسیار کوچک باشد (به عنوان مثال، یک column country ممکن است تقریباً 200 distinct values داشته باشد)، آن bitmaps را می‌توان با یک bit در هر ردیف ذخیره کرد. اما اگر n بزرگتر باشد، zeros زیادی در بیشتر bitmaps وجود خواهد داشت (ما می‌گوییم که آن‌ها sparse هستند). در این صورت، bitmaps می‌توانند علاوه بر این run-length encoded باشند، همانطور که در قسمت پایین شکل 3-11 نشان داده شده است. این می‌تواند encoding از یک column را به طرز چشمگیری compact کند.
    </p>
<p>
        Bitmap indexes مانند این‌ها برای انواع queries که در یک data warehouse رایج هستند، بسیار مناسب هستند. به عنوان مثال:
    </p>
<pre><code class="language-sql">WHERE product_sk IN (30, 68, 69):
</code></pre>
<p>
        بارگذاری سه bitmaps برای product_sk = 30، product_sk = 68 و product_sk = 69، و محاسبه OR bitwise از سه bitmaps، که می‌تواند بسیار کارآمد انجام شود.
    </p>
<p>
        98 | Chapter 3: Storage and Retrieval
    </p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 120" src="page_0120/image_1.png"/></div>
</div>
                <div class="page-number">صفحه 0120</div>
            </div>
        </div>
        <!-- Page 0121 -->
        <div class="chapter" id="page-0121">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        WHERE product_sk = 31 AND store_sk = 3:
    </p>
<p>
        Load the bitmaps for product_sk = 31 و store_sk = 3، و محاسبه AND bitwise. این کار می‌کند زیرا columns حاوی ردیف‌ها به همان ترتیب هستند، بنابراین kth bit در bitmap یک column به همان ردیف به عنوان kth bit در bitmap یک column دیگر مربوط می‌شود.
    </p>
<p>
        همچنین طرح‌های compression مختلفی برای انواع مختلف data وجود دارد، اما ما به جزئیات آن‌ها نمی‌پردازیم—به [58] برای یک overview مراجعه کنید.
    </p>
<h4>Column-oriented storage و column families</h4>
<p>
        Cassandra و HBase یک مفهوم از column families دارند که آن‌ها از Bigtable [9] به ارث برده‌اند. با این حال، نامیدن آن‌ها به عنوان column-oriented بسیار گمراه‌کننده است: در داخل هر column family، آن‌ها همه columns از یک row را با هم، همراه با یک row key، ذخیره می‌کنند و از column compression استفاده نمی‌کنند. بنابراین، the Bigtable model هنوز عمدتاً row-oriented است.
    </p>
<h4>Memory bandwidth و vectorized processing</h4>
<p>
        برای data warehouse queries که نیاز به scan بر روی میلیون‌ها row دارند، یک bottleneck بزرگ، پهنای باند برای دریافت data از دیسک به memory است. با این حال، این تنها bottleneck نیست. Developers از databases analytical نیز در مورد استفاده کارآمد از پهنای باند از main memory به CPU cache، اجتناب از branch mispredic‐tions و bubbles در CPU instruction processing pipeline، و استفاده از single-instruction-multi-data (SIMD) instructions در CPUs مدرن نگران هستند [59, 60].
    </p>
<p>
        علاوه بر کاهش حجم data که باید از دیسک بارگذاری شود، layouts column-oriented storage برای استفاده کارآمد از چرخه CPU نیز خوب هستند. به عنوان مثال، query engine می‌تواند یک chunk از data column compressed را بگیرد که به راحتی در L1 cache از CPU جا می‌شود و آن را در یک حلقه فشرده (یعنی، بدون function calls) تکرار کند. یک CPU می‌تواند چنین loop را بسیار سریعتر از کدی اجرا کند که برای هر record که پردازش می‌شود، به function calls و conditions زیادی نیاز دارد. Col‐umn compression به ردیف‌های بیشتری از یک column اجازه می‌دهد تا در همان مقدار L1 cache قرار گیرند. Operators، مانند bitwise AND و OR که قبلاً توضیح داده شد، می‌توانند طوری طراحی شوند که مستقیماً بر روی چنین chunks از data column compressed کار کنند. این technique به عنوان vectorized processing [58, 49] شناخته می‌شود.
    </p>
<h4>Sort Order in Column Storage</h4>
<p>
        در یک column store، لزوماً مهم نیست که rows به چه ترتیبی ذخیره می‌شوند.
        ساده‌ترین راه برای ذخیره آن‌ها به ترتیبی است که در آن درج شده‌اند، زیرا در این صورت درج یک ردیف جدید فقط به معنای append کردن به هر یک از فایل‌های column است. با این حال، ما می‌توانیم انتخاب کنیم که یک order را اعمال کنیم، همانطور که قبلاً با SSTables انجام دادیم، و از آن به عنوان یک indexing mechanism استفاده کنیم.
    </p>
<p>
        Column-Oriented Storage | 99
    </p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 121" src="page_0121/image_1.png"/></div>
</div>
                <div class="page-number">صفحه 0121</div>
            </div>
        </div>
        <!-- Page 0122 -->
        <div class="chapter" id="page-0122">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        Note that it wouldn’t make sense to sort each column independently, because then we would no longer know which items in the columns belong to the same row. We can only reconstruct a row because we know that the kth item in one column belongs to the same row as the kth item in another column.
    </p>
<p>
        Rather, the data needs to be sorted an entire row at a time, even though it is stored by column. The administrator of the database can choose the columns by which the table should be sorted, using their knowledge of common queries. For example, if queries often target date ranges, such as the last month, it might make sense to make date_key the first sort key. Then the query optimizer can scan only the rows from the last month, which will be much faster than scanning all rows.
    </p>
<p>
        A second column can determine the sort order of any rows that have the same value in the first column. For example, if date_key is the first sort key in Figure 3-10, it might make sense for product_sk to be the second sort key so that all sales for the same product on the same day are grouped together in storage. That will help queries that need to group or filter sales by product within a certain date range.
    </p>
<p>
        Another advantage of sorted order is that it can help with compression of columns. If the primary sort column does not have many distinct values, then after sorting, it will have long sequences where the same value is repeated many times in a row. A simple run-length encoding, like we used for the bitmaps in Figure 3-11, could compress that column down to a few kilobytes—even if the table has billions of rows.
    </p>
<p>
        That compression effect is strongest on the first sort key. The second and third sort keys will be more jumbled up, and thus not have such long runs of repeated values. Columns further down the sorting priority appear in essentially random order, so they probably won’t compress as well. But having the first few columns sorted is still a win overall.
    </p>
<h4>Several different sort orders</h4>
<p>
        A clever extension of this idea was introduced in C-Store and adopted in the com‐mercial data warehouse Vertica [61, 62]. Different queries benefit from different sort orders, so why not store the same data sorted in several different ways? Data needs to be replicated to multiple machines anyway, so that you don’t lose data if one machine fails. You might as well store that redundant data sorted in different ways so that when you’re processing a query, you can use the version that best fits the query pattern.
    </p>
<p>
        Having multiple sort orders in a column-oriented store is a bit similar to having mul‐tiple secondary indexes in a row-oriented store. But the big difference is that the row-oriented store keeps every row in one place (in the heap file or a clustered index), and secondary indexes just contain pointers to the matching rows. In a column store, there normally aren’t any pointers to data elsewhere, only columns containing values.
    </p>
<p>
        100 | Chapter 3: Storage and Retrieval
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0122</div>
            </div>
        </div>
        <!-- Page 0123 -->
        <div class="chapter" id="page-0123">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<h4>Writing to Column-Oriented Storage</h4>
<p>
        این optimizations در data warehouses منطقی هستند، زیرا بیشتر load شامل queries read-only بزرگ است که توسط analysts اجرا می‌شوند. Column-oriented storage، compres‐sion و sorting همگی به سریعتر کردن آن queries read کمک می‌کنند. با این حال، آن‌ها downside از مشکل‌تر کردن writes را دارند.
    </p>
<p>
        یک رویکرد update-in-place، مانند استفاده از B-trees، با compressed col‐umns امکان‌پذیر نیست. اگر شما می‌خواستید یک ردیف را در وسط یک جدول مرتب شده درج کنید، به احتمال زیاد مجبور بودید که تمام فایل‌های column را دوباره بنویسید. از آنجایی که rows با موقعیت خود در یک column شناسایی می‌شوند، درج باید تمام columns را به طور مداوم به‌روزرسانی کند.
    </p>
<p>
        خوشبختانه، ما قبلاً یک راه‌حل خوب را در این فصل دیده‌ایم: LSM-trees.
        همه writes ابتدا به یک in-memory store می‌روند، جایی که به یک ساختار مرتب شده اضافه می‌شوند و برای نوشتن به دیسک آماده می‌شوند. مهم نیست که آیا in-memory store row-oriented یا column-oriented است. هنگامی که writes کافی جمع شدند، آن‌ها با فایل‌های column روی دیسک merge می‌شوند و به صورت bulk در فایل‌های جدید نوشته می‌شوند. این اساساً همان کاری است که Vertica انجام می‌دهد [62].
    </p>
<p>
        Queries نیاز به بررسی هر دو data column روی دیسک و writes اخیر در memory دارند و این دو را ترکیب می‌کنند. با این حال، query optimizer این تمایز را از user پنهان می‌کند. از دیدگاه یک analyst، data که با inserts، updates یا deletes اصلاح شده است، بلافاصله در queries بعدی منعکس می‌شود.
    </p>
<h4>Aggregation: Data Cubes and Materialized Views</h4>
<p>
        Not every data warehouse necessarily a column store: traditional row-oriented databases و چند architecture دیگر نیز استفاده می‌شوند. با این حال، columnar storage می‌تواند برای ad hoc analytical queries به طور قابل توجهی سریع‌تر باشد، بنابراین به سرعت در حال gaining popularity است [51, 63].
    </p>
<p>
        یکی دیگر از جنبه‌های data warehouses که ارزش ذکر دارد، materialized aggregates است. همانطور که قبلاً بحث شد، data warehouse queries اغلب شامل یک aggregate function، مانند COUNT, SUM, AVG, MIN یا MAX در SQL هستند. اگر از همان aggregates توسط بسیاری از queries مختلف استفاده می‌شود، crunch کردن از طریق data خام در هر زمان می‌تواند هدر رفته باشد. چرا برخی از counts یا sums را که queries اغلب استفاده می‌کنند، cache نکنیم؟
    </p>
<p>
        یک راه برای ایجاد چنین cache، a materialized view است. در یک relational data model، اغلب مانند یک view استاندارد (مجازی) تعریف می‌شود: یک object table-like که محتویات آن نتایج یک query است. تفاوت این است که a materialized view یک کپی واقعی از نتایج query است که به دیسک نوشته شده است، در حالی که یک virtual view فقط یک میانبر برای نوشتن queries است. هنگامی که شما از یک virtual view می‌خوانید، SQL engine آن را در query اساسی view در fly گسترش می‌دهد و سپس query گسترش‌یافته را پردازش می‌کند.
    </p>
<p>
        هنگامی که data اساسی تغییر می‌کند، یک materialized view نیاز به به‌روزرسانی دارد، زیرا این یک کپی denormalized از داده‌ها است. database می‌تواند این کار را به طور خودکار انجام دهد، اما
    </p>
<p>
        Column-Oriented Storage | 101
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0123</div>
            </div>
        </div>
        <!-- Page 0124 -->
        <div class="chapter" id="page-0124">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        such updates make writes more expensive, which is why materialized views are not often used in OLTP databases. In read-heavy data warehouses they can make more sense (whether or not they actually improve read performance depends on the indi‐vidual case).
    </p>
<p>
        A common special case of a materialized view is known as a data cube or OLAP cube [64]. It is a grid of aggregates grouped by different dimensions. Figure 3-12 shows an example.
    </p>
<p>
        شکل 3-12. Two dimensions از یک data cube، جمع‌آوری data با summing.
    </p>
<p>
        فرض کنید در حال حاضر هر fact دارای foreign keys فقط به دو dimension tables است—در شکل 3-12، این‌ها date و product هستند. اکنون شما می‌توانید یک جدول دو بعدی رسم کنید، با تاریخ‌ها در یک محور و محصولات در محور دیگر. هر cell حاوی aggregate (به عنوان مثال، SUM) از یک attribute (به عنوان مثال، net_price) از تمام facts با آن combination date-product است. سپس شما می‌توانید همان aggregate را در امتداد هر ردیف یا column اعمال کنید و یک summary دریافت کنید که توسط یک dimension (فروش بر اساس محصول، صرف نظر از تاریخ، یا فروش بر اساس تاریخ، صرف نظر از محصول) کاهش یافته است.
    </p>
<p>
        به طور کلی، facts اغلب بیش از دو dimension دارند. در شکل 3-9، پنج dimension وجود دارد: date، product، store، promotion و customer. تصور اینکه یک hypercube پنج بعدی چگونه خواهد بود، بسیار دشوارتر است، اما اصل یکسان باقی می‌ماند: هر cell حاوی فروش برای یک combination خاص date-product-store-promotion-customer است. این values را می‌توان سپس مکرراً در امتداد هر یک از dimensions خلاصه کرد.
    </p>
<p>
        مزیت یک data cube materialized این است که queries خاصی بسیار سریع می‌شوند زیرا آن‌ها به طور موثر precomputed شده‌اند. به عنوان مثال، اگر شما می‌خواهید بدانید
    </p>
<p>
        102 | Chapter 3: Storage and Retrieval
    </p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 124" src="page_0124/image_1.png"/></div>
</div>
                <div class="page-number">صفحه 0124</div>
            </div>
        </div>
        <!-- Page 0125 -->
        <div class="chapter" id="page-0125">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        the total sales per store yesterday، شما فقط باید به totals در امتداد the appro‐priate dimension نگاه کنید—نیازی به scan کردن میلیون‌ها ردیف نیست.
    </p>
<p>
        The disadvantage این است که یک data cube همان انعطاف‌پذیری را query کردن data خام ندارد. به عنوان مثال، هیچ راهی برای محاسبه اینکه چه نسبتی از فروش از آیتم‌هایی که بیش از 100 دلار قیمت دارند، وجود ندارد، زیرا قیمت یکی از dimensions نیست.
    </p>
<p>
        بنابراین اکثر data warehouses سعی می‌کنند تا حد امکان data خام را حفظ کنند و از aggregates مانند data cubes فقط به عنوان یک boost performance برای queries خاص استفاده می‌کنند.
    </p>
<h4>Summary</h4>
<p>
        در این فصل ما سعی کردیم بفهمیم که databases چگونه storage و retrieval را مدیریت می‌کنند. چه اتفاقی می‌افتد وقتی شما داده‌ها را در یک database ذخیره می‌کنید و database چه می‌کند وقتی دوباره data را query می‌کنید؟
    </p>
<p>
        در یک سطح بالا، ما دیدیم که storage engines به دو دسته گسترده تقسیم می‌شوند: آن‌هایی که برای transaction processing (OLTP) بهینه شده‌اند و آن‌هایی که برای analytics (OLAP) بهینه شده‌اند. تفاوت‌های بزرگی بین الگوهای دسترسی در آن use cases وجود دارد:
    </p>
<ul>
<li>سیستم‌های OLTP معمولاً user-facing هستند، به این معنی که ممکن است حجم زیادی از درخواست‌ها را ببینند. به منظور مدیریت load، applications معمولاً فقط به تعداد کمی از records در هر query دست می‌زنند. application رکوردهایی را با استفاده از نوعی key درخواست می‌کند و storage engine از یک index برای یافتن data برای key درخواستی استفاده می‌کند. Disk seek time اغلب در اینجا bottleneck است.</li>
<li>Data warehouses و سیستم‌های analytic مشابه، کمتر شناخته شده هستند، زیرا آن‌ها در درجه اول توسط business analysts استفاده می‌شوند، نه توسط end users. آن‌ها حجم بسیار کمتری از queries را نسبت به سیستم‌های OLTP مدیریت می‌کنند، اما هر query معمولاً بسیار demanding است و نیاز به میلیون‌ها records برای scan کردن در یک زمان کوتاه دارد. Disk bandwidth (نه seek time) اغلب در اینجا bottleneck است و column-oriented storage یک راه‌حل فزاینده محبوب برای این نوع workload است.</li>
</ul>
<p>
        در سمت OLTP، ما storage engines را از دو مدرسه اصلی تفکر دیدیم:
    </p>
<ul>
<li>The log-structured school، که فقط به اضافه کردن به فایل‌ها و حذف فایل‌های منسوخ شده اجازه می‌دهد، اما هرگز یک فایل را که نوشته شده است، به‌روزرسانی نمی‌کند. Bitcask، SSTables، LSM-trees، LevelDB، Cassandra، HBase، Lucene و موارد دیگر به این گروه تعلق دارند.</li>
<li>The update-in-place school، که با دیسک به عنوان مجموعه‌ای از صفحات با اندازه ثابت که می‌توانند overwrite شوند، برخورد می‌کند. B-trees بزرگترین نمونه از این فلسفه هستند، که در همه relational databases اصلی و همچنین بسیاری از غیر relational ها استفاده می‌شوند.</li>
</ul>
<p>
        Storage engines log-structured یک توسعه نسبتاً اخیر هستند. ایده اصلی آن‌ها این است که به طور سیستماتیک random-access writes را به sequential writes روی دیسک تبدیل می‌کنند، که به دلیل ویژگی‌های performance از hard drives و SSDs، throughput write بالاتری را فعال می‌کند.
    </p>
<p>
        Summary | 103
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0125</div>
            </div>
        </div>
        <!-- Page 0126 -->
        <div class="chapter" id="page-0126">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        Finishing off the OLTP side، ما یک تور مختصر را از طریق برخی از structures indexing پیچیده‌تر، و databases که برای نگه‌داشتن همه داده‌ها در memory بهینه شده‌اند، انجام دادیم.
    </p>
<p>
        سپس ما از internals of storage engines به معماری high-level از یک data warehouse معمولی نگاه کردیم. این background نشان داد که چرا analytic workloads با OLTP بسیار متفاوت هستند: وقتی queries شما نیاز به scan کردن به صورت sequential در یک تعداد زیادی از rows دارند، indexes بسیار کم‌اهمیت‌تر هستند. در عوض این مهم می‌شود که data را بسیار compact رمزگذاری کنید، تا مقدار داده‌ای که query نیاز دارد از دیسک بخواند، به حداقل برسد. ما در مورد اینکه چگونه column-oriented storage به دستیابی به این هدف کمک می‌کند، بحث کردیم.
    </p>
<p>
        به عنوان یک application developer، اگر شما مجهز به این دانش در مورد internals of storage engines هستید، شما در موقعیت بسیار بهتری قرار دارید تا بدانید کدام ابزار برای application خاص شما مناسب است. اگر شما نیاز به تنظیم پارامترهای tuning از یک database دارید، این درک به شما اجازه می‌دهد تا تصور کنید که یک value بالاتر یا پایین‌تر چه تأثیری می‌تواند داشته باشد.
    </p>
<p>
        اگرچه این فصل نمی‌توانست شما را به یک expert در تنظیم هر storage engine خاصی تبدیل کند، اما امیدواریم که شما را با لغات و ایده‌های کافی مجهز کرده باشد تا بتوانید اسناد database مورد نظر خود را درک کنید.
    </p>
<h4>References</h4>
<p>
        [1] Alfred V. Aho, John E. Hopcroft, and Jeffrey D. Ullman: Data Structures and Algorithms. Addison-Wesley, 1983. ISBN: 978-0-201-00023-8
    </p>
<p>
        [2] Thomas H. Cormen, Charles E. Leiserson, Ronald L. Rivest, and Clifford Stein: Introduction to Algorithms, 3rd edition. MIT Press, 2009. ISBN: 978-0-262-53305-8
    </p>
<p>
        [3] Justin Sheehy and David Smith: “Bitcask: A Log-Structured Hash Table for Fast Key/Value Data,” Basho Technologies, April 2010.
    </p>
<p>
        [4] Yinan Li, Bingsheng He, Robin Jun Yang, et al.: “Tree Indexing on Solid State Drives,” Proceedings of the VLDB Endowment, volume 3, number 1, pages 1195–1206, September 2010.
    </p>
<p>
        [5] Goetz Graefe: “Modern B-Tree Techniques,” Foundations and Trends in Databases, volume 3, number 4, pages 203–402, August 2011. doi:10.1561/1900000028
    </p>
<p>
        [6] Jeffrey Dean and Sanjay Ghemawat: “LevelDB Implementation Notes,” leveldb.googlecode.com.
    </p>
<p>
        [7] Dhruba Borthakur: “The History of RocksDB,” rocksdb.blogspot.com, November 24, 2013.
    </p>
<p>
        [8] Matteo Bertozzi: “Apache HBase I/O – HFile,” blog.cloudera.com, June, 29 2012.
    </p>
<p>
        104 | Chapter 3: Storage and Retrieval
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0126</div>
            </div>
        </div>
        <!-- Page 0127 -->
        <div class="chapter" id="page-0127">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        [9] Fay Chang, Jeffrey Dean, Sanjay Ghemawat, et al.: “Bigtable: A Distributed Stor‐age System for Structured Data,” at 7th USENIX Symposium on Operating System Design and Implementation (OSDI), November 2006.
    </p>
<p>
        [10] Patrick O’Neil, Edward Cheng, Dieter Gawlick, and Elizabeth O’Neil: “The Log-Structured Merge-Tree (LSM-Tree),” Acta Informatica, volume 33, number 4, pages 351–385, June 1996. doi:10.1007/s002360050048
    </p>
<p>
        [11] Mendel Rosenblum and John K. Ousterhout: “The Design and Implementation of a Log-Structured File System,” ACM Transactions on Computer Systems, volume 10, number 1, pages 26–52, February 1992. doi:10.1145/146941.146943
    </p>
<p>
        [12] Adrien Grand: “What Is in a Lucene Index?,” at Lucene/Solr Revolution, November 14, 2013.
    </p>
<p>
        [13] Deepak Kandepet: “Hacking Lucene—The Index Format,” hackerlabs.org, October 1, 2011.
    </p>
<p>
        [14] Michael McCandless: “Visualizing Lucene’s Segment Merges,” blog.mikemccand‐less.com, February 11, 2011.
    </p>
<p>
        [15] Burton H. Bloom: “Space/Time Trade-offs in Hash Coding with Allowable Errors,” Communications of the ACM, volume 13, number 7, pages 422–426, July 1970. doi:10.1145/362686.362692
    </p>
<p>
        [16] “Operating Cassandra: Compaction,” Apache Cassandra Documentation v4.0, 2016.
    </p>
<p>
        [17] Rudolf Bayer and Edward M. McCreight: “Organization and Maintenance of Large Ordered Indices,” Boeing Scientific Research Laboratories, Mathematical and Information Sciences Laboratory, report no. 20, July 1970.
    </p>
<p>
        [18] Douglas Comer: “The Ubiquitous B-Tree,” ACM Computing Surveys, volume 11, number 2, pages 121–137, June 1979. doi:10.1145/356770.356776
    </p>
<p>
        [19] Emmanuel Goossaert: “Coding for SSDs,” codecapsule.com, February 12, 2014.
    </p>
<p>
        [20] C. Mohan and Frank Levine: “ARIES/IM: An Efficient and High Concurrency Index Management Method Using Write-Ahead Logging,” at ACM International Conference on Management of Data (SIGMOD), June 1992. doi: 10.1145/130283.130338
    </p>
<p>
        [21] Howard Chu: “LDAP at Lightning Speed,” at Build Stuff ’14, November 2014.
    </p>
<p>
        [22] Bradley C. Kuszmaul: “A Comparison of Fractal Trees to Log-Structured Merge (LSM) Trees,” tokutek.com, April 22, 2014.
    </p>
<p>
        [23] Manos Athanassoulis, Michael S. Kester, Lukas M. Maas, et al.: “Designing Access Methods: The RUM Conjecture,” at 19th International Conference on Extending Database Technology (EDBT), March 2016. doi:10.5441/002/edbt.2016.42
    </p>
<p>
        Summary | 105
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0127</div>
            </div>
        </div>
        <!-- Page 0128 -->
        <div class="chapter" id="page-0128">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        [24] Peter Zaitsev: “Innodb Double Write,” percona.com, August 4, 2006.
    </p>
<p>
        [25] Tomas Vondra: “On the Impact of Full-Page Writes,” blog.2ndquadrant.com, November 23, 2016.
    </p>
<p>
        [26] Mark Callaghan: “The Advantages of an LSM vs a B-Tree,” smalldatum.blogspot.co.uk, January 19, 2016.
    </p>
<p>
        [27] Mark Callaghan: “Choosing Between Efficiency and Performance with RocksDB,” at Code Mesh, November 4, 2016.
    </p>
<p>
        [28] Michi Mutsuzaki: “MySQL vs. LevelDB,” github.com, August 2011.
    </p>
<p>
        [29] Benjamin Coverston, Jonathan Ellis, et al.: “CASSANDRA-1608: Redesigned Compaction, issues.apache.org, July 2011.
    </p>
<p>
        [30] Igor Canadi, Siying Dong, and Mark Callaghan: “RocksDB Tuning Guide,” github.com, 2016.
    </p>
<p>
        [31] MySQL 5.7 Reference Manual. Oracle, 2014.
    </p>
<p>
        [32] Books Online for SQL Server 2012. Microsoft, 2012.
    </p>
<p>
        [33] Joe Webb: “Using Covering Indexes to Improve Query Performance,” simple-talk.com, 29 September 2008.
    </p>
<p>
        [34] Frank Ramsak, Volker Markl, Robert Fenk, et al.: “Integrating the UB-Tree into a Database System Kernel,” at 26th International Conference on Very Large Data Bases (VLDB), September 2000.
    </p>
<p>
        [35] The PostGIS Development Group: “PostGIS 2.1.2dev Manual,” postgis.net, 2014.
    </p>
<p>
        [36] Robert Escriva, Bernard Wong, and Emin Gün Sirer: “HyperDex: A Distributed, Searchable Key-Value Store,” at ACM SIGCOMM Conference, August 2012. doi: 10.1145/2377677.2377681
    </p>
<p>
        [37] Michael McCandless: “Lucene’s FuzzyQuery Is 100 Times Faster in 4.0,” blog.mikemccandless.com, March 24, 2011.
    </p>
<p>
        [38] Steffen Heinz, Justin Zobel, and Hugh E. Williams: “Burst Tries: A Fast, Efficient Data Structure for String Keys,” ACM Transactions on Information Systems, volume 20, number 2, pages 192–223, April 2002. doi:10.1145/506309.506312
    </p>
<p>
        [39] Klaus U. Schulz and Stoyan Mihov: “Fast String Correction with Levenshtein Automata,” International Journal on Document Analysis and Recognition, volume 5, number 1, pages 67–85, November 2002. doi:10.1007/s10032-002-0082-8
    </p>
<p>
        [40] Christopher D. Manning, Prabhakar Raghavan, and Hinrich Schütze: Introduc‐tion to Information Retrieval. Cambridge University Press, 2008. ISBN: 978-0-521-86571-5, available online at nlp.stanford.edu/IR-book
    </p>
<p>
        106 | Chapter 3: Storage and Retrieval
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0128</div>
            </div>
        </div>
        <!-- Page 0129 -->
        <div class="chapter" id="page-0129">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        [41] Michael Stonebraker, Samuel Madden, Daniel J. Abadi, et al.: “The End of an Architectural Era (It’s Time for a Complete Rewrite),” at 33rd International Conference on Very Large Data Bases (VLDB), September 2007.
    </p>
<p>
        [42] “VoltDB Technical Overview White Paper,” VoltDB, 2014.
    </p>
<p>
        [43] Stephen M. Rumble, Ankita Kejriwal, and John K. Ousterhout: “Log-Structured Memory for DRAM-Based Storage,” at 12th USENIX Conference on File and Storage Technologies (FAST), February 2014.
    </p>
<p>
        [44] Stavros Harizopoulos, Daniel J. Abadi, Samuel Madden, and Michael Stonebraker: “OLTP Through the Looking Glass, and What We Found There,” at ACM International Conference on Management of Data (SIGMOD), June 2008. doi: 10.1145/1376616.1376713
    </p>
<p>
        [45] Justin DeBrabant, Andrew Pavlo, Stephen Tu, et al.: “Anti-Caching: A New Approach to Database Management System Architecture,” Proceedings of the VLDB Endowment, volume 6, number 14, pages 1942–1953, September 2013.
    </p>
<p>
        [46] Joy Arulraj, Andrew Pavlo, and Subramanya R. Dulloor: “Let’s Talk About Storage &amp; Recovery Methods for Non-Volatile Memory Database Systems,” at ACM International Conference on Management of Data (SIGMOD), June 2015. doi: 10.1145/2723372.2749441
    </p>
<p>
        [47] Edgar F. Codd, S. B. Codd, and C. T. Salley: “Providing OLAP to User-Analysts: An IT Mandate,” E. F. Codd Associates, 1993.
    </p>
<p>
        [48] Surajit Chaudhuri and Umeshwar Dayal: “An Overview of Data Warehousing and OLAP Technology,” ACM SIGMOD Record, volume 26, number 1, pages 65–74, March 1997. doi:10.1145/248603.248616
    </p>
<p>
        [49] Per-Åke Larson, Cipri Clinciu, Campbell Fraser, et al.: “Enhancements to SQL Server Column Stores,” at ACM International Conference on Management of Data (SIGMOD), June 2013.
    </p>
<p>
        [50] Franz Färber, Norman May, Wolfgang Lehner, et al.: “The SAP HANA Database – An Architecture Overview,” IEEE Data Engineering Bulletin, volume 35, number 1, pages 28–33, March 2012.
    </p>
<p>
        [51] Michael Stonebraker: “The Traditional RDBMS Wisdom Is (Almost Certainly) All Wrong,” presentation at EPFL, May 2013.
    </p>
<p>
        [52] Daniel J. Abadi: “Classifying the SQL-on-Hadoop Solutions,” hadapt.com, October 2, 2013.
    </p>
<p>
        [53] Marcel Kornacker, Alexander Behm, Victor Bittorf, et al.: “Impala: A Modern, Open-Source SQL Engine for Hadoop,” at 7th Biennial Conference on Innovative Data Systems Research (CIDR), January 2015.
    </p>
<p>
        Summary | 107
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0129</div>
            </div>
        </div>
        <!-- Page 0130 -->
        <div class="chapter" id="page-0130">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        [54] Sergey Melnik, Andrey Gubarev, Jing Jing Long, et al.: “Dremel: Interactive Analysis of Web-Scale Datasets,” at 36th International Conference on Very Large Data Bases (VLDB), pages 330–339, September 2010.
    </p>
<p>
        [55] Ralph Kimball and Margy Ross: The Data Warehouse Toolkit: The Definitive Guide to Dimensional Modeling, 3rd edition. John Wiley &amp; Sons, July 2013. ISBN: 978-1-118-53080-1
    </p>
<p>
        [56] Derrick Harris: “Why Apple, eBay, and Walmart Have Some of the Biggest Data Warehouses You’ve Ever Seen,” gigaom.com, March 27, 2013.
    </p>
<p>
        [57] Julien Le Dem: “Dremel Made Simple with Parquet,” blog.twitter.com, September 11, 2013.
    </p>
<p>
        [58] Daniel J. Abadi, Peter Boncz, Stavros Harizopoulos, et al.: “The Design and Implementation of Modern Column-Oriented Database Systems,” Foundations and Trends in Databases, volume 5, number 3, pages 197–280, December 2013. doi: 10.1561/1900000024
    </p>
<p>
        [59] Peter Boncz, Marcin Zukowski, and Niels Nes: “MonetDB/X100: Hyper-Pipelining Query Execution,” at 2nd Biennial Conference on Innovative Data Systems Research (CIDR), January 2005.
    </p>
<p>
        [60] Jingren Zhou and Kenneth A. Ross: “Implementing Database Operations Using SIMD Instructions,” at ACM International Conference on Management of Data (SIGMOD), pages 145–156, June 2002. doi:10.1145/564691.564709
    </p>
<p>
        [61] Michael Stonebraker, Daniel J. Abadi, Adam Batkin, et al.: “C-Store: A Column-oriented DBMS,” at 31st International Conference on Very Large Data Bases (VLDB), pages 553–564, September 2005.
    </p>
<p>
        [62] Andrew Lamb, Matt Fuller, Ramakrishna Varadarajan, et al.: “The Vertica Analytic Database: C-Store 7 Years Later,” Proceedings of the VLDB Endowment, volume 5, number 12, pages 1790–1801, August 2012.
    </p>
<p>
        [63] Julien Le Dem and Nong Li: “Efficient Data Storage for Analytics with Apache Parquet 2.0,” at Hadoop Summit, San Jose, June 2014.
    </p>
<p>
        [64] Jim Gray, Surajit Chaudhuri, Adam Bosworth, et al.: “Data Cube: A Relational Aggregation Operator Generalizing Group-By, Cross-Tab, and Sub-Totals,” Data Mining and Knowledge Discovery, volume 1, number 1, pages 29–53, March 2007. doi:10.1023/A:1009726021843
    </p>
<p>
        108 | Chapter 3: Storage and Retrieval
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0130</div>
            </div>
        </div>
        <!-- Page 0133 -->
        <div class="chapter" id="page-0133">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<h3>فصل 4</h3>
<h4>Encoding و Evolution</h4>
<p>
        Everything changes and nothing stands still.
        —Heraclitus of Ephesus, as quoted by Plato in Cratylus (360 BCE)
    </p>
<p>
        Applications ناگزیر با گذشت زمان تغییر می‌کنند. features اضافه یا اصلاح می‌شوند زیرا محصولات جدید راه‌اندازی می‌شوند، الزامات user بهتر درک می‌شوند یا شرایط کسب‌وکار تغییر می‌کند. در فصل 1 ما ایده evolvability را معرفی کردیم: ما باید هدفمان این باشد که سیستم‌هایی بسازیم که انطباق با تغییر را آسان می‌کنند ("Evolvability: Making Change Easy" در صفحه 21 را ببینید).
    </p>
<p>
        در اکثر موارد، یک تغییر در features یک application، نیاز به یک تغییر در داده‌هایی که ذخیره می‌کند نیز دارد: شاید یک فیلد جدید یا نوع record نیاز به ثبت داشته باشد، یا شاید data موجود نیاز به ارائه به یک روش جدید داشته باشد.
    </p>
<p>
        The data models که ما در فصل 2 در مورد آن‌ها بحث کردیم، راه‌های مختلفی برای مقابله با چنین تغییری دارند. Relational databases به طور کلی فرض می‌کنند که همه داده‌ها در database با یک schema مطابقت دارند: اگرچه آن schema را می‌توان تغییر داد (از طریق schema migrations؛ یعنی، دستورات ALTER)، دقیقاً یک schema در هر لحظه وجود دارد.
    </p>
<p>
        در مقابل، databases schema-on-read (“schemaless”) یک schema را اعمال نمی‌کنند، بنابراین database می‌تواند ترکیبی از formats data قدیمی‌تر و جدیدتر را که در زمان‌های مختلف نوشته شده‌اند، شامل شود ("Schema flexibility in the document model" در صفحه 39 را ببینید).
    </p>
<p>
        وقتی یک format data یا schema تغییر می‌کند، یک تغییر متناظر در application code اغلب باید اتفاق بیفتد (به عنوان مثال، شما یک فیلد جدید به یک record اضافه می‌کنید و application code شروع به خواندن و نوشتن آن فیلد می‌کند). با این حال، در یک application بزرگ، تغییرات کد اغلب نمی‌توانند به طور آنی اتفاق بیفتند:
    </p>
<p>
        111
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0133</div>
            </div>
        </div>
        <!-- Page 0134 -->
        <div class="chapter" id="page-0134">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<ul>
<li>With server-side applications شما ممکن است بخواهید یک rolling upgrade را انجام دهید (که همچنین به عنوان a staged rollout شناخته می‌شود)، deploying the new version به چند node در یک زمان، بررسی اینکه آیا نسخه جدید به آرامی در حال اجرا است یا خیر، و به تدریج از طریق همه nodes کار می‌کنید. این به نسخه‌های جدید اجازه می‌دهد بدون service downtime، deploy شوند و بنابراین releases مکرر و بهتر evolva‐bility را تشویق می‌کند.</li>
<li>With client-side applications شما در mercy of the user هستید، که ممکن است update را برای مدتی نصب نکند.</li>
</ul>
<p>
        این بدان معناست که نسخه‌های قدیمی و جدید از code، و formats data قدیمی و جدید، ممکن است به طور بالقوه در همان زمان در سیستم وجود داشته باشند. به منظور اینکه سیستم به طور روان به کار خود ادامه دهد، ما نیاز به حفظ compatibility در هر دو جهت داریم:
    </p>
<ul>
<li>Backward compatibility</li>
<li>Newer code می‌تواند داده‌هایی را که توسط کد قدیمی‌تر نوشته شده است، بخواند.</li>
<li>Forward compatibility</li>
<li>Older code می‌تواند داده‌هایی را که توسط کد جدیدتر نوشته شده است، بخواند.</li>
</ul>
<p>
        Backward compatibility معمولاً سخت نیست: به عنوان author از the newer code، شما format از data نوشته شده توسط older code را می‌دانید، و بنابراین شما می‌توانید صریحاً آن را handle کنید (در صورت لزوم با نگه داشتن ساده کد قدیمی برای خواندن data قدیمی). Forward compati‐bility می‌تواند trickier باشد، زیرا به older code نیاز دارد که additions ساخته شده توسط یک نسخه جدیدتر از code را نادیده بگیرد.
    </p>
<p>
        در این فصل ما به چندین format برای encoding data، از جمله JSON، XML، Protocol Buffers، Thrift و Avro نگاه خواهیم کرد. به طور خاص، ما به چگونگی handling schema changes و نحوه پشتیبانی آن‌ها از systems که در آن داده‌ها و کد قدیمی و جدید باید همزیستی داشته باشند، نگاه خواهیم کرد. سپس ما در مورد نحوه استفاده از آن formats برای data storage و برای communication بحث خواهیم کرد: در web services، Representational State Transfer (REST)، و remote procedure calls (RPC)، و همچنین systems message-passing مانند actors و message queues.
    </p>
<h4>Formats for Encoding Data</h4>
<p>
        برنامه‌ها معمولاً با داده‌ها در (حداقل) دو representation مختلف کار می‌کنند:
    </p>
<ol>
<li>In memory, داده‌ها در objects، structs، lists، arrays، hash tables، trees و غیره نگهداری می‌شوند. این data structures برای دسترسی و دستکاری کارآمد توسط CPU (معمولاً با استفاده از pointers) بهینه شده‌اند.</li>
<li>When you want to write data to a file or send it over the network, you have to encode it as some kind of self-contained sequence of bytes (for example, a JSON document). Since a pointer wouldn’t make sense to any other process, this</li>
</ol>
<p>
        112 | Chapter 4: Encoding and Evolution
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0134</div>
            </div>
        </div>
        <!-- Page 0135 -->
        <div class="chapter" id="page-0135">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        i. With the exception of some special cases, such as certain memory-mapped files or when operating directly on compressed data (as described in “Column Compression” on page 97).
    </p>
<p>
        ii. Note that encoding has nothing to do with encryption. We don’t discuss encryption in this book.
    </p>
<p>
        sequence-of-bytes representation کاملاً متفاوت از data structures است که معمولاً در memory استفاده می‌شوند.i
    </p>
<p>
        بنابراین، ما به نوعی translation بین دو representation نیاز داریم. The trans‐lation از representation in-memory به یک byte sequence encoding نامیده می‌شود (که همچنین به عنوان serialization یا marshalling شناخته می‌شود) و معکوس آن decoding نامیده می‌شود (parsing, deserialization, unmarshalling).ii
    </p>
<h4>Terminology clash</h4>
<p>
        Serialization متأسفانه در context از transactions (فصل 7 را ببینید) نیز استفاده می‌شود، با یک معنای کاملاً متفاوت. برای اجتناب از overloading word ما در این کتاب با encoding همراه خواهیم بود، حتی اگر serialization شاید یک اصطلاح رایج‌تر باشد.
    </p>
<p>
        از آنجایی که این یک مشکل بسیار رایج است، تعداد بی‌شماری library و encoding formats مختلف برای انتخاب وجود دارد. بیایید یک overview مختصر انجام دهیم.
    </p>
<h4>Language-Specific Formats</h4>
<p>
        بسیاری از زبان‌های برنامه‌نویسی با پشتیبانی داخلی برای encoding in-memory objects به byte sequences ارائه می‌شوند. به عنوان مثال، Java دارای java.io.Serializable [1]، Ruby دارای Marshal [2]، Python دارای pickle [3] و غیره است. بسیاری از libraries third-party نیز وجود دارند، مانند Kryo برای Java [4].
    </p>
<p>
        این encoding libraries بسیار راحت هستند، زیرا به objects in-memory اجازه می‌دهند تا با حداقل کد اضافی ذخیره و بازیابی شوند. با این حال، آن‌ها همچنین تعدادی از مشکلات عمیق را دارند:
    </p>
<ul>
<li>The encoding اغلب به یک زبان برنامه‌نویسی خاص مرتبط است و خواندن data در یک زبان دیگر بسیار دشوار است. اگر شما داده‌ها را در چنین encoding ذخیره یا منتقل می‌کنید، خود را متعهد به زبان برنامه‌نویسی فعلی خود برای مدت زمان بسیار طولانی می‌کنید و ادغام systems خود را با سازمان‌های دیگر (که ممکن است از زبان‌های مختلفی استفاده کنند) نامشخص می‌کنید.</li>
<li>به منظور بازیابی داده‌ها در همان object types، فرآیند decoding باید قادر به ایجاد نمونه از classes دلخواه باشد. این اغلب منبع مشکلات security است [5]: اگر یک attacker می‌تواند application شما را وادار به decoding یک byte sequence دلخواه کند، آن‌ها می‌توانند classes دلخواه را ایجاد کنند، که به نوبه خود اغلب به آن‌ها اجازه می‌دهد کارهای وحشتناکی مانند اجرای از راه دور کد دلخواه را انجام دهند [6, 7].</li>
</ul>
<p>
        Formats for Encoding Data | 113
    </p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 135" src="page_0135/image_1.png"/></div>
</div>
                <div class="page-number">صفحه 0135</div>
            </div>
        </div>
        <!-- Page 0136 -->
        <div class="chapter" id="page-0136">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<ul>
<li>Versioning data is often an afterthought in these libraries: as they are intended for quick and easy encoding of data, they often neglect the inconvenient prob‐lems of forward and backward compatibility.</li>
<li>Efficiency (CPU time taken to encode or decode, and the size of the encoded structure) is also often an afterthought. For example, Java’s built-in serialization is notorious for its bad performance and bloated encoding [8].</li>
</ul>
<p>
        به همین دلایل، استفاده از encoding زبان شما برای هر چیزی به جز اهداف بسیار transient، عموماً یک ایده بد است.
    </p>
<h4>JSON, XML, and Binary Variants</h4>
<p>
        حرکت به سمت encodings standardized که می‌توانند توسط بسیاری از زبان‌های برنامه‌نویسی نوشته و خوانده شوند، JSON و XML رقبا آشکاری هستند. آن‌ها به طور گسترده شناخته شده‌اند، به طور گسترده پشتیبانی می‌شوند و تقریباً به همان اندازه مورد بی‌علاقگی قرار می‌گیرند. XML اغلب به دلیل بیش از حد verbose بودن و پیچیدگی غیرضروری مورد انتقاد قرار می‌گیرد [9]. محبوبیت JSON عمدتاً به دلیل پشتیبانی داخلی آن در web browsers (با توجه به اینکه یک subset از JavaScript است) و سادگی آن نسبت به XML است. CSV یک format language-independent محبوب دیگر است، اگرچه کمتر قدرتمند است.
    </p>
<p>
        JSON, XML و CSV formats متنی هستند و بنابراین تا حدودی human-readable هستند (اگرچه syntax یک موضوع محبوب بحث است). علاوه بر issues سطحی syntax، آن‌ها همچنین مشکلات ظریفی دارند:
    </p>
<ul>
<li>There is a lot of ambiguity around the encoding of numbers. In XML and CSV, شما نمی‌توانید بین یک عدد و یک رشته که اتفاقاً از digits تشکیل شده است، تمایز قائل شوید (به جز با اشاره به یک schema خارجی). JSON بین strings و numbers تمایز قائل می‌شود، اما بین integers و floating-point numbers تمایز قائل نمی‌شود، و یک دقت را مشخص نمی‌کند.
        این یک مشکل هنگام برخورد با اعداد بزرگ است. به عنوان مثال، integers بزرگتر از 253 را نمی‌توان دقیقاً در یک عدد floating-point double-precision IEEE 754 نشان داد، بنابراین چنین اعدادی هنگام parse شدن در یک زبان که از floating-point numbers استفاده می‌کند (مانند JavaScript) نادرست می‌شوند. نمونه‌ای از اعداد بزرگتر از 253 در Twitter رخ می‌دهد، که از یک عدد 64 بیتی برای شناسایی هر tweet استفاده می‌کند. JSON که توسط API توییتر برگردانده می‌شود شامل tweet IDs دو بار است، یک بار به عنوان یک عدد JSON و یک بار به عنوان یک decimal string، برای دور زدن این واقعیت که اعداد به درستی توسط applications JavaScript parse نمی‌شوند [10].</li>
<li>JSON و XML پشتیبانی خوبی برای Unicode character strings دارند (یعنی، متن human-readable)، اما آن‌ها از binary strings (دنباله‌هایی از bytes بدون یک character encoding) پشتیبانی نمی‌کنند. Binary strings یک ویژگی مفید هستند، بنابراین افراد این محدودیت را با encoding data binary به عنوان متن با استفاده از Base64 دور می‌زنند. سپس schema برای نشان دادن اینکه value باید به عنوان Base64-encoded تفسیر شود، استفاده می‌شود. این کار می‌کند، اما تا حدودی hacky است و اندازه data را 33٪ افزایش می‌دهد.</li>
</ul>
<p>
        114 | Chapter 4: Encoding and Evolution
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0136</div>
            </div>
        </div>
        <!-- Page 0137 -->
        <div class="chapter" id="page-0137">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<ul>
<li>There is optional schema support for both XML [11] and JSON [12]. These schema languages are quite powerful, and thus quite complicated to learn and implement. Use of XML schemas is fairly widespread, but many JSON-based tools don’t bother using schemas. Since the correct interpretation of data (such as numbers and binary strings) depends on information in the schema, applications that don’t use XML/JSON schemas need to potentially hardcode the appro‐priate encoding/decoding logic instead.</li>
<li>CSV does not have any schema, so it is up to the application to define the meaning of each row and column. If an application change adds a new row or column, you have to handle that change manually. CSV is also a quite vague format (what happens if a value contains a comma or a newline character?). Although its escaping rules have been formally specified [13], not all parsers implement them correctly.</li>
</ul>
<p>
        با وجود این flaws، JSON, XML و CSV برای بسیاری از اهداف به اندازه کافی خوب هستند. احتمال دارد که آن‌ها محبوب باقی بمانند، به خصوص به عنوان data interchange formats (یعنی، برای ارسال داده‌ها از یک سازمان به سازمان دیگر). در این شرایط، تا زمانی که افراد در مورد format توافق داشته باشند، اغلب مهم نیست که format چقدر زیبا یا کارآمد است. دشواری در متقاعد کردن سازمان‌های مختلف به توافق بر سر هر چیزی، بر بیشتر نگرانی‌های دیگر غلبه می‌کند.
    </p>
<h4>Binary encoding</h4>
<p>
        برای داده‌هایی که فقط به صورت داخلی در سازمان شما استفاده می‌شوند، فشار کمتری برای استفاده از یک format encoding lowest-common-denominator وجود دارد. به عنوان مثال، شما می‌توانید یک format را انتخاب کنید که compact‌تر یا سریع‌تر برای parsing است. برای یک dataset کوچک، gains ناچیز هستند، اما هنگامی که شما وارد terabytes می‌شوید، انتخاب data format می‌تواند تأثیر زیادی داشته باشد.
    </p>
<p>
        JSON کمتر از XML verbose است، اما هر دو همچنان فضای زیادی را نسبت به binary formats استفاده می‌کنند. این observation منجر به توسعه a profusion of binary encodings برای JSON (MessagePack, BSON, BJSON, UBJSON, BISON و Smile، برای نام بردن از چند مورد) و برای XML (WBXML و Fast Infoset، به عنوان مثال) شد. این formats در niches مختلف پذیرفته شده‌اند، اما هیچ یک از آن‌ها به اندازه نسخه‌های textual از JSON و XML به طور گسترده پذیرفته نشده‌اند.
    </p>
<p>
        برخی از این formats مجموعه datatypes را گسترش می‌دهند (به عنوان مثال، تمایز integers و floating-point numbers، یا اضافه کردن پشتیبانی برای binary strings)، اما در غیر این صورت آن‌ها data model JSON/XML را بدون تغییر حفظ می‌کنند. به طور خاص، از آنجایی که آن‌ها یک schema را تجویز نمی‌کنند، آن‌ها نیاز به شامل شدن همه object field names در data encoded دارند.
        یعنی، در یک binary encoding از document JSON در Example 4-1، آن‌ها نیاز به شامل کردن رشته‌های userName, favoriteNumber و interests در جایی دارند.
    </p>
<p>
        Formats for Encoding Data | 115
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0137</div>
            </div>
        </div>
        <!-- Page 0138 -->
        <div class="chapter" id="page-0138">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        Example 4-1. Example record که ما در این فصل در چندین binary formats آن را encoding خواهیم کرد
    </p>
<pre><code class="language-json">{
    "userName": "Martin",
    "favoriteNumber": 1337,
    "interests": ["daydreaming", "hacking"]
}
</code></pre>
<p>
        بیایید به یک نمونه از MessagePack نگاهی بیندازیم، یک binary encoding برای JSON. شکل 4-1 byte sequence را نشان می‌دهد که اگر شما document JSON را در Example 4-1 با MessagePack [14] encoding کنید، دریافت می‌کنید. چند بایت اول به شرح زیر است:
    </p>
<ol>
<li>The first byte, 0x83, نشان می‌دهد که آنچه در ادامه می‌آید یک object (top four bits = 0x80) با سه فیلد (bottom four bits = 0x03) است. (در صورتی که از خود می‌پرسید اگر یک object بیش از 15 فیلد داشته باشد چه اتفاقی می‌افتد، به طوری که تعداد فیلدها در چهار بیت جا نمی‌شود، سپس یک نوع indicator متفاوت دریافت می‌کند و تعداد فیلدها در دو یا چهار بایت encoding می‌شود.)</li>
<li>The second byte, 0xa8, نشان می‌دهد که آنچه در ادامه می‌آید یک string (top four bits = 0xa0) است که هشت بایت طول دارد (bottom four bits = 0x08).</li>
<li>The next هشت بایت، field name userName در ASCII است. از آنجایی که طول قبلاً نشان داده شده بود، نیازی به هیچ marker برای گفتن اینکه string به کجا ختم می‌شود (یا هیچ escaping) وجود ندارد.</li>
<li>The next هفت بایت، value string شش حرفی Martin را با یک پیشوند 0xa6 encoding می‌کنند، و به همین ترتیب.</li>
</ol>
<p>
        The binary encoding 66 بایت طول دارد که فقط کمی کمتر از 81 بایت است که توسط the textual JSON encoding (با حذف space سفید) گرفته شده است. همه the binary encodings از JSON در این مورد مشابه هستند. مشخص نیست که آیا چنین کاهش فضای کوچکی (و شاید سرعت بخشیدن به parsing) ارزش از دست دادن human-readability را دارد یا خیر.
    </p>
<p>
        در بخش‌های بعدی ما خواهیم دید که چگونه می‌توانیم خیلی بهتر عمل کنیم و همان record را فقط در 32 بایت encoding کنیم.
    </p>
<p>
        116 | Chapter 4: Encoding and Evolution
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0138</div>
            </div>
        </div>
        <!-- Page 0139 -->
        <div class="chapter" id="page-0139">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        شکل 4-1. Example record (Example 4-1) encoded با استفاده از MessagePack.
    </p>
<h4>Thrift و Protocol Buffers</h4>
<p>
        Apache Thrift [15] و Protocol Buffers (protobuf) [16] binary encoding libraries هستند که بر اساس همان اصل هستند. Protocol Buffers در اصل در Google توسعه یافته است، Thrift در اصل در Facebook توسعه یافته است و هر دو در سال‌های 2007–08 [17] open source شدند.
    </p>
<p>
        هم Thrift و هم Protocol Buffers به یک schema برای هر data که encoding شده است، نیاز دارند. برای encoding داده‌ها در Example 4-1 در Thrift، شما schema را در زبان تعریف interface از Thrift (IDL) به این صورت توصیف می‌کنید:
    </p>
<pre><code class="language-thrift">struct Person {
  1: required string       userName,
  2: optional i64          favoriteNumber,
  3: optional list&lt;string&gt; interests
}
</code></pre>
<p>
        Formats for Encoding Data | 117
    </p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 139" src="page_0139/image_1.png"/></div>
</div>
                <div class="page-number">صفحه 0139</div>
            </div>
        </div>
        <!-- Page 0140 -->
        <div class="chapter" id="page-0140">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        iii. Actually, it has three—BinaryProtocol, CompactProtocol و DenseProtocol—اگرچه DenseProtocol فقط توسط پیاده‌سازی C++ پشتیبانی می‌شود، بنابراین به عنوان cross-language محسوب نمی‌شود [18]. علاوه بر این‌ها، format encodings مبتنی بر JSON مختلفی نیز دارد [19]. چه سرگرم‌کننده!
    </p>
<p>
        The equivalent schema definition برای Protocol Buffers بسیار شبیه است:
    </p>
<pre><code class="language-protobuf">message Person {
    required string user_name       = 1;
    optional int64  favorite_number = 2;
    repeated string interests       = 3;
}
</code></pre>
<p>
        Thrift و Protocol Buffers هر کدام با یک code generation tool همراه هستند که یک schema definition مانند مواردی که در اینجا نشان داده شده‌اند، می‌گیرند و classes را تولید می‌کنند که schema را در زبان‌های برنامه‌نویسی مختلف پیاده‌سازی می‌کنند [18]. application code شما می‌تواند این code تولید شده را فراخوانی کند تا records از schema را encode یا decode کند.
    </p>
<p>
        داده‌ها با این schema چگونه encoding می‌شوند؟ گیج‌کننده است که Thrift دارای دو binary encoding formats متفاوت است،iii که به ترتیب BinaryProtocol و CompactProtocol نامیده می‌شوند. بیایید ابتدا به BinaryProtocol نگاهی بیندازیم. encoding Example 4-1 در آن format 59 بایت طول می‌کشد، همانطور که در شکل 4-2 نشان داده شده است [19].
    </p>
<p>
        شکل 4-2. Example record encoded با استفاده از BinaryProtocol از Thrift.
    </p>
<p>
        118 | Chapter 4: Encoding and Evolution
    </p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 140" src="page_0140/image_1.png"/></div>
</div>
                <div class="page-number">صفحه 0140</div>
            </div>
        </div>
        <!-- Page 0141 -->
        <div class="chapter" id="page-0141">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        مشابه شکل 4-1، هر فیلد دارای یک type annotation است (برای نشان دادن اینکه آیا این یک string، integer، list و غیره است) و در صورت نیاز، یک length indication (طول یک string، تعداد آیتم‌ها در یک list). The strings که در داده‌ها ظاهر می‌شوند (“Martin”، “daydream‐ing” و “hacking”) نیز به عنوان ASCII (یا بهتر است بگوییم، UTF-8)، مشابه قبل، encoding شده‌اند.
    </p>
<p>
        The big difference compared to Figure 4-1 این است که هیچ field names (userName, favoriteNumber, interests) وجود ندارد. در عوض، data encoded شامل field tags است که اعداد هستند (1، 2 و 3). این‌ها اعدادی هستند که در تعریف schema ظاهر می‌شوند.
        Field tags مانند aliases برای fields هستند—آن‌ها یک راه compact از گفتن اینکه در مورد کدام فیلد صحبت می‌کنیم، بدون نیاز به نوشتن نام فیلد هستند.
    </p>
<p>
        The Thrift CompactProtocol encoding از نظر معنایی معادل BinaryProtocol است، اما همانطور که در شکل 4-3 مشاهده می‌کنید، همان اطلاعات را فقط در 34 بایت بسته‌بندی می‌کند. این کار را با بسته‌بندی field type و tag number در یک بایت واحد و با استفاده از integers با variable-length انجام می‌دهد. به جای استفاده از هشت بایت کامل برای عدد 1337، در دو بایت encoding شده است، با top bit از هر بایت که برای نشان دادن اینکه آیا bytes بیشتری در راه است، استفاده می‌شود. این بدان معناست که اعداد بین –64 و 63 در یک بایت، اعداد بین –8192 و 8191 در دو بایت، و غیره encoding می‌شوند. اعداد بزرگتر از bytes بیشتری استفاده می‌کنند.
    </p>
<p>
        شکل 4-3. Example record encoded با استفاده از CompactProtocol از Thrift.
    </p>
<p>
        در نهایت، Protocol Buffers (که فقط یک binary encoding format دارد) همان داده‌ها را همانطور که در شکل 4-4 نشان داده شده است، encoding می‌کند. bit packing را کمی متفاوت انجام می‌دهد، اما
    </p>
<p>
        Formats for Encoding Data | 119
    </p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 141" src="page_0141/image_1.png"/></div>
</div>
                <div class="page-number">صفحه 0141</div>
            </div>
        </div>
        <!-- Page 0142 -->
        <div class="chapter" id="page-0142">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        otherwise بسیار شبیه به CompactProtocol از Thrift است. Protocol Buffers همان record را در 33 بایت جا می‌دهد.
    </p>
<p>
        شکل 4-4. Example record encoded با استفاده از Protocol Buffers.
    </p>
<p>
        یک نکته قابل توجه: در schemas که قبلاً نشان داده شد، هر فیلد یا required یا optional علامت‌گذاری شده بود، اما این هیچ تفاوتی در نحوه encoding فیلد ایجاد نمی‌کند (هیچ چیز در داده‌های binary نشان نمی‌دهد که آیا یک فیلد required بوده است یا خیر). تفاوت به سادگی این است که required یک بررسی runtime را فعال می‌کند که در صورت تنظیم نشدن فیلد، fail می‌شود، که می‌تواند برای گرفتن bugs مفید باشد.
    </p>
<h4>Field tags و schema evolution</h4>
<p>
        ما قبلاً گفتیم که schemas ناگزیر نیاز به تغییر در طول زمان دارند. ما به این schema evolution می‌گوییم. چگونه Thrift و Protocol Buffers تغییرات schema را در حین حفظ backward و forward compatibility مدیریت می‌کنند؟
    </p>
<p>
        همانطور که از مثال‌ها مشاهده می‌کنید، یک record encoded، فقط concatenation از fields encoded آن است. هر فیلد توسط tag number خود (اعداد 1، 2، 3 در نمونه schemas) شناسایی می‌شود و با یک datatype (به عنوان مثال، string یا integer) حاشیه‌نویسی می‌شود. اگر یک فیلد value تنظیم نشده باشد، به سادگی از record encoded حذف می‌شود. از این می‌توانید ببینید که field tags برای معنای داده‌های encoded بسیار مهم هستند. شما می‌توانید name از یک فیلد را در schema تغییر دهید، زیرا data encoded هرگز به field names اشاره نمی‌کند، اما شما نمی‌توانید tag یک فیلد را تغییر دهید، زیرا این کار تمام داده‌های موجود را invalid می‌کند.
    </p>
<p>
        120 | Chapter 4: Encoding and Evolution
    </p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 142" src="page_0142/image_1.png"/></div>
</div>
                <div class="page-number">صفحه 0142</div>
            </div>
        </div>
        <!-- Page 0143 -->
        <div class="chapter" id="page-0143">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        You can add new fields to the schema، به شرطی که شما به هر فیلد یک tag number جدید بدهید. اگر کد قدیمی (که در مورد tag numbers جدیدی که شما اضافه کرده‌اید، اطلاعی ندارد) تلاش می‌کند data نوشته شده توسط کد جدید را بخواند، از جمله یک فیلد جدید با یک tag number که آن را تشخیص نمی‌دهد، به سادگی می‌تواند آن فیلد را نادیده بگیرد. the datatype annotation به parser اجازه می‌دهد تا تعیین کند که چند بایت نیاز به skip دارد. این backward com‐patibility را حفظ می‌کند: کد قدیمی می‌تواند records را که توسط کد جدید نوشته شده‌اند، بخواند.
    </p>
<p>
        در مورد backward compatibility چطور؟ تا زمانی که هر فیلد دارای یک tag number یکتا باشد، کد جدید همیشه می‌تواند data قدیمی را بخواند، زیرا tag numbers هنوز همان معنا را دارند. تنها جزئیات این است که اگر شما یک فیلد جدید اضافه می‌کنید، شما نمی‌توانید آن را required کنید. اگر شما بخواهید یک فیلد را اضافه کنید و آن را required کنید، آن check در صورت خواندن data توسط کد قدیمی، fail می‌شود، زیرا کد قدیمی فیلد جدیدی را که شما اضافه کرده‌اید، نخواهد نوشت. بنابراین، برای حفظ backward compatibility، هر فیلدی که شما پس از deployment اولیه از schema اضافه می‌کنید، باید optional یا دارای یک default value باشد.
    </p>
<p>
        حذف یک فیلد درست مانند اضافه کردن یک فیلد است، با نگرانی‌های backward و forward compatibility معکوس شده است. این بدان معناست که شما فقط می‌توانید یک فیلد را که optional است، حذف کنید (یک فیلد required هرگز نمی‌تواند حذف شود) و شما هرگز نمی‌توانید دوباره از همان tag number استفاده کنید (زیرا شما هنوز هم ممکن است data را در جایی داشته باشید که شامل tag number قدیمی است، و آن فیلد باید توسط کد جدید نادیده گرفته شود).
    </p>
<h4>Datatypes and schema evolution</h4>
<p>
        تغییر datatype یک فیلد چطور؟ این ممکن است امکان‌پذیر باشد—جزئیات را در documentation بررسی کنید—اما خطر این وجود دارد که values دقت خود را از دست بدهند یا truncated شوند. به عنوان مثال، فرض کنید شما یک integer 32 بیتی را به یک integer 64 بیتی تغییر می‌دهید. کد جدید می‌تواند به راحتی data نوشته شده توسط کد قدیمی را بخواند، زیرا parser می‌تواند هر bit گمشده را با zeros پر کند. با این حال، اگر کد قدیمی data نوشته شده توسط کد جدید را می‌خواند، کد قدیمی همچنان از یک متغیر 32 بیتی برای نگه داشتن value استفاده می‌کند. اگر value 64 بیتی decoded در 32 bits جا نشود، truncated خواهد شد.
    </p>
<p>
        A curious detail از Protocol Buffers این است که آن یک list یا array datatype ندارد، اما در عوض یک repeated marker برای fields دارد (که یک گزینه سوم در کنار required و optional است). همانطور که در شکل 4-4 مشاهده می‌کنید، encoding از یک repeated field دقیقاً همان چیزی است که در مورد آن گفته می‌شود: همان field tag به سادگی چندین بار در record ظاهر می‌شود. این effect خوبی دارد که تغییر یک فیلد optional (single-valued) به یک فیلد repeated (multi-valued) خوب است. کد جدید که data قدیمی را می‌خواند، یک list با صفر یا یک element را می‌بیند (بسته به اینکه آیا فیلد وجود داشته است یا خیر). کد قدیمی که data جدید را می‌خواند، فقط آخرین عنصر از list را می‌بیند.
    </p>
<p>
        Thrift دارای یک list datatype اختصاصی است که با datatype از list elements پارامتر شده است. این به همان evolution از single-valued به multi-valued که Protocol Buffers انجام می‌دهد، اجازه نمی‌دهد، اما مزیت پشتیبانی از lists nested را دارد.
    </p>
<p>
        Formats for Encoding Data | 121
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0143</div>
            </div>
        </div>
        <!-- Page 0144 -->
        <div class="chapter" id="page-0144">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<h4>Avro</h4>
<p>
        Apache Avro [20] یک binary encoding format دیگر است که به طور جالبی با Protocol Buffers و Thrift متفاوت است. این در سال 2009 به عنوان یک subproject از Hadoop شروع شد، در نتیجه عدم تناسب Thrift با use cases Hadoop [21].
    </p>
<p>
        Avro همچنین از یک schema برای مشخص کردن structure از data که encoding می‌شود، استفاده می‌کند. این دو schema languages دارد: یکی (Avro IDL) برای editing انسانی در نظر گرفته شده است، و دیگری (بر اساس JSON) که خواندن آن توسط machine آسان‌تر است.
    </p>
<p>
        Our example schema، که در Avro IDL نوشته شده است، ممکن است به این صورت باشد:
    </p>
<pre><code class="language-avro">record Person {
    string               userName;
    union { null, long } favoriteNumber = null;
    array&lt;string&gt;        interests;
}
</code></pre>
<p>
        The equivalent JSON representation از آن schema به شرح زیر است:
    </p>
<pre><code class="language-json">{
    "type": "record",
    "name": "Person",
    "fields": [
        {"name": "userName",       "type": "string"},
        {"name": "favoriteNumber", "type": ["null", "long"], "default": null},
        {"name": "interests",      "type": {"type": "array", "items": "string"}}
    ]
}
</code></pre>
<p>
        First of all, توجه داشته باشید که هیچ tag numbers در schema وجود ندارد. اگر ما record مثال خودمان (Example 4-1) را با استفاده از این schema encoding کنیم، the Avro binary encoding فقط 32 بایت طول دارد—compact‌ترین از تمام encodings که ما دیده‌ایم. تفکیک the encoded byte sequence در شکل 4-5 نشان داده شده است.
    </p>
<p>
        اگر شما byte sequence را بررسی کنید، شما می‌توانید ببینید که هیچ چیزی برای شناسایی fields یا datatypes آن‌ها وجود ندارد. The encoding به سادگی از values که در کنار هم concatenated شده‌اند، تشکیل شده است. A string فقط یک length prefix است که با bytes UTF-8 دنبال می‌شود، اما در داده‌های encoded چیزی وجود ندارد که به شما بگوید که این یک string است. به همان اندازه می‌تواند یک integer، یا چیزی کاملاً متفاوت باشد. یک integer با استفاده از یک variable-length encoding (همانند CompactProtocol از Thrift) encoding می‌شود.
    </p>
<p>
        122 | Chapter 4: Encoding and Evolution
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0144</div>
            </div>
        </div>
        <!-- Page 0145 -->
        <div class="chapter" id="page-0145">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        شکل 4-5. Example record encoded با استفاده از Avro.
    </p>
<p>
        برای parsing data binary، شما فیلدها را به ترتیبی که در schema ظاهر می‌شوند، طی می‌کنید و از schema برای تعیین datatype از هر فیلد استفاده می‌کنید. این بدان معناست که data binary فقط می‌تواند به درستی decode شود اگر کد که data را می‌خواند، از schema دقیقاً مشابه کدی که داده‌ها را نوشته است، استفاده می‌کند. هر mismatch در schema بین reader و writer به معنای data incorrectly decoded خواهد بود.
    </p>
<p>
        بنابراین، Avro چگونه از schema evolution پشتیبانی می‌کند؟
    </p>
<h4>The writer’s schema and the reader’s schema</h4>
<p>
        با Avro، هنگامی که یک application می‌خواهد مقداری داده را encoding کند (برای نوشتن آن در یک فایل یا database، ارسال آن از طریق شبکه و غیره)، data را با استفاده از هر نسخه از schema که در مورد آن می‌داند، encoding می‌کند—به عنوان مثال، آن schema ممکن است در application کامپایل شده باشد. این به عنوان the writer’s schema شناخته می‌شود.
    </p>
<p>
        وقتی یک application می‌خواهد data را decode کند (آن را از یک فایل یا database بخواند، از شبکه دریافت کند و غیره)، انتظار دارد data در یک schema باشد، که به عنوان the reader’s schema شناخته می‌شود. این schema است که application code به آن تکیه می‌کند—code ممکن است در طول فرآیند ساخت application از آن schema تولید شده باشد.
    </p>
<p>
        ایده کلیدی با Avro این است که the writer’s schema و the reader’s schema نیازی به یکسان بودن ندارند—آن‌ها فقط باید compatible باشند. هنگامی که data decode می‌شود (خوانده می‌شود)، the
    </p>
<p>
        Formats for Encoding Data | 123
    </p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 145" src="page_0145/image_1.png"/></div>
</div>
                <div class="page-number">صفحه 0145</div>
            </div>
        </div>
        <!-- Page 0146 -->
        <div class="chapter" id="page-0146">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        کتابخانه Avro این تفاوت‌ها را با نگاه کردن به the writer’s schema و the reader’s schema در کنار هم و ترجمه data از the writer’s schema به the reader’s schema حل می‌کند. the Avro specification [20] دقیقاً نحوه عملکرد این resolution را تعریف می‌کند و در شکل 4-6 نشان داده شده است.
    </p>
<p>
        به عنوان مثال، هیچ مشکلی وجود ندارد اگر the writer’s schema و the reader’s schema فیلدهای خود را به ترتیب متفاوتی داشته باشند، زیرا schema resolution، فیلدها را بر اساس field name با هم مطابقت می‌دهد. اگر کد که data را می‌خواند، با یک فیلد مواجه شود که در the writer’s schema ظاهر می‌شود اما در the reader’s schema وجود ندارد، به سادگی آن فیلد را نادیده می‌گیرد. اگر کد که data را می‌خواند، انتظار یک فیلد را داشته باشد، اما the writer’s schema حاوی یک فیلد با آن نام نباشد، با یک default value که در the reader’s schema اعلام شده است، پر می‌شود.
    </p>
<p>
        شکل 4-6. A Avro reader تفاوت‌ها بین the writer’s schema و the reader’s schema را حل می‌کند.
    </p>
<h4>Schema evolution rules</h4>
<p>
        با Avro، forward compatibility به این معنی است که شما می‌توانید یک نسخه جدید از schema را به عنوان writer و یک نسخه قدیمی از schema را به عنوان reader داشته باشید. برعکس، backward compatibility به این معنی است که شما می‌توانید یک نسخه جدید از schema را به عنوان reader و یک نسخه قدیمی را به عنوان writer داشته باشید.
    </p>
<p>
        برای حفظ compatibility، شما فقط ممکن است یک فیلد را اضافه یا حذف کنید که دارای default value باشد. (فیلد favoriteNumber در schema Avro ما دارای یک default value از null است.)
    </p>
<p>
        به عنوان مثال، فرض کنید شما یک فیلد را با یک default value اضافه می‌کنید، بنابراین این فیلد جدید در new schema وجود دارد اما در old schema وجود ندارد. هنگامی که یک reader با استفاده از schema جدید، یک record را که با schema قدیمی نوشته شده است، می‌خواند، the default value برای فیلد گمشده پر می‌شود.
    </p>
<p>
        اگر شما یک فیلد را اضافه کنید که هیچ default value ندارد، readers جدید نمی‌توانند data نوشته شده توسط writers قدیمی را بخوانند، بنابراین شما backward compatibility را خراب خواهید کرد. اگر شما یک فیلد را که هیچ default value ندارد، حذف کنید، readers قدیمی نمی‌توانند data نوشته شده توسط writers جدید را بخوانند، بنابراین شما forward compatibility را خراب خواهید کرد.
    </p>
<p>
        124 | Chapter 4: Encoding and Evolution
    </p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 146" src="page_0146/image_1.png"/></div>
</div>
                <div class="page-number">صفحه 0146</div>
            </div>
        </div>
        <!-- Page 0147 -->
        <div class="chapter" id="page-0147">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        iv. To be precise, the default value must be of the type of the first branch of the union, although this is a specific limitation of Avro, not a general feature of union types.
    </p>
<p>
        در برخی از زبان‌های برنامه‌نویسی، null یک default قابل قبول برای هر متغیری است، اما این مورد در Avro صدق نمی‌کند: اگر شما می‌خواهید به یک فیلد اجازه دهید null باشد، شما باید از یک type union استفاده کنید. به عنوان مثال، union { null, long, string } field; نشان می‌دهد که فیلد می‌تواند یک عدد، یا یک string، یا null باشد. شما فقط می‌توانید از null به عنوان یک default value استفاده کنید اگر یکی از branches از union باشد.iv این کمی verboseتر از داشتن همه چیز nullable به طور پیش‌فرض است، اما به جلوگیری از bugs با صریح بودن در مورد آنچه می‌تواند و نمی‌تواند null باشد، کمک می‌کند [22].
    </p>
<p>
        در نتیجه، Avro markers optional و required را به همان روشی که Protocol Buffers و Thrift انجام می‌دهند، ندارد (در عوض دارای union types و default values است).
    </p>
<p>
        تغییر datatype از یک فیلد امکان‌پذیر است، به شرطی که Avro بتواند type را تبدیل کند.
        تغییر نام یک فیلد امکان‌پذیر است اما کمی دشوار است: the reader’s schema می‌تواند شامل aliases برای field names باشد، بنابراین می‌تواند field names از old writer’s schema را با aliases مطابقت دهد. این بدان معناست که تغییر یک field name backward compatible است، اما forward compatible نیست. به طور مشابه، اضافه کردن یک branch به یک type union backward compatible است، اما forward compatible نیست.
    </p>
<h4>But what is the writer’s schema?</h4>
<p>
        یک سوال مهم وجود دارد که ما تاکنون از آن چشم‌پوشی کرده‌ایم: چگونه reader، the writer’s schema را که یک قطعه خاص از داده با آن encoding شده است، می‌داند؟ ما نمی‌توانیم فقط کل schema را با هر record قرار دهیم، زیرا schema احتمالاً بسیار بزرگتر از داده‌های encoded خواهد بود و باعث می‌شود که تمام صرفه‌جویی در فضا از encoding binary بی‌فایده باشد.
    </p>
<p>
        پاسخ به context که در آن Avro استفاده می‌شود، بستگی دارد. برای ارائه چند مثال:
    </p>
<ul>
<li>Large file with lots of records</li>
<li>A common use for Avro—به ویژه در context از Hadoop—برای ذخیره یک فایل بزرگ که شامل میلیون‌ها record است، است، که همگی با همان schema encoding شده‌اند. (ما در مورد این نوع شرایط در فصل 10 بحث خواهیم کرد.) در این مورد، writer از آن فایل می‌تواند فقط the writer’s schema را یک بار در ابتدای فایل شامل شود. Avro یک file format (object container files) را برای انجام این کار مشخص می‌کند.</li>
<li>Database with individually written records</li>
<li>In a database, records مختلف ممکن است در زمان‌های مختلف با استفاده از the writer’s schemas مختلف نوشته شوند—شما نمی‌توانید فرض کنید که همه records schema یکسانی خواهند داشت. ساده‌ترین راه‌حل این است که یک شماره version را در ابتدای هر record encoded قرار دهید و یک list از schema versions را در data‐</li>
</ul>
<p>
        Formats for Encoding Data | 125
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0147</div>
            </div>
        </div>
        <!-- Page 0148 -->
        <div class="chapter" id="page-0148">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        base. A reader می‌تواند یک record را واکشی کند، شماره version را استخراج کند، و سپس the writer’s schema را برای آن شماره version از database واکشی کند. با استفاده از آن writer’s schema، می‌توان بقیه record را decode کرد. (به عنوان مثال، Espresso [23] به این روش عمل می‌کند.)
    </p>
<h4>Sending records over a network connection</h4>
<p>
        هنگامی که دو فرآیند در حال برقراری ارتباط از طریق یک network connec‐tion bidirectional هستند، آن‌ها می‌توانند version schema را در راه‌اندازی اتصال مذاکره کنند و سپس از آن schema برای طول عمر اتصال استفاده کنند. The Avro RPC protocol (به "Dataflow Through Services: REST and RPC" در صفحه 131 مراجعه کنید) اینگونه کار می‌کند.
    </p>
<p>
        یک database از schema versions یک چیز مفید است که در هر صورت داشته باشید، زیرا به عنوان documentation عمل می‌کند و به شما این شانس را می‌دهد که schema compatibility را بررسی کنید [24]. به عنوان شماره version، شما می‌توانید یک integer incrementing ساده، یا یک hash از schema را استفاده کنید.
    </p>
<h4>Dynamically generated schemas</h4>
<p>
        One advantage از رویکرد Avro، در مقایسه با Protocol Buffers و Thrift، این است که schema هیچ tag numbers ندارد. اما چرا این مهم است؟ مشکل در نگه‌داشتن چند number در schema چیست؟
    </p>
<p>
        تفاوت این است که Avro به schemas dynamically generated friendlyتر است. به عنوان مثال، فرض کنید شما یک relational database دارید که محتویات آن را می‌خواهید در یک فایل dump کنید، و شما می‌خواهید از یک binary format برای اجتناب از مشکلات ذکر شده با textual formats (JSON, CSV, SQL) استفاده کنید. اگر شما از Avro استفاده می‌کنید، شما می‌توانید به آسانی یک schema Avro (در representation JSON که قبلاً دیدیم) را از relational schema تولید کنید و محتویات database را با استفاده از آن schema encoding کنید، و همه آن را در یک فایل object container Avro dump کنید [25]. شما یک record schema برای هر جدول database تولید می‌کنید و هر column به یک فیلد در آن record تبدیل می‌شود. Column name در database به field name در Avro نگاشت می‌شود.
    </p>
<p>
        اکنون، اگر database schema تغییر کند (به عنوان مثال، یک جدول یک column اضافه شده و یک column حذف شده است)، شما فقط می‌توانید یک schema Avro جدید را از database schema به‌روزرسانی شده تولید کنید و data را در schema Avro جدید export کنید. فرآیند data export نیازی به توجه به تغییر schema ندارد—آن می‌تواند به سادگی تبدیل schema را هر بار که اجرا می‌شود، انجام دهد. هر کسی که فایل‌های data جدید را می‌خواند، خواهد دید که فیلدهای record تغییر کرده‌اند، اما از آنجایی که فیلدها توسط نام شناسایی می‌شوند، the updated writer’s schema هنوز هم می‌تواند با the old reader’s schema مطابقت داشته باشد.
    </p>
<p>
        در مقابل، اگر شما از Thrift یا Protocol Buffers برای این منظور استفاده می‌کردید، field tags احتمالاً باید به صورت دستی اختصاص داده می‌شدند: هر بار که database schema تغییر می‌کند، یک administrator باید به صورت دستی mapping را از data‐base column names به field tags به‌روزرسانی کند. (ممکن است این کار را بتوان اتوماتیک کرد، اما the schema generator باید بسیار مراقب باشد که tag field قبلاً استفاده شده را اختصاص ندهد)
    </p>
<p>
        126 | Chapter 4: Encoding and Evolution
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0148</div>
            </div>
        </div>
        <!-- Page 0149 -->
        <div class="chapter" id="page-0149">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        tags.) این نوع schema dynamically generated به سادگی یک هدف طراحی از Thrift یا Protocol Buffers نبود، در حالی که برای Avro بود.
    </p>
<h4>Code generation و dynamically typed languages</h4>
<p>
        Thrift و Protocol Buffers به code generation تکیه می‌کنند: پس از تعریف یک schema، شما می‌توانید کدی را تولید کنید که این schema را در یک زبان برنامه‌نویسی از انتخاب شما پیاده‌سازی می‌کند. این در زبان‌های statically typed مانند Java, C++ یا C# مفید است، زیرا به structures in-memory کارآمد اجازه می‌دهد تا برای data decoded استفاده شوند و به نوع checking و autocompletion در IDEs هنگام نوشتن برنامه‌هایی که به data structures دسترسی دارند، اجازه می‌دهد.
    </p>
<p>
        در زبان‌های برنامه‌نویسی dynamically typed مانند JavaScript, Ruby یا Python، تولید کد چندان منطقی ندارد، زیرا هیچ type checker در زمان کامپایل وجود ندارد که باید برآورده شود. Code generation اغلب در این زبان‌ها ناخوشایند است، زیرا آن‌ها در غیر این صورت از یک گام compilation صریح اجتناب می‌کنند. علاوه بر این، در مورد یک schema dynamically generated (مانند یک schema Avro که از یک database table تولید شده است)، code generation یک مانع غیرضروری برای رسیدن به داده‌ها است.
    </p>
<p>
        Avro code generation اختیاری را برای زبان‌های برنامه‌نویسی statically typed ارائه می‌دهد، اما می‌توان از آن نیز بدون هیچ code generation استفاده کرد. اگر شما یک object con‐tainer file (که schema writer’s را تعبیه می‌کند) دارید، شما می‌توانید به سادگی آن را با استفاده از کتابخانه Avro باز کنید و به data به همان روشی که می‌توانید به یک فایل JSON نگاه کنید، نگاه کنید. فایل self-describing است زیرا شامل تمام metadata ضروری است.
    </p>
<p>
        این property به ویژه در conjunction با زبان‌های data pro‐cessing dynamically typed مانند Apache Pig [26] مفید است. در Pig، شما می‌توانید فقط برخی از فایل‌های Avro را باز کنید، شروع به تجزیه و تحلیل آن‌ها کنید و datasets مشتق شده را به فایل‌های خروجی در format Avro بنویسید، بدون اینکه حتی به schemas فکر کنید.
    </p>
<h4>The Merits of Schemas</h4>
<p>
        همانطور که دیدیم، Protocol Buffers, Thrift و Avro همگی از یک schema برای توصیف یک binary encoding format استفاده می‌کنند. زبان‌های schema آن‌ها بسیار ساده‌تر از XML Schema یا JSON Schema هستند، که از قوانین اعتبارسنجی بسیار دقیق‌تری پشتیبانی می‌کنند (به عنوان مثال، "string value از این فیلد باید با این regular expression مطابقت داشته باشد" یا "the integer value از این فیلد باید بین 0 و 100 باشد"). از آنجایی که Protocol Buffers, Thrift و Avro ساده‌تر برای پیاده‌سازی و ساده‌تر برای استفاده هستند، آن‌ها برای پشتیبانی از طیف نسبتاً گسترده‌ای از زبان‌های برنامه‌نویسی رشد کرده‌اند.
    </p>
<p>
        ایده‌هایی که این encodings بر اساس آن‌ها هستند، به هیچ وجه جدید نیستند. به عنوان مثال، آن‌ها اشتراکات زیادی با ASN.1 دارند، یک زبان تعریف schema که اولین بار در سال 1984 [27] استاندارد شد. این برای تعریف پروتکل‌های شبکه مختلف استفاده می‌شد و encoding binary آن (DER) هنوز برای encoding SSL certificates (X.509)، به عنوان مثال، استفاده می‌شود [28]. ASN.1 از schema evolution با استفاده از tag numbers پشتیبانی می‌کند، مشابه Protocol Buf‐
    </p>
<p>
        Formats for Encoding Data | 127
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0149</div>
            </div>
        </div>
        <!-- Page 0150 -->
        <div class="chapter" id="page-0150">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        fers و Thrift [29]. با این حال، همچنین بسیار پیچیده و بد مستند شده است، بنابراین ASN.1 احتمالاً انتخاب خوبی برای applications جدید نیست.
    </p>
<p>
        بسیاری از data systems نیز نوعی encoding binary اختصاصی را برای data خود پیاده‌سازی می‌کنند. به عنوان مثال، اکثر relational databases دارای یک network protocol هستند که از طریق آن شما می‌توانید queries را به database ارسال کنید و پاسخ‌هایی را دریافت کنید. آن protocols به طور کلی مختص یک database خاص هستند و vendor database یک driver (به عنوان مثال، با استفاده از APIs ODBC یا JDBC) ارائه می‌دهد که پاسخ‌ها را از network protocol database به data structures in-memory decode می‌کند.
    </p>
<p>
        بنابراین، ما می‌توانیم ببینیم که اگرچه formats data textual مانند JSON, XML و CSV گسترده هستند، encodings binary مبتنی بر schemas نیز یک گزینه مناسب هستند. آن‌ها تعدادی از properties خوب را دارند:
    </p>
<ul>
<li>They can be much more compact than the various “binary JSON” variants, since they can omit field names from the encoded data.</li>
<li>The schema is a valuable form of documentation, and because the schema is required for decoding, you can be sure that it is up to date (whereas manually maintained documentation may easily diverge from reality).</li>
<li>Keeping a database of schemas allows you to check forward and backward com‐patibility of schema changes, before anything is deployed.</li>
<li>For users of statically typed programming languages, the ability to generate code from the schema is useful, since it enables type checking at compile time.</li>
</ul>
<p>
        به طور خلاصه، schema evolution همان نوع انعطاف‌پذیری را که databases schema-on-read/schemaless JSON ارائه می‌دهند (به "Schema flexibility in the document model" در صفحه 39 مراجعه کنید)، فراهم می‌کند، در حالی که تضمین‌های بهتری را در مورد data شما و tooling بهتر نیز ارائه می‌دهد.
    </p>
<h4>Modes of Dataflow</h4>
<p>
        در ابتدای این فصل ما گفتیم که هر زمان که شما می‌خواهید data را به یک فرآیند دیگر که شما memory را با آن به اشتراک نمی‌گذارید—به عنوان مثال، هر زمان که شما می‌خواهید data را از طریق شبکه ارسال کنید یا آن را در یک فایل بنویسید—شما باید آن را به عنوان یک sequence of bytes encoding کنید. سپس ما در مورد انواع مختلفی از encodings برای انجام این کار بحث کردیم.
    </p>
<p>
        ما در مورد forward و backward compatibility صحبت کردیم، که برای evolvability مهم هستند (آسان کردن تغییر با اجازه دادن به شما برای ارتقاء قسمت‌های مختلف سیستم خود به طور مستقل، و نیازی به تغییر همه چیز به یکباره ندارید). Compatibility یک رابطه بین یک فرآیند است که داده‌ها را encoding می‌کند و یک فرآیند دیگر که آن را decoding می‌کند.
    </p>
<p>
        128 | Chapter 4: Encoding and Evolution
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0150</div>
            </div>
        </div>
        <!-- Page 0151 -->
        <div class="chapter" id="page-0151">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        That’s a fairly abstract idea—there are many ways data can flow from one process to another. Who encodes the data, and who decodes it? In the rest of this chapter we will explore some of the most common ways how data flows between processes:
    </p>
<ul>
<li>Via databases (see “Dataflow Through Databases” on page 129)</li>
<li>Via service calls (see “Dataflow Through Services: REST and RPC” on page 131)</li>
<li>Via asynchronous message passing (see “Message-Passing Dataflow” on page 136)</li>
</ul>
<h4>Dataflow Through Databases</h4>
<p>
        در یک database، فرآیندی که به database می‌نویسد، داده‌ها را encoding می‌کند و فرآیندی که از database می‌خواند، آن را decoding می‌کند. ممکن است فقط یک فرآیند واحد وجود داشته باشد که به database دسترسی دارد، که در این صورت reader به سادگی یک نسخه بعدی از همان فرآیند است—در آن صورت شما می‌توانید به ذخیره کردن چیزی در database به عنوان ارسال یک message به خود آینده‌تان فکر کنید.
    </p>
<p>
        Backward compatibility در اینجا به وضوح ضروری است. در غیر این صورت، خود آینده شما قادر به decode کردن آنچه قبلاً نوشته‌اید، نخواهد بود.
    </p>
<p>
        به طور کلی، دسترسی چندین فرآیند مختلف به یک database در یک زمان، رایج است. آن فرآیندها ممکن است چندین application یا سرویس مختلف باشند، یا ممکن است به سادگی چندین نمونه از یک سرویس (که به موازات برای scal‐ability یا fault tolerance در حال اجرا هستند) باشند. به هر حال، در محیطی که application در حال تغییر است، احتمال دارد که برخی از فرآیندهای دسترسی به database در حال اجرای کد جدیدتر باشند و برخی در حال اجرای کد قدیمی‌تر باشند—به عنوان مثال، به این دلیل که یک نسخه جدید در حال حاضر در یک rolling upgrade deployment است، بنابراین برخی از نمونه‌ها به‌روزرسانی شده‌اند در حالی که بقیه هنوز نشده‌اند.
    </p>
<p>
        این بدان معناست که یک value در database ممکن است توسط یک نسخه جدیدتر از code نوشته شده باشد و متعاقباً توسط یک نسخه قدیمی‌تر از code که هنوز در حال اجرا است، خوانده شود.
    </p>
<p>
        بنابراین، forward compatibility نیز اغلب برای databases مورد نیاز است.
    </p>
<p>
        با این حال، یک snag اضافی وجود دارد. فرض کنید شما یک فیلد را به یک record schema اضافه می‌کنید و the newer code یک value را برای آن فیلد جدید به database می‌نویسد. متعاقباً، یک نسخه قدیمی‌تر از code (که هنوز در مورد فیلد جدید چیزی نمی‌داند) record را می‌خواند، آن را update می‌کند و دوباره می‌نویسد. در این شرایط، رفتار مطلوب معمولاً این است که کد قدیمی، فیلد جدید را دست نخورده نگه دارد، حتی اگر نتواند آن را تفسیر کند.
    </p>
<p>
        The encoding formats که قبلاً مورد بحث قرار گرفت، از چنین preservation of unknown fields پشتیبانی می‌کنند، اما گاهی اوقات شما نیاز دارید در سطح application مراقبت کنید، همانطور که در شکل 4-7 نشان داده شده است. به عنوان مثال، اگر شما یک database value را به objects model در application decode می‌کنید و بعداً آن objects model را دوباره encoding می‌کنید، فیلد unknown ممکن است در آن فرآیند translation از دست برود. حل این مشکل سختی نیست. شما فقط باید از آن آگاه باشید.
    </p>
<p>
        Modes of Dataflow | 129
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0151</div>
            </div>
        </div>
        <!-- Page 0152 -->
        <div class="chapter" id="page-0152">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        v. Except for MySQL، که اغلب یک جدول کامل را دوباره می‌نویسد، حتی اگر strictly necessary نباشد، همانطور که در "Schema flexibility in the document model" در صفحه 39 ذکر شد.
    </p>
<p>
        شکل 4-7. هنگامی که یک نسخه قدیمی‌تر از application، داده‌هایی را که قبلاً توسط یک نسخه جدیدتر از application نوشته شده است، به‌روزرسانی می‌کند، اگر شما مراقب نباشید، data ممکن است از بین برود.
    </p>
<h4>Different values written at different times</h4>
<p>
        یک database به طور کلی به هر value اجازه می‌دهد که در هر زمانی به‌روزرسانی شود. این بدان معناست که در یک database واحد شما ممکن است برخی از values را داشته باشید که پنج میلی‌ثانیه پیش نوشته شده‌اند و برخی از values را که پنج سال پیش نوشته شده‌اند.
    </p>
<p>
        هنگامی که شما یک نسخه جدید از application خود را (حداقل از یک server-side application) deploy می‌کنید، شما ممکن است کل نسخه قدیمی را در عرض چند دقیقه با نسخه جدید جایگزین کنید. همین در مورد محتویات database صدق نمی‌کند: داده‌های پنج ساله همچنان در آنجا، در encoding اصلی، خواهد بود، مگر اینکه شما صریحاً از آن زمان آن را دوباره بازنویسی کرده باشید. این observation گاهی اوقات به این صورت خلاصه می‌شود که داده‌ها از code عمر بیشتری دارند.
    </p>
<p>
        Rewriting (migrating) داده‌ها به یک schema جدید قطعاً امکان‌پذیر است، اما انجام آن روی یک dataset بزرگ، گران است، بنابراین اکثر databases از آن در صورت امکان اجتناب می‌کنند. اکثر relational databases به تغییرات schema ساده، مانند اضافه کردن یک column جدید با یک value default null، بدون rewriting data موجود، اجازه می‌دهند.v وقتی یک ردیف قدیمی خوانده می‌شود، database، nulls را برای هر columns که از data encoded روی دیسک از دست رفته‌اند، پر می‌کند. The document database از LinkedIn یعنی Espresso از Avro برای storage استفاده می‌کند، و به آن اجازه می‌دهد تا از rules schema evolution از Avro استفاده کند [23].
    </p>
<p>
        130 | Chapter 4: Encoding and Evolution
    </p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 152" src="page_0152/image_1.png"/></div>
</div>
                <div class="page-number">صفحه 0152</div>
            </div>
        </div>
        <!-- Page 0153 -->
        <div class="chapter" id="page-0153">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        Schema evolution به این ترتیب به کل database اجازه می‌دهد که گویی با یک schema واحد encoding شده است، حتی اگر storage اساسی ممکن است شامل records encoded با نسخه‌های تاریخی مختلف از schema باشد.
    </p>
<h4>Archival storage</h4>
<p>
        شاید شما از database خود هر از چند گاهی یک snapshot می‌گیرید، مثلاً برای اهداف پشتیبان‌گیری یا برای بارگذاری در یک data warehouse (به "Data Warehousing" در صفحه 91 مراجعه کنید). در این حالت، data dump معمولاً با استفاده از latest schema encoding می‌شود، حتی اگر the original encoding در database source شامل ترکیبی از schema versions از eras مختلف باشد. از آنجایی که شما در حال کپی کردن data هستید، ممکن است encoding از copy از data را به طور مداوم انجام دهید.
    </p>
<p>
        از آنجایی که data dump در یک go نوشته شده است و پس از آن immutable است، formats مانند فایل‌های object container Avro مناسب هستند. این همچنین یک فرصت خوب برای encoding داده‌ها در یک format column-oriented analysis-friendly مانند Parquet است ("Column Com‐pression" در صفحه 97 را ببینید).
    </p>
<p>
        در فصل 10 ما بیشتر در مورد استفاده از داده‌ها در archival storage صحبت خواهیم کرد.
    </p>
<h4>Dataflow Through Services: REST and RPC</h4>
<p>
        وقتی شما فرآیندهایی دارید که نیاز به برقراری ارتباط از طریق یک شبکه دارند، راه‌های مختلفی برای مرتب کردن آن ارتباط وجود دارد. رایج‌ترین arrangement این است که دو نقش داشته باشید: clients و servers. Servers یک API را از طریق شبکه ارائه می‌دهند و clients می‌توانند به servers متصل شوند تا درخواست‌هایی را به آن API ارسال کنند. The API که توسط server ارائه می‌شود، به عنوان یک service شناخته می‌شود.
    </p>
<p>
        وب به این شکل کار می‌کند: clients (web browsers) درخواست‌هایی را به web servers ارسال می‌کنند، با ایجاد requests GET برای دانلود HTML, CSS, JavaScript, images و غیره و ایجاد requests POST برای ارسال داده‌ها به server. The API شامل یک مجموعه استاندارد از پروتکل‌ها و formats data (HTTP, URLs, SSL/TLS, HTML و غیره) است. از آنجایی که web browsers، web servers و website authors عمدتاً در مورد این استانداردها موافق هستند، شما می‌توانید از هر web browser برای دسترسی به هر وب‌سایتی (حداقل از نظر تئوری!) استفاده کنید.
    </p>
<p>
        Web browsers تنها نوع client نیستند. به عنوان مثال، یک native app که روی یک دستگاه تلفن همراه یا یک کامپیوتر دسکتاپ در حال اجرا است نیز می‌تواند درخواست‌های network را به یک server ارسال کند و یک application JavaScript client-side که در داخل یک web browser در حال اجرا است می‌تواند از XMLHttpRequest برای تبدیل شدن به یک client HTTP استفاده کند (این تکنیک به عنوان Ajax [30] شناخته می‌شود).
    </p>
<p>
        در این حالت، پاسخ server معمولاً HTML برای نمایش به یک انسان نیست، بلکه data در یک encoding است که برای پردازش بیشتر توسط application code client-side مناسب است (مانند JSON). اگرچه HTTP ممکن است به عنوان پروتکل transport استفاده شود، the API که در بالای آن پیاده‌سازی شده است، application-specific است و client و server نیاز به توافق بر سر جزئیات آن API دارند.
    </p>
<p>
        Modes of Dataflow | 131
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0153</div>
            </div>
        </div>
        <!-- Page 0154 -->
        <div class="chapter" id="page-0154">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        Moreover, a server can itself be a client to another service (به عنوان مثال، یک web app server معمولی به عنوان client به یک database عمل می‌کند). این رویکرد اغلب برای decompose کردن یک application بزرگ به services کوچک‌تر بر اساس حوزه functionality استفاده می‌شود، به طوری که یک service یک request را به service دیگری می‌دهد، زمانی که به برخی از functionality یا data از آن service دیگر نیاز دارد. این روش ساختن applications به طور سنتی a service-oriented architecture (SOA) نامیده می‌شود و اخیراً اصلاح شده و به عنوان معماری microservices نام‌گذاری شده است [31, 32].
    </p>
<p>
        در برخی جهات، services شبیه به databases هستند: آن‌ها معمولاً به clients اجازه می‌دهند تا داده‌ها را submit و query کنند. با این حال، در حالی که databases اجازه queries دلخواه را با استفاده از query lan‐guages که در فصل 2 مورد بحث قرار دادیم، می‌دهند، services یک application-specific API را ارائه می‌دهند که فقط ورودی‌ها و خروجی‌هایی را که توسط business logic (application code) از service از قبل تعیین شده‌اند، مجاز می‌دانند [33]. این محدودیت درجه‌ای از encapsulation را فراهم می‌کند: services می‌توانند محدودیت‌های fine-grained را بر آنچه که clients می‌توانند انجام دهند و نمی‌توانند انجام دهند، اعمال کنند.
    </p>
<p>
        یک هدف اصلی طراحی از یک service-oriented/microservices architecture این است که application را با ساختن services، independently deployable و evolvable آسان‌تر می‌کند. به عنوان مثال، هر service باید توسط یک تیم متعلق به آن باشد و آن تیم باید بتواند نسخه‌های جدیدی از service را به دفعات، بدون نیاز به هماهنگی با تیم‌های دیگر منتشر کند. به عبارت دیگر، ما باید انتظار داشته باشیم که نسخه‌های قدیمی و جدید از servers و clients به طور همزمان در حال اجرا باشند، و بنابراین data encoding که توسط servers و clients استفاده می‌شود، باید در سراسر نسخه‌های service API سازگار باشد—دقیقاً همان چیزی که ما در این فصل در مورد آن صحبت می‌کنیم.
    </p>
<h4>Web services</h4>
<p>
        وقتی HTTP به عنوان the underlying protocol برای صحبت با service استفاده می‌شود، به آن web service گفته می‌شود. این شاید یک misnomer جزئی باشد، زیرا web services تنها در وب استفاده نمی‌شوند، بلکه در چندین context مختلف استفاده می‌شوند. به عنوان مثال:
    </p>
<ol>
<li>یک application client که روی دستگاه user در حال اجرا است (به عنوان مثال، یک native app روی یک دستگاه تلفن همراه، یا یک web app JavaScript با استفاده از Ajax) ایجاد requests به یک service over HTTP. این requests معمولاً از طریق اینترنت عمومی انجام می‌شود.</li>
<li>یک service که درخواست‌هایی را به service دیگری که متعلق به همان سازمان است، می‌دهد، که اغلب در همان datacenter واقع شده است، به عنوان بخشی از یک service-oriented/microser‐vices architecture. (Software که از این نوع use case پشتیبانی می‌کند، گاهی middleware نامیده می‌شود.)</li>
<li>یک service که درخواست‌هایی را به یک service که متعلق به یک سازمان دیگر است، معمولاً از طریق اینترنت می‌دهد. این برای تبادل داده‌ها بین systems backend سازمان‌های مختلف استفاده می‌شود. این دسته شامل public APIs است که توسط web services آنلاین، مانند systems credit card processing یا OAuth برای دسترسی مشترک به data user ارائه می‌شود.</li>
</ol>
<p>
        132 | Chapter 4: Encoding and Evolution
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0154</div>
            </div>
        </div>
        <!-- Page 0155 -->
        <div class="chapter" id="page-0155">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        vi. Even within each camp there are plenty of arguments. For example, HATEOAS (hypermedia as the engine of application state)، اغلب بحث‌ها را تحریک می‌کند [35].
    </p>
<p>
        vii. Despite the similarity of acronyms, SOAP is not a requirement for SOA. SOAP یک technology خاص است، در حالی که SOA یک رویکرد کلی برای ساخت systems است.
    </p>
<p>
        دو رویکرد محبوب برای web services وجود دارد: REST و SOAP. آن‌ها تقریباً از نظر فلسفی در مقابل یکدیگر قرار دارند و اغلب موضوع بحث‌های داغ در بین طرفداران مربوطه هستند.vi
    </p>
<p>
        REST یک protocol نیست، بلکه یک design philosophy است که بر اساس اصول HTTP بنا شده است [34, 35]. این بر formats داده ساده، استفاده از URLs برای شناسایی resources و استفاده از features HTTP برای cache control, Authentication و content type negotiation تأکید دارد. REST در مقایسه با SOAP در حال کسب محبوبیت است، حداقل در context از cross-organizational service integration [36]، و اغلب با microservices مرتبط است [31]. یک API که مطابق با اصول REST طراحی شده است، RESTful نامیده می‌شود.
    </p>
<p>
        در مقابل، SOAP یک protocol مبتنی بر XML برای ایجاد network API requests است.vii اگرچه بیشتر بر روی HTTP استفاده می‌شود، هدف آن این است که از HTTP مستقل باشد و از اکثر features HTTP اجتناب کند. در عوض، این با یک multitude گسترده و پیچیده از استانداردهای مرتبط (the web service framework، که به عنوان WS-* شناخته می‌شود) همراه است که features مختلف را اضافه می‌کنند [37].
    </p>
<p>
        The API از یک web service SOAP با استفاده از یک زبان مبتنی بر XML به نام the Web Services Description Language یا WSDL توضیح داده شده است. WSDL code generation را فعال می‌کند تا یک client بتواند به یک service remote با استفاده از classes و method calls محلی دسترسی پیدا کند (که به پیام‌های XML رمزگذاری شده و دوباره توسط framework decode می‌شوند). این در زبان‌های برنامه‌نویسی statically typed مفید است، اما در زبان‌های dynamically typed کمتر (به "Code generation and dynamically typed languages" در صفحه 127 مراجعه کنید).
    </p>
<p>
        از آنجایی که WSDL برای human-readable بودن طراحی نشده است، و از آنجایی که پیام‌های SOAP اغلب بیش از حد پیچیده هستند که به صورت دستی ساخته شوند، users از SOAP به شدت به پشتیبانی از ابزارها، code generation و IDEs متکی هستند [38]. برای users از زبان‌های برنامه‌نویسی که توسط vendors SOAP پشتیبانی نمی‌شوند، integration با services SOAP دشوار است.
    </p>
<p>
        حتی اگر SOAP و گسترش‌های مختلف آن ظاهراً استاندارد شده‌اند، interoper‐ability بین پیاده‌سازی‌های vendors مختلف اغلب باعث ایجاد مشکل می‌شود [39]. به همین دلیل، اگرچه SOAP هنوز در بسیاری از enterprises بزرگ استفاده می‌شود، اما در اکثر شرکت‌های کوچک‌تر از رده خارج شده است.
    </p>
<p>
        APIs RESTful تمایل به رویکردهای ساده‌تر دارند که معمولاً شامل code generation کمتر و tooling خودکار است. یک تعریف format مانند OpenAPI، که همچنین به عنوان Swagger [40] شناخته می‌شود، می‌تواند برای توصیف APIs RESTful و تولید documentation استفاده شود.
    </p>
<p>
        Modes of Dataflow | 133
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0155</div>
            </div>
        </div>
        <!-- Page 0156 -->
        <div class="chapter" id="page-0156">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        The problems with remote procedure calls (RPCs)
        Web services صرفاً جدیدترین incarnation از یک خط طولانی از technologies برای ایجاد API requests از طریق یک شبکه هستند که بسیاری از آن‌ها تبلیغات زیادی دریافت کرده‌اند، اما مشکلات جدی دارند. Enterprise JavaBeans (EJB) و Remote Method Invocation از Java (RMI) به Java محدود می‌شوند. The Distributed Component Object Model (DCOM) به پلتفرم‌های Microsoft محدود می‌شود. The Common Object Request Broker Architecture (CORBA) بیش از حد پیچیده است و backward یا forward compat‐ibility را ارائه نمی‌دهد [41].
    </p>
<p>
        All of these بر اساس ایده a remote procedure call (RPC) هستند که از دهه 1970 وجود داشته است [42]. The RPC model سعی می‌کند یک request به یک service network remote را مشابه فراخوانی یک function یا method در زبان برنامه‌نویسی شما، در همان فرآیند نشان دهد (این abstraction transparency location نامیده می‌شود).
    </p>
<p>
        اگرچه RPC در ابتدا راحت به نظر می‌رسد، رویکرد اساساً اشتباه است [43, 44]. یک request network بسیار متفاوت از یک function call محلی است:
    </p>
<ul>
<li>A local function call قابل پیش‌بینی است و یا موفق می‌شود یا fail می‌شود، فقط به پارامترهایی که تحت کنترل شما هستند، بستگی دارد. A network request غیرقابل پیش‌بینی است: request یا response ممکن است به دلیل یک مشکل network از بین برود، یا machine remote ممکن است کند یا در دسترس نباشد، و چنین مشکلاتی کاملاً خارج از کنترل شما هستند. مشکلات Network رایج هستند، بنابراین شما باید آن‌ها را پیش‌بینی کنید، به عنوان مثال با retrying یک request fail شده.</li>
<li>A local function call یا یک نتیجه را برمی‌گرداند یا یک exception را throw می‌کند، یا هرگز return نمی‌شود (زیرا وارد یک حلقه بی‌نهایت می‌شود یا فرآیند crash می‌کند). A network request یک نتیجه ممکن دیگر دارد: ممکن است بدون نتیجه برگردد، به دلیل یک timeout. در آن صورت، شما به سادگی نمی‌دانید چه اتفاقی افتاده است: اگر شما یک response از service remote دریافت نمی‌کنید، شما هیچ راهی برای دانستن اینکه آیا request انجام شده است یا خیر، ندارید. (ما این موضوع را با جزئیات بیشتر در فصل 8 بحث می‌کنیم.)</li>
<li>If you retry a failed network request، ممکن است اتفاق بیفتد که requests واقعاً در حال انجام هستند و فقط responses از بین می‌روند. در آن صورت، retrying باعث می‌شود که عمل چندین بار انجام شود، مگر اینکه شما یک مکانیزم برای deduplication (idempotence) در protocol بسازید. A local function calls این مشکل را ندارند. (ما idempotence را با جزئیات بیشتر در فصل 11 بحث می‌کنیم.)</li>
<li>Every time you call a local function, it normally takes about the same time to exe‐cute. A network request بسیار کندتر از a function call است، و latency آن نیز به شدت متغیر است: در زمان‌های خوب ممکن است در کمتر از یک میلی‌ثانیه تکمیل شود، اما هنگامی که network congested یا service remote overloaded است، ممکن است چندین ثانیه طول بکشد تا دقیقاً همان کار را انجام دهد.</li>
<li>When you call a local function, you can efficiently pass it references (pointers) to objects in local memory. When you make a network request, all those parameters</li>
</ul>
<p>
        134 | Chapter 4: Encoding and Evolution
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0156</div>
            </div>
        </div>
        <!-- Page 0157 -->
        <div class="chapter" id="page-0157">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        need to be encoded into a sequence of bytes که می‌توانند از طریق شبکه ارسال شوند.
        That’s okay if the parameters are primitives like numbers or strings, but quickly becomes problematic with larger objects.
    </p>
<ul>
<li>The client و service ممکن است در زبان‌های برنامه‌نویسی مختلف پیاده‌سازی شوند، بنابراین framework RPC باید datatypes را از یک زبان به زبان دیگر ترجمه کند. این می‌تواند زشت تمام شود، زیرا همه زبان‌ها دارای types یکسانی نیستند—به یاد داشته باشید مشکلات JavaScript با اعداد بزرگتر از 253، به عنوان مثال ("JSON, XML, and Binary Variants" در صفحه 114 را ببینید). این مشکل در یک فرآیند واحد که در یک زبان واحد نوشته شده است، وجود ندارد.</li>
</ul>
<p>
        همه این عوامل به این معنی است که هیچ فایده‌ای در تلاش برای ایجاد یک service remote وجود ندارد تا بیش از حد شبیه به یک object محلی در زبان برنامه‌نویسی شما باشد، زیرا این یک چیز اساساً متفاوت است. بخشی از جذابیت REST این است که سعی نمی‌کند این واقعیت را پنهان کند که این یک network protocol است (اگرچه به نظر می‌رسد که این امر مانع از ساختن libraries RPC بر روی REST نمی‌شود).
    </p>
<h4>Current directions for RPC</h4>
<p>
        علیرغم همه این مشکلات، RPC از بین نمی‌رود. Frameworks مختلف RPC بر روی همه encodings که در این فصل ذکر شد، ساخته شده‌اند: به عنوان مثال، Thrift و Avro با پشتیبانی RPC همراه هستند، gRPC یک پیاده‌سازی RPC با استفاده از Protocol Buffers است، Finagle همچنین از Thrift استفاده می‌کند، و Rest.li از JSON over HTTP استفاده می‌کند.
    </p>
<p>
        این نسل جدید از framework‌های RPC در مورد این واقعیت که یک request remote با یک function call محلی متفاوت است، صریح‌تر است. به عنوان مثال، Finagle و Rest.li از futures (promises) برای کپسوله کردن actions asynchronous که ممکن است fail شوند، استفاده می‌کنند. Futures همچنین موقعیت‌هایی را ساده می‌کنند که در آن‌ها شما نیاز به ایجاد requests به services متعدد به صورت موازی دارید و نتایج آن‌ها را ترکیب می‌کنید [45]. gRPC از streams پشتیبانی می‌کند، جایی که یک call شامل فقط یک request و یک response نیست، بلکه یک سری از requests و responses در طول زمان است [46].
    </p>
<p>
        برخی از این frameworks همچنین service discovery را ارائه می‌دهند—یعنی، اجازه دادن به یک client برای یافتن اینکه در کدام IP address و port number می‌تواند یک service خاص را پیدا کند. ما به این موضوع در "Request Routing" در صفحه 214 باز خواهیم گشت.
    </p>
<p>
        پروتکل‌های RPC سفارشی با یک binary encoding format می‌توانند performance بهتری نسبت به چیزی generic مانند JSON over REST داشته باشند. با این حال، یک API RESTful مزایای مهم دیگری دارد: برای آزمایش و debugging خوب است (شما به سادگی می‌توانید درخواست‌هایی را با استفاده از یک web browser یا ابزار command-line curl، بدون هیچ code generation یا نصب software انجام دهید)، توسط همه زبان‌های برنامه‌نویسی و پلتفرم‌های اصلی پشتیبانی می‌شود و یک اکوسیستم وسیع از ابزارهای موجود وجود دارد (servers، caches، load balancers، proxies، firewalls، monitoring، debugging tools، testing tools و غیره).
    </p>
<p>
        Modes of Dataflow | 135
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0157</div>
            </div>
        </div>
        <!-- Page 0158 -->
        <div class="chapter" id="page-0158">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        به همین دلایل، REST به نظر می‌رسد که سبک غالب برای public APIs است. The main focus از frameworkهای RPC بر روی requests بین services که متعلق به همان سازمان هستند، متمرکز است، که معمولاً در همان datacenter قرار دارند.
    </p>
<h4>Data encoding و evolution برای RPC</h4>
<p>
        برای evolvability، این مهم است که clients و servers RPC می‌توانند به طور مستقل تغییر داده و deploy شوند. در مقایسه با داده‌هایی که از طریق databases جریان دارند (همانطور که در بخش قبل توضیح داده شد)، ما می‌توانیم یک فرض ساده‌کننده را در مورد dataflow از طریق services در نظر بگیریم: منطقی است که فرض کنیم که همه servers ابتدا به‌روزرسانی می‌شوند و همه clients در مرحله دوم. بنابراین، شما فقط به backward compatibility در requests، و forward compatibility در responses نیاز دارید.
    </p>
<p>
        The backward و forward compatibility properties از یک طرح RPC از هر encoding که استفاده می‌کند، به ارث می‌رسد:
    </p>
<ul>
<li>Thrift، gRPC (Protocol Buffers) و Avro RPC می‌توانند با توجه به قوانین compatibility از encoding format مربوطه، تکامل یابند.</li>
<li>در SOAP، requests و responses با XML schemas مشخص می‌شوند. این‌ها می‌توانند تکامل یابند، اما برخی از pitfalls ظریف وجود دارد [47].</li>
<li>APIs RESTful به طور معمول از JSON (بدون یک schema formally specified) برای responses استفاده می‌کنند و پارامترهای request JSON یا URI-encoded/form-encoded برای requests. اضافه کردن پارامترهای request اختیاری و اضافه کردن فیلدهای جدید به objectهای response معمولاً تغییراتی در نظر گرفته می‌شوند که compatibility را حفظ می‌کنند.</li>
</ul>
<p>
        Service compatibility با این واقعیت دشوارتر می‌شود که RPC اغلب برای communication در سراسر مرزهای سازمانی استفاده می‌شود، بنابراین ارائه دهنده یک service اغلب هیچ کنترلی بر روی clients خود ندارد و نمی‌تواند آن‌ها را مجبور به ارتقاء کند. بنابراین، compatibility نیاز به مدت طولانی، شاید به طور نامحدود، حفظ می‌شود. اگر یک تغییر compatibility-breaking مورد نیاز باشد، service provider اغلب در نهایت multiple versions از service API را در کنار هم نگهداری می‌کند.
    </p>
<p>
        هیچ توافقی در مورد چگونگی عملکرد API versioning وجود ندارد (یعنی، چگونه یک client می‌تواند نشان دهد که از کدام version از API می‌خواهد استفاده کند [48]). برای APIs RESTful، رویکردهای common استفاده از یک version number در URL یا در header HTTP Accept است.
    </p>
<p>
        برای services که از API keys برای شناسایی یک client خاص استفاده می‌کنند، یک گزینه دیگر این است که یک API version درخواست شده client را در server ذخیره کنید و به این انتخاب version اجازه دهید از طریق یک interface administrative جداگانه به‌روزرسانی شود [49].
    </p>
<h4>Message-Passing Dataflow</h4>
<p>
        ما به راه‌های مختلفی نگاه می‌کردیم که data encoded از یک process به دیگری جریان می‌یابد. تاکنون، ما در مورد REST و RPC (که در آن یک فرآیند یک request را از طریق network به یک فرآیند دیگر ارسال می‌کند و انتظار یک response را در اسرع وقت دارد) بحث کرده‌ایم،
    </p>
<p>
        136 | Chapter 4: Encoding and Evolution
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0158</div>
            </div>
        </div>
        <!-- Page 0159 -->
        <div class="chapter" id="page-0159">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        and databases (که در آن یک فرآیند داده‌های encoded را می‌نویسد و یک فرآیند دیگر آن را در زمانی در آینده دوباره می‌خواند).
    </p>
<p>
        در این بخش نهایی، ما به طور خلاصه به سیستم‌های asynchronous message-passing نگاه خواهیم کرد، که در جایی بین RPC و databases قرار دارند. آن‌ها شبیه به RPC هستند زیرا request یک client (معمولاً یک message نامیده می‌شود) با low latency به یک فرآیند دیگر تحویل داده می‌شود. آن‌ها شبیه به databases هستند زیرا message از طریق یک connection network مستقیم ارسال نمی‌شود، بلکه از طریق یک واسطه به نام message broker (همچنین به عنوان a message queue یا message-oriented middleware نامیده می‌شود) می‌رود که message را به طور موقت ذخیره می‌کند.
    </p>
<p>
        استفاده از یک message broker، مزایای متعددی نسبت به RPC مستقیم دارد:
    </p>
<ul>
<li>It can act as a buffer if the recipient is unavailable or overloaded, and thus improve system reliability.</li>
<li>It can automatically redeliver messages to a process that has crashed, and thus prevent messages from being lost.</li>
<li>It avoids the sender needing to know the IP address and port number of the recipient (which is particularly useful in a cloud deployment where virtual machines often come and go).</li>
<li>It allows one message to be sent to several recipients.</li>
<li>It logically decouples the sender from the recipient (the sender just publishes messages and doesn’t care who consumes them).</li>
</ul>
<p>
        با این حال، یک تفاوت در مقایسه با RPC این است که communication message-passing معمولاً یک‌طرفه است: یک sender معمولاً انتظار دریافت یک reply را به messages خود ندارد.
        امکان ارسال یک response وجود دارد، اما این کار معمولاً در یک channel جداگانه انجام می‌شود. این الگوی communication asynchronous است: sender منتظر تحویل message نمی‌ماند، بلکه به سادگی آن را ارسال می‌کند و سپس آن را فراموش می‌کند.
    </p>
<h4>Message brokers</h4>
<p>
        در گذشته، چشم‌انداز message brokers تحت سلطه software enterprise commercial از شرکت‌هایی مانند TIBCO، IBM WebSphere و webMethods بود.
        اخیراً، پیاده‌سازی‌های open source مانند RabbitMQ, ActiveMQ, HornetQ, NATS و Apache Kafka محبوب شده‌اند. ما آن‌ها را با جزئیات بیشتر در فصل 11 مقایسه خواهیم کرد.
    </p>
<p>
        The detailed delivery semantics با پیاده‌سازی و configuration متفاوت است، اما به طور کلی، message brokers به صورت زیر استفاده می‌شوند: یک فرآیند، یک message را به یک queue یا topic نام‌گذاری شده ارسال می‌کند و broker اطمینان می‌دهد که message به یک یا چند consumer یا مشترک از آن queue یا topic تحویل داده می‌شود. می‌توانند producers و consumers زیادی در همان topic وجود داشته باشند.
    </p>
<p>
        Modes of Dataflow | 137
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0159</div>
            </div>
        </div>
        <!-- Page 0160 -->
        <div class="chapter" id="page-0160">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        A topic فقط یک dataflow یک‌طرفه را ارائه می‌دهد. با این حال، یک consumer ممکن است خود، messages را به یک topic دیگر منتشر کند (بنابراین شما می‌توانید آن‌ها را با هم زنجیر کنید، همانطور که در Chap‐ter 11 خواهیم دید)، یا به یک reply queue که توسط sender از the original message مصرف می‌شود (اجازه دادن به a request/response dataflow، شبیه به RPC).
    </p>
<p>
        Message brokers معمولاً هیچ data model خاصی را اعمال نمی‌کنند—یک message فقط یک sequence از bytes با مقداری metadata است، بنابراین شما می‌توانید از هر encoding format استفاده کنید. اگر encoding backward و forward compatible باشد، شما بیشترین انعطاف‌پذیری را برای تغییر publishers و consumers به طور مستقل دارید و آن‌ها را به هر ترتیبی deploy می‌کنید.
    </p>
<p>
        If a consumer messages را به یک topic دیگر republishes می‌کند، شما ممکن است نیاز داشته باشید که در مورد حفظ unknown fields مراقب باشید، تا از issue که قبلاً در context از databases توضیح داده شد (شکل 4-7) جلوگیری کنید.
    </p>
<h4>Distributed actor frameworks</h4>
<p>
        The actor model یک programming model برای concurrency در یک فرآیند واحد است. به جای برخورد مستقیم با threads (و مشکلات مرتبط با race conditions، locking و deadlock)، logic در actors encapsulated شده است. هر actor معمولاً یک client یا entity را نشان می‌دهد، ممکن است مقداری state local داشته باشد (که با هیچ actor دیگری به اشتراک گذاشته نمی‌شود) و با ارسال و دریافت asynchro‐nous messages با سایر actors ارتباط برقرار می‌کند. Message delivery تضمین نمی‌شود: در سناریوهای خطای خاص، messages از بین خواهند رفت. از آنجایی که هر actor فقط یک message را در یک زمان پردازش می‌کند، نیازی به نگرانی در مورد threads ندارد و هر actor می‌تواند به طور مستقل توسط framework زمان‌بندی شود.
    </p>
<p>
        در distributed actor frameworks، این programming model برای scale کردن یک application در سراسر multiple nodes استفاده می‌شود. همان مکانیزم message-passing استفاده می‌شود، مهم نیست که آیا sender و recipient در یک node یا nodes مختلف قرار دارند. اگر آن‌ها در nodes مختلف هستند، message به طور شفاف به یک byte sequence encoding می‌شود، از طریق شبکه ارسال می‌شود و در طرف دیگر decode می‌شود.
    </p>
<p>
        Location transparency در the actor model بهتر از RPC عمل می‌کند، زیرا the actor model قبلاً فرض می‌کند که messages ممکن است از بین بروند، حتی در داخل یک فرآیند واحد.
    </p>
<p>
        اگرچه latency over the network احتمالاً بالاتر از داخل همان فرآیند است، اما در استفاده از actor model، mismatch اساسی کمتری بین communication local و remote وجود دارد.
    </p>
<p>
        A distributed actor framework اساساً یک message broker و the actor programming model را در یک framework واحد ادغام می‌کند. با این حال، اگر شما می‌خواهید rolling upgrades از application مبتنی بر actor خود را انجام دهید، شما هنوز هم باید در مورد forward و backward compatibility نگران باشید، زیرا messages ممکن است از یک node که نسخه جدید را اجرا می‌کند، به یک node که نسخه قدیمی را اجرا می‌کند، ارسال شود و بالعکس.
    </p>
<p>
        سه framework actor distributed محبوب، message encoding را به شرح زیر handle می‌کنند:
    </p>
<p>
        138 | Chapter 4: Encoding and Evolution
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0160</div>
            </div>
        </div>
        <!-- Page 0161 -->
        <div class="chapter" id="page-0161">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<ul>
<li>Akka از serialization داخلی Java به طور پیش‌فرض استفاده می‌کند، که forward یا backward compatibility را ارائه نمی‌دهد. با این حال، شما می‌توانید آن را با چیزی مانند Protocol Buffers جایگزین کنید، و در نتیجه توانایی انجام rolling upgrades را به دست آورید [50].</li>
<li>Orleans به طور پیش‌فرض از یک custom data encoding format استفاده می‌کند که از deployments rolling upgrade پشتیبانی نمی‌کند. برای deploy کردن یک نسخه جدید از application خود، شما نیاز به راه‌اندازی یک cluster جدید، انتقال traffic از cluster قدیمی به new one و خاموش کردن old one دارید [51, 52]. مانند Akka، می‌توان از plug-ins serialization custom استفاده کرد.</li>
<li>In Erlang OTP، تغییر schema records به طرز شگفت‌انگیزی دشوار است (علیرغم داشتن features زیادی که برای high availability طراحی شده است). rolling upgrades امکان‌پذیر هستند اما نیاز به برنامه‌ریزی دقیق دارند [53]. یک datatype maps جدید آزمایشی (یک ساختار شبیه به JSON، که در Erlang R17 در سال 2014 معرفی شد) ممکن است این کار را در آینده آسان‌تر کند [54].</li>
</ul>
<h4>Summary</h4>
<p>
        در این فصل ما به راه‌های مختلف تبدیل data structures به bytes در شبکه یا bytes روی دیسک نگاه کردیم. ما دیدیم که چگونه جزئیات این encodings، نه تنها بر کارایی آن‌ها، بلکه مهمتر از آن، بر معماری applications و گزینه‌های شما برای deploy کردن آن‌ها تأثیر می‌گذارد.
    </p>
<p>
        به طور خاص، بسیاری از services نیاز به پشتیبانی از rolling upgrades دارند، جایی که یک نسخه جدید از یک service به تدریج به چند node در یک زمان deploy می‌شود، به جای deploy کردن به همه nodes به طور همزمان. Rolling upgrades به نسخه‌های جدید از یک service اجازه می‌دهد تا بدون downtime منتشر شوند (بنابراین releases کوچک و مکرر را به جای releases بزرگ و نادر تشویق می‌کند) و deployments را کم‌خطرتر می‌کند (اجازه دادن به releases معیوب برای شناسایی و rollback شدن قبل از اینکه بر تعداد زیادی از users تأثیر بگذارد). این properties برای evolvability، سهولت ایجاد تغییرات در یک application، بسیار مفید هستند.
    </p>
<p>
        در طول rolling upgrades، یا به دلایل مختلف دیگر، ما باید فرض کنیم که nodes مختلف در حال اجرای نسخه‌های مختلف از کد application ما هستند. بنابراین، این مهم است که همه data که در اطراف سیستم جریان دارد، به گونه‌ای encoding شده باشد که backward compatibility (کد جدید می‌تواند داده‌های قدیمی را بخواند) و forward compatibility (کد قدیمی می‌تواند داده‌های جدید را بخواند) را فراهم کند.
    </p>
<p>
        ما در مورد چندین data encoding formats و properties compatibility آن‌ها بحث کردیم:
    </p>
<ul>
<li>encodings language-specific به یک زبان برنامه‌نویسی محدود شده‌اند و اغلب در ارائه forward و backward compatibility fail می‌شوند.</li>
<li>Formats textual مانند JSON, XML و CSV گسترده هستند و compatibility آن‌ها به نحوه استفاده شما از آن‌ها بستگی دارد. آن‌ها schema languages اختیاری دارند که گاهی اوقات مفید و گاهی اوقات یک مانع هستند. این formats تا حدودی</li>
</ul>
<p>
        Summary | 139
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0161</div>
            </div>
        </div>
        <!-- Page 0162 -->
        <div class="chapter" id="page-0162">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<ul>
<li>Textual formats like JSON, XML, and CSV are somewhat vague about datatypes, so you have to be careful with things like numbers and binary strings.</li>
<li>Binary schema–driven formats like Thrift, Protocol Buffers و Avro allow compact, efficient encoding with clearly defined forward and backward com‐patibility semantics. The schemas can be useful for documentation and code generation in statically typed languages. However, they have the downside that data needs to be decoded before it is human-readable.</li>
</ul>
<p>
        ما همچنین در مورد چندین حالت از dataflow بحث کردیم که سناریوهای مختلفی را نشان می‌دهد که در آن‌ها data encodings مهم هستند:
    </p>
<ul>
<li>Databases، جایی که فرآیند نوشتن به database، داده‌ها را encoding می‌کند و فرآیند خواندن از database، آن را decoding می‌کند.</li>
<li>APIs RPC و REST، که در آن client یک request را encoding می‌کند، server request را decode می‌کند و یک response را encoding می‌کند، و client در نهایت response را decode می‌کند.</li>
<li>Asynchronous message passing (با استفاده از message brokers یا actors)، که در آن nodes با ارسال messages که توسط sender encoding شده‌اند و توسط recipient decode شده‌اند، با یکدیگر ارتباط برقرار می‌کنند.</li>
</ul>
<p>
        ما می‌توانیم نتیجه بگیریم که با کمی مراقبت، backward/forward compatibility و rolling upgrades کاملاً قابل دستیابی هستند. باشد که evolution application شما سریع و deployments شما مکرر باشد.
    </p>
<h4>References</h4>
<p>
        [1] “Java Object Serialization Specification,” docs.oracle.com, 2010.
    </p>
<p>
        [2] “Ruby 2.2.0 API Documentation,” ruby-doc.org, Dec 2014.
    </p>
<p>
        [3] “The Python 3.4.3 Standard Library Reference Manual,” docs.python.org, February 2015.
    </p>
<p>
        [4] “EsotericSoftware/kryo,” github.com, October 2014.
    </p>
<p>
        [5] “CWE-502: Deserialization of Untrusted Data,” Common Weakness Enumeration, cwe.mitre.org, July 30, 2014.
    </p>
<p>
        [6] Steve Breen: “What Do WebLogic, WebSphere, JBoss, Jenkins, OpenNMS, and Your Application Have in Common? This Vulnerability,” foxglovesecurity.com, November 6, 2015.
    </p>
<p>
        [7] Patrick McKenzie: “What the Rails Security Issue Means for Your Startup,” kalzumeus.com, January 31, 2013.
    </p>
<p>
        [8] Eishay Smith: “jvm-serializers wiki,” github.com, November 2014.
    </p>
<p>
        140 | Chapter 4: Encoding and Evolution
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0162</div>
            </div>
        </div>
        <!-- Page 0163 -->
        <div class="chapter" id="page-0163">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        [9] “XML Is a Poor Copy of S-Expressions,” c2.com wiki.
    </p>
<p>
        [10] Matt Harris: “Snowflake: An Update and Some Very Important Information,” email to Twitter Development Talk mailing list, October 19, 2010.
    </p>
<p>
        [11] Shudi (Sandy) Gao, C. M. Sperberg-McQueen, and Henry S. Thompson: “XML Schema 1.1,” W3C Recommendation, May 2001.
    </p>
<p>
        [12] Francis Galiegue, Kris Zyp, and Gary Court: “JSON Schema,” IETF Internet-Draft, February 2013.
    </p>
<p>
        [13] Yakov Shafranovich: “RFC 4180: Common Format and MIME Type for Comma-Separated Values (CSV) Files,” October 2005.
    </p>
<p>
        [14] “MessagePack Specification,” msgpack.org.
    </p>
<p>
        [15] Mark Slee, Aditya Agarwal, and Marc Kwiatkowski: “Thrift: Scalable Cross-Language Services Implementation,” Facebook technical report, April 2007.
    </p>
<p>
        [16] “Protocol Buffers Developer Guide,” Google, Inc., developers.google.com.
    </p>
<p>
        [17] Igor Anishchenko: “Thrift vs Protocol Buffers vs Avro - Biased Comparison,” slideshare.net, September 17, 2012.
    </p>
<p>
        [18] “A Matrix of the Features Each Individual Language Library Supports,” wiki.apache.org.
    </p>
<p>
        [19] Martin Kleppmann: “Schema Evolution in Avro, Protocol Buffers and Thrift,” martin.kleppmann.com, December 5, 2012.
    </p>
<p>
        [20] “Apache Avro 1.7.7 Documentation,” avro.apache.org, July 2014.
    </p>
<p>
        [21] Doug Cutting, Chad Walters, Jim Kellerman, et al.: “[PROPOSAL] New Subproject: Avro,” email thread on hadoop-general mailing list, mail-archives.apache.org, April 2009.
    </p>
<p>
        [22] Tony Hoare: “Null References: The Billion Dollar Mistake,” at QCon London, March 2009.
    </p>
<p>
        [23] Aditya Auradkar and Tom Quiggle: “Introducing Espresso—LinkedIn’s Hot New Distributed Document Store,” engineering.linkedin.com, January 21, 2015.
    </p>
<p>
        [24] Jay Kreps: “Putting Apache Kafka to Use: A Practical Guide to Building a Stream Data Platform (Part 2),” blog.confluent.io, February 25, 2015.
    </p>
<p>
        [25] Gwen Shapira: “The Problem of Managing Schemas,” radar.oreilly.com, November 4, 2014.
    </p>
<p>
        [26] “Apache Pig 0.14.0 Documentation,” pig.apache.org, November 2014.
    </p>
<p>
        [27] John Larmouth: ASN.1 Complete. Morgan Kaufmann, 1999. ISBN: 978-0-122-33435-1
    </p>
<p>
        Summary | 141
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0163</div>
            </div>
        </div>
        <!-- Page 0164 -->
        <div class="chapter" id="page-0164">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        [28] Russell Housley, Warwick Ford, Tim Polk, and David Solo: “RFC 2459: Internet X.509 Public Key Infrastructure: Certificate and CRL Profile,” IETF Network Working Group, Standards Track, January 1999.
    </p>
<p>
        [29] Lev Walkin: “Question: Extensibility and Dropping Fields,” lionet.info, September 21, 2010.
    </p>
<p>
        [30] Jesse James Garrett: “Ajax: A New Approach to Web Applications,” adaptive-path.com, February 18, 2005.
    </p>
<p>
        [31] Sam Newman: Building Microservices. O’Reilly Media, 2015. ISBN: 978-1-491-95035-7
    </p>
<p>
        [32] Chris Richardson: “Microservices: Decomposing Applications for Deployability and Scalability,” infoq.com, May 25, 2014.
    </p>
<p>
        [33] Pat Helland: “Data on the Outside Versus Data on the Inside,” at 2nd Biennial Conference on Innovative Data Systems Research (CIDR), January 2005.
    </p>
<p>
        [34] Roy Thomas Fielding: “Architectural Styles and the Design of Network-Based Software Architectures,” PhD Thesis, University of California, Irvine, 2000.
    </p>
<p>
        [35] Roy Thomas Fielding: “REST APIs Must Be Hypertext-Driven,” roy.gbiv.com, October 20 2008.
    </p>
<p>
        [36] “REST in Peace, SOAP,” royal.pingdom.com, October 15, 2010.
    </p>
<p>
        [37] “Web Services Standards as of Q1 2007,” innoq.com, February 2007.
    </p>
<p>
        [38] Pete Lacey: “The S Stands for Simple,” harmful.cat-v.org, November 15, 2006.
    </p>
<p>
        [39] Stefan Tilkov: “Interview: Pete Lacey Criticizes Web Services,” infoq.com, December 12, 2006.
    </p>
<p>
        [40] “OpenAPI Specification (fka Swagger RESTful API Documentation Specification) Version 2.0,” swagger.io, September 8, 2014.
    </p>
<p>
        [41] Michi Henning: “The Rise and Fall of CORBA,” ACM Queue, volume 4, number 5, pages 28–34, June 2006. doi:10.1145/1142031.1142044
    </p>
<p>
        [42] Andrew D. Birrell and Bruce Jay Nelson: “Implementing Remote Procedure Calls,” ACM Transactions on Computer Systems (TOCS), volume 2, number 1, pages 39–59, February 1984. doi:10.1145/2080.357392
    </p>
<p>
        [43] Jim Waldo, Geoff Wyant, Ann Wollrath, and Sam Kendall: “A Note on Distributed Computing,” Sun Microsystems Laboratories, Inc., Technical Report TR-94-29, November 1994.
    </p>
<p>
        [44] Steve Vinoski: “Convenience over Correctness,” IEEE Internet Computing, volume 12, number 4, pages 89–92, July 2008. doi:10.1109/MIC.2008.75
    </p>
<p>
        142 | Chapter 4: Encoding and Evolution
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0164</div>
            </div>
        </div>
        <!-- Page 0165 -->
        <div class="chapter" id="page-0165">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        [45] Marius Eriksen: “Your Server as a Function,” at 7th Workshop on Programming Languages and Operating Systems (PLOS), November 2013. doi: 10.1145/2525528.2525538
    </p>
<p>
        [46] “grpc-common Documentation,” Google, Inc., github.com, February 2015.
    </p>
<p>
        [47] Aditya Narayan and Irina Singh: “Designing and Versioning Compatible Web Services,” ibm.com, March 28, 2007.
    </p>
<p>
        [48] Troy Hunt: “Your API Versioning Is Wrong, Which Is Why I Decided to Do It 3 Different Wrong Ways,” troyhunt.com, February 10, 2014.
    </p>
<p>
        [49] “API Upgrades,” Stripe, Inc., April 2015.
    </p>
<p>
        [50] Jonas Bonér: “Upgrade in an Akka Cluster,” email to akka-user mailing list, grokbase.com, August 28, 2013.
    </p>
<p>
        [51] Philip A. Bernstein, Sergey Bykov, Alan Geller, et al.: “Orleans: Distributed Virtual Actors for Programmability and Scalability,” Microsoft Research Technical Report MSR-TR-2014-41, March 2014.
    </p>
<p>
        [52] “Microsoft Project Orleans Documentation,” Microsoft Research, dotnet.github.io, 2015.
    </p>
<p>
        [53] David Mercer, Sean Hinde, Yinso Chen, and Richard A O’Keefe: “beginner: Updating Data Structures,” email thread on erlang-questions mailing list, erlang.com, October 29, 2007.
    </p>
<p>
        [54] Fred Hebert: “Postscript: Maps,” learnyousomeerlang.com, April 9, 2014.
    </p>
<p>
        Summary | 143
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0165</div>
            </div>
        </div>
        <!-- Page 0167 -->
        <div class="chapter" id="page-0167">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<h3>PART II</h3>
<h4>Distributed Data</h4>
<p>
        For a successful technology, reality must take precedence over public relations, for nature cannot be fooled.
        —Richard Feynman, Rogers Commission Report (1986)
    </p>
<p>
        در قسمت I این کتاب، ما جنبه‌هایی از data systems را که هنگام ذخیره داده‌ها بر روی یک machine واحد اعمال می‌شوند، مورد بحث قرار دادیم. اکنون، در قسمت II، ما یک level را بالا می‌بریم و می‌پرسیم: اگر چندین machine در storage و retrieval از data دخیل باشند، چه اتفاقی می‌افتد؟
    </p>
<p>
        دلایل مختلفی وجود دارد که چرا شما ممکن است بخواهید یک database را در سراسر multiple machines توزیع کنید:
    </p>
<ul>
<li>Scalability</li>
<li>اگر حجم داده‌های شما، read load یا write load بزرگتر از یک machine واحد شود، شما به طور بالقوه می‌توانید load را در سراسر multiple machines پخش کنید.</li>
<li>Fault tolerance/high availability</li>
<li>If your application نیاز دارد که به کار خود ادامه دهد، حتی اگر یک machine (یا چندین machines، یا network یا یک datacenter کامل) از کار بیفتد، شما می‌توانید از multiple machines برای ارائه redundancy استفاده کنید. هنگامی که یکی fail می‌شود، دیگری می‌تواند کنترل را در دست بگیرد.</li>
<li>Latency</li>
<li>اگر شما users در سراسر جهان دارید، شما ممکن است بخواهید servers را در locations مختلف در سراسر جهان داشته باشید تا هر user بتواند از یک datacenter که از نظر جغرافیایی به آن‌ها نزدیک است، خدمات دریافت کند. این باعث می‌شود که users مجبور نباشند منتظر network pack‐ets بمانند تا در سراسر جهان سفر کنند.</li>
</ul>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0167</div>
            </div>
        </div>
        <!-- Page 0168 -->
        <div class="chapter" id="page-0168">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        i. In a large machine، اگرچه هر CPU می‌تواند به هر بخشی از memory دسترسی داشته باشد، اما برخی از banks از memory به یک CPU نزدیک‌تر از سایرین هستند (این به نام nonuniform memory access یا NUMA [1] نامیده می‌شود). برای استفاده کارآمد از این architecture، پردازش باید به گونه‌ای تقسیم شود که هر CPU عمدتاً به memory که نزدیک است، دسترسی داشته باشد—که به این معنی است که partitioning همچنان مورد نیاز است، حتی زمانی که ظاهراً روی یک machine واحد اجرا می‌شود.
    </p>
<p>
        ii. Network Attached Storage (NAS) or Storage Area Network (SAN).
    </p>
<h4>Scaling to Higher Load</h4>
<p>
        اگر تنها چیزی که شما نیاز دارید این است که به load بالاتر scale کنید، ساده‌ترین رویکرد این است که یک machine قدرتمندتر بخرید (که گاهی vertical scaling یا scaling up نامیده می‌شود). Many CPUs، many RAM chips و many disks را می‌توان تحت یک operating system به هم متصل کرد و یک fast interconnect به هر CPU اجازه می‌دهد تا به هر بخشی از memory یا دیسک دسترسی داشته باشد. در این نوع shared-memory architecture، همه components را می‌توان به عنوان یک machine واحد در نظر گرفت [1].i
    </p>
<p>
        مشکل رویکرد shared-memory این است که هزینه سریعتر از خطی رشد می‌کند: یک machine با دو برابر تعداد CPUs، دو برابر RAM و دو برابر ظرفیت دیسک نسبت به دیگری معمولاً به طور قابل توجهی بیش از دو برابر هزینه دارد. و به دلیل bottlenecks، یک machine دو برابر بزرگتر لزوماً نمی‌تواند دو برابر load را مدیریت کند.
    </p>
<p>
        یک shared-memory architecture ممکن است fault tolerance محدودی را ارائه دهد—machines high-end دارای اجزای hot-swappable هستند (شما می‌توانید دیسک‌ها، ماژول‌های memory و حتی CPUs را بدون خاموش کردن machines جایگزین کنید)—اما قطعاً به یک location جغرافیایی واحد محدود می‌شود.
    </p>
<p>
        یک رویکرد دیگر the shared-disk architecture است که از چندین machine با CPUs و RAM مستقل استفاده می‌کند، اما داده‌ها را در یک آرایه از دیسک‌ها ذخیره می‌کند که بین machines به اشتراک گذاشته شده است، که از طریق یک network fast متصل هستند.ii این architecture برای برخی از workloads data warehousing استفاده می‌شود، اما contention و overhead از locking، مقیاس‌پذیری رویکرد shared-disk را محدود می‌کند [2].
    </p>
<h4>Shared-Nothing Architectures</h4>
<p>
        در مقابل، shared-nothing architectures [3] (که گاهی scaling horizontal یا scaling out نامیده می‌شود) محبوبیت زیادی پیدا کرده‌اند. در این رویکرد، هر machine یا virtual machine که نرم‌افزار database را اجرا می‌کند، یک node نامیده می‌شود. هر node از CPUs، RAM و دیسک‌های خود به طور مستقل استفاده می‌کند. هرگونه هماهنگی بین nodes در سطح نرم‌افزار، با استفاده از یک network conventional انجام می‌شود.
    </p>
<p>
        هیچ سخت‌افزار خاصی توسط یک سیستم shared-nothing مورد نیاز نیست، بنابراین شما می‌توانید از هر machines که بهترین ratio price/performance را دارد، استفاده کنید. شما به طور بالقوه می‌توانید داده‌ها را در سراسر مناطق جغرافیایی متعدد توزیع کنید، و بنابراین latency را برای users کاهش دهید و به طور بالقوه قادر به survival the loss از یک datacenter کامل باشید. با cloud deployments از virtual
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0168</div>
            </div>
        </div>
        <!-- Page 0169 -->
        <div class="chapter" id="page-0169">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        machines، شما نیازی به operating در مقیاس Google ندارید: حتی برای شرکت‌های کوچک، یک architecture distributed multi-region اکنون امکان‌پذیر است.
    </p>
<p>
        در این بخش از کتاب، ما بر shared-nothing architectures متمرکز می‌شویم—نه به این دلیل که آن‌ها لزوماً بهترین انتخاب برای هر use case هستند، بلکه به این دلیل که آن‌ها بیشترین احتیاط را از شما، developer application، می‌طلبند. اگر data شما در سراسر multiple nodes توزیع شده است، شما باید از constraints و trade-offs که در چنین سیستم distributed رخ می‌دهد، آگاه باشید—database نمی‌تواند جادویی آن‌ها را از شما پنهان کند.
    </p>
<p>
        در حالی که یک shared-nothing architecture distributed مزایای زیادی دارد، اما معمولاً پیچیدگی‌های اضافی را برای applications به همراه دارد و گاهی اوقات expressiveness از data models که شما می‌توانید استفاده کنید را محدود می‌کند. در برخی موارد، یک برنامه تک رشته‌ای ساده می‌تواند به طور قابل توجهی بهتر از یک cluster با بیش از 100 هسته CPU عمل کند [4]. از سوی دیگر، سیستم‌های shared-nothing می‌توانند بسیار قدرتمند باشند. چند فصل آینده به جزئیات در مورد issues که هنگام توزیع داده‌ها به وجود می‌آیند، می‌پردازد.
    </p>
<h4>Replication Versus Partitioning</h4>
<p>
        دو روش رایج برای توزیع داده‌ها در سراسر multiple nodes وجود دارد:
    </p>
<ul>
<li>Replication</li>
<li>نگه‌داشتن یک کپی از همان داده‌ها در چندین node مختلف، که به طور بالقوه در locations متفاوت هستند. Replication redundancy را فراهم می‌کند: اگر برخی از nodes در دسترس نباشند، data هنوز هم می‌تواند از nodes باقی‌مانده ارائه شود. Replication همچنین می‌تواند به بهبود performance کمک کند. ما در مورد replication در فصل 5 بحث می‌کنیم.</li>
<li>Partitioning</li>
<li>تقسیم یک database بزرگ به زیرمجموعه‌های کوچکتر که partitions نامیده می‌شوند، به طوری که partitions مختلف می‌توانند به nodes مختلف (که همچنین به عنوان sharding شناخته می‌شوند) اختصاص داده شوند. ما در مورد partitioning در فصل 6 بحث می‌کنیم.</li>
</ul>
<p>
        این‌ها مکانیزم‌های جداگانه‌ای هستند، اما آن‌ها اغلب با هم همراه می‌شوند، همانطور که در شکل II-1 نشان داده شده است.
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0169</div>
            </div>
        </div>
        <!-- Page 0170 -->
        <div class="chapter" id="page-0170">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        شکل II-1. یک database که به دو partition تقسیم شده است، با دو replicas در هر partition.
    </p>
<p>
        با درک آن مفاهیم، ما می‌توانیم در مورد trade-offs دشواری که شما باید در یک سیستم distributed ایجاد کنید، بحث کنیم. ما در مورد transactions در فصل 7 بحث خواهیم کرد، زیرا این به شما کمک می‌کند تا همه چیزهایی را که می‌توانند در یک data system اشتباه شوند، درک کنید و آنچه را که شما می‌توانید در مورد آن‌ها انجام دهید. ما این بخش از کتاب را با بحث در مورد limitations اساسی از سیستم‌های distributed در فصل‌های 8 و 9 به پایان می‌رسانیم.
    </p>
<p>
        بعداً، در قسمت III این کتاب، ما بحث خواهیم کرد که چگونه شما می‌توانید از چندین datastores (که به طور بالقوه distributed هستند) استفاده کنید و آن‌ها را در یک سیستم بزرگتر ادغام کنید و نیازهای یک application پیچیده را برآورده کنید. اما ابتدا، بیایید در مورد داده‌های distributed صحبت کنیم.
    </p>
<h4>References</h4>
<p>
        [1] Ulrich Drepper: “What Every Programmer Should Know About Memory,” akkadi.org, November 21, 2007.
    </p>
<p>
        [2] Ben Stopford: “Shared Nothing vs. Shared Disk Architectures: An Independent View,” benstopford.com, November 24, 2009.
    </p>
<p>
        [3] Michael Stonebraker: “The Case for Shared Nothing,” IEEE Database Engineering Bulletin, volume 9, number 1, pages 4–9, March 1986.
    </p>
<p>
        [4] Frank McSherry, Michael Isard, and Derek G. Murray: “Scalability! But at What COST?,” at 15th USENIX Workshop on Hot Topics in Operating Systems (HotOS), May 2015.
    </p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 170" src="page_0170/image_1.png"/></div>
</div>
                <div class="page-number">صفحه 0170</div>
            </div>
        </div>
        <!-- Page 0173 -->
        <div class="chapter" id="page-0173">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<h3>فصل 5</h3>
<h4>Replication</h4>
<p>
        The major difference between a thing that might go wrong and a thing that cannot possibly go wrong is that when a thing that cannot possibly go wrong goes wrong it usually turns out to be impossible to get at or repair.
        —Douglas Adams, Mostly Harmless (1992)
    </p>
<p>
        Replication به معنای نگه‌داشتن یک کپی از داده‌های یکسان در چندین machine است که از طریق یک شبکه متصل هستند. همانطور که در مقدمه قسمت II بحث شد، دلایل متعددی وجود دارد که چرا شما ممکن است بخواهید data را replicate کنید:
    </p>
<ul>
<li>To keep data geographically close to your users (و در نتیجه کاهش latency)</li>
<li>To allow the system to continue working even if some of its parts have failed (و در نتیجه افزایش availability)</li>
<li>To scale out the number of machines that can serve read queries (و در نتیجه افزایش read throughput)</li>
</ul>
<p>
        در این فصل ما فرض خواهیم کرد که dataset شما آنقدر کوچک است که هر machine می‌تواند یک کپی از کل dataset را در خود نگه دارد. در فصل 6 ما این فرضیه را کم می‌کنیم و در مورد partitioning (sharding) از datasets که برای یک machine واحد خیلی بزرگ هستند، بحث می‌کنیم. در فصل‌های بعدی ما در مورد انواع مختلف faults که می‌توانند در یک replicated data sys‐tem رخ دهند، و نحوه مقابله با آن‌ها بحث خواهیم کرد.
    </p>
<p>
        اگر داده‌هایی که شما در حال replication آن‌ها هستید، با گذشت زمان تغییر نکنند، replication آسان است: شما فقط نیاز دارید data را یک بار به هر node کپی کنید و کارتان تمام می‌شود. همه مشکل در replication در handling changes to replicated data نهفته است، و این موضوع فصل حاضر است. ما در مورد سه الگوریتم محبوب برای replicating changes بین nodes بحث خواهیم کرد: single-leader، multi-leader و leaderless replication. تقریباً همه databases distributed از یکی از این سه رویکرد استفاده می‌کنند. همه آن‌ها مزایا و معایب مختلفی دارند که ما آن‌ها را با جزئیات بررسی خواهیم کرد.
    </p>
<p>
        151
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0173</div>
            </div>
        </div>
        <!-- Page 0174 -->
        <div class="chapter" id="page-0174">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        i. Different people have different definitions for hot, warm, and cold standby servers. In PostgreSQL, for example, hot standby is used to refer to a replica that accepts reads from clients, whereas a warm standby processes changes from the leader but doesn’t process any queries from clients. For purposes of this book, the difference isn’t important.
    </p>
<p>
        Trade-offs زیادی برای در نظر گرفتن با replication وجود دارد: به عنوان مثال، اینکه آیا از replication synchronous یا asynchronous استفاده شود و چگونه replicas fail شده را مدیریت کنیم. آن‎ها اغلب configuration options در databases هستند و اگرچه جزئیات با database متفاوت است، اما اصول کلی در بسیاری از پیاده‌سازی‌های مختلف مشابه است. ما در این فصل در مورد عواقب این انتخاب‌ها بحث خواهیم کرد.
    </p>
<p>
        Replication از databases یک موضوع قدیمی است—اصول از زمانی که در دهه 1970 مورد مطالعه قرار گرفتند، چندان تغییر نکرده است [1]، زیرا constraints اساسی از شبکه‌ها یکسان باقی مانده‌اند. با این حال، خارج از تحقیق، بسیاری از developers برای مدت طولانی فرض می‌کردند که یک database فقط از یک node تشکیل شده است. استفاده جریان اصلی از databases distributed اخیراً بیشتر است. از آنجایی که بسیاری از application developers در این زمینه تازه‌وارد هستند، سوءتفاهم‌های زیادی در مورد مسائلی مانند eventual consistency وجود داشته است. در "Problems with Replication Lag" در صفحه 161 ما در مورد eventual consistency دقیق‌تر خواهیم شد و در مورد چیزهایی مانند read-your-writes و mono‐tonic reads guarantees بحث خواهیم کرد.
    </p>
<h4>Leaders and Followers</h4>
<p>
        هر node که یک کپی از database را ذخیره می‌کند، یک replica نامیده می‌شود. با multiple replicas، یک سوال به ناچار مطرح می‌شود: چگونه اطمینان حاصل کنیم که همه داده‌ها در همه replicas قرار می‌گیرند؟
    </p>
<p>
        Every write به database نیاز دارد که توسط هر replica پردازش شود. در غیر این صورت، the rep‐licas دیگر شامل همان data نخواهند بود. The most common solution for this به نام leader-based replication (همچنین به عنوان active/passive یا master–slave replica‐tion شناخته می‌شود) نامیده می‌شود و در شکل 5-1 نشان داده شده است. این به شرح زیر عمل می‌کند:
    </p>
<ol>
<li>One of the replicas is designated the leader (also known as master or primary). When clients want to write to the database, they must send their requests to the leader, which first writes the new data to its local storage.</li>
<li>The other replicas are known as followers (read replicas, slaves, secondaries, or hot standbys).i Whenever the leader writes new data to its local storage, it also sends the data change to all of its followers as part of a replication log or change stream. Each follower takes the log from the leader and updates its local copy of the data‐base accordingly, by applying all writes in the same order as they were processed on the leader.</li>
</ol>
<p>
        152 | Chapter 5: Replication
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0174</div>
            </div>
        </div>
        <!-- Page 0175 -->
        <div class="chapter" id="page-0175">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<ol start="3">
<li>When a client wants to read from the database, it can query either the leader or any of the followers. However, writes are only accepted on the leader (the follow‐ers are read-only from the client’s point of view).</li>
</ol>
<p>
        شکل 5-1. Leader-based (master–slave) replication.
    </p>
<p>
        این mode از replication یک ویژگی داخلی از بسیاری از relational databases، مانند PostgreSQL (از نسخه 9.0)، MySQL، Oracle Data Guard [2] و SQL Server’s AlwaysOn Availability Groups [3] است. همچنین در برخی از databases nonrelational، از جمله MongoDB, RethinkDB و Espresso [4] استفاده می‌شود. در نهایت، leader-based replication فقط به databases محدود نمی‌شود: message brokers distributed مانند Kafka [5] و RabbitMQ highly available queues [6] نیز از آن استفاده می‌کنند. برخی از network filesystems و replicated block devices مانند DRBD مشابه هستند.
    </p>
<h4>Synchronous Versus Asynchronous Replication</h4>
<p>
        یک جزئیات مهم از یک سیستم replicated این است که آیا replication به صورت synchronous یا asynchronous رخ می‌دهد. (در relational databases، این اغلب یک option قابل پیکربندی است. سایر سیستم‌ها اغلب hardcoded شده‌اند که یا یکی از دیگری باشند.)
    </p>
<p>
        در مورد آنچه در شکل 5-1 اتفاق می‌افتد، جایی که user از یک وب‌سایت، تصویر profile خود را به‌روزرسانی می‌کند، فکر کنید. در یک زمان، client درخواست update را به leader ارسال می‌کند. اندکی پس از آن، توسط leader دریافت می‌شود. در یک نقطه، leader تغییر data را به followers ارسال می‌کند. در نهایت، leader به client اطلاع می‌دهد که update موفقیت‌آمیز بوده است.
    </p>
<p>
        شکل 5-2 ارتباط بین components مختلف سیستم را نشان می‌دهد: the user’s client، leader و دو follower. زمان از چپ به راست جریان دارد. A request یا message response به عنوان یک فلش ضخیم نشان داده شده است.
    </p>
<p>
        Leaders and Followers | 153
    </p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 175" src="page_0175/image_1.png"/></div>
</div>
                <div class="page-number">صفحه 0175</div>
            </div>
        </div>
        <!-- Page 0176 -->
        <div class="chapter" id="page-0176">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        شکل 5-2. Leader-based replication با یک synchronous و یک asynchronous fol‐lower.
    </p>
<p>
        در مثال شکل 5-2، replication به follower 1 synchronous است: leader منتظر می‌ماند تا follower 1 تأیید کند که write را دریافت کرده است، قبل از گزارش موفقیت به user و قبل از قابل مشاهده کردن write برای other clients. The replication to follower 2 asynchronous است: leader message را ارسال می‌کند، اما منتظر یک response از follower نمی‌ماند.
    </p>
<p>
        این نمودار نشان می‌دهد که یک delay قابل توجه قبل از اینکه follower 2 message را پردازش کند، وجود دارد. به طور معمول، replication بسیار سریع است: اکثر systems database تغییرات را در followers در کمتر از یک ثانیه اعمال می‌کنند. با این حال، هیچ تضمینی وجود ندارد که چقدر طول بکشد. شرایطی وجود دارد که followers ممکن است از leader به میزان چند دقیقه یا بیشتر عقب بمانند. به عنوان مثال، اگر یک follower از یک failure در حال بازیابی است، اگر سیستم در حال کار نزدیک به حداکثر ظرفیت است، یا اگر مشکلات network بین nodes وجود داشته باشد.
    </p>
<p>
        مزیت synchronous replication این است که follower تضمین شده است که یک کپی up-to-date از داده‌ها دارد که با leader سازگار است. اگر leader ناگهان fail شود، ما می‌توانیم مطمئن باشیم که داده‌ها هنوز در follower در دسترس هستند. The disadvantage این است که اگر synchronous follower پاسخ ندهد (زیرا crash کرده است، یا یک network fault وجود دارد، یا به هر دلیل دیگر)، write نمی‌تواند پردازش شود.
        leader باید همه writes را block کند و تا زمانی که synchronous replica دوباره در دسترس قرار گیرد، منتظر بماند.
    </p>
<p>
        به همین دلیل، غیر عملی است که همه followers synchronous باشند: هر یک node outage باعث می‌شود که کل سیستم به حالت توقف درآید. در عمل، اگر شما synchronous replication را در یک database فعال کنید، معمولاً به این معنی است که یکی از followers synchronous است و بقیه asynchronous هستند. اگر synchronous follower در دسترس نباشد یا کند شود، یکی از followers asynchronous synchronous می‌شود. این تضمین می‌کند که شما یک کپی up-to-date از داده‌ها را حداقل در دو nodes دارید: the
    </p>
<p>
        154 | Chapter 5: Replication
    </p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 176" src="page_0176/image_1.png"/></div>
</div>
                <div class="page-number">صفحه 0176</div>
            </div>
        </div>
        <!-- Page 0177 -->
        <div class="chapter" id="page-0177">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        leader و یک follower synchronous. این configuration گاهی اوقات semi-synchronous [7] نیز نامیده می‌شود.
    </p>
<p>
        اغلب، leader-based replication به طور کامل asynchronous پیکربندی می‌شود. در این حالت، اگر leader fail شود و قابل بازیابی نباشد، هر writes که هنوز به followers replicate نشده‌اند، از بین می‌روند. این بدان معناست که تضمین نمی‌شود که یک write durable باشد، حتی اگر به client تأیید شده باشد. با این حال، یک configuration کاملاً asynchronous این مزیت را دارد که leader می‌تواند به پردازش writes ادامه دهد، حتی اگر همه followers آن عقب افتاده باشند.
    </p>
<p>
        Weakening durability ممکن است مانند یک trade-off بد به نظر برسد، اما replication asynchronous با این وجود به طور گسترده‌ای استفاده می‌شود، به خصوص اگر followers زیادی وجود داشته باشند یا اگر آن‌ها geographically distributed باشند. ما در "Problems with Replication Lag" در صفحه 161 به این موضوع باز خواهیم گشت.
    </p>
<h4>Research on Replication</h4>
<p>
        از دست دادن data توسط systems asynchronously replicated، اگر leader fail شود، می‌تواند یک مشکل جدی باشد، بنابراین محققان به بررسی روش‌های replication ادامه داده‌اند که داده‌ها را از دست نمی‌دهند، اما همچنان performance و availability خوبی را ارائه می‌دهند. به عنوان مثال، chain replication [8, 9] یک variant از synchronous replication است که با موفقیت در چند سیستم مانند Microsoft Azure Storage [10, 11] پیاده‌سازی شده است.
    </p>
<p>
        یک اتصال قوی بین consistency of replication و consensus (موافقت چندین node بر روی یک value) وجود دارد و ما این حوزه از نظریه را با جزئیات بیشتر در فصل 9 بررسی خواهیم کرد. در این فصل ما بر روی ساده‌ترین فرم‌های replication که معمولاً در databases در عمل استفاده می‌شوند، تمرکز خواهیم کرد.
    </p>
<h4>Setting Up New Followers</h4>
<p>
        هر از چند گاهی، شما نیاز دارید که followers جدید را راه‌اندازی کنید—شاید برای افزایش تعداد replicas یا جایگزینی nodes fail شده. چگونه اطمینان حاصل می‌کنید که follower جدید یک کپی دقیق از data leader دارد؟
    </p>
<p>
        کپی کردن ساده فایل‌های data از یک node به node دیگر معمولاً کافی نیست: clients دائماً در حال نوشتن در database هستند و data همیشه در حال نوسان است، بنابراین یک copy فایل استاندارد، بخش‌های مختلفی از database را در زمان‌های مختلف خواهد دید. نتیجه ممکن است هیچ معنایی نداشته باشد.
    </p>
<p>
        شما می‌توانید فایل‌ها را روی دیسک با locking database (که آن را برای writes غیرقابل دسترس می‌کند) سازگار کنید، اما این با هدف ما از high availability مغایرت دارد. خوشبختانه، راه‌اندازی یک follower معمولاً می‌تواند بدون downtime انجام شود. از نظر مفهومی، فرآیند به این صورت است:
    </p>
<p>
        Leaders and Followers | 155
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0177</div>
            </div>
        </div>
        <!-- Page 0178 -->
        <div class="chapter" id="page-0178">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<ol>
<li>Take a consistent snapshot of the leader’s database at some point in time—if pos‐sible, without taking a lock on the entire database. Most databases have this fea‐ture, as it is also required for backups. In some cases, third-party tools are needed, such as innobackupex for MySQL [12].</li>
<li>Copy the snapshot to the new follower node.</li>
<li>The follower connects to the leader and requests all the data changes that have happened since the snapshot was taken. This requires that the snapshot is associ‐ated with an exact position in the leader’s replication log. That position has vari‐ous names: for example, PostgreSQL calls it the log sequence number, and MySQL calls it the binlog coordinates.</li>
<li>When the follower has processed the backlog of data changes since the snapshot, we say it has caught up. It can now continue to process data changes from the leader as they happen.</li>
</ol>
<p>
        The practical steps of setting up a follower vary significantly by database. In some systems the process is fully automated, whereas in others it can be a somewhat arcane multi-step workflow that needs to be manually performed by an administrator.
    </p>
<h4>Handling Node Outages</h4>
<p>
        هر node در سیستم می‌تواند از کار بیفتد، شاید به طور غیرمنتظره به دلیل یک fault، اما به همان اندازه محتمل است که به دلیل maintenance برنامه‌ریزی شده (به عنوان مثال، راه‌اندازی مجدد یک machine برای نصب a ker‐nel security patch). توانایی reboot کردن nodes مجزا بدون downtime یک مزیت بزرگ برای operations و maintenance است. بنابراین، هدف ما این است که سیستم را به عنوان یک whole running نگه داریم، علیرغم individual node failures، و تأثیر یک node out‐age را تا حد امکان کوچک نگه داریم.
    </p>
<p>
        چگونه شما به high availability با leader-based replication دست می‌یابید؟
    </p>
<h4>Follower failure: Catch-up recovery</h4>
<p>
        On its local disk، هر follower یک log از data changes که از leader دریافت کرده است، نگه می‌دارد. اگر یک follower crash کند و دوباره راه‌اندازی شود، یا اگر network بین leader و follower به طور موقت قطع شود، follower می‌تواند کاملاً راحت بازیابی شود: از log خود، آخرین transaction را که قبل از وقوع fault پردازش شده است، می‌داند. بنابراین، the follower می‌تواند به leader متصل شود و تمام data changes را که در طول زمانی که follower قطع شده بود، درخواست کند. وقتی این تغییرات را اعمال کرد، آن را به leader catch up کرده است و می‌تواند به دریافت یک stream از data changes مانند قبل ادامه دهد.
    </p>
<p>
        156 | Chapter 5: Replication
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0178</div>
            </div>
        </div>
        <!-- Page 0179 -->
        <div class="chapter" id="page-0179">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<h4>Leader failure: Failover</h4>
<p>
        Handling a failure of the leader is trickier: one of the followers نیاز دارد که به عنوان leader جدید ارتقا یابد، clients نیاز به reconfigured شدن دارند تا writes خود را به leader جدید ارسال کنند، و سایر followers نیاز دارند که شروع به مصرف data changes از leader جدید کنند. این فرآیند failover نامیده می‌شود.
    </p>
<p>
        Failover می‌تواند به صورت دستی (یک administrator مطلع می‌شود که leader fail شده است و مراحل لازم را برای ایجاد یک leader جدید انجام می‌دهد) یا به طور خودکار اتفاق بیفتد. یک فرآیند failover اتوماتیک معمولاً از مراحل زیر تشکیل شده است:
    </p>
<ol>
<li>Determining که leader fail شده است. چیزهای زیادی وجود دارد که می‌تواند به طور بالقوه اشتباه پیش برود: crashes، power outages، network issues و موارد دیگر. هیچ راه مطمئنی برای تشخیص اینکه چه چیزی اشتباه پیش رفته است وجود ندارد، بنابراین اکثر سیستم‌ها به سادگی از یک timeout استفاده می‌کنند: nodes به طور مکرر messages را بین یکدیگر bounce می‌کنند، و اگر یک node برای مدتی—مثلاً 30 ثانیه—پاسخ ندهد، فرض می‌شود که مرده است. (اگر leader عمداً برای maintenance برنامه‌ریزی شده برداشته شود، این مورد اعمال نمی‌شود.)</li>
<li>Choosing a new leader. این کار را می‌توان از طریق یک فرآیند election (جایی که leader توسط اکثریت replicas باقی‌مانده انتخاب می‌شود)، یا یک leader جدید را می‌توان توسط یک node controller که قبلاً انتخاب شده است، منصوب کرد. The best candidate for leadership معمولاً replica با most up-to-date data changes از old leader است (برای به حداقل رساندن هرگونه data loss). Getting all the nodes to agree on a new leader یک مشکل consensus است، که در فصل 9 با جزئیات مورد بحث قرار می‌گیرد.</li>
<li>Reconfiguring the system to use the new leader. Clients اکنون نیاز به ارسال write requests خود به leader جدید دارند (ما این را در "Request Routing" در صفحه 214 بحث می‌کنیم). اگر the old leader برگردد، ممکن است همچنان بر این باور باشد که leader است، و متوجه نشود که سایر replicas آن را مجبور به کناره‌گیری کرده‌اند. سیستم باید اطمینان حاصل کند که the old leader به یک follower تبدیل می‌شود و leader جدید را می‌شناسد.</li>
</ol>
<p>
        Failover با مواردی که می‌توانند اشتباه پیش بروند، همراه است:
    </p>
<ul>
<li>If asynchronous replication is used, the new leader may not have received all the writes from the old leader before it failed. If the former leader rejoins the cluster after a new leader has been chosen, what should happen to those writes? The new leader may have received conflicting writes in the meantime. The most common solution is for the old leader’s unreplicated writes to simply be discarded, which may violate clients’ durability expectations.</li>
<li>Discarding writes is especially dangerous if other storage systems outside of the database need to be coordinated with the database contents. For example, in one incident at GitHub [13], an out-of-date MySQL follower was promoted to leader. The database used an autoincrementing counter to assign primary keys to new</li>
</ul>
<p>
        Leaders and Followers | 157
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0179</div>
            </div>
        </div>
        <!-- Page 0180 -->
        <div class="chapter" id="page-0180">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        ii. This approach is known as fencing or, more emphatically, Shoot The Other Node In The Head (STONITH).
        We will discuss fencing in more detail in “The leader and the lock” on page 301.
    </p>
<p>
        ردیف‌ها، اما از آنجایی که counter leader جدید از leader قدیمی‌تر عقب بود، از برخی از primary keys که قبلاً توسط leader قدیمی‌تر اختصاص داده شده بودند، دوباره استفاده کرد. این primary keys همچنین در یک فروشگاه Redis استفاده می‌شدند، بنابراین استفاده مجدد از primary keys منجر به inconsistency بین MySQL و Redis شد که باعث شد برخی از data private برای کاربران اشتباه فاش شود.
    </p>
<ul>
<li>In certain fault scenarios (see Chapter 8)، ممکن است اتفاق بیفتد که دو node هر دو بر این باور باشند که آن‌ها leader هستند. این وضعیت split brain نامیده می‌شود و خطرناک است: اگر هر دو leader writes را بپذیرند و هیچ فرآیندی برای حل conflicts وجود نداشته باشد ("Multi-Leader Replication" در صفحه 168 را ببینید)، داده‌ها احتمالاً از بین می‌روند یا corrupted می‌شوند. به عنوان یک safety catch، برخی از systems یک مکانیزم برای خاموش کردن یک node دارند، اگر دو leader شناسایی شوند.ii با این حال، اگر این مکانیزم با دقت طراحی نشده باشد، شما می‌توانید با خاموش شدن هر دو node به پایان برسید [14].</li>
<li>What is the right timeout before the leader is declared dead? A longer timeout به معنای زمان طولانی‌تری برای recovery در موردی است که leader fail می‌شود. با این حال، اگر timeout خیلی کوتاه باشد، ممکن است failovers غیرضروری وجود داشته باشد. به عنوان مثال، یک tempo‐rary load spike می‌تواند باعث شود که زمان پاسخ یک node، بالاتر از timeout افزایش یابد، یا یک network glitch می‌تواند باعث تاخیر در بسته‌ها شود. اگر سیستم در حال حاضر با high load یا network problems در حال مبارزه است، یک failover غیرضروری احتمالاً وضعیت را بدتر می‌کند، نه بهتر.</li>
</ul>
<p>
        هیچ راه‌حل آسانی برای این مشکلات وجود ندارد. به همین دلیل، برخی از teams operations ترجیح می‌دهند failovers را به صورت دستی انجام دهند، حتی اگر software از automatic failover پشتیبانی کند.
    </p>
<p>
        These issues—node failures; unreliable networks; and trade-offs around replica con‐sistency, durability, availability, and latency—are in fact fundamental problems in distributed systems. In Chapter 8 and Chapter 9 we will discuss them in greater depth.
    </p>
<h4>Implementation of Replication Logs</h4>
<p>
        How does leader-based replication work under the hood? Several different replication methods are used in practice, so let’s look at each one briefly.
    </p>
<h4>Statement-based replication</h4>
<p>
        در ساده‌ترین حالت، leader هر write request (statement) را که اجرا می‌کند، log می‌کند و آن statement log را به followers خود ارسال می‌کند. برای یک relational database، این بدان معناست که هر statement INSERT, UPDATE, یا DELETE به followers ارسال می‌شود و هر
    </p>
<p>
        158 | Chapter 5: Replication
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0180</div>
            </div>
        </div>
        <!-- Page 0181 -->
        <div class="chapter" id="page-0181">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        follower آن SQL statement را parse و اجرا می‌کند، گویی از یک client دریافت شده است.
    </p>
<p>
        اگرچه این ممکن است منطقی به نظر برسد، اما راه‌های مختلفی وجود دارد که در آن‌ها این رویکرد به replication می‌تواند خراب شود:
    </p>
<ul>
<li>هر statement که یک تابع nondeterministic را فراخوانی می‌کند، مانند NOW() برای دریافت تاریخ و زمان current یا RAND() برای دریافت یک عدد تصادفی، احتمالاً یک value متفاوت را در هر replica تولید می‌کند.</li>
<li>If statements از یک column autoincrementing استفاده می‌کنند، یا اگر آن‌ها به data موجود در database وابسته باشند (به عنوان مثال، UPDATE … WHERE &lt;some condition&gt;)، باید دقیقاً به همان ترتیب در هر replica اجرا شوند، در غیر این صورت ممکن است یک effect متفاوت داشته باشند. این می‌تواند محدودکننده باشد وقتی که تراکنش‌های همزمان در حال اجرا هستند.</li>
<li>Statements که side effects (به عنوان مثال، triggers، stored procedures، user-defined functions) دارند، ممکن است منجر به side effects مختلفی شوند که در هر replica رخ می‌دهد، مگر اینکه side effects کاملاً deterministic باشند.</li>
</ul>
<p>
        امکان کار کردن در اطراف آن issues وجود دارد—به عنوان مثال، leader می‌تواند هر فراخوانی تابع nondeterministic را با یک fixed return value جایگزین کند، هنگامی که statement log‐ged می‌شود تا همه followers همان value را دریافت کنند. با این حال، به دلیل وجود موارد لبه بسیار زیاد، سایر روش‌های replication در حال حاضر عموماً ترجیح داده می‌شوند.
    </p>
<p>
        Statement-based replication در MySQL قبل از نسخه 5.1 استفاده می‌شد. هنوز هم امروزه گاهی اوقات استفاده می‌شود، زیرا کاملاً compact است، اما به طور پیش‌فرض MySQL اکنون به replication row-based (که به زودی مورد بحث قرار می‌گیرد) تغییر می‌کند، اگر هرگونه nondeterminism در یک statement وجود داشته باشد.
        VoltDB از statement-based replication استفاده می‌کند و با ملزم کردن تراکنش‌ها به deterministic بودن، آن را ایمن می‌کند [15].
    </p>
<h4>Write-ahead log (WAL) shipping</h4>
<p>
        در فصل 3 ما در مورد اینکه چگونه storage engines داده‌ها را روی دیسک نشان می‌دهند، بحث کردیم و دریافتیم که معمولاً هر write به یک log اضافه می‌شود:
    </p>
<ul>
<li>در مورد یک storage engine log-structured (به "SSTables and LSM-Trees" در صفحه 76 مراجعه کنید)، این log مکان اصلی برای storage است. Log segments در background compacted و garbage-collected می‌شوند.</li>
<li>در مورد یک B-tree (به "B-Trees" در صفحه 79 مراجعه کنید)، که individual disk blocks را overwrite می‌کند، هر modification ابتدا به یک write-ahead log نوشته می‌شود تا index بتواند پس از یک crash به یک state consistent بازیابی شود.</li>
</ul>
<p>
        در هر دو مورد، log یک sequence append-only از bytes است که شامل تمام writes به database می‌شود. ما می‌توانیم از همان log برای ساختن یک replica در یک node دیگر استفاده کنیم: علاوه بر نوشتن log به دیسک، leader آن را از طریق network به followers خود نیز ارسال می‌کند.
    </p>
<p>
        Leaders and Followers | 159
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0181</div>
            </div>
        </div>
        <!-- Page 0182 -->
        <div class="chapter" id="page-0182">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        When the follower processes this log, it builds a copy of the exact same data struc‐tures as found on the leader.
    </p>
<p>
        این method از replication در PostgreSQL و Oracle و موارد دیگر استفاده می‌شود [16]. The main disadvantage این است که log داده‌ها را در یک سطح بسیار پایین توصیف می‌کند: a WAL حاوی جزئیات از اینکه کدام bytes در کدام disk blocks تغییر کرده‌اند. این باعث می‌شود replication به storage engine نزدیک‌تر شود. اگر database format storage خود را از یک نسخه به نسخه دیگر تغییر دهد، معمولاً اجرای نسخه‌های مختلف از software database روی leader و followers امکان‌پذیر نیست.
    </p>
<p>
        این ممکن است یک جزئیات پیاده‌سازی جزئی به نظر برسد، اما می‌تواند یک impact عملیاتی بزرگ داشته باشد. اگر the replication protocol به follower اجازه می‌دهد تا از یک نسخه software جدیدتر از leader استفاده کند، شما می‌توانید یک zero-downtime upgrade از software database را با ارتقای first the followers و سپس انجام یک failover برای تبدیل یکی از nodes ارتقا یافته به leader جدید انجام دهید. اگر the replication protocol این version mismatch را مجاز نمی‌کند، که اغلب در مورد WAL shipping صدق می‌کند، چنین upgrades نیاز به downtime دارند.
    </p>
<h4>Logical (row-based) log replication</h4>
<p>
        یک جایگزین این است که از formats log متفاوتی برای replication و برای storage engine استفاده کنید، که به log replication اجازه می‌دهد تا از internals storage engine جدا شود. این نوع replication log یک logical log نامیده می‌شود تا آن را از representation data (physical) storage engine متمایز کند.
    </p>
<p>
        یک logical log برای یک relational database معمولاً یک sequence از records است که writes را به جداول database در granularity از یک ردیف توصیف می‌کند:
    </p>
<ul>
<li>For an inserted row، log حاوی values جدید از تمام columns است.</li>
<li>For a deleted row، log حاوی اطلاعات کافی برای شناسایی منحصر به فرد ردیفی است که حذف شده است. معمولاً این primary key خواهد بود، اما اگر هیچ primary key روی جدول وجود نداشته باشد، باید values قدیمی از تمام columns را log کرد.</li>
<li>For an updated row، log حاوی اطلاعات کافی برای شناسایی منحصر به فرد ردیف به‌روزرسانی شده و values جدید از تمام columns است (یا حداقل values جدید از تمام columns که تغییر کرده‌اند).</li>
</ul>
<p>
        یک transaction که چندین ردیف را اصلاح می‌کند، چندین record log از این دست را تولید می‌کند، و به دنبال آن یک record که نشان می‌دهد transaction committed شده است. binlog از MySQL (هنگامی که برای استفاده از replication row-based پیکربندی شده است) از این رویکرد استفاده می‌کند [17].
    </p>
<p>
        از آنجایی که یک logical log از internals storage engine جدا شده است، می‌تواند با سهولت بیشتری backward compatible باقی بماند، و به leader و the follower اجازه می‌دهد تا نسخه‌های مختلفی از software database، یا حتی storage engines مختلف را اجرا کنند.
    </p>
<p>
        A logical log format همچنین برای applications خارجی راحت‌تر parse می‌شود. این جنبه مفید است اگر شما می‌خواهید محتویات یک database را به یک سیستم خارجی، مانند یک data
    </p>
<p>
        160 | Chapter 5: Replication
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0182</div>
            </div>
        </div>
        <!-- Page 0183 -->
        <div class="chapter" id="page-0183">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        warehouse for offline analysis, or for building custom indexes and caches [18]. This technique is called change data capture و ما در فصل 11 به آن باز خواهیم گشت.
    </p>
<h4>Trigger-based replication</h4>
<p>
        رویکردهای replication که تاکنون توضیح داده شد، توسط سیستم database، بدون دخالت هیچ application code، پیاده‌سازی شده‌اند. در بسیاری از موارد، این همان چیزی است که شما می‌خواهید—اما شرایطی وجود دارد که در آن‌ها به انعطاف‌پذیری بیشتری نیاز است. به عنوان مثال، اگر شما می‌خواهید فقط یک زیرمجموعه از data را replicate کنید، یا می‌خواهید از یک نوع database به دیگری replicate کنید، یا اگر شما به منطق حل conflict نیاز دارید (به "Handling Write Conflicts" در صفحه 171 مراجعه کنید)، پس شما ممکن است نیاز به جابجایی replication به application layer داشته باشید.
    </p>
<p>
        برخی از ابزارها، مانند Oracle GoldenGate [19]، می‌توانند تغییرات data را با خواندن log database در دسترس یک application قرار دهند. یک جایگزین این است که از features که در بسیاری از relational databases موجود است، استفاده کنید: triggers و stored procedures.
    </p>
<p>
        A trigger به شما این امکان را می‌دهد که کد application سفارشی را ثبت کنید که به طور خودکار هنگامی که یک data change (write transaction) در یک database system رخ می‌دهد، اجرا می‌شود. The trigger این فرصت را دارد که این تغییر را در یک جدول جداگانه log کند، که از آنجا می‌توان آن را توسط یک فرآیند خارجی خواند. آن فرآیند خارجی می‌تواند سپس هر منطق application لازم را اعمال کند و data change را به یک سیستم دیگر replicate کند. Databus برای Oracle [20] و Bucardo برای Postgres [21] به این شکل عمل می‌کنند، به عنوان مثال.
    </p>
<p>
        Trigger-based replication معمولاً overheads بیشتری نسبت به other replication methods دارد و بیشتر مستعد bugs و محدودیت‌ها نسبت به built-in repli‐cation database است. با این حال، با توجه به انعطاف‌پذیری آن، ممکن است مفید باشد.
    </p>
<h4>Problems with Replication Lag</h4>
<p>
        The ability to tolerate node failures فقط یک دلیل برای تمایل به replication است. همانطور که در مقدمه قسمت II ذکر شد، دلایل دیگر، scalability (پردازش درخواست‌های بیشتر از یک machine واحد) و latency (قرار دادن replicas به صورت geographically closer to users) است.
    </p>
<p>
        Leader-based replication نیاز به این دارد که همه writes از طریق یک node واحد انجام شوند، اما queries read-only می‌توانند به هر replica بروند. برای workloads که عمدتاً از reads تشکیل شده‌اند و فقط درصد کمی از writes دارند (یک الگوی common در وب)، یک گزینه جذاب وجود دارد: ایجاد followers های زیاد و توزیع read requests در سراسر آن followers. این load را از leader حذف می‌کند و به requests read اجازه می‌دهد تا توسط replicas نزدیک ارائه شوند.
    </p>
<p>
        در این read-scaling architecture، شما می‌توانید ظرفیت را برای serving read-only requests به سادگی با افزودن followers های بیشتر افزایش دهید. با این حال، این رویکرد تنها با replication asynchronous به طور واقع‌بینانه کار می‌کند—اگر شما سعی می‌کردید به صورت synchronous به همه followers replicate کنید، یک node failure یا network outage واحد باعث می‌شود کل سیستم
    </p>
<p>
        Problems with Replication Lag | 161
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0183</div>
            </div>
        </div>
        <!-- Page 0184 -->
        <div class="chapter" id="page-0184">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        iii. The term eventual consistency was coined by Douglas Terry et al. [24], popularized by Werner Vogels [22], and became the battle cry of many NoSQL projects. However, not only NoSQL databases are eventually consistent: followers in an asynchronously replicated relational database have the same characteristics.
    </p>
<p>
        unavailable for writing. و هرچه nodes بیشتری داشته باشید، احتمال بیشتری وجود دارد که یکی از آن‌ها از کار بیفتد، بنابراین یک configuration کاملاً synchronous بسیار غیرقابل اعتماد خواهد بود.
    </p>
<p>
        متأسفانه، اگر یک application از یک follower asynchronous بخواند، ممکن است اطلاعات outdated را ببیند اگر follower عقب افتاده باشد. این منجر به inconsistencies آشکار در database می‌شود: اگر شما همان query را در leader و a follower به طور همزمان اجرا کنید، شما ممکن است نتایج متفاوتی دریافت کنید، زیرا همه writes در the follower منعکس نشده‌اند. این inconsistency فقط یک state موقت است—اگر شما نوشتن در database را متوقف کنید و مدتی صبر کنید، the followers در نهایت catch up خواهند شد و با leader سازگار می‌شوند. به همین دلیل، این effect به عنوان eventual consistency [22, 23] شناخته می‌شود.iii
    </p>
<p>
        اصطلاح "eventually" عمداً مبهم است: به طور کلی، هیچ محدودیتی برای اینکه یک replica چقدر می‌تواند عقب بیفتد، وجود ندارد. در عملکرد normal، تأخیر بین رخ دادن یک write در leader و منعکس شدن آن در یک follower—the replication lag—ممکن است فقط یک fraction از یک ثانیه باشد و در عمل قابل توجه نیست. با این حال، اگر سیستم در نزدیکی ظرفیت در حال کار باشد یا اگر مشکلی در network وجود داشته باشد، the lag می‌تواند به راحتی به چند ثانیه یا حتی چند دقیقه افزایش یابد.
    </p>
<p>
        وقتی lag آنقدر بزرگ است، inconsistencies که معرفی می‌کند، فقط یک مشکل نظری نیست بلکه یک مشکل واقعی برای applications است. در این بخش ما سه نمونه از مشکلاتی را که احتمالاً هنگام وجود replication lag رخ می‌دهند، برجسته می‌کنیم و برخی از رویکردها را برای حل آن‌ها تشریح می‌کنیم.
    </p>
<h4>Reading Your Own Writes</h4>
<p>
        Many applications به user اجازه می‌دهند که مقداری data را submit کنند و سپس آنچه را که submit کرده‌اند، مشاهده کنند. این ممکن است یک record در یک customer database باشد، یا یک comment در یک discussion thread، یا چیز دیگری از این نوع. وقتی data جدید ارسال می‌شود، باید به leader ارسال شود، اما وقتی user data را مشاهده می‌کند، می‌توان آن را از یک follower خواند. این به خصوص مناسب است اگر data اغلب مشاهده شود اما فقط گهگاهی نوشته شود.
    </p>
<p>
        با replication asynchronous، یک مشکل وجود دارد، که در شکل 5-3 نشان داده شده است: اگر user data را اندکی پس از ایجاد یک write مشاهده کند، data جدید ممکن است هنوز به replica نرسیده باشد. برای user، به نظر می‌رسد که داده‌هایی که ارسال کرده‌اند، از دست رفته است، بنابراین آن‌ها قابل درک هستند و ناراحت خواهند بود.
    </p>
<p>
        162 | Chapter 5: Replication
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0184</div>
            </div>
        </div>
        <!-- Page 0185 -->
        <div class="chapter" id="page-0185">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        شکل 5-3. A user یک write را انجام می‌دهد، و به دنبال آن یک read از یک replica stale. برای جلوگیری از این anomaly، ما نیاز به read-after-write consistency داریم.
    </p>
<p>
        در این شرایط، ما نیاز به read-after-write consistency داریم، که همچنین به عنوان read-your-writes consistency [24] شناخته می‌شود. این یک guarantee است که اگر user صفحه را دوباره بارگیری کند، همیشه هر updates که خودشان submit کرده‌اند، را خواهند دید. این در مورد سایر users وعده‌ای نمی‌دهد: updates از other users ممکن است تا مدتی بعد قابل مشاهده نباشد. با این حال، user را مطمئن می‌کند که ورودی خودشان به درستی ذخیره شده است.
    </p>
<p>
        چگونه می‌توانیم read-after-write consistency را در یک سیستم با leader-based replication پیاده‌سازی کنیم؟ تکنیک‌های مختلفی وجود دارد. برای ذکر چند مورد:
    </p>
<ul>
<li>هنگام خواندن چیزی که user ممکن است آن را اصلاح کرده باشد، آن را از leader بخوانید. در غیر این صورت، آن را از یک follower بخوانید. این نیاز به این دارد که شما یک روش برای دانستن اینکه آیا چیزی ممکن است تغییر کرده باشد، داشته باشید، بدون اینکه واقعاً آن را query کنید. به عنوان مثال، اطلاعات profile user در یک social network معمولاً فقط توسط owner از profile قابل ویرایش است، نه توسط هیچ کس دیگری. بنابراین، یک rule ساده این است: همیشه profile خود user را از leader بخوانید و profiles از هر user دیگر را از یک follower.</li>
<li>If most things in the application are potentially editable by the user, that approach won’t be effective, as most things would have to be read from the leader (negating the benefit of read scaling). In that case, other criteria may be used to decide whether to read from the leader. For example, you could track the time of the last update and, for one minute after the last update, make all reads from the leader. You could also monitor the replication lag on followers and pre‐vent queries on any follower that is more than one minute behind the leader.</li>
<li>The client می‌تواند timestamp از most recent write خود را به خاطر بسپارد—سپس سیستم می‌تواند اطمینان حاصل کند که replica serving هر reads برای آن user، updates را حداقل تا آن timestamp منعکس می‌کند. اگر یک replica به اندازه کافی به‌روز نباشد، یا read را می‌توان توسط یک replica دیگر handle کرد یا query می‌تواند منتظر بماند تا the replica has</li>
</ul>
<p>
        Problems with Replication Lag | 163
    </p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 185" src="page_0185/image_1.png"/></div>
</div>
                <div class="page-number">صفحه 0185</div>
            </div>
        </div>
        <!-- Page 0186 -->
        <div class="chapter" id="page-0186">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        caught up. The timestamp could be a logical timestamp (something that indicates ordering of writes, such as the log sequence number) or the actual system clock (in which case clock synchronization becomes critical; see “Unreliable Clocks” on page 287).
    </p>
<ul>
<li>If your replicas are distributed across multiple datacenters (for geographical proximity to users or for availability)، there is additional complexity. Any request که نیاز به serving توسط leader دارد، باید به datacenter که حاوی leader است، هدایت شود.</li>
</ul>
<p>
        Another complication arises when the same user is accessing your service from multiple devices, for example a desktop web browser and a mobile app. In this case you may want to provide cross-device read-after-write consistency: if the user enters some information on one device and then views it on another device, they should see the information they just entered.
    </p>
<p>
        In this case, there are some additional issues to consider:
    </p>
<ul>
<li>Approaches که نیاز به به خاطر سپردن timestamp از last update user دارند، دشوارتر می‌شوند، زیرا کد که روی یک دستگاه اجرا می‌شود، نمی‌داند چه updates بر روی device دیگر رخ داده است. This metadata باید centralized شود.</li>
<li>If your replicas are distributed across different datacenters, there is no guarantee that connections from different devices will be routed to the same datacenter. (For example, if the user’s desktop computer uses the home broadband connec‐tion and their mobile device uses the cellular data network, the devices’ network routes may be completely different.) If your approach requires reading from the leader, you may first need to route requests from all of a user’s devices to the same datacenter.</li>
</ul>
<h4>Monotonic Reads</h4>
<p>
        Our second example از یک anomaly که می‌تواند هنگام خواندن از followers asynchronous رخ دهد این است که ممکن است یک user چیزهایی را ببیند که در زمان به عقب حرکت می‌کنند.
    </p>
<p>
        This can happen if a user makes several reads from different replicas. For example, Figure 5-4 shows user 2345 making the same query twice, first to a follower with little lag, then to a follower with greater lag. (This scenario is quite likely if the user refreshes a web page, and each request is routed to a random server.) The first query returns a comment that was recently added by user 1234, but the second query doesn’t return anything because the lagging follower has not yet picked up that write.
    </p>
<p>
        در واقع، the second query در حال مشاهده سیستم در یک زمان earlier than the first query. This wouldn’t be so bad if the first query hadn’t returned anything, because user 2345 probably wouldn’t know that user 1234 had recently added a com‐
    </p>
<p>
        164 | Chapter 5: Replication
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0186</div>
            </div>
        </div>
        <!-- Page 0187 -->
        <div class="chapter" id="page-0187">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        ment. با این حال، برای user 2345 بسیار گیج‌کننده است اگر آن‌ها ابتدا comment از user 1234 را ببینند، و سپس ببینند که دوباره ناپدید می‌شود.
    </p>
<p>
        شکل 5-4. A user ابتدا از یک replica تازه می‌خواند، سپس از یک replica stale. زمان به نظر می‌رسد به عقب برمی‌گردد. برای جلوگیری از این anomaly، ما نیاز به monotonic reads داریم.
    </p>
<p>
        Monotonic reads [23] یک guarantee است که این نوع anomaly رخ نمی‌دهد. این یک guarantee کوچکتر از strong consistency است، اما یک guarantee قوی‌تر از eventual con‐sistency است. هنگامی که شما داده‌ها را می‌خوانید، ممکن است یک value قدیمی را ببینید. monotonic reads فقط به این معنی است که اگر یک user چندین read را به ترتیب انجام دهد، آن‌ها زمان را به عقب نخواهند دید—یعنی، آن‌ها data قدیمی‌تر را پس از خواندن قبلی data جدیدتر، نخواهند خواند.
    </p>
<p>
        یک راه برای دستیابی به monotonic reads این است که اطمینان حاصل شود که هر user همیشه reads خود را از یک replica یکسان انجام می‌دهد (users مختلف می‌توانند از replicas مختلف بخوانند). به عنوان مثال، replica را می‌توان بر اساس یک hash از the user ID انتخاب کرد، نه به طور تصادفی. با این حال، اگر آن replica fail شود، queries user نیاز به rerouted شدن به یک replica دیگر دارند.
    </p>
<h4>Consistent Prefix Reads</h4>
<p>
        The third example از replication lag anomalies concern violation of causality. تصور کنید مکالمه کوتاه زیر بین آقای Poons و خانم Cake:
    </p>
<p>
        آقای Poons
        تا چه حد در آینده می‌توانی ببینی، خانم Cake؟
    </p>
<p>
        خانم Cake
        معمولاً حدود ده ثانیه، آقای Poons.
    </p>
<p>
        Problems with Replication Lag | 165
    </p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 187" src="page_0187/image_1.png"/></div>
</div>
                <div class="page-number">صفحه 0187</div>
            </div>
        </div>
        <!-- Page 0188 -->
        <div class="chapter" id="page-0188">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        یک causal dependency بین آن دو جمله وجود دارد: خانم Cake سؤال آقای Poons را شنید و به آن پاسخ داد.
    </p>
<p>
        حالا، تصور کنید که یک فرد سوم در حال گوش دادن به این مکالمه از طریق followers است. چیزهایی که توسط خانم Cake گفته می‌شود، از طریق یک follower با lag کمی عبور می‌کنند، اما چیزهایی که توسط آقای Poons گفته می‌شود، یک replication lag طولانی‌تر دارند (شکل 5-5 را ببینید). این observer موارد زیر را خواهد شنید:
    </p>
<p>
        خانم Cake
        معمولاً حدود ده ثانیه، آقای Poons.
    </p>
<p>
        آقای Poons
        تا چه حد در آینده می‌توانی ببینی، خانم Cake؟
    </p>
<p>
        به observer به نظر می‌رسد که خانم Cake در حال پاسخ دادن به سؤال قبل از اینکه آقای Poons حتی آن را بپرسد، است. این قدرت‌های روانی چشمگیر هستند، اما بسیار گیج‌کننده [25].
    </p>
<p>
        شکل 5-5. If some partitions are replicated slower than others، یک observer ممکن است پاسخ را قبل از اینکه سؤال را ببیند، مشاهده کند.
    </p>
<p>
        جلوگیری از این نوع anomaly نیاز به نوع دیگری از guarantee دارد: consistent prefix reads [23]. این guarantee می‌گوید که اگر یک sequence از writes به یک ترتیب خاص اتفاق می‌افتد، پس هر کسی که آن writes را می‌خواند، آن‌ها را به همان ترتیب خواهد دید.
    </p>
<p>
        این یک مشکل خاص در partitioned (sharded) databases است، که ما در فصل 6 در مورد آن بحث خواهیم کرد. اگر database همیشه writes را به همان ترتیب اعمال کند، reads همیشه یک prefix consistent را می‌بینند، بنابراین این anomaly نمی‌تواند اتفاق بیفتد. با این حال، در بسیاری از distributed
    </p>
<p>
        166 | Chapter 5: Replication
    </p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 188" src="page_0188/image_1.png"/></div>
</div>
                <div class="page-number">صفحه 0188</div>
            </div>
        </div>
        <!-- Page 0189 -->
        <div class="chapter" id="page-0189">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        databases، partitions مختلف به طور مستقل عمل می‌کنند، بنابراین هیچ ordering global از writes وجود ندارد: وقتی یک user از database می‌خواند، آن‌ها ممکن است بخش‌هایی از database را در یک state قدیمی‌تر و برخی دیگر را در یک state جدیدتر ببینند.
    </p>
<p>
        One solution این است که اطمینان حاصل شود که هر writes که به صورت causal به یکدیگر مرتبط هستند، به یک partition یکسان نوشته می‌شوند—اما در برخی از applications این کار نمی‌تواند به طور کارآمد انجام شود. همچنین الگوریتم‌هایی وجود دارند که صریحاً dependencies causal را پیگیری می‌کنند، موضوعی که ما در "The “happens-before” relationship and concurrency" در صفحه 186 به آن باز خواهیم گشت.
    </p>
<h4>Solutions for Replication Lag</h4>
<p>
        When working with an eventually consistent system، ارزش دارد که در مورد نحوه رفتار application اگر replication lag به چند دقیقه یا حتی ساعت افزایش یابد، فکر کنید. اگر پاسخ "مشکلی نیست" باشد، عالی است. با این حال، اگر نتیجه یک تجربه بد برای users باشد، این مهم است که سیستم را طوری طراحی کنید که یک guarantee قوی‌تر، مانند read-after-write را ارائه دهد. تظاهر به اینکه replication synchronous است، در حالی که در واقع asynchronous است، یک دستورالعمل برای مشکلات در آینده است.
    </p>
<p>
        همانطور که قبلاً بحث شد، راه‌هایی وجود دارد که یک application می‌تواند یک guarantee قوی‌تر از database اساسی ارائه دهد—به عنوان مثال، با انجام انواع خاصی از reads بر روی leader. با این حال، برخورد با این issues در application code پیچیده است و به راحتی اشتباه گرفته می‌شود.
    </p>
<p>
        بهتر است اگر developers application نیازی به نگرانی در مورد مسائل ظریف replication نداشته باشند و فقط بتوانند به databases خود اعتماد کنند که "کار درست را انجام می‌دهند". به همین دلیل است که transactions وجود دارند: آن‌ها یک راه برای یک database هستند که guarantees قوی‌تری را ارائه می‌دهند تا application بتواند ساده‌تر باشد.
    </p>
<p>
        Single-node transactions برای مدت طولانی وجود داشته‌اند. با این حال، در حرکت به databases distributed (replicated و partitioned)، بسیاری از systems آن‌ها را رها کرده‌اند و ادعا می‌کنند که transactions از نظر performance و availability بسیار گران هستند و تأیید می‌کنند که eventual consistency در یک سیستم scalable اجتناب‌ناپذیر است. در این جمله مقداری حقیقت وجود دارد، اما بیش از حد ساده‌انگارانه است و ما یک دیدگاه ظریف‌تری را در طول بقیه این کتاب توسعه خواهیم داد. ما در مورد موضوع transactions در فصل‌های 7 و 9 باز خواهیم گشت و در مورد برخی از مکانیزم‌های جایگزین در قسمت III بحث خواهیم کرد.
    </p>
<p>
        Problems with Replication Lag | 167
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0189</div>
            </div>
        </div>
        <!-- Page 0190 -->
        <div class="chapter" id="page-0190">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        iv. If the database is partitioned (see Chapter 6)، هر partition یک leader دارد. Partitions مختلف ممکن است leaders خود را در nodes مختلف داشته باشند، اما هر partition باید با این وجود یک node leader داشته باشد.
    </p>
<h4>Multi-Leader Replication</h4>
<p>
        تا کنون در این فصل ما فقط معماری‌های replication را با استفاده از یک leader واحد در نظر گرفته‌ایم. اگرچه این یک رویکرد رایج است، اما جایگزین‌های جالبی وجود دارد.
    </p>
<p>
        Leader-based replication یک downside اصلی دارد: فقط یک leader وجود دارد و همه writes باید از آن عبور کنند.iv اگر شما نمی‌توانید به leader به هر دلیلی متصل شوید، به عنوان مثال به دلیل یک network interruption بین شما و leader، شما نمی‌توانید در database بنویسید.
    </p>
<p>
        A natural extension از the leader-based replication model این است که به بیش از یک node اجازه دهد تا writes را بپذیرد. Replication هنوز هم به همان روش انجام می‌شود: هر node که یک write را پردازش می‌کند، باید آن data change را به همه nodes دیگر ارسال کند. ما این را a multi-leader configuration می‌نامیم (همچنین به عنوان master–master یا active/active replication شناخته می‌شود).
        در این setup، هر leader به طور همزمان به عنوان یک follower برای other leaders عمل می‌کند.
    </p>
<h4>Use Cases for Multi-Leader Replication</h4>
<p>
        استفاده از یک setup multi-leader در داخل یک datacenter واحد به ندرت منطقی است، زیرا مزایا به ندرت از پیچیدگی اضافه شده بیشتر می‌شود. با این حال، شرایطی وجود دارد که در آن‌ها این configuration منطقی است.
    </p>
<p>
        Multi-datacenter operation
        تصور کنید شما یک database با replicas در چندین datacenters مختلف دارید (شاید به طوری که شما می‌توانید failure از یک datacenter کامل را تحمل کنید، یا شاید به منظور نزدیک‌تر بودن به users خود). با یک setup leader-based replication معمولی، leader باید در یکی از datacenters باشد و همه writes باید از آن datacenter عبور کنند.
    </p>
<p>
        در یک multi-leader configuration، شما می‌توانید یک leader در هر datacenter داشته باشید. شکل 5-6 نشان می‌دهد که این architecture چگونه ممکن است به نظر برسد. در داخل هر datacenter، از leader–follower replication معمولی استفاده می‌شود. بین datacenters، leader از هر datacenter، changes خود را به leaders در other datacenters replicate می‌کند.
    </p>
<p>
        168 | Chapter 5: Replication
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0190</div>
            </div>
        </div>
        <!-- Page 0191 -->
        <div class="chapter" id="page-0191">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        شکل 5-6. Multi-leader replication در سراسر multiple datacenters.
    </p>
<p>
        بیایید مقایسه کنیم که چگونه configuration single-leader و multi-leader در یک deployment multi-datacenter عمل می‌کنند:
    </p>
<h4>Performance</h4>
<p>
        در یک configuration single-leader، هر write باید از طریق اینترنت به datacenter با leader برود. این می‌تواند به writes latency قابل توجهی اضافه کند و ممکن است هدف داشتن multiple datacenters را در وهله اول نقض کند. در یک configuration multi-leader، هر write می‌تواند در datacenter محلی پردازش شود و به طور asynchronous به other datacenters replicate شود. بنابراین، inter-datacenter network delay از users پنهان شده است، که به این معنی است که performance درک شده ممکن است بهتر باشد.
    </p>
<h4>Tolerance of datacenter outages</h4>
<p>
        در یک configuration single-leader، اگر datacenter با leader fail شود، failover می‌تواند یک follower را در یک datacenter دیگر به عنوان leader ارتقا دهد. در یک configuration multi-leader، هر datacenter می‌تواند به طور مستقل از دیگران به فعالیت خود ادامه دهد و replication هنگامی که datacenter fail شده دوباره آنلاین می‌شود، catch up می‌شود.
    </p>
<h4>Tolerance of network problems</h4>
<p>
        Traffic بین datacenters معمولاً از طریق اینترنت عمومی انجام می‌شود، که ممکن است کمتر قابل اعتماد از network local در یک datacenter باشد. A single-leader configu‐ration به مشکلات در این inter-datacenter link بسیار حساس است، زیرا writes به صورت synchronous از طریق این link انجام می‌شوند. A multi-leader configuration با asyn‐chronous replication معمولاً می‌تواند مشکلات network را بهتر تحمل کند: یک network interruption موقت، مانع از پردازش شدن writes نمی‌شود.
    </p>
<p>
        Multi-Leader Replication | 169
    </p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 191" src="page_0191/image_1.png"/></div>
</div>
                <div class="page-number">صفحه 0191</div>
            </div>
        </div>
        <!-- Page 0192 -->
        <div class="chapter" id="page-0192">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        Some databases از configuration multi-leader پشتیبانی می‌کنند، اما اغلب با ابزارهای خارجی، مانند Tungsten Replicator برای MySQL [26]، BDR برای PostgreSQL [27] و GoldenGate برای Oracle [19] پیاده‌سازی می‌شود.
    </p>
<p>
        اگرچه multi-leader replication مزایایی دارد، اما یک downside بزرگ نیز دارد: داده‌های یکسان ممکن است به طور همزمان در دو datacenters مختلف اصلاح شوند و آن write conflicts باید حل شوند (که در "conflict resolution" در شکل 5-6 نشان داده شده است). ما این موضوع را در "Handling Write Conflicts" در صفحه 171 بحث خواهیم کرد.
    </p>
<p>
        از آنجایی که multi-leader replication یک ویژگی تا حدودی retrofitted در بسیاری از databases است، اغلب pitfalls configuration ظریف و interactions شگفت‌انگیزی با other database features وجود دارد. به عنوان مثال، autoincrementing keys، triggers و integrity constraints می‌توانند مشکل‌ساز باشند. به همین دلیل، multi-leader replication اغلب یک قلمرو خطرناک در نظر گرفته می‌شود که در صورت امکان باید از آن اجتناب کرد [28].
    </p>
<h4>Clients with offline operation</h4>
<p>
        یک موقعیت دیگر که در آن multi-leader replication مناسب است، این است که اگر شما یک application دارید که نیاز به ادامه کار در حالی که از اینترنت قطع است، دارید. به عنوان مثال، application‌های calendar را روی تلفن همراه، لپ‌تاپ و سایر دستگاه‌های خود در نظر بگیرید. شما نیاز دارید که بتوانید meetings خود را مشاهده کنید (ایجاد read requests) و meetings جدید را وارد کنید (ایجاد write requests) در هر زمان، صرف نظر از اینکه دستگاه شما در حال حاضر به اینترنت متصل است یا خیر. اگر شما در حالت offline هر تغییری ایجاد کنید، آن‌ها باید با یک server و other devices شما sync شوند، زمانی که دستگاه در next online قرار دارد.
    </p>
<p>
        در این مورد، چندین issue اضافی برای در نظر گرفتن وجود دارد:
    </p>
<p>
        • Approaches که نیاز به یادآوری timestamp از last update user دارند، دشوارتر می‌شوند، زیرا کد که روی یک دستگاه اجرا می‌شود، نمی‌داند چه updates بر روی دستگاه دیگر رخ داده است. این metadata باید centralized شود.
    </p>
<p>
        • If your replicas are distributed across different datacenters, there is no guarantee that connections from different devices will be routed to the same datacenter. (For example, if the user’s desktop computer uses the home broadband connec‐tion and their mobile device uses the cellular data network, the devices’ network routes may be completely different.) If your approach requires reading from the leader, you may first need to route requests from all of a user’s devices to the same datacenter.
    </p>
<p>
        در حال حاضر، یک معماری actor (و یا در حال اجرا) می‌تواند در یک state واحد (به عنوان مثال، زمان)، حتی در صورت وجود چندین منبع در یک فرآیند، باشد.
        برنامه درسی.
    </p>
<p>
        حالت، یک معماری در برنامه‌نویسی است.
    </p>
<h4>Monotonic Reads</h4>
<p>
        درست مانند یک مورد، یک user می تواند به عنوان یک برنامه در مورد اطلاعات در مورد اطلاعات در مورد information در مورد information در مورد information اطلاعاتی را در زمینه داده‌ها از دست بدهد.
    </p>
<p>
        برای اینکه بتوانید اطلاعات بیشتری کسب کنید، یک موضوع اصلی و مهم، یک رویکرد را می‌توان در این مقاله به طور متقابل بررسی کرد.
    </p>
<p>
        این، به شما این اطمینان را می‌دهد که شما داده‌ها را در یک سیستم با یک leader مشخص می‌کنید.
    </p>
<p>
        از این موضوع، یک راه برای انجام این است.
    </p>
<p>
        برای یک حالت واحد.
    </p>
<h4>Consistent Prefix Reads</h4>
<p>
        در نتیجه،
    </p>
<p>
        Our third example از replication lag anomalies concerns violation of causality. Imag‐ine the following short dialog between Mr. Poons و Mrs. Cake:
    </p>
<p>
        یک فایل از database را می توان در زمینه data.
    </p>
<p>
        165 | Chapter 5: Replication
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0192</div>
            </div>
        </div>
        <!-- Page 0193 -->
        <div class="chapter" id="page-0193">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        ما معمولاً به ویرایش مشارکتی به عنوان یک database replication problem فکر نمی‌کنیم، اما با استفاده از data و با استفاده از اطلاعات موجود در زمینه data.
    </p>
<p>
        هنگامی که یک user یک document را ویرایش می‌کند، تغییرات فوراً به replica محلی آن‌ها اعمال می‌شود (state از document در web browser یا application client آن‌ها) و به طور asynchronous به server و هر user دیگری که در حال ویرایش همان document هستند، replicate می‌شود.
    </p>
<p>
        اگر شما می‌خواهید تضمین کنید که هیچ editing conflicts وجود نخواهد داشت، application باید یک lock را روی document قبل از اینکه یک user بتواند آن را ویرایش کند، دریافت کند. اگر user دیگری می‌خواهد همان document را ویرایش کند، ابتدا باید منتظر بماند تا user اول changes خود را committed کند و lock را release کند. این مدل collaboration معادل replication single-leader با transactions روی leader است.
    </p>
<p>
        با این حال، برای collaboration سریعتر، شما ممکن است بخواهید unit of change را بسیار کوچک کنید (به عنوان مثال، یک ضربه کلید واحد) و از locking اجتناب کنید. این رویکرد به multiple users اجازه می‌دهد تا به طور همزمان ویرایش کنند، اما همچنین تمام چالش‌های multi-leader replication، از جمله نیاز به conflict resolution [32] را به همراه دارد.
    </p>
<h4>Handling Write Conflicts</h4>
<p>
        The biggest problem با multi-leader replication این است که write conflicts ممکن است رخ دهند، که به این معنی است که conflict resolution مورد نیاز است.
    </p>
<p>
        به عنوان مثال، یک صفحه wiki را در نظر بگیرید که به طور همزمان توسط دو user ویرایش می‌شود، همانطور که در شکل 5-7 نشان داده شده است. User 1 title از صفحه را از A به B تغییر می‌دهد و user 2 title را از A به C در همان زمان تغییر می‌دهد. تغییر هر user با موفقیت به leader محلی آن‌ها اعمال می‌شود. با این حال، وقتی changes به طور asynchronous replicate می‌شوند، یک conflict شناسایی می‌شود [33]. این مشکل در یک database single-leader رخ نمی‌دهد.
    </p>
<p>
        شکل 5-7. A write conflict که توسط دو leader که به طور همزمان همان record را به‌روزرسانی می‌کنند، ایجاد شده است.
    </p>
<p>
        Multi-Leader Replication | 171
    </p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 193" src="page_0193/image_1.png"/></div>
</div>
                <div class="page-number">صفحه 0193</div>
            </div>
        </div>
        <!-- Page 0194 -->
        <div class="chapter" id="page-0194">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<h4>Synchronous versus asynchronous conflict detection</h4>
<p>
        در یک database single-leader، the second writer یا بلاک می‌شود و منتظر می‌ماند تا first write کامل شود یا transaction write دوم را abort می‌کند و user را مجبور می‌کند که write را دوباره امتحان کند. از سوی دیگر، در یک setup multi-leader، هر دو writes موفقیت‌آمیز هستند و conflict تنها به طور asynchronous در یک نقطه زمانی بعدی شناسایی می‌شود. در آن زمان، ممکن است برای درخواست از user برای حل conflict خیلی دیر شده باشد.
    </p>
<p>
        In principle، شما می‌توانید conflict detection را synchronous کنید—یعنی، صبر کنید تا write به همه replicas replicate شود، قبل از اینکه به user بگویید که write موفقیت‌آمیز بود. با این حال، با انجام این کار، شما مزیت اصلی multi-leader repli‐cation را از دست می‌دهید: اجازه دادن به هر replica برای پذیرش writes به طور مستقل. اگر شما می‌خواهید synchronous conflict detection، شما ممکن است به سادگی از single-leader replication استفاده کنید.
    </p>
<h4>Conflict avoidance</h4>
<p>
        ساده‌ترین strategy برای مقابله با conflicts این است که از آن‌ها اجتناب کنید: اگر application می‌تواند اطمینان حاصل کند که همه writes برای یک record خاص از طریق همان leader انجام می‌شوند، پس con‐flicts نمی‌توانند رخ دهند. از آنجایی که بسیاری از پیاده‌سازی‌های multi-leader replication، conflicts را بسیار ضعیف handle می‌کنند، اجتناب از conflicts یک رویکردی است که اغلب توصیه می‌شود [34].
    </p>
<p>
        به عنوان مثال، در یک application که در آن یک user می‌تواند داده‌های خود را ویرایش کند، شما می‌توانید اطمینان حاصل کنید که requests از یک user خاص همیشه به یک datacenter یکسان هدایت می‌شوند و از leader در آن datacenter برای خواندن و نوشتن استفاده می‌کنند. Users مختلف ممکن است datacenters “home” متفاوتی داشته باشند (شاید بر اساس geographic proximity to the user انتخاب شده باشد)، اما از دیدگاه هر user، the configuration اساساً single-leader است.
    </p>
<p>
        با این حال، گاهی اوقات شما ممکن است بخواهید leader تعیین شده را برای یک record تغییر دهید—شاید به این دلیل که یک datacenter fail شده است و شما نیاز دارید که traffic را به یک datacenter دیگر reroute کنید، یا شاید به این دلیل که یک user به یک location متفاوت منتقل شده است و اکنون به یک datacenter متفاوت نزدیکتر است. در این شرایط، conflict avoidance فرو می‌پاشد و شما باید با احتمال concurrent writes در leaders مختلف برخورد کنید.
    </p>
<h4>Converging toward a consistent state</h4>
<p>
        یک database single-leader writes را به یک ترتیب sequential اعمال می‌کند: اگر چندین update به یک فیلد یکسان وجود داشته باشد، آخرین write، value نهایی فیلد را تعیین می‌کند.
    </p>
<p>
        در یک configuration multi-leader، هیچ ordering تعریف شده از writes وجود ندارد، بنابراین مشخص نیست که value نهایی باید چه باشد. در شکل 5-7، در leader 1 title ابتدا به B و سپس به C به‌روزرسانی می‌شود. در leader 2 ابتدا به C و سپس به B به‌روزرسانی می‌شود. هیچ‌کدام از این ordering "صحیح‌تر" از دیگری نیستند.
    </p>
<p>
        If each replica به سادگی writes را به ترتیبی که آن‌ها را می‌بیند، اعمال می‌کند، database در یک state inconsistent به پایان می‌رسد: the final value در leader 1 C و در leader 2 B خواهد بود. این قابل قبول نیست—هر replication scheme باید اطمینان حاصل کند که داده‌ها در نهایت در همه replicas یکسان هستند. بنابراین، database باید conflict را به یک
    </p>
<p>
        172 | Chapter 5: Replication
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0194</div>
            </div>
        </div>
        <!-- Page 0195 -->
        <div class="chapter" id="page-0195">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        convergent way، که به این معنی است که همه replicas باید به همان value نهایی برسند، هنگامی که تمام تغییرات replicate شده‌اند.
    </p>
<p>
        راه‌های مختلفی برای دستیابی به convergent conflict resolution وجود دارد:
    </p>
<ul>
<li>Give each write یک unique ID (به عنوان مثال، یک timestamp، یک عدد تصادفی طولانی، یک UUID یا یک hash از key و value)، write با بالاترین ID را به عنوان برنده انتخاب کنید و سایر writes را دور بریزید. اگر یک timestamp استفاده شود، این تکنیک به عنوان last write wins (LWW) شناخته می‌شود. اگرچه این رویکرد محبوب است، اما به طور خطرناکی مستعد data loss است [35]. ما در پایان این فصل در مورد LWW با جزئیات بیشتر بحث خواهیم کرد ("Detecting Concurrent Writes" در صفحه 184).</li>
<li>Give each replica یک unique ID، و به writes که در یک replica با شماره بالاتر منشأ شده‌اند، همیشه بر writes که در یک replica با شماره پایین‌تر منشأ شده‌اند، تقدم دهید. این رویکرد نیز به data loss اشاره دارد.</li>
<li>به نوعی values را با هم merge کنید—به عنوان مثال، آن‌ها را به ترتیب حروف الفبا مرتب کنید و سپس آن‌ها را concatenate کنید (در شکل 5-7، the merged title ممکن است چیزی شبیه "B/C") باشد.</li>
<li>Record the conflict در یک data structure صریح که تمام اطلاعات را حفظ می‌کند و application code را می‌نویسد که conflict را در زمانی در آینده حل می‌کند (شاید با درخواست از user).</li>
</ul>
<h4>Custom conflict resolution logic</h4>
<p>
        از آنجایی که مناسب‌ترین روش برای حل یک conflict ممکن است به application بستگی داشته باشد، اکثر ابزارهای multi-leader replication به شما اجازه می‌دهند که منطق conflict resolution را با استفاده از application code بنویسید. آن کد ممکن است در زمان write یا در زمان read اجرا شود:
    </p>
<ul>
<li>On write</li>
<li>به محض اینکه سیستم database یک conflict را در log of replicated changes تشخیص می‌دهد، the conflict handler را فراخوانی می‌کند. به عنوان مثال، Bucardo به شما اجازه می‌دهد تا یک snippet از Perl را برای این منظور بنویسید. این handler معمولاً نمی‌تواند یک user را prompt کند—این در یک فرآیند background اجرا می‌شود و باید سریع اجرا شود.</li>
<li>On read</li>
<li>هنگامی که یک conflict شناسایی می‌شود، همه writes conflicting ذخیره می‌شوند. دفعه بعد که data خوانده می‌شود، این نسخه‌های متعدد از data به application برگردانده می‌شوند. The application ممکن است user را prompt کند یا به طور خودکار conflict را حل کند و نتیجه را به database برگرداند. به عنوان مثال، CouchDB به این شکل عمل می‌کند.</li>
</ul>
<p>
        توجه داشته باشید که conflict resolution معمولاً در سطح یک ردیف یا document مجزا اعمال می‌شود، نه برای یک transaction کامل [36]. بنابراین، اگر شما یک transaction دارید که به طور اتمی چندین write مختلف انجام می‌دهد (فصل 7 را ببینید)، هر write هنوز هم به طور جداگانه برای اهداف conflict resolution در نظر گرفته می‌شود.
    </p>
<p>
        Multi-Leader Replication | 173
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0195</div>
            </div>
        </div>
        <!-- Page 0196 -->
        <div class="chapter" id="page-0196">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<h4>Automatic Conflict Resolution</h4>
<p>
        Conflict resolution rules می‌تواند به سرعت پیچیده شود و application code custom می‌تواند مستعد error باشد. Amazon یک مثال از اثرات شگفت‌انگیز به دلیل a con‐flict resolution handler است: برای مدتی، منطق conflict resolution در shopping cart آیتم‌های اضافه شده به cart را حفظ می‌کرد، اما آیتم‌های حذف شده از cart را حفظ نمی‌کرد.
        بنابراین، customers گاهی اوقات آیتم‌هایی را در carts خود دوباره می‌دیدند، حتی اگر قبلاً آن‌ها را حذف کرده بودند [37].
    </p>
<p>
        تحقیقات جالبی در مورد حل خودکار conflicts که ناشی از data modifications concurrent هستند، وجود داشته است. چند خط از تحقیقات ارزش ذکر کردن را دارند:
    </p>
<ul>
<li>Conflict-free replicated datatypes (CRDTs) [32, 38] یک family از data structures برای sets، maps، lists مرتب شده، counters و غیره هستند که می‌توانند به طور همزمان توسط multiple users ویرایش شوند و که به طور خودکار conflicts را به روش‌های معقول حل می‌کنند. برخی از CRDTs در Riak 2.0 پیاده‌سازی شده‌اند [39, 40].</li>
<li>Mergeable persistent data structures [41] تاریخچه را صریحاً ردیابی می‌کنند، مشابه system کنترل version Git، و از یک تابع merge سه طرفه استفاده می‌کنند (در حالی که CRDTs از merges دو طرفه استفاده می‌کنند).</li>
<li>Operational transformation [42] الگوریتم conflict resolution پشت application‌های collaborative editing مانند Etherpad [30] و Google Docs [31] است. این به ویژه برای editing همزمان از یک list مرتب شده از آیتم‌ها، مانند list of characters که یک document text را تشکیل می‌دهند، طراحی شده است.</li>
</ul>
<p>
        Implementations از این الگوریتم‌ها در databases هنوز جوان هستند، اما احتمال دارد که آن‌ها در آینده در systems data replicated بیشتری ادغام شوند. Automatic conflict resolution می‌تواند synchronization data multi-leader را برای application‌ها بسیار ساده‌تر کند.
    </p>
<h4>What is a conflict?</h4>
<p>
        برخی از انواع conflict مشخص هستند. در مثال شکل 5-7، دو writes به طور همزمان همان فیلد را در همان record اصلاح کردند و آن را به دو value متفاوت تنظیم کردند. هیچ شکی وجود ندارد که این یک conflict است.
    </p>
<p>
        سایر انواع conflict می‌توانند تشخیص آن‌ها ظریف‌تر باشند. به عنوان مثال، یک سیستم رزرو اتاق جلسه را در نظر بگیرید: این ردیابی می‌کند که کدام اتاق توسط کدام گروه از افراد در چه زمانی رزرو شده است. این application نیاز دارد که اطمینان حاصل کند که هر اتاق فقط توسط یک گروه از افراد در هر زمان رزرو می‌شود (یعنی، نباید هیچ overlapping bookings برای همان اتاق وجود داشته باشد). در این مورد، یک conflict ممکن است ایجاد شود اگر دو booking متفاوت برای همان اتاق در همان زمان ایجاد شوند. حتی اگر application availability را قبل از
    </p>
<p>
        Problems with Replication Lag | 174
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0196</div>
            </div>
        </div>
        <!-- Page 0197 -->
        <div class="chapter" id="page-0197">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        v. Not to be confused with a star schema (see “Stars and Snowflakes: Schemas for Analytics” on page 93)، که structure از یک data model را توصیف می‌کند، نه توپولوژی communication بین nodes.
    </p>
<p>
        allowing a user to make a booking، ممکن است یک conflict وجود داشته باشد اگر دو booking در دو leader مختلف ساخته شوند.
    </p>
<p>
        یک پاسخ سریع و آماده وجود ندارد، اما در فصل‌های زیر ما یک مسیر را به سمت درک خوب از این مشکل دنبال خواهیم کرد. ما در فصل 7 نمونه‌های بیشتری از conflicts را خواهیم دید و در فصل 12 ما در مورد رویکردهای scalable برای شناسایی و حل conflicts در یک سیستم replicated بحث خواهیم کرد.
    </p>
<h4>Multi-Leader Replication Topologies</h4>
<p>
        A replication topology مسیرهای communication را توصیف می‌کند که در آن writes از یک node به node دیگر منتشر می‌شوند. اگر شما دو leader دارید، همانطور که در شکل 5-7 نشان داده شده است، فقط یک topology محتمل وجود دارد: leader 1 باید همه writes خود را به leader 2 ارسال کند و بالعکس. با بیش از دو leader، topologies مختلفی امکان‌پذیر است.
    </p>
<p>
        برخی از نمونه‌ها در شکل 5-8 نشان داده شده است.
    </p>
<p>
        شکل 5-8. Three example topologies که در آن multi-leader replication می‌تواند تنظیم شود.
    </p>
<p>
        The most general topology is all-to-all (Figure 5-8 [c])، که در آن هر leader writes خود را به هر leader دیگری ارسال می‌کند. با این حال، topologies محدودتر نیز استفاده می‌شوند: به عنوان مثال، MySQL به طور پیش‌فرض فقط از یک topology circular پشتیبانی می‌کند [34]، که در آن هر node writes را از یک node دریافت می‌کند و آن writes را (به علاوه هر writes از خودش) به یک node دیگر ارسال می‌کند. یک topology محبوب دیگر، شکل یک ستاره را دارد: v یک node root تعیین شده، writes را به همه other nodes ارسال می‌کند. The star topology می‌تواند به یک tree تعمیم داده شود.
    </p>
<p>
        در topologies circular و star، یک write ممکن است نیاز به عبور از چندین node داشته باشد قبل از اینکه به همه replicas برسد. بنابراین، nodes نیاز دارند که data changes را که از other nodes دریافت می‌کنند، forward کنند. برای جلوگیری از infinite replication loops، به هر node یک unique identifier داده می‌شود و در the replication log، هر write با شناسه‌های همه nodes که از آن عبور کرده است، برچسب‌گذاری می‌شود [43]. هنگامی که یک node یک data change را دریافت می‌کند که tagged
    </p>
<p>
        Multi-Leader Replication | 175
    </p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 197" src="page_0197/image_1.png"/></div>
</div>
                <div class="page-number">صفحه 0197</div>
            </div>
        </div>
        <!-- Page 0198 -->
        <div class="chapter" id="page-0198">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        with its own identifier، that data change is ignored، زیرا node می‌داند که قبلاً آن را پردازش کرده است.
    </p>
<p>
        A problem با topologies circular و star این است که اگر فقط یک node fail شود، می‌تواند flow از replication messages بین other nodes را قطع کند و باعث می‌شود که آن‌ها نتوانند ارتباط برقرار کنند تا زمانی که node تعمیر شود. The topology می‌تواند برای کار در اطراف node fail شده دوباره پیکربندی شود، اما در اکثر deployments، چنین reconfiguration باید به صورت دستی انجام شود. The fault tolerance از یک topology متصل‌تر (مانند all-to-all) بهتر است زیرا به messages اجازه می‌دهد تا در امتداد paths مختلف حرکت کنند و از یک point of failure واحد اجتناب کنند.
    </p>
<p>
        از سوی دیگر، all-to-all topologies نیز می‌توانند مشکلاتی داشته باشند. به طور خاص، برخی از network links ممکن است سریعتر از دیگران باشند (به عنوان مثال، به دلیل network congestion)، با نتیجه این که برخی از replication messages ممکن است other را "overtake" کنند، همانطور که در شکل 5-9 نشان داده شده است.
    </p>
<p>
        شکل 5-9. With multi-leader replication، writes ممکن است به ترتیب اشتباه در برخی از replicas برسند.
    </p>
<p>
        در شکل 5-9، client A یک ردیف را در leader 1 درج می‌کند و client B آن ردیف را در leader 3 به‌روزرسانی می‌کند. با این حال، leader 2 ممکن است writes را به ترتیب متفاوتی دریافت کند: ممکن است ابتدا update را دریافت کند (که، از دیدگاه آن، یک update به یک ردیف است که در database وجود ندارد) و فقط بعداً insert مربوطه را دریافت کند (که
        باید قبل از update آمده باشد).
    </p>
<p>
        This is a problem of causality، similar to the one we saw in “Consistent Prefix Reads” on page 165: the update depends on the prior insert, so we need to make sure that all nodes process the insert first, and then the update. Simply attaching a timestamp to
    </p>
<p>
        176 | Chapter 5: Replication
    </p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 198" src="page_0198/image_1.png"/></div>
</div>
                <div class="page-number">صفحه 0198</div>
            </div>
        </div>
        <!-- Page 0199 -->
        <div class="chapter" id="page-0199">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        vi. Dynamo به کاربران خارج از Amazon در دسترس نیست. Confusingly، AWS یک محصول database hosted را ارائه می‌دهد که DynamoDB نامیده می‌شود، که از یک architecture کاملاً متفاوت استفاده می‌کند: این بر اساس replication single-leader است.
    </p>
<p>
        هر write کافی نیست، زیرا نمی‌توان به ساعت‌ها اعتماد کرد که به اندازه کافی برای مرتب کردن صحیح این events در leader 2 sync شده باشند (فصل 8 را ببینید).
    </p>
<p>
        To order این events به درستی، یک تکنیک به نام version vectors می‌تواند استفاده شود که ما بعداً در این فصل در مورد آن بحث خواهیم کرد ("Detecting Concurrent Writes" در صفحه 184 را ببینید).
    </p>
<p>
        با این حال، تکنیک‌های conflict detection در بسیاری از سیستم‌های multi-leader replication به خوبی پیاده‌سازی نشده‌اند. به عنوان مثال، در زمان نوشتن، PostgreSQL BDR ordering causal از writes را ارائه نمی‌دهد [27] و Tungsten Replicator برای MySQL حتی تلاش نمی‌کند تا conflicts را شناسایی کند [34].
    </p>
<p>
        If you are using یک سیستم با multi-leader replication، ارزش دارد که از این issues آگاه باشید، با دقت documentation را بخوانید و database خود را کاملاً تست کنید تا اطمینان حاصل کنید که واقعاً guarantees که شما معتقدید دارد را ارائه می‌دهد.
    </p>
<h4>Leaderless Replication</h4>
<p>
        The replication approaches که ما تاکنون در این فصل بحث کرده‌ایم—single-leader و multi-leader replication—بر اساس این ایده هستند که یک client یک write request را به یک node (leader) ارسال می‌کند و سیستم database مراقب کپی کردن آن write به other replicas است. یک leader، order را که در آن writes باید پردازش شوند، تعیین می‌کند و followers writes از leader را به همان ترتیب اعمال می‌کنند.
    </p>
<p>
        برخی از systems data storage یک رویکرد متفاوت را در پیش می‌گیرند و مفهوم یک leader را کنار می‌گذارند و به هر replica اجازه می‌دهند که به طور مستقیم writes را از clients بپذیرد. برخی از قدیمی‌ترین systems data replicated، leaderless بودند [1, 44]، اما ایده در دوران تسلط relational databases، عمدتاً فراموش شد. این دوباره به یک architecture fashionable برای databases پس از استفاده Amazon از آن برای سیستم Dynamo داخلی خود [37] تبدیل شد.vi Riak, Cassandra و Voldemort datastores open source با leaderless replication models هستند که از Dynamo الهام گرفته‌اند، بنابراین این نوع database همچنین به عنوان Dynamo-style شناخته می‌شود.
    </p>
<p>
        در برخی از پیاده‌سازی‌های leaderless، client به طور مستقیم writes خود را به چندین replicas ارسال می‌کند، در حالی که در موارد دیگر، یک node coordinator این کار را از طرف client انجام می‌دهد. با این حال، بر خلاف یک leader database، آن coordinator یک ordering خاص از writes را اعمال نمی‌کند. همانطور که خواهیم دید، این تفاوت در طراحی، عواقب عمیقی برای روش استفاده از database دارد.
    </p>
<h4>Writing to the Database When a Node Is Down</h4>
<p>
        تصور کنید شما یک database با سه replicas دارید و یکی از replicas در حال حاضر در دسترس نیست—شاید در حال reboot شدن برای نصب یک update system است. در یک leader-based
    </p>
<p>
        Leaderless Replication | 177
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0199</div>
            </div>
        </div>
        <!-- Page 0200 -->
        <div class="chapter" id="page-0200">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        در حالی که یک node ناپدید شده است، شما نیازی به انجام a failover ندارید.
    </p>
<p>
        In a leader-based configuration، اگر شما می‌خواهید به پردازش writes ادامه دهید، شما ممکن است نیاز به انجام a failover داشته باشید ("Handling Node Outages" در صفحه 156 را ببینید).
    </p>
<p>
        از سوی دیگر، در یک configuration leaderless، failover وجود ندارد. شکل 5-10 نشان می‌دهد که چه اتفاقی می‌افتد: client (user 1234) write را به هر سه replica به صورت موازی ارسال می‌کند و دو replicas در دسترس، write را می‌پذیرند اما replica غیرقابل دسترس، آن را از دست می‌دهد. بگذارید بگوییم که کافی است که دو replica از سه replica، write را تأیید کنند: پس از اینکه user 1234 دو response ok دریافت کرد، ما در نظر می‌گیریم که write موفقیت‌آمیز بوده است.
        Client به سادگی واقعیت را نادیده می‌گیرد که یکی از replicas، write را از دست داده است.
    </p>
<p>
        شکل 5-10. A quorum write, quorum read, و read repair پس از یک node outage.
    </p>
<p>
        حالا تصور کنید که the unavailable node دوباره آنلاین می‌شود و clients شروع به خواندن از آن می‌کنند. هر writes که در حالی که node down بود، رخ داده است، از آن node از دست رفته‌اند. بنابراین، اگر شما از آن node بخوانید، شما ممکن است values stale (outdated) را به عنوان responses دریافت کنید.
    </p>
<p>
        برای حل آن مشکل، هنگامی که یک client از database می‌خواند، آن فقط request خود را به یک replica ارسال نمی‌کند: read requests نیز به چندین node به صورت موازی ارسال می‌شوند. The client ممکن است responses مختلفی از nodes مختلف دریافت کند. یعنی، the up-to-date value از یک node و یک value stale از دیگری. Version numbers برای تعیین اینکه کدام value جدیدتر است، استفاده می‌شوند ("Detecting Concurrent Writes" در صفحه 184 را ببینید).
    </p>
<h4>Read repair and anti-entropy</h4>
<p>
        The replication scheme باید اطمینان حاصل کند که در نهایت همه داده‌ها به هر replica کپی می‌شوند. پس از اینکه یک node unavailable دوباره آنلاین شد، چگونه آن catch up بر روی the writes که از دست داده است، انجام می‌شود؟
    </p>
<p>
        178 | Chapter 5: Replication
    </p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 200" src="page_0200/image_1.png"/></div>
</div>
                <div class="page-number">صفحه 0200</div>
            </div>
        </div>
        <!-- Page 0201 -->
        <div class="chapter" id="page-0201">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        vii. Sometimes this kind of quorum is called a strict quorum, to contrast with sloppy quorums (discussed in “Sloppy Quorums and Hinted Handoff” on page 183).
    </p>
<p>
        دو مکانیزم اغلب در Dynamo-style datastores استفاده می‌شوند:
    </p>
<ul>
<li>Read repair</li>
<li>هنگامی که یک client یک read را از چندین node به طور موازی انجام می‌دهد، می‌تواند هر پاسخ stale را تشخیص دهد. به عنوان مثال، در شکل 5-10، user 2345 یک value نسخه 6 را از replica 3 و یک value نسخه 7 را از replicas 1 و 2 دریافت می‌کند. client می‌بیند که replica 3 یک value stale دارد و value جدیدتر را به آن replica می‌نویسد. این رویکرد برای values که اغلب خوانده می‌شوند، خوب عمل می‌کند.</li>
<li>Anti-entropy process</li>
<li>علاوه بر این، برخی از datastores یک فرآیند background دارند که به طور مداوم به دنبال تفاوت‌ها در data بین replicas می‌گردد و هر داده‌ای که از یک replica در دسترس نیست، را کپی می‌کند. برخلاف the replication log در leader-based replication، این anti-entropy process در هیچ order خاصی writes را کپی نمی‌کند و ممکن است یک delay قابل توجه قبل از کپی شدن data وجود داشته باشد.</li>
</ul>
<p>
        Not all systems implement both of these. به عنوان مثال، Voldemort در حال حاضر یک فرآیند anti-entropy ندارد. توجه داشته باشید که بدون یک فرآیند anti-entropy، values که به ندرت خوانده می‌شوند، ممکن است از برخی از replicas از دست رفته باشند و بنابراین durability کاهش یافته است، زیرا read repair تنها زمانی انجام می‌شود که یک value توسط application خوانده می‌شود.
    </p>
<h4>Quorums for reading and writing</h4>
<p>
        در مثال شکل 5-10، ما این write را موفقیت‌آمیز در نظر گرفتیم، حتی اگر فقط در دو replica از سه replica پردازش شده باشد. اگر فقط یک replica از سه replica write را بپذیرد، چه می‌شود؟ چقدر می‌توانیم این را پیش ببریم؟
    </p>
<p>
        If we know that every successful write is guaranteed to be present on at least two out of three replicas, that means at most one replica can be stale. Thus, if we read from at least two replicas, we can be sure that at least one of the two is up to date. If the third replica is down or slow to respond, reads can nevertheless continue returning an up-to-date value.
    </p>
<p>
        به طور کلی، اگر n replicas وجود داشته باشد، هر write باید توسط w nodes تأیید شود تا موفقیت‌آمیز تلقی شود و ما باید حداقل r nodes را برای هر read query کنیم. (در مثال ما، n = 3, w = 2, r = 2.) تا زمانی که w + r &gt; n، ما انتظار داریم که یک value up-to-date را هنگام خواندن دریافت کنیم، زیرا حداقل یکی از r nodes که ما از آن‌ها می‌خوانیم، باید up to date باشد. Reads و writes که از این values r و w پیروی می‌کنند، quorum reads و writes [44] نامیده می‌شوند.vii شما می‌توانید به r و w به عنوان حداقل تعداد votes که برای valid بودن read یا write مورد نیاز است، فکر کنید.
    </p>
<p>
        Leaderless Replication | 179
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0201</div>
            </div>
        </div>
        <!-- Page 0202 -->
        <div class="chapter" id="page-0202">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        در databases Dynamo-style، پارامترهای n, w و r معمولاً قابل تنظیم هستند. A common choice این است که n را یک عدد فرد (معمولاً 3 یا 5) قرار دهید و w = r = (n + 1) / 2 (به سمت بالا گرد شده) را تنظیم کنید. با این حال، شما می‌توانید اعداد را آنطور که صلاح می‌دانید تغییر دهید. به عنوان مثال، یک workload با writes کم و reads زیاد ممکن است از تنظیم w = n و r = 1 سود ببرد. این باعث می‌شود که reads سریع‌تر شوند، اما این downside را دارد که تنها یک node fail شده باعث می‌شود که تمام writes database fail شوند.
    </p>
<p>
        ممکن است بیش از n nodes در cluster وجود داشته باشد، اما هر value داده شده
        فقط در n nodes ذخیره می‌شود. این به dataset اجازه می‌دهد تا partitioned شود، که از datasets پشتیبانی می‌کند که بزرگتر از آن چیزی هستند که شما می‌توانید در یک node جا دهید.
    </p>
<p>
        ما در فصل 6 به partitioning باز خواهیم گشت.
    </p>
<p>
        The quorum condition, w + r &gt; n، به سیستم اجازه می‌دهد تا nodes unavailable را به شرح زیر تحمل کند:
    </p>
<ul>
<li>If w &lt; n، ما هنوز می‌توانیم writes را پردازش کنیم اگر یک node در دسترس نباشد.</li>
<li>If r &lt; n، ما هنوز می‌توانیم reads را پردازش کنیم اگر یک node در دسترس نباشد.</li>
<li>With n = 3, w = 2, r = 2 ما می‌توانیم یک node unavailable را تحمل کنیم.</li>
<li>With n = 5, w = 3, r = 3 ما می‌توانیم دو nodes unavailable را تحمل کنیم. این case در شکل 5-11 نشان داده شده است.</li>
<li>Normally، reads و writes همیشه به همه n replicas به طور موازی ارسال می‌شوند. پارامترهای w و r تعیین می‌کنند که ما منتظر چند node می‌مانیم—یعنی، چند عدد از nodes n باید موفقیت را گزارش دهند قبل از اینکه ما read یا write را موفقیت‌آمیز در نظر بگیریم.</li>
</ul>
<p>
        شکل 5-11. If w + r &gt; n، حداقل یکی از r replicas که شما از آن‌ها می‌خوانید، باید most recent successful write را دیده باشد.
    </p>
<p>
        180 | Chapter 5: Replication
    </p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 202" src="page_0202/image_1.png"/></div>
<div class="page-image"><img alt="Image from page 202" src="page_0202/image_2.png"/></div>
</div>
                <div class="page-number">صفحه 0202</div>
            </div>
        </div>
        <!-- Page 0203 -->
        <div class="chapter" id="page-0203">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        If fewer than the required w or r nodes are available, writes or reads return an error.
    </p>
<p>
        A node could be unavailable for many reasons: because the node is down (crashed, powered down)، به دلیل یک error اجرای operation (نمی‌تواند بنویسد زیرا دیسک پر است)، به دلیل یک network interruption بین client و node، یا به هر دلیل دیگری. ما فقط نگران این هستیم که آیا node یک response موفقیت‌آمیز را برگردانده است و نیازی به تمایز بین انواع مختلف fault نداریم.
    </p>
<h4>Limitations of Quorum Consistency</h4>
<p>
        If you have n replicas، و شما w و r را طوری انتخاب کنید که w + r &gt; n، شما به طور کلی انتظار دارید که هر read، recent value نوشته شده برای یک key را برگرداند. این حالت به این دلیل است که مجموعه nodes که شما به آن‌ها نوشته‌اید و مجموعه nodes که شما از آن‌ها خوانده‌اید، باید با هم overlap داشته باشند. یعنی، در میان nodes که شما خواندید باید حداقل یک node با latest value وجود داشته باشد (که در شکل 5-11 نشان داده شده است).
    </p>
<p>
        اغلب، r و w به عنوان یک majority (بیشتر از n/2) از nodes انتخاب می‌شوند، زیرا این اطمینان را می‌دهد که w + r &gt; n در حالی که همچنان تا n/2 node failures را تحمل می‌کند. اما quorums لزوماً majorities نیستند—فقط این مهم است که مجموعه‌های nodes که توسط عمليات read و write استفاده می‌شوند، حداقل در یک node با هم overlap داشته باشند. Other quorum assignments ممکن است، که اجازه انعطاف‌پذیری در طراحی از algorithms distributed را می‌دهد [45].
    </p>
<p>
        You may also set w and r to smaller numbers, so that w + r ≤ n (i.e., the quorum con‐dition is not satisfied). In this case, reads and writes will still be sent to n nodes, but a smaller number of successful responses is required for the operation to succeed.
    </p>
<p>
        With a smaller w and r شما به احتمال زیاد values stale را می‌خوانید، زیرا احتمال بیشتری وجود دارد که read شما node را با latest value شامل نشود. در جنبه مثبت، این configuration به latency کمتر و availability بالاتر اجازه می‌دهد: اگر یک network inter‐ruption وجود داشته باشد و بسیاری از replicas غیرقابل دسترس شوند، احتمال بیشتری وجود دارد که شما بتوانید به پردازش reads و writes ادامه دهید.
        Only after the number of reachable replicas falls below w or r does the database become unavailable for writing or reading, respectively.
    </p>
<p>
        با این حال، حتی با w + r &gt; n، احتمالاً موارد لبه وجود دارد که در آن‌ها values stale برگردانده می‌شوند. این‌ها به پیاده‌سازی بستگی دارند، اما سناریوهای ممکن شامل موارد زیر هستند:
    </p>
<ul>
<li>If a sloppy quorum is used (see “Sloppy Quorums and Hinted Handoff” on page 183)، w writes ممکن است در نهایت در nodes مختلفی نسبت به r reads قرار بگیرند، بنابراین دیگر یک overlap تضمین شده بین r nodes و w nodes وجود ندارد [46].</li>
<li>If two writes occur concurrently، مشخص نیست که کدام یک اول رخ داده است. در این مورد، تنها راه‌حل ایمن این است که writes concurrent را merge کنید (به "Handling Write Conflicts" در صفحه 171 مراجعه کنید). اگر یک برنده بر اساس یک timestamp انتخاب شود (last write wins)، writes می‌توانند به دلیل clock skew از بین بروند [35]. ما در این مورد در "Detecting Concurrent Writes" در صفحه 184 باز خواهیم گشت.</li>
</ul>
<p>
        Leaderless Replication | 181
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0203</div>
            </div>
        </div>
        <!-- Page 0204 -->
        <div class="chapter" id="page-0204">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<ul>
<li>If a write happens concurrently with a read، the write may be reflected on only some of the replicas. In this case, it’s undetermined whether the read returns the old or the new value.</li>
<li>If a write succeeded on some replicas but failed on others (for example because the disks on some nodes are full)، and overall succeeded on fewer than w replicas، it is not rolled back on the replicas where it succeeded. This means that if a write was reported as failed, subsequent reads may or may not return the value from that write [47].</li>
<li>If a node carrying a new value fails, and its data is restored from a replica carrying an old value, the number of replicas storing the new value may fall below w, breaking the quorum condition.</li>
<li>Even if everything is working correctly, there are edge cases in which you can get unlucky with the timing, as we shall see in “Linearizability and quorums” on page 334.</li>
</ul>
<p>
        Thus, although quorums appear to guarantee that a read returns the latest written value, in practice it is not so simple. Dynamo-style databases are generally optimized for use cases that can tolerate eventual consistency. The parameters w and r allow you to adjust the probability of stale values being read, but it’s wise to not take them as absolute guarantees.
    </p>
<p>
        In particular, you usually do not get the guarantees discussed in “Problems with Rep‐lication Lag” on page 161 (reading your writes, monotonic reads, or consistent prefix reads)، بنابراین anomalies قبلاً ذکر شده می‌توانند در applications رخ دهند. guarantees قوی‌تر عموماً به transactions یا consensus نیاز دارند. ما در فصل 7 و فصل 9 به این موضوعات باز خواهیم گشت.
    </p>
<h4>Monitoring staleness</h4>
<p>
        از دیدگاه عملیاتی، این مهم است که نظارت کنید که آیا databases شما در حال بازگرداندن نتایج up-to-date هستند یا خیر. حتی اگر application شما بتواند reads stale را تحمل کند، شما نیاز دارید که از سلامت replication خود آگاه باشید. اگر به طور قابل توجهی عقب بیفتد، باید به شما هشدار دهد تا شما بتوانید علت را بررسی کنید (به عنوان مثال، یک مشکل در network یا یک node overloaded).
    </p>
<p>
        For leader-based replication، database معمولاً metrics را برای replication lag نشان می‌دهد، که شما می‌توانید آن را به یک سیستم نظارتی ارسال کنید. این امکان‌پذیر است زیرا writes به leader و به followers به همان ترتیب اعمال می‌شوند و هر node یک position در the replication log (تعداد writes که به صورت محلی اعمال کرده است) دارد. با تفریق current position از یک follower از the leader’s current position، شما می‌توانید مقدار replication lag را اندازه‌گیری کنید.
    </p>
<p>
        با این حال، در systems with leaderless replication، هیچ order ثابتی وجود ندارد که در آن writes اعمال می‌شوند، که نظارت را دشوارتر می‌کند. علاوه بر این، اگر database
    </p>
<p>
        182 | Chapter 5: Replication
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0204</div>
            </div>
        </div>
        <!-- Page 0205 -->
        <div class="chapter" id="page-0205">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        فقط از read repair استفاده می‌کند (نه anti-entropy)، هیچ محدودیتی برای اینکه یک value چقدر می‌تواند قدیمی باشد، وجود ندارد—اگر value فقط به ندرت خوانده شود، value که توسط یک replica stale برگردانده می‌شود، ممکن است قدیمی باشد.
    </p>
<p>
        تحقیقاتی در مورد اندازه‌گیری staleness replica در databases با leaderless replication و پیش‌بینی درصد مورد انتظار از reads stale بسته به پارامترهای n, w و r وجود داشته است [48]. متأسفانه این هنوز یک practice رایج نیست، اما خوب است که اندازه‌گیری‌های staleness را در مجموعه استانداردی از metrics برای databases قرار دهیم. Eventual consistency یک guarantee از پیش تعیین شده است، اما برای operability، مهم است که بتوانیم "eventual" را کمی کنیم.
    </p>
<h4>Sloppy Quorums and Hinted Handoff</h4>
<p>
        Databases با quorums مناسب پیکربندی شده‌اند که می‌توانند failure از individual nodes را بدون نیاز به failover تحمل کنند. آن‌ها همچنین می‌توانند nodes slow مجزا را تحمل کنند، زیرا requests نیازی به انتظار برای پاسخ دادن همه n nodes ندارند—آن‌ها می‌توانند زمانی return شوند که w یا r nodes پاسخ داده‌اند. این ویژگی‌ها، databases با leaderless replication را برای use cases که نیاز به high availability و low latency دارند و می‌توانند reads stale گاه به گاه را تحمل کنند، جذاب می‌کند.
    </p>
<p>
        با این حال، quorums (همانطور که تاکنون توضیح داده شد) به اندازه کافی fault-tolerant نیستند. A network interruption می‌تواند به راحتی یک client را از تعداد زیادی از database nodes قطع کند. اگرچه آن nodes زنده هستند و سایر clients ممکن است بتوانند به آن‌ها متصل شوند، برای یک client که از database nodes قطع شده است، ممکن است آن‌ها نیز مرده باشند.
    </p>
<p>
        در این شرایط، احتمال دارد که تعداد کمتری از w یا r nodes قابل دسترس باقی بمانند، بنابراین client دیگر نمی‌تواند به یک quorum دسترسی پیدا کند.
    </p>
<p>
        در یک cluster بزرگ (با nodes بسیار بیشتر از n) احتمالاً client می‌تواند در طول network interruption به برخی از nodes database متصل شود، فقط نه به nodes که برای جمع‌آوری یک quorum برای یک value خاص نیاز دارد. در این صورت، طراحان database با یک trade-off روبرو هستند:
    </p>
<ul>
<li>آیا بهتر است که errors را به همه requests که ما نمی‌توانیم به یک quorum از w یا r nodes دسترسی داشته باشیم، برگردانیم؟</li>
<li>Or should we accept writes anyway, and write them to some nodes that are reachable but aren’t among the n nodes on which the value usually lives?</li>
</ul>
<p>
        دومی به عنوان a sloppy quorum شناخته می‌شود [37]: writes و reads همچنان به پاسخ‌های w و r موفقیت‌آمیز نیاز دارند، اما ممکن است شامل nodes باشند که در میان nodes n “home” برای یک value تعیین شده نیستند. با تشبیه، اگر شما خودتان را از خانه‌تان قفل کنید، ممکن است به در خانه همسایه بزنید و بپرسید که آیا می‌توانم موقتاً روی کاناپه آن‌ها بمانم.
    </p>
<p>
        هنگامی که network interruption برطرف شد، هر writes که یک node به طور موقت از طرف node دیگری پذیرفته است، به nodes “home” مناسب ارسال می‌شود. این
    </p>
<p>
        Leaderless Replication | 183
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0205</div>
            </div>
        </div>
        <!-- Page 0206 -->
        <div class="chapter" id="page-0206">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        نامیده می‌شود hinted handoff. (هنگامی که دوباره کلیدهای خانه‌تان را پیدا می‌کنید، همسایه‌تان مودبانه از شما می‌خواهد که از کاناپه آن‌ها بلند شوید و به خانه بروید.)
    </p>
<p>
        Sloppy quorums به ویژه برای افزایش write availability مفید هستند: تا زمانی که w nodes در دسترس باشند، database می‌تواند writes را بپذیرد. با این حال، این بدان معناست که حتی when w + r &gt; n، شما نمی‌توانید مطمئن باشید که latest value را برای یک key می‌خوانید، زیرا the latest value ممکن است به طور موقت به برخی از nodes خارج از n نوشته شده باشد [47].
    </p>
<p>
        بنابراین، یک sloppy quorum در واقع یک quorum در sense سنتی نیست. این فقط یک اطمینان از durability است، یعنی اینکه داده‌ها در w nodes در جایی ذخیره شده‌اند.
        هیچ تضمینی وجود ندارد که یک read از r nodes آن را ببیند تا زمانی که hinted handoff کامل شود.
    </p>
<p>
        Sloppy quorums در همه پیاده‌سازی‌های رایج Dynamo اختیاری هستند. در Riak آن‌ها به طور پیش‌فرض فعال هستند و در Cassandra و Voldemort به طور پیش‌فرض غیرفعال هستند [46, 49, 50].
    </p>
<h4>Multi-datacenter operation</h4>
<p>
        ما قبلاً در مورد cross-datacenter replication به عنوان یک use case برای multi-leader replication بحث کردیم ("Multi-Leader Replication" در صفحه 168 را ببینید). Leaderless replication همچنین برای multi-datacenter operation مناسب است، زیرا برای تحمل conflicting concurrent writes، network interruptions و latency spikes طراحی شده است.
    </p>
<p>
        Cassandra و Voldemort از پشتیبانی multi-datacenter خود در داخل the nor‐mal leaderless model استفاده می‌کنند: تعداد replicas n شامل nodes در همه datacenters است و در configuration شما می‌توانید مشخص کنید که چند تا از n replicas را می‌خواهید در هر datacenter داشته باشید. هر write از یک client به همه replicas ارسال می‌شود، صرف نظر از datacenter، اما client معمولاً فقط منتظر acknowledgment از یک quorum از nodes در داخل datacenter محلی خود می‌ماند تا تحت تأثیر delays و interruptions در inter-datacenter link قرار نگیرد. The higher-latency writes به other datacenters اغلب به صورت asynchronous پیکربندی می‌شوند، اگرچه در configuration مقداری انعطاف‌پذیری وجود دارد [50, 51].
    </p>
<p>
        Riak تمام ارتباطات بین clients و database nodes را local به یک data‐center نگه می‌دارد، بنابراین n تعداد replicas را در یک datacenter توصیف می‌کند. Cross-datacenter replication بین database clusters به طور asynchronous در background اتفاق می‌افتد، به سبکی که شبیه به multi-leader replication است [52].
    </p>
<h4>Detecting Concurrent Writes</h4>
<p>
        databases Dynamo-style به چندین client اجازه می‌دهند تا به طور همزمان در یک key یکسان بنویسند، که به این معنی است که conflicts حتی اگر strict quorums استفاده شود نیز رخ خواهد داد. این وضعیت مشابه multi-leader replication است ("Handling Write Conflicts" در صفحه 171 را ببینید)، اگرچه در databases Dynamo-style conflicts می‌توانند در طول read repair یا hinted handoff نیز ایجاد شوند.
    </p>
<p>
        184 | Chapter 5: Replication
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0206</div>
            </div>
        </div>
        <!-- Page 0207 -->
        <div class="chapter" id="page-0207">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        The problem is that events may arrive in a different order at different nodes, due to variable network delays and partial failures. For example, Figure 5-12 shows two cli‐ents, A and B, simultaneously writing to a key X in a three-node datastore:
    </p>
<ul>
<li>Node 1 receives the write from A, but never receives the write from B due to a transient outage.</li>
<li>Node 2 first receives the write from A, then the write from B.</li>
<li>Node 3 first receives the write from B, then the write from A.</li>
</ul>
<p>
        شکل 5-12. Concurrent writes در یک Dynamo-style datastore: هیچ ordering well-defined وجود ندارد.
    </p>
<p>
        اگر هر node به سادگی value را برای یک key overwrote می‌کرد، هر زمان که یک write request از یک client دریافت می‌کرد، nodes به طور دائمی inconsistent می‌شدند، همانطور که توسط the final get request در شکل 5-12 نشان داده شده است: node 2 فکر می‌کند که the final value از X، B است، در حالی که other nodes فکر می‌کنند که value، A است.
    </p>
<p>
        به منظور تبدیل شدن به eventual consistent، replicas باید به سمت same value همگرا شوند. چگونه این کار را انجام می‌دهند؟ ممکن است فرد امیدوار باشد که databases replicated این کار را به طور خودکار انجام دهند، اما متاسفانه اکثر پیاده‌سازی‌ها بسیار ضعیف هستند: اگر شما می‌خواهید از دست دادن data اجتناب کنید، شما—developer application—نیاز دارید که اطلاعات زیادی در مورد internals از conflict handling database خود بدانید.
    </p>
<p>
        ما به طور خلاصه در مورد برخی از تکنیک‌ها برای conflict resolution در "Handling Write Conflicts" در صفحه 171 اشاره کردیم. قبل از اینکه این فصل را جمع‌بندی کنیم، بیایید این issue را با جزئیات بیشتری بررسی کنیم.
    </p>
<p>
        Leaderless Replication | 185
    </p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 207" src="page_0207/image_1.png"/></div>
</div>
                <div class="page-number">صفحه 0207</div>
            </div>
        </div>
        <!-- Page 0208 -->
        <div class="chapter" id="page-0208">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        The first write wins (discarding concurrent writes)
        One approach for achieving eventual convergence این است که اعلام کنیم که هر replica فقط نیاز دارد که most “recent” value را ذخیره کند و به values “older” اجازه داده شود که overwrite و dis‐carded شوند. سپس، تا زمانی که ما به نوعی می‌توانیم به طور unambiguous تعیین کنیم که کدام write more “recent” است و هر write در نهایت به هر replica کپی می‌شود، the repli‐cas در نهایت به same value همگرا خواهند شد.
    </p>
<p>
        As indicated by the quotes around “recent,” این ایده در واقع کاملاً گمراه‌کننده است. در مثال شکل 5-12، هیچ یک از clients در مورد دیگری نمی‌دانستند، هنگامی که request writes خود را به database nodes ارسال می‌کردند، بنابراین مشخص نیست که کدام یک اول رخ داده است. در واقع، این واقعاً منطقی نیست که بگوییم که هر یک "first" رخ داده‌اند: ما می‌گوییم که writes concurrent هستند، بنابراین order آن‌ها تعریف نشده است.
    </p>
<p>
        Even though the writes don’t have a natural ordering، ما می‌توانیم یک order دلخواه را بر روی آن‌ها اعمال کنیم. به عنوان مثال، ما می‌توانیم یک timestamp را به هر write متصل کنیم، بزرگترین timestamp را به عنوان most “recent” انتخاب کنیم و هر writes را با یک timestamp earlier دور بریزیم.
        این الگوریتم conflict resolution، last write wins (LWW) نامیده می‌شود، تنها method conflict resolution است که در Cassandra پشتیبانی می‌شود [53] و یک feature optional در Riak است [35].
    </p>
<p>
        LWW به هدف eventual convergence دست می‌یابد، اما به قیمت durability: اگر چندین concurrent writes به یک key یکسان وجود داشته باشد، حتی اگر همه آن‌ها به client موفقیت‌آمیز گزارش شده باشند (زیرا به w replicas نوشته شده‌اند)، فقط یکی از writes زنده می‌ماند و بقیه به طور silent discarded می‌شوند. علاوه بر این، LWW ممکن است حتی writes که concurrent نیستند را رها کند، همانطور که در "Timestamps for ordering events" در صفحه 291 بحث خواهیم کرد.
    </p>
<p>
        برخی از شرایط، مانند caching، که در آن‌ها writes lost شاید قابل قبول باشند. اگر از دست دادن data قابل قبول نباشد، LWW یک انتخاب ضعیف برای conflict resolution است.
    </p>
<p>
        The only safe way از استفاده از یک database با LWW این است که اطمینان حاصل شود که یک key فقط یک بار نوشته شده است و پس از آن به عنوان immutable رفتار می‌شود، بنابراین از هرگونه updates concurrent به همان key اجتناب می‌شود. به عنوان مثال، یک روش توصیه شده برای استفاده از Cassandra این است که از یک UUID به عنوان key استفاده کنید، بنابراین به هر عملیات write یک key یکتا می‌دهید [53].
    </p>
<h4>The “happens-before” relationship and concurrency</h4>
<p>
        How do we decide whether two operations are concurrent or not? To develop an intuition, let’s look at some examples:
    </p>
<ul>
<li>In Figure 5-9، دو writes concurrent نیستند: insert از A قبل از increment از B اتفاق می‌افتد، زیرا the value که توسط B افزایش یافته است، value است که توسط A درج شده است. به عبارت دیگر، operation از B بر روی operation از A ساخته شده است، بنابراین operation از B باید later اتفاق افتاده باشد. ما همچنین می‌گوییم که B causally dependent بر A است.</li>
</ul>
<p>
        186 | Chapter 5: Replication
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0208</div>
            </div>
        </div>
        <!-- Page 0209 -->
        <div class="chapter" id="page-0209">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<ul>
<li>On the other hand, the two writes in Figure 5-12 are concurrent: when each cli‐ent starts the operation, it does not know that another client is also performing an operation on the same key. Thus, there is no causal dependency between the operations.</li>
</ul>
<p>
        An operation A happens before another operation B if B knows about A, or depends on A, or builds upon A in some way. Whether one operation happens before another operation is the key to defining what concurrency means. In fact, we can simply say that two operations are concurrent if neither happens before the other (i.e., neither knows about the other) [54].
    </p>
<p>
        بنابراین، هر زمان که شما دو operation A و B داشته باشید، سه احتمال وجود دارد: یا A قبل از B اتفاق افتاده است، یا B قبل از A اتفاق افتاده است، یا A و B concurrent هستند. آنچه ما نیاز داریم یک الگوریتم است که به ما بگوید که آیا دو operation concurrent هستند یا خیر. اگر یک operation قبل از دیگری اتفاق افتاده باشد، operation بعدی باید operation قبلی را overwrite کند، اما اگر operations concurrent باشند، ما یک conflict داریم که نیاز به حل شدن دارد.
    </p>
<h4>Concurrency, Time, and Relativity</h4>
<p>
        It may seem that two operations should be called concurrent if they occur “at the same time”—but in fact, it is not important whether they literally overlap in time.
        Because of problems with clocks in distributed systems, it is actually quite difficult to tell whether two things happened at exactly the same time—an issue we will discuss in more detail in Chapter 8.
    </p>
<p>
        For defining concurrency، زمان دقیق مهم نیست: ما به سادگی دو operations را concurrent می‌نامیم اگر هر دو از یکدیگر بی‌خبر باشند، صرف نظر از زمان فیزیکی که در آن رخ داده‌اند. مردم گاهی اوقات یک اتصال بین این اصل و the special theory of relativity در فیزیک ایجاد می‌کنند [54]، که این ایده را مطرح کرد که اطلاعات نمی‌توانند سریع‌تر از سرعت نور سفر کنند. در نتیجه، دو event که در فاصله معینی از هم رخ می‌دهند، اگر زمان بین events کوتاه‌تر از زمانی باشد که نور برای طی کردن فاصله بین آن‌ها طول می‌کشد، احتمالاً نمی‌توانند بر یکدیگر تأثیر بگذارند.
    </p>
<p>
        In computer systems، دو operations ممکن است concurrent باشند، حتی اگر سرعت نور در اصل به یک operation اجازه داده باشد که بر دیگری تأثیر بگذارد. به عنوان مثال، اگر network در آن زمان کند یا مختل بود، دو operations می‌توانند مدتی از هم دورتر رخ دهند و هنوز هم concurrent باشند، زیرا مشکلات network مانع از این شده است که یک operation بتواند در مورد دیگری بداند.
    </p>
<h4>Capturing the happens-before relationship</h4>
<p>
        Let’s look at an algorithm that determines whether two operations are concurrent, or whether one happened before another. To keep things simple, let’s start with a data‐
    </p>
<p>
        Leaderless Replication | 187
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0209</div>
            </div>
        </div>
        <!-- Page 0210 -->
        <div class="chapter" id="page-0210">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        base که تنها یک replica دارد. هنگامی که ما متوجه شدیم که چگونه این کار را در یک replica واحد انجام دهیم، ما می‌توانیم رویکرد را به یک database leaderless با multiple replicas تعمیم دهیم.
    </p>
<p>
        شکل 5-13 نشان می‌دهد که دو client به طور همزمان آیتم‌هایی را به یک shopping cart اضافه می‌کنند. (اگر آن مثال برای شما too inane به نظر می‌رسد، به جای آن تصور کنید که دو کنترل‌کننده ترافیک هوایی به طور همزمان هواپیماهایی را به بخشی که در حال ردیابی آن هستند، اضافه می‌کنند.) در ابتدا، cart خالی است. بین آن‌ها، clients پنج write را به database انجام می‌دهند:
    </p>
<ol>
<li>Client 1، milk را به cart اضافه می‌کند. این اولین write به آن key است، بنابراین server با موفقیت آن را ذخیره می‌کند و version 1 را به آن اختصاص می‌دهد. server همچنین value را به همراه شماره version به client بازمی‌گرداند.</li>
<li>Client 2، eggs را به cart اضافه می‌کند، بدون اینکه بداند که client 1 به طور همزمان milk را اضافه کرده است (client 2 فکر می‌کرد که eggs تنها آیتم در cart است). server، version 2 را به این write اختصاص می‌دهد و eggs و milk را به عنوان دو values جداگانه ذخیره می‌کند. سپس هر دو value را به همراه شماره version 2 به client برمی‌گرداند.</li>
<li>Client 1، که از write از client 2 بی‌خبر است، می‌خواهد flour را به cart اضافه کند، بنابراین فکر می‌کند که محتویات current cart باید [milk, flour] باشد. این value را به همراه شماره version 1 که server قبلاً به client 1 داده بود، به server ارسال می‌کند.
        The server می‌تواند از شماره version تشخیص دهد که write از [milk, flour] value قبلی از [milk] را supersedes می‌کند، اما با [eggs] concurrent است. بنابراین، server version 3 را به [milk, flour] اختصاص می‌دهد، value version 1 از [milk] را overwrite می‌کند، اما value version 2 از [eggs] را نگه می‌دارد و هر دو remaining values را به client برمی‌گرداند.</li>
<li>در همین حال، client 2 می‌خواهد ham را به cart اضافه کند، بدون اینکه بداند client 1 به تازگی flour را اضافه کرده است. Client 2، دو value [milk] و [eggs] را از server در the last response دریافت کرد، بنابراین client اکنون آن values را merge می‌کند و ham را اضافه می‌کند تا یک value جدید، [eggs, milk, ham] را تشکیل دهد. آن value را به همراه شماره version 2 قبلی به server ارسال می‌کند. server تشخیص می‌دهد که version 2، [eggs] را overwrite می‌کند، اما با [milk, flour] concurrent است، بنابراین دو remaining values [milk, flour] با version 3 و [eggs, milk, ham] با version 4 هستند.</li>
<li>در نهایت، client 1 می‌خواهد bacon را اضافه کند. این قبلاً [milk, flour] و [eggs] را از server در version 3 دریافت کرد، بنابراین آن‎ها را merge می‌کند، bacon را اضافه می‌کند و the final value [milk, flour, eggs, bacon] را به server ارسال می‌کند، به همراه شماره version 3. این [milk, flour] را overwrite می‌کند (توجه داشته باشید که [eggs] قبلاً در گام آخر over‐written شده بود) اما با [eggs, milk, ham] concurrent است، بنابراین server آن دو concurrent values را نگه می‌دارد.</li>
</ol>
<p>
        188 | Chapter 5: Replication
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0210</div>
            </div>
        </div>
        <!-- Page 0211 -->
        <div class="chapter" id="page-0211">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        شکل 5-13. Capturing causal dependencies بین دو client که به طور همزمان در حال ویرایش a shopping cart هستند.
    </p>
<p>
        The dataflow بین operations در شکل 5-13 به صورت گرافیکی در شکل 5-14 نشان داده شده است. The arrows نشان می‌دهند که کدام operation قبل از کدام operation دیگر اتفاق افتاده است، به این معنی که operation بعدی در مورد operation قبلی اطلاع داشته است یا به آن وابسته بوده است یا به نوعی بر روی آن ساخته شده است.
        در این مثال، clients هرگز به طور کامل با داده‌ها در server up to date نیستند، زیرا همیشه یک operation دیگر به طور همزمان در حال انجام است. اما نسخه‌های قدیمی از value در نهایت overwrite می‌شوند و هیچ write از دست نمی‌رود.
    </p>
<p>
        شکل 5-14. Graph of causal dependencies در شکل 5-13.
    </p>
<p>
        Note that the server can determine whether two operations are concurrent by looking at the version numbers—it does not need to interpret the value itself (so the value could be any data structure). The algorithm works as follows:
    </p>
<p>
        Leaderless Replication | 189
    </p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 211" src="page_0211/image_1.png"/></div>
<div class="page-image"><img alt="Image from page 211" src="page_0211/image_2.png"/></div>
</div>
                <div class="page-number">صفحه 0211</div>
            </div>
        </div>
        <!-- Page 0212 -->
        <div class="chapter" id="page-0212">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<ul>
<li>The server maintains a version number for every key, increments the version number every time that key is written, and stores the new version number along with the value written.</li>
<li>When a client reads a key, the server returns all values that have not been over‐written, as well as the latest version number. A client must read a key before writing.</li>
<li>When a client writes a key, it must include the version number from the prior read, and it must merge together all values that it received in the prior read. (The response from a write request can be like a read, returning all current values, which allows us to chain several writes like in the shopping cart example.)</li>
<li>When the server receives a write with a particular version number, it can over‐write all values with that version number or below (since it knows that they have been merged into the new value), but it must keep all values with a higher ver‐sion number (because those values are concurrent with the incoming write).</li>
</ul>
<p>
        When a write includes the version number from a prior read, that tells us which pre‐vious state the write is based on. اگر شما یک write را بدون شامل کردن یک شماره version انجام دهید، آن با همه other writes concurrent است، بنابراین چیزی را overwrite نخواهد کرد—آن فقط به عنوان یکی از values در reads بعدی برگردانده می‌شود.
    </p>
<h4>Merging concurrently written values</h4>
<p>
        این الگوریتم تضمین می‌کند که هیچ data به طور silent رها نمی‌شود، اما متأسفانه نیاز دارد که clients مقداری کار اضافی انجام دهند: اگر چندین operations به طور concurrent اتفاق بیفتند، clients باید بعداً با merging the concurrently written values، cleanup کنند. Riak این values concurrent را siblings می‌نامد.
    </p>
<p>
        Merging sibling values اساساً همان مشکل conflict resolution در multi-leader replication است که ما قبلاً در مورد آن بحث کردیم ("Handling Write Conflicts" در صفحه 171 را ببینید). یک رویکرد ساده این است که فقط یکی از values را بر اساس یک شماره version یا timestamp (last write wins) انتخاب کنید، اما این بدان معناست که data از دست می‌رود. بنابراین، شما ممکن است نیاز داشته باشید که کاری هوشمندانه‌تر در application code انجام دهید.
    </p>
<p>
        با مثال یک shopping cart، یک رویکرد منطقی برای merging siblings این است که فقط union را بگیرید. در شکل 5-14، دو siblings نهایی [milk, flour, eggs, bacon] و [eggs, milk, ham] هستند. توجه داشته باشید که milk و eggs در هر دو ظاهر می‌شوند، حتی اگر هر کدام فقط یک بار نوشته شده باشند. The merged value ممکن است چیزی شبیه [milk, flour, eggs, bacon, ham] باشد، بدون duplicates.
    </p>
<p>
        با این حال، اگر شما می‌خواهید به افراد اجازه دهید که همچنین چیزهایی را از carts خود حذف کنند، و نه فقط چیزهایی را اضافه کنند، سپس گرفتن union از siblings ممکن است نتیجه درستی را به دست ندهد: اگر شما دو cart sibling را merge کنید و یک آیتم فقط در یکی از آن‌ها حذف شده باشد، سپس آیتم حذف شده دوباره در union از the siblings ظاهر می‌شود [37]. برای جلوگیری از این prob‐
    </p>
<p>
        190 | Chapter 5: Replication
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0212</div>
            </div>
        </div>
        <!-- Page 0213 -->
        <div class="chapter" id="page-0213">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        lem، یک آیتم را نمی‌توان به سادگی از database حذف کرد، زمانی که آن حذف می‌شود؛ در عوض، سیستم باید یک marker را با یک شماره version مناسب باقی بگذارد تا نشان دهد که آیتم حذف شده است، هنگام merging siblings. چنین deletion marker به عنوان یک tombstone شناخته می‌شود. (ما قبلاً tombstones را در context از log compaction در "Hash Indexes" در صفحه 72 مشاهده کردیم.)
    </p>
<p>
        از آنجایی که merging siblings در application code پیچیده و مستعد خطا است، برخی تلاش‌ها برای طراحی data structures وجود دارد که می‌تواند این merging را به طور خودکار انجام دهد، همانطور که در "Automatic Conflict Resolution" در صفحه 174 بحث شد. به عنوان مثال، پشتیبانی datatype از Riak از یک family از data structures به نام CRDTs [38, 39, 55] استفاده می‌کند که می‌تواند به طور خودکار siblings را به روش‌های معقول merge کند، از جمله preservation deletions.
    </p>
<h4>Version vectors</h4>
<p>
        The example in Figure 5-13 فقط از یک replica واحد استفاده می‌کرد. چگونه الگوریتم تغییر می‌کند، زمانی که multiple replicas وجود دارد، اما هیچ leader وجود ندارد؟
    </p>
<p>
        شکل 5-13 از یک شماره version واحد برای گرفتن dependencies بین opera‐tions استفاده می‌کرد، اما این برای زمانیکه multiple replicas به طور همزمان writes را می‌پذیرند، کافی نیست. در عوض، ما نیاز داریم که از یک شماره version per replica و همچنین per key استفاده کنیم.
    </p>
<p>
        هر replica شماره version خود را هنگام پردازش یک write افزایش می‌دهد و همچنین شماره‌های version را که از هر یک از other replicas دیده‌ است، پیگیری می‌کند. این اطلاعات نشان می‌دهد که کدام values را overwrite و کدام values را به عنوان siblings حفظ کنیم.
        مجموعه شماره‌های version از همه replicas، یک version vector [56] نامیده می‌شود.
    </p>
<p>
        چندین variant از این ایده در حال استفاده است، اما جالب‌ترین آن احتمالاً dotted version vector [57] است که در Riak 2.0 استفاده می‌شود [58, 59]. ما به جزئیات آن نخواهیم پرداخت، اما روش کار آن کاملاً شبیه به چیزی است که ما در مثال cart خود دیدیم.
    </p>
<p>
        Like the version numbers in Figure 5-13, version vectors از database replicas به clients هنگامی که values خوانده می‌شوند، ارسال می‌شوند، و نیاز به بازگشت به database دارند هنگامی که یک value متعاقباً نوشته می‌شود. (Riak version vector را به عنوان یک string که آن را causal context می‌نامد، رمزگذاری می‌کند.) The version vector به database اجازه می‌دهد که بین overwrites و concurrent writes تمایز قائل شود.
    </p>
<p>
        همچنین، همانند مثال single-replica، application ممکن است نیاز به merge siblings داشته باشد.
        The version vector structure اطمینان می‌دهد که خواندن از یک replica و متعاقباً نوشتن به replica دیگر، ایمن است. انجام این کار ممکن است منجر به ایجاد siblings شود، اما تا زمانی که siblings به درستی merge شوند، هیچ داده‌ای از دست نمی‌رود.
    </p>
<h4>Version vectors and vector clocks</h4>
<p>
        A version vector is sometimes also called a vector clock, even though they are not quite the same. The difference is subtle—please see the references for details [57, 60, 61]. In brief, when comparing the state of replicas, version vectors are the right data structure to use.
    </p>
<p>
        Leaderless Replication | 191
    </p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 213" src="page_0213/image_1.png"/></div>
</div>
                <div class="page-number">صفحه 0213</div>
            </div>
        </div>
        <!-- Page 0214 -->
        <div class="chapter" id="page-0214">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<h4>Summary</h4>
<p>
        در این فصل ما به issue از replication نگاه کردیم. Replication می‌تواند چندین هدف را دنبال کند:
    </p>
<ul>
<li>High availability</li>
<li>نگه‌داشتن سیستم در حال اجرا، حتی زمانی که یک machine (یا چندین machines، یا یک datacenter کامل) از کار بیفتد</li>
<li>Disconnected operation</li>
<li>اجازه دادن به یک application برای ادامه کار، زمانی که یک network interrup‐tion وجود دارد</li>
<li>Latency</li>
<li>قرار دادن داده‌ها از نظر جغرافیایی نزدیک به users، به طوری که users می‌توانند با آن سریعتر تعامل داشته باشند</li>
<li>Scalability</li>
<li>توانایی مدیریت حجم بالاتری از reads که یک machine واحد می‌تواند manage کند، با انجام reads روی replicas</li>
</ul>
<p>
        با وجود اینکه یک هدف ساده است—نگه‌داشتن یک کپی از داده‌های یکسان در چندین machine—replication به طور قابل توجهی یک مشکل دشوار است. این امر نیاز به تفکر دقیق در مورد concurrency و در مورد همه چیزهایی دارد که می‌توانند اشتباه پیش بروند و رسیدگی به عواقب آن faults. در حداقل، ما نیاز داریم که با nodes unavailable و network interruptions مقابله کنیم (و این حتی در نظر گرفتن انواع insidious بیشتری از fault، مانند silent data corruption به دلیل software bugs، نیست).
    </p>
<p>
        ما در مورد سه رویکرد اصلی به replication بحث کردیم:
    </p>
<ul>
<li>Single-leader replication</li>
<li>Clients تمام writes را به یک node واحد (leader) ارسال می‌کنند، که یک stream از data change events را به other replicas (followers) ارسال می‌کند. Reads را می‌توان در هر replica انجام داد، اما reads از followers ممکن است stale باشند.</li>
<li>Multi-leader replication</li>
<li>Clients هر write را به یکی از چندین leader nodes ارسال می‌کنند، که هر کدام می‌توانند writes را بپذیرند. The leaders streams از data change events را به یکدیگر و به هر node follower ارسال می‌کنند.</li>
<li>Leaderless replication</li>
<li>Clients هر write را به چندین node ارسال می‌کنند و از چندین nodes به طور موازی می‌خوانند تا nodes را با داده‌های stale شناسایی و اصلاح کنند.</li>
</ul>
<p>
        هر رویکرد مزایا و معایب خود را دارد. Single-leader replication محبوب است زیرا درک آن نسبتاً آسان است و هیچ conflict resolution برای نگرانی وجود ندارد. Multi-leader و leaderless replication می‌توانند در حضور
    </p>
<p>
        192 | Chapter 5: Replication
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0214</div>
            </div>
        </div>
        <!-- Page 0215 -->
        <div class="chapter" id="page-0215">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        nodes faulty، network interruptions و latency spikes—به قیمت سخت‌تر شدن برای استدلال در مورد آن و ارائه guarantees بسیار ضعیف consistency.
    </p>
<p>
        Replication می‌تواند synchronous یا asynchronous باشد، که یک تأثیر عمیق بر رفتار سیستم هنگام وجود یک fault دارد. اگرچه replication asynchronous می‌تواند سریع باشد، هنگامی که سیستم به خوبی در حال اجرا است، مهم است که بفهمیم چه اتفاقی می‌افتد when replication lag افزایش می‌یابد و servers fail می‌شوند. اگر یک leader fail شود و شما یک follower که به صورت asynchronous به‌روزرسانی شده است را به عنوان leader جدید ارتقا دهید، data که اخیراً committed شده است، ممکن است از دست برود.
    </p>
<p>
        ما به برخی از اثرات عجیبی نگاه کردیم که می‌تواند ناشی از replication lag باشد، و ما در مورد چند consistency models بحث کردیم که برای تصمیم‌گیری در مورد چگونگی رفتار یک application در زیر replication lag مفید هستند:
    </p>
<ul>
<li>Read-after-write consistency</li>
<li>Users همیشه باید داده‌هایی را که خودشان submit کرده‌اند، ببینند.</li>
<li>Monotonic reads</li>
<li>After users have seen the data at one point in time, they shouldn’t later see the data from some earlier point in time.</li>
<li>Consistent prefix reads</li>
<li>Users باید داده‌ها را در یک state ببینند که causal sense ایجاد می‌کند: به عنوان مثال، دیدن یک question و پاسخ آن به ترتیب صحیح.</li>
</ul>
<p>
        در نهایت، ما در مورد issues concurrency که در رویکردهای multi-leader و leaderless replication ذاتی هستند، بحث کردیم: زیرا آن‌ها به چندین writes اجازه می‌دهند تا به طور همزمان اتفاق بیفتند، conflicts ممکن است رخ دهد. ما یک الگوریتم را بررسی کردیم که یک database ممکن است برای تعیین اینکه آیا یک operation قبل از دیگری اتفاق افتاده است یا خیر، یا اینکه آیا به طور همزمان اتفاق افتاده‌اند، استفاده کند. ما همچنین به روش‌هایی برای حل conflicts با merging updates concurrent با هم اشاره کردیم.
    </p>
<p>
        در فصل بعد ما به ادامه نگاه به data که در سراسر multiple machines توزیع شده است، از طریق counterpart از replication: splitting یک dataset بزرگ به partitions، خواهیم پرداخت.
    </p>
<h4>References</h4>
<p>
        [1] Bruce G. Lindsay, Patricia Griffiths Selinger, C. Galtieri, et al.: “Notes on Distributed Databases,” IBM Research, Research Report RJ2571(33471), July 1979.
    </p>
<p>
        [2] “Oracle Active Data Guard Real-Time Data Protection and Availability,” Oracle White Paper, June 2013.
    </p>
<p>
        [3] “AlwaysOn Availability Groups,” in SQL Server Books Online, Microsoft, 2012.
    </p>
<p>
        Summary | 193
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0215</div>
            </div>
        </div>
        <!-- Page 0216 -->
        <div class="chapter" id="page-0216">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        [4] Lin Qiao, Kapil Surlaker, Shirshanka Das, et al.: “On Brewing Fresh Espresso: LinkedIn’s Distributed Data Serving Platform,” at ACM International Conference on Management of Data (SIGMOD), June 2013.
    </p>
<p>
        [5] Jun Rao: “Intra-Cluster Replication for Apache Kafka,” at ApacheCon North America, February 2013.
    </p>
<p>
        [6] “Highly Available Queues,” in RabbitMQ Server Documentation, Pivotal Software, Inc., 2014.
    </p>
<p>
        [7] Yoshinori Matsunobu: “Semi-Synchronous Replication at Facebook,” yoshinorimatsunobu.blogspot.co.uk, April 1, 2014.
    </p>
<p>
        [8] Robbert van Renesse and Fred B. Schneider: “Chain Replication for Supporting High Throughput and Availability,” at 6th USENIX Symposium on Operating System Design and Implementation (OSDI), December 2004.
    </p>
<p>
        [9] Jeff Terrace and Michael J. Freedman: “Object Storage on CRAQ: High-Throughput Chain Replication for Read-Mostly Workloads,” at USENIX Annual Technical Conference (ATC), June 2009.
    </p>
<p>
        [10] Brad Calder, Ju Wang, Aaron Ogus, et al.: “Windows Azure Storage: A Highly Available Cloud Storage Service with Strong Consistency,” at 23rd ACM Symposium on Operating Systems Principles (SOSP), October 2011.
    </p>
<p>
        [11] Andrew Wang: “Windows Azure Storage,” umbrant.com, February 4, 2016.
    </p>
<p>
        [12] “Percona Xtrabackup - Documentation,” Percona LLC, 2014.
    </p>
<p>
        [13] Jesse Newland: “GitHub Availability This Week,” github.com, September 14, 2012.
    </p>
<p>
        [14] Mark Imbriaco: “Downtime Last Saturday,” github.com, December 26, 2012.
    </p>
<p>
        [15] John Hugg: “‘All in’ with Determinism for Performance and Testing in Distributed Systems,” at Strange Loop, September 2015.
    </p>
<p>
        [16] Amit Kapila: “WAL Internals of PostgreSQL,” at PostgreSQL Conference (PGCon), May 2012.
    </p>
<p>
        [17] MySQL Internals Manual. Oracle, 2014.
    </p>
<p>
        [18] Yogeshwer Sharma, Philippe Ajoux, Petchean Ang, et al.: “Wormhole: Reliable Pub-Sub to Support Geo-Replicated Internet Services,” at 12th USENIX Symposium on Networked Systems Design and Implementation (NSDI), May 2015.
    </p>
<p>
        [19] “Oracle GoldenGate 12c: Real-Time Access to Real-Time Information,” Oracle White Paper, October 2013.
    </p>
<p>
        [20] Shirshanka Das, Chavdar Botev, Kapil Surlaker, et al.: “All Aboard the Databus!,” at ACM Symposium on Cloud Computing (SoCC), October 2012.
    </p>
<p>
        194 | Chapter 5: Replication
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0216</div>
            </div>
        </div>
        <!-- Page 0217 -->
        <div class="chapter" id="page-0217">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        [21] Greg Sabino Mullane: “Version 5 of Bucardo Database Replication System,” blog.endpoint.com, June 23, 2014.
    </p>
<p>
        [22] Werner Vogels: “Eventually Consistent,” ACM Queue, volume 6, number 6, pages 14–19, October 2008. doi:10.1145/1466443.1466448
    </p>
<p>
        [23] Douglas B. Terry: “Replicated Data Consistency Explained Through Baseball,” Microsoft Research, Technical Report MSR-TR-2011-137, October 2011.
    </p>
<p>
        [24] Douglas B. Terry, Alan J. Demers, Karin Petersen, et al.: “Session Guarantees for Weakly Consistent Replicated Data,” at 3rd International Conference on Parallel and Distributed Information Systems (PDIS), September 1994. doi:10.1109/PDIS. 1994.331722
    </p>
<p>
        [25] Terry Pratchett: Reaper Man: A Discworld Novel. Victor Gollancz, 1991. ISBN: 978-0-575-04979-6
    </p>
<p>
        [26] “Tungsten Replicator,” Continuent, Inc., 2014.
    </p>
<p>
        [27] “BDR 0.10.0 Documentation,” The PostgreSQL Global Development Group, bdr-project.org, 2015.
    </p>
<p>
        [28] Robert Hodges: “If You *Must* Deploy Multi-Master Replication, Read This First,” scale-out-blog.blogspot.co.uk, March 30, 2012.
    </p>
<p>
        [29] J. Chris Anderson, Jan Lehnardt, and Noah Slater: CouchDB: The Definitive Guide. O’Reilly Media, 2010. ISBN: 978-0-596-15589-6
    </p>
<p>
        [30] AppJet, Inc.: “Etherpad and EasySync Technical Manual,” github.com, March 26, 2011.
    </p>
<p>
        [31] John Day-Richter: “What’s Different About the New Google Docs: Making Collaboration Fast,” googledrive.blogspot.com, 23 September 2010.
    </p>
<p>
        [32] Martin Kleppmann and Alastair R. Beresford: “A Conflict-Free Replicated JSON Datatype,” arXiv:1608.03960, August 13, 2016.
    </p>
<p>
        [33] Frazer Clement: “Eventual Consistency – Detecting Conflicts,” messagepassing.blogspot.co.uk, October 20, 2011.
    </p>
<p>
        [34] Robert Hodges: “State of the Art for MySQL Multi-Master Replication,” at Percona Live: MySQL Conference &amp; Expo, April 2013.
    </p>
<p>
        [35] John Daily: “Clocks Are Bad, or, Welcome to the Wonderful World of Distributed Systems,” basho.com, November 12, 2013.
    </p>
<p>
        [36] Riley Berton: “Is Bi-Directional Replication (BDR) in Postgres Transactional?,” sdf.org, January 4, 2016.
    </p>
<p>
        Summary | 193
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0217</div>
            </div>
        </div>
        <!-- Page 0218 -->
        <div class="chapter" id="page-0218">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        [37] Giuseppe DeCandia, Deniz Hastorun, Madan Jampani, et al.: “Dynamo: Amazon’s Highly Available Key-Value Store,” at 21st ACM Symposium on Operating Systems Principles (SOSP), October 2007.
    </p>
<p>
        [38] Marc Shapiro, Nuno Preguiça, Carlos Baquero, and Marek Zawirski: “A Comprehensive Study of Convergent and Commutative Replicated Data Types,” INRIA Research Report no. 7506, January 2011.
    </p>
<p>
        [39] Sam Elliott: “CRDTs: An UPDATE (or Maybe Just a PUT),” at RICON West, October 2013.
    </p>
<p>
        [40] Russell Brown: “A Bluffers Guide to CRDTs in Riak,” gist.github.com, October 28, 2013.
    </p>
<p>
        [41] Benjamin Farinier, Thomas Gazagnaire, and Anil Madhavapeddy: “Mergeable Persistent Data Structures,” at 26es Journées Francophones des Langages Applicatifs (JFLA), January 2015.
    </p>
<p>
        [42] Chengzheng Sun and Clarence Ellis: “Operational Transformation in Real-Time Group Editors: Issues, Algorithms, and Achievements,” at ACM Conference on Com‐puter Supported Cooperative Work (CSCW), November 1998.
    </p>
<p>
        [43] Lars Hofhansl: “HBASE-7709: Infinite Loop Possible in Master/Master Replication,” issues.apache.org, January 29, 2013.
    </p>
<p>
        [44] David K. Gifford: “Weighted Voting for Replicated Data,” at 7th ACM Sympo‐sium on Operating Systems Principles (SOSP), December 1979. doi: 10.1145/800215.806583
    </p>
<p>
        [45] Heidi Howard, Dahlia Malkhi, and Alexander Spiegelman: “Flexible Paxos: Quorum Intersection Revisited,” arXiv:1608.06696, August 24, 2016.
    </p>
<p>
        [46] Joseph Blomstedt: “Re: Absolute Consistency,” email to riak-users mailing list, lists.basho.com, January 11, 2012.
    </p>
<p>
        [47] Joseph Blomstedt: “Bringing Consistency to Riak,” at RICON West, October 2012.
    </p>
<p>
        [48] Peter Bailis, Shivaram Venkataraman, Michael J. Franklin, et al.: “Quantifying Eventual Consistency with PBS,” Communications of the ACM, volume 57, number 8, pages 93–102, August 2014. doi:10.1145/2632792
    </p>
<p>
        [49] Jonathan Ellis: “Modern Hinted Handoff,” datastax.com, December 11, 2012.
    </p>
<p>
        [50] “Project Voldemort Wiki,” github.com, 2013.
    </p>
<p>
        [51] “Apache Cassandra 2.0 Documentation,” DataStax, Inc., 2014.
    </p>
<p>
        [52] “Riak Enterprise: Multi-Datacenter Replication.” Technical whitepaper, Basho Technologies, Inc., September 2014.
    </p>
<p>
        196 | Chapter 5: Replication
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0218</div>
            </div>
        </div>
        <!-- Page 0219 -->
        <div class="chapter" id="page-0219">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        [53] Jonathan Ellis: “Why Cassandra Doesn’t Need Vector Clocks,” datastax.com, September 2, 2013.
    </p>
<p>
        [54] Leslie Lamport: “Time, Clocks, and the Ordering of Events in a Distributed Sys‐tem,” Communications of the ACM, volume 21, number 7, pages 558–565, July 1978. doi:10.1145/359545.359563
    </p>
<p>
        [55] Joel Jacobson: “Riak 2.0: Data Types,” blog.joeljacobson.com, March 23, 2014.
    </p>
<p>
        [56] D. Stott Parker Jr., Gerald J. Popek, Gerard Rudisin, et al.: “Detection of Mutual Inconsistency in Distributed Systems,” IEEE Transactions on Software Engineering, volume 9, number 3, pages 240–247, May 1983. doi:10.1109/TSE.1983.236733
    </p>
<p>
        [57] Nuno Preguiça, Carlos Baquero, Paulo Sérgio Almeida, et al.: “Dotted Version Vectors: Logical Clocks for Optimistic Replication,” arXiv:1011.5808, November 26, 2010.
    </p>
<p>
        [58] Sean Cribbs: “A Brief History of Time in Riak,” at RICON, October 2014.
    </p>
<p>
        [59] Russell Brown: “Vector Clocks Revisited Part 2: Dotted Version Vectors,” basho.com, November 10, 2015.
    </p>
<p>
        [60] Carlos Baquero: “Version Vectors Are Not Vector Clocks,” haslab.wordpress.com, July 8, 2011.
    </p>
<p>
        [61] Reinhard Schwarz and Friedemann Mattern: “Detecting Causal Relationships in Distributed Computations: In Search of the Holy Grail,” Distributed Computing, volume 7, number 3, pages 149–174, March 1994. doi:10.1007/BF02277859
    </p>
<p>
        Summary | 197
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0219</div>
            </div>
        </div>
        <!-- Page 0221 -->
        <div class="chapter" id="page-0221">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        i. Partitioning، همانطور که در این فصل مورد بحث قرار می‌گیرد، یک راه برای عمداً شکستن یک database بزرگ به databases کوچکتر است. این هیچ ارتباطی با network partitions (netsplits)، یک نوع fault در network بین nodes ندارد. ما در مورد چنین faults در فصل 8 بحث خواهیم کرد.
    </p>
<h3>فصل 6</h3>
<h4>Partitioning</h4>
<p>
        Clearly, we must break away from the sequential and not limit the computers. We must state definitions and provide for priorities and descriptions of data. We must state relation‐ships, not procedures.
        —Grace Murray Hopper, Management and the Computer of the Future (1962)
    </p>
<p>
        در فصل 5 ما در مورد replication بحث کردیم—یعنی، داشتن multiple copies از همان data در nodes مختلف. برای datasets بسیار بزرگ، یا very high query throughput، این کافی نیست: ما نیاز داریم تا data را به partitions، که همچنین به عنوان sharding شناخته می‌شوند، تقسیم کنیم.i
    </p>
<p>
        Terminological confusion
        آنچه ما در اینجا یک partition می‌نامیم، در MongoDB, Elas‐ticsearch و SolrCloud a shard نامیده می‌شود. در HBase یک region، در Bigtable یک tablet، در Cassandra و Riak یک vnode، و در Couchbase یک vBucket نامیده می‌شود. با این حال، partitioning رایج‌ترین اصطلاح است، بنابراین ما به آن پایبند خواهیم بود.
    </p>
<p>
        به طور معمول، partitions به گونه‌ای تعریف می‌شوند که هر قطعه از data (هر record، row یا document) دقیقاً به یک partition تعلق داشته باشد. راه‌های مختلفی برای دستیابی به این امر وجود دارد، که ما در این فصل به طور مفصل در مورد آن‌ها بحث می‌کنیم. در واقع، هر partition یک database کوچک از خودش است، اگرچه database ممکن است از operations پشتیبانی کند که به طور همزمان چندین partition را لمس می‌کند.
    </p>
<p>
        دلیل اصلی برای تمایل به partition data، scalability است. Partitions مختلف را می‌توان بر روی nodes مختلف در یک shared-nothing cluster قرار داد (به مقدمه
    </p>
<p>
        199
    </p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 221" src="page_0221/image_1.png"/></div>
</div>
                <div class="page-number">صفحه 0221</div>
            </div>
        </div>
        <!-- Page 0222 -->
        <div class="chapter" id="page-0222">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        (به قسمت II برای تعریف shared nothing مراجعه کنید). بنابراین، یک dataset بزرگ را می‌توان در سراسر بسیاری از دیسک‌ها توزیع کرد و بار query را می‌توان در سراسر many processors توزیع کرد.
    </p>
<p>
        For queries که روی یک partition واحد عمل می‌کنند، هر node می‌تواند به طور مستقل queries را برای partition خود اجرا کند، بنابراین throughput query را می‌توان با افزودن nodes بیشتر scale کرد. Queries بزرگ و پیچیده به طور بالقوه می‌توانند در سراسر many nodes parallelized شوند، اگرچه این کار به طور قابل توجهی دشوارتر می‌شود.
    </p>
<p>
        Partitioned databases در دهه 1980 توسط محصولاتی مانند Teradata و Tandem NonStop SQL [1] پیشگام شدند و اخیراً توسط databases NoSQL و data warehouses مبتنی بر Hadoop دوباره کشف شدند. برخی از سیستم‌ها برای workloads transactional و برخی دیگر برای analytics طراحی شده‌اند ("Transaction Processing or Analytics?" در صفحه 90 را ببینید): این تفاوت بر نحوه تنظیم سیستم تأثیر می‌گذارد، اما اصول اساسی partitioning برای هر دو نوع workloads اعمال می‌شود.
    </p>
<p>
        در این فصل ما ابتدا به رویکردهای مختلف برای partitioning large datasets نگاه خواهیم کرد و مشاهده خواهیم کرد که چگونه indexing of data با partitioning تعامل دارد. سپس در مورد rebalancing صحبت خواهیم کرد، که در صورتی که شما می‌خواهید nodes را در cluster خود اضافه یا حذف کنید، ضروری است. در نهایت، ما یک overview از چگونگی هدایت requests توسط databases به partitions مناسب و اجرای queries دریافت خواهیم کرد.
    </p>
<h4>Partitioning and Replication</h4>
<p>
        Partitioning معمولاً با replication ترکیب می‌شود تا کپی‌هایی از هر partition در multiple nodes ذخیره شوند. این بدان معناست که، حتی اگر هر record دقیقاً به یک partition تعلق داشته باشد، ممکن است هنوز هم در چندین node مختلف برای fault toler‐ance ذخیره شود.
    </p>
<p>
        یک node ممکن است بیش از یک partition را ذخیره کند. اگر یک leader–follower replication model استفاده شود، ترکیب partitioning و replication می‌تواند شبیه به شکل 6-1 باشد. The leader از هر partition به یک node اختصاص داده می‌شود و followers آن به other nodes اختصاص داده می‌شوند. هر node ممکن است leader برای برخی از partitions و یک follower برای other par‐titions باشد.
    </p>
<p>
        Everything که ما در فصل 5 در مورد replication از databases بحث کردیم، به طور مساوی در مورد replication of partitions اعمال می‌شود. انتخاب partitioning scheme عمدتاً مستقل از انتخاب replication scheme است، بنابراین ما در این فصل موضوع replication را ساده در نظر می‌گیریم و نادیده می‌گیریم.
    </p>
<p>
        200 | Chapter 6: Partitioning
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0222</div>
            </div>
        </div>
        <!-- Page 0223 -->
        <div class="chapter" id="page-0223">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        شکل 6-1. Combining replication و partitioning: هر node به عنوان leader برای برخی از partitions و follower برای other partitions عمل می‌کند.
    </p>
<h4>Partitioning of Key-Value Data</h4>
<p>
        فرض کنید شما مقدار زیادی داده دارید و می‌خواهید آن را partition کنید. چگونه تصمیم می‌گیرید که کدام records را در کدام nodes ذخیره کنید؟
    </p>
<p>
        هدف ما از partitioning این است که data و query load را به طور مساوی در سراسر nodes پخش کنیم. اگر هر node یک سهم منصفانه بگیرد، سپس—در تئوری—10 nodes باید بتوانند 10 برابر data و 10 برابر throughput read و write از یک node واحد را مدیریت کنند (در حال حاضر replication را نادیده می‌گیریم).
    </p>
<p>
        اگر partitioning ناعادلانه باشد، به طوری که برخی از partitions داده‌ها یا queries بیشتری نسبت به دیگران داشته باشند، ما آن را skewed می‌نامیم. وجود skew باعث می‌شود که partitioning بسیار کم اثر داشته باشد.
    </p>
<p>
        در یک مورد شدید، تمام load می‌تواند در یک partition به پایان برسد، بنابراین 9 node از 10 node بیکار هستند و bottleneck شما، node busy واحد است. یک partition با load disproportion‐ately بالا، a hot spot نامیده می‌شود.
    </p>
<p>
        The simplest approach برای اجتناب از hot spots این است که records را به طور تصادفی به nodes اختصاص دهید. این data را به طور مساوی در سراسر nodes توزیع می‌کند، اما یک disadvantage بزرگ دارد: هنگامی که شما در حال تلاش برای خواندن یک item خاص هستید، شما هیچ راهی برای دانستن اینکه آن در کدام node قرار دارد، ندارید، بنابراین شما باید همه nodes را به طور موازی query کنید.
    </p>
<p>
        ما می‌توانیم بهتر عمل کنیم. بیایید در حال حاضر فرض کنیم که شما یک key-value data model ساده دارید، که در آن شما همیشه به یک record با primary key آن دسترسی دارید. به عنوان مثال، در یک دایره‌المعارف کاغذی قدیمی، شما یک ورودی را با title آن جستجو می‌کنید. از آنجایی که تمام ورودی‌ها به ترتیب حروف الفبا بر اساس title مرتب شده‌اند، شما می‌توانید به سرعت موردی را که به دنبال آن هستید، پیدا کنید.
    </p>
<p>
        Partitioning of Key-Value Data | 201
    </p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 223" src="page_0223/image_1.png"/></div>
</div>
                <div class="page-number">صفحه 0223</div>
            </div>
        </div>
        <!-- Page 0224 -->
        <div class="chapter" id="page-0224">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<h4>Partitioning by Key Range</h4>
<p>
        One way of partitioning این است که یک range پیوسته از keys (از برخی mini‐mum تا برخی maximum) را به هر partition اختصاص دهید، مانند volume از یک paper encyclopedia (شکل 6-2). اگر شما مرزها را بین ranges می‌دانید، شما می‌توانید به راحتی تعیین کنید که کدام partition حاوی یک key داده شده است. اگر شما همچنین می‌دانید که کدام partition به کدام node اختصاص داده شده است، پس شما می‌توانید request خود را مستقیماً به node مناسب (یا، در مورد encyclopedia، کتاب صحیح را از قفسه بردارید) ارسال کنید.
    </p>
<p>
        شکل 6-2. A print encyclopedia توسط key range partition شده است.
    </p>
<p>
        The ranges از keys لزوماً به طور مساوی فاصله‌گذاری نشده‌اند، زیرا data شما ممکن است به طور مساوی توزیع نشده باشد. به عنوان مثال، در شکل 6-2، volume 1 شامل کلماتی است که با A و B شروع می‌شوند، اما volume 12 شامل کلماتی است که با T, U, V, X, Y و Z شروع می‌شوند. به سادگی داشتن یک volume برای هر دو حرف از الفبا، منجر به بزرگ‌تر شدن برخی از volumes نسبت به بقیه می‌شود. به منظور توزیع داده‌ها به طور مساوی، the partition bound‐aries نیاز به انطباق با داده‌ها دارند.
    </p>
<p>
        The partition boundaries ممکن است به صورت دستی توسط یک administrator انتخاب شوند، یا database می‌تواند آن‌ها را به طور خودکار انتخاب کند (ما در مورد انتخاب partition boundaries با جزئیات بیشتر در "Rebalancing Partitions" در صفحه 209 بحث خواهیم کرد). این strategy partitioning توسط Bigtable، نمونه open source آن HBase [2, 3]، RethinkDB و MongoDB قبل از نسخه 2.4 [4] استفاده می‌شود.
    </p>
<p>
        Within each partition، ما می‌توانیم keys را به ترتیب مرتب شده نگه داریم (به "SSTables and LSM-Trees" در صفحه 76 مراجعه کنید). این مزیت دارد که range scans آسان هستند و شما می‌توانید با key به عنوان یک concatenated index رفتار کنید تا چندین record مرتبط را در یک query واکشی کنید ("Multi-column indexes" در صفحه 87 را ببینید). به عنوان مثال، یک application را در نظر بگیرید که data را از یک network از sensors ذخیره می‌کند، جایی که key، timestamp از measurement (year-month-day-hour-minute-second) است. Range scans در این مورد بسیار مفید هستند، زیرا به شما اجازه می‌دهند که به راحتی، به عنوان مثال، تمام readings را از یک ماه خاص واکشی کنید.
    </p>
<p>
        202 | Chapter 6: Partitioning
    </p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 224" src="page_0224/image_1.png"/></div>
</div>
                <div class="page-number">صفحه 0224</div>
            </div>
        </div>
        <!-- Page 0225 -->
        <div class="chapter" id="page-0225">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        با این حال، the downside of key range partitioning این است که الگوهای دسترسی خاصی می‌توانند منجر به hot spots شوند. اگر key یک timestamp باشد، سپس partitions با ranges of time مطابقت دارند—به عنوان مثال، یک partition برای هر روز. متأسفانه، از آنجایی که ما data را از sensors به database در حین وقوع اندازه‌گیری‌ها می‌نویسیم، همه writes به همان partition ختم می‌شوند (آن برای امروز)، بنابراین آن partition می‌تواند با writes بیش از حد بارگذاری شود در حالی که بقیه بیکار هستند [5].
    </p>
<p>
        برای اجتناب از این مشکل در sensor database، شما نیاز دارید که از چیزی به غیر از timestamp به عنوان اولین عنصر از key استفاده کنید. به عنوان مثال، شما می‌توانید هر timestamp را با sensor name پیشوند کنید تا partitioning ابتدا بر اساس sensor name و سپس بر اساس زمان انجام شود. با فرض اینکه شما بسیاری از sensors را دارید که به طور همزمان فعال هستند، write load در نهایت به طور مساوی در سراسر partitions پخش می‌شود. اکنون، هنگامی که شما می‌خواهید values از چندین sensors را در یک زمان range واکشی کنید، شما نیاز دارید که یک query range جداگانه را برای هر sensor name انجام دهید.
    </p>
<h4>Partitioning by Hash of Key</h4>
<p>
        به دلیل این خطر از skew و hot spots، بسیاری از datastores distributed از یک hash function برای تعیین partition برای یک key داده شده، استفاده می‌کنند.
    </p>
<p>
        A good hash function داده‌های skewed را می‌گیرد و آن‌ها را به طور یکنواخت توزیع می‌کند. فرض کنید شما یک hash function 32 بیتی دارید که یک string را می‌گیرد. هر زمان که شما یک string جدید به آن می‌دهید، آن یک عدد ظاهراً تصادفی بین 0 و 232 − 1 برمی‌گرداند. حتی اگر strings ورودی بسیار شبیه به هم باشند، hashes آن‌ها در سراسر آن range از اعداد به طور مساوی توزیع شده‌اند.
    </p>
<p>
        For partitioning purposes، hash function نباید cryptographically strong باشد: به عنوان مثال، Cassandra و MongoDB از MD5 استفاده می‌کنند و Voldemort از the Fowler–Noll–Vo function استفاده می‌کند. بسیاری از زبان‌های برنامه‌نویسی دارای hash functions ساده‌ای هستند (چون آن‌ها برای hash tables استفاده می‌شوند)، اما ممکن است برای partitioning مناسب نباشند: به عنوان مثال، در Object.hashCode() از Java و Object#hash از Ruby، همان key ممکن است در فرآیندهای مختلف، یک مقدار hash متفاوت داشته باشد [6].
    </p>
<p>
        Once you have a suitable hash function for keys، شما می‌توانید هر partition را به یک range از hashes (به جای یک range از keys) اختصاص دهید و هر key که hash آن در range یک partition قرار می‌گیرد، در آن partition ذخیره می‌شود. این در شکل 6-3 نشان داده شده است.
    </p>
<p>
        Partitioning of Key-Value Data | 203
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0225</div>
            </div>
        </div>
        <!-- Page 0226 -->
        <div class="chapter" id="page-0226">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        شکل 6-3. Partitioning توسط hash از key.
    </p>
<p>
        این تکنیک در توزیع keys به طور منصفانه در میان partitions، خوب است. the partition boundaries می‌توانند به طور مساوی فاصله‌گذاری شوند، یا می‌توانند به صورت pseudorandom انتخاب شوند (که در این صورت تکنیک، گاهی اوقات consistent hashing نامیده می‌شود).
    </p>
<h4>Consistent Hashing</h4>
<p>
        Consistent hashing، همانطور که توسط Karger و همکاران [7] تعریف شده است، یک راه برای توزیع مساوی load در یک سیستم از caches در سراسر اینترنت، مانند یک content delivery network (CDN)، است.
        این از partition boundaries که به طور تصادفی انتخاب شده‌اند، استفاده می‌کند تا از نیاز به کنترل مرکزی یا distributed consensus اجتناب کند. توجه داشته باشید که consistent در اینجا هیچ ارتباطی با replica consis‐tency (فصل 5 را ببینید) یا ACID consistency (فصل 7 را ببینید)، ندارد، بلکه یک رویکرد خاص را برای rebalancing توصیف می‌کند.
    </p>
<p>
        همانطور که در "Rebalancing Partitions" در صفحه 209 خواهیم دید، این رویکرد خاص، در واقع برای databases بسیار خوب عمل نمی‌کند [8]، بنابراین در عمل به ندرت استفاده می‌شود (documentation از برخی از databases هنوز به consistent hashing اشاره دارد، اما اغلب نادرست است). از آنجایی که این بسیار گیج‌کننده است، بهتر است از اصطلاح consistent hashing اجتناب کنید و به جای آن، آن را hash partitioning بنامید.
    </p>
<p>
        متاسفانه با استفاده از hash از key برای partitioning ما یک property خوب از key-range partitioning را از دست می‌دهیم: توانایی انجام efficient range queries. Keys که زمانی مجاور بودند، اکنون در تمام partitions پراکنده شده‌اند، بنابراین sort order آن‌ها از بین می‌رود. در MongoDB، اگر شما حالت sharding مبتنی بر hash را فعال کرده باشید، هر query range باید به تمام partitions ارسال شود [4]. Range queries روی primary key توسط Riak [9], Couchbase [10] یا Voldemort پشتیبانی نمی‌شوند.
    </p>
<p>
        Cassandra یک compromise را بین دو strategy partitioning به دست می‌آورد [11, 12, 13]. A table در Cassandra می‌تواند با یک primary key compound declaration شود که شامل چندین column است. فقط قسمت اول آن key، hash می‌شود تا partition را تعیین کند، اما columns دیگر به عنوان یک concatenated index برای sorting the data در SSTables از Cassandra استفاده می‌شوند. بنابراین یک query نمی‌تواند به دنبال یک range از values در داخل
    </p>
<p>
        204 | Chapter 6: Partitioning
    </p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 226" src="page_0226/image_1.png"/></div>
</div>
                <div class="page-number">صفحه 0226</div>
            </div>
        </div>
        <!-- Page 0227 -->
        <div class="chapter" id="page-0227">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        first column of a compound key، اما اگر یک value ثابت برای first column مشخص کند، می‌تواند یک range scan کارآمد را بر روی columns دیگر از key انجام دهد.
    </p>
<p>
        The concatenated index approach یک data model elegant را برای one-to-many relationships فعال می‌کند. به عنوان مثال، در یک سایت social media، یک user ممکن است updates زیادی را ارسال کند. اگر primary key برای updates به (user_id, update_timestamp) انتخاب شود، سپس شما می‌توانید به طور کارآمد تمام updates که توسط یک user خاص در یک time inter‐val خاص، مرتب شده بر اساس timestamp، انجام شده‌اند را بازیابی کنید. Users مختلف ممکن است در partitions مختلف ذخیره شوند، اما در داخل هر user، the updates بر اساس timestamp در یک partition واحد ذخیره می‌شوند.
    </p>
<h4>Skewed Workloads and Relieving Hot Spots</h4>
<p>
        همانطور که بحث شد، hashing یک key برای تعیین partition آن می‌تواند به کاهش hot spots کمک کند.
    </p>
<p>
        با این حال، نمی‌تواند به طور کامل از آن‌ها اجتناب کند: در حالت حاد، جایی که همه reads و writes برای همان key هستند، شما همچنان با همه requests که به همان parti‐tion هدایت می‌شوند، پایان می‌یابید.
    </p>
<p>
        این نوع workload شاید غیرمعمول باشد، اما غیرقابل شنیدن نیست: به عنوان مثال، در یک سایت social media، یک user celebrity با میلیون‌ها follower ممکن است یک storm of activity را ایجاد کند، زمانی که کاری انجام می‌دهد [14]. این event می‌تواند منجر به حجم زیادی از writes به همان key شود (جایی که key شاید user ID از celebrity، یا ID از action که مردم در مورد آن نظر می‌دهند، باشد). Hashing the key کمک نمی‌کند، زیرا hash از دو IDs یکسان همچنان یکسان است.
    </p>
<p>
        امروزه، اکثر systems data قادر به جبران خودکار برای چنین workload skewed بسیار بالا نیستند، بنابراین این مسئولیت application است که skew را کاهش دهد. به عنوان مثال، اگر یک key شناخته شده است که بسیار hot است، یک تکنیک ساده این است که یک عدد تصادفی را به ابتدای یا انتهای key اضافه کنید. فقط یک عدد تصادفی decimal دو رقمی، writes را به key به طور مساوی در سراسر 100 keys مختلف تقسیم می‌کند و به آن keys اجازه می‌دهد تا به partitions مختلف توزیع شوند.
    </p>
<p>
        با این حال، با تقسیم writes در سراسر keys مختلف، هر reads اکنون باید کار اضافی انجام دهد، زیرا آن‌ها باید data را از همه 100 keys بخوانند و آن را ترکیب کنند. این technique همچنین نیاز به bookkeeping اضافی دارد: فقط منطقی است که عدد تصادفی را برای تعداد کمی از hot keys اضافه کنید. برای اکثریت قریب به اتفاق keys با throughput write کم، این overhead غیرضروری خواهد بود. بنابراین، شما همچنین نیاز به یک روش برای پیگیری دارید که کدام keys در حال تقسیم شدن هستند.
    </p>
<p>
        شاید در آینده، data systems قادر به تشخیص و جبران خودکار برای workloads skewed باشند. اما در حال حاضر، شما نیاز دارید که trade-offs را برای application خودتان در نظر بگیرید.
    </p>
<p>
        Partitioning of Key-Value Data | 205
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0227</div>
            </div>
        </div>
        <!-- Page 0228 -->
        <div class="chapter" id="page-0228">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        ii. If your database only supports a key-value model، شما ممکن است وسوسه شوید که یک secondary index را خودتان با ایجاد یک mapping از values به document IDs در application code پیاده‌سازی کنید. اگر شما این مسیر را طی کنید، شما نیاز دارید که مراقبت زیادی کنید تا اطمینان حاصل شود که indexes شما با data اساسی سازگار هستند. Race condi‐tions و write failures intermittent (که در آن برخی از تغییرات ذخیره شده‌اند اما بقیه ذخیره نشده‌اند) می‌توانند بسیار آسان باعث شوند که داده‌ها از sync خارج شوند—"The need for multi-object transactions" در صفحه 231 را ببینید.
    </p>
<h4>Partitioning and Secondary Indexes</h4>
<p>
        The partitioning schemes که ما تا کنون بحث کردیم، به یک key-value data model وابسته هستند. اگر records فقط از طریق primary key خود دسترسی پیدا کنند، ما می‌توانیم partition را از آن key تعیین کنیم و از آن برای هدایت read و write requests به partition مسئول آن key استفاده کنیم.
    </p>
<p>
        The situation اگر secondary indexes درگیر باشند، پیچیده‌تر می‌شود (همچنین به "Other Indexing Structures" در صفحه 85 مراجعه کنید). A secondary index معمولاً یک record را به طور منحصر به فرد شناسایی نمی‌کند، بلکه یک راه برای جستجوی occurrences از یک value خاص است: یافتن همه actions توسط user 123، یافتن همه مقالاتی که حاوی کلمه hogwash هستند، یافتن همه ماشین‌هایی که رنگ آن‌ها قرمز است، و غیره.
    </p>
<p>
        Secondary indexes bread and butter از relational databases هستند و در document databases نیز رایج هستند. بسیاری از key-value stores (مانند HBase و Volde‐mort) از secondary indexes اجتناب کرده‌اند زیرا پیچیدگی پیاده‌سازی آن‌ها اضافه شده است، اما برخی (مانند Riak) شروع به افزودن آن‌ها کرده‌اند زیرا برای data modeling بسیار مفید هستند. و در نهایت، secondary indexes دلیل وجود از search servers مانند Solr و Elasticsearch هستند.
    </p>
<p>
        مشکل با secondary indexes این است که آن‌ها به طور مرتب به partitions نگاشت نمی‌شوند.
        دو رویکرد اصلی برای partitioning یک database با secondary indexes وجود دارد: document-based partitioning و term-based partitioning.
    </p>
<h4>Partitioning Secondary Indexes by Document</h4>
<p>
        به عنوان مثال، تصور کنید شما در حال راه‌اندازی یک وب‌سایت برای فروش ماشین‌های used هستید (که در شکل 6-4 نشان داده شده است). هر listing یک ID منحصر به فرد دارد—آن را document ID بنامید—و شما database را توسط the document ID (به عنوان مثال، IDs 0 to 499 در partition 0، IDs 500 to 999 در partition 1 و غیره) partition می‌کنید.
    </p>
<p>
        You want to let users search for cars, allowing them to filter by color and by make, so you need a secondary index on color and make (in a document database these would be fields; in a relational database they would be columns). If you have declared the index, the database can perform the indexing automatically.ii به عنوان مثال، هر زمان که یک ماشین قرمز به database اضافه می‌شود، database partition آن را به طور خودکار به list of document IDs برای index entry color:red اضافه می‌کند.
    </p>
<p>
        206 | Chapter 6: Partitioning
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0228</div>
            </div>
        </div>
        <!-- Page 0229 -->
        <div class="chapter" id="page-0229">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        شکل 6-4. Partitioning secondary indexes توسط document.
    </p>
<p>
        In this indexing approach، هر partition کاملاً جداگانه است: هر partition، indexes secondary خود را حفظ می‌کند و فقط documents را در آن partition پوشش می‌دهد. به اینکه چه data در other partitions ذخیره شده است، اهمیت نمی‌دهد. هر زمان که شما نیاز به write به database دارید—برای اضافه کردن، حذف یا update یک document—شما فقط نیاز دارید که با partition که حاوی document ID است که شما در حال نوشتن آن هستید، سروکار داشته باشید. به همین دلیل، یک index document-partitioned، also known as a local index (برخلاف یک global index که در بخش بعدی توضیح داده شده است) نامیده می‌شود.
    </p>
<p>
        با این حال، خواندن از یک index document-partitioned نیاز به مراقبت دارد: مگر اینکه شما با document IDs کار خاصی انجام داده باشید، هیچ دلیلی وجود ندارد که چرا همه ماشین‌ها با یک رنگ خاص یا یک make خاص در یک partition یکسان باشند. در شکل 6-4، ماشین‌های قرمز در هر دو partition 0 و partition 1 ظاهر می‌شوند. بنابراین، اگر شما می‌خواهید به دنبال ماشین‌های قرمز باشید، شما نیاز دارید که query را به همه partitions ارسال کنید و تمام نتایجی را که دریافت می‌کنید، ترکیب کنید.
    </p>
<p>
        This approach to querying a partitioned database گاهی اوقات scatter/gather نامیده می‌شود و می‌تواند queries read را روی secondary indexes بسیار گران کند. حتی اگر شما partitions را به طور موازی query کنید، scatter/gather مستعد tail latency amplifica‐tion است (به "Percentiles in Practice" در صفحه 16 مراجعه کنید). با این حال، به طور گسترده‌ای استفاده می‌شود: MongoDB، Riak [15]، Cassandra [16]، Elasticsearch [17]، SolrCloud [18] و VoltDB [19] همگی از indexes secondary document-partitioned استفاده می‌کنند.
        اکثر vendors database توصیه می‌کنند که شما scheme partitioning خود را طوری ساختاربندی کنید که queries secondary index بتواند از یک partition واحد ارائه شود، اما این همیشه امکان‌پذیر نیست، به خصوص زمانی که شما در حال استفاده از multiple secondary indexes در یک query واحد هستید (مانند filtering cars by color و by make در همان زمان).
    </p>
<p>
        Partitioning and Secondary Indexes | 207
    </p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 229" src="page_0229/image_1.png"/></div>
</div>
                <div class="page-number">صفحه 0229</div>
            </div>
        </div>
        <!-- Page 0230 -->
        <div class="chapter" id="page-0230">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        شکل 6-5. Partitioning secondary indexes توسط term.
    </p>
<h4>Partitioning Secondary Indexes by Term</h4>
<p>
        به جای اینکه هر partition، index secondary خود را داشته باشد (a local index)، ما می‌توانیم یک global index بسازیم که داده‌ها را در همه partitions پوشش می‌دهد. با این حال، ما نمی‌توانیم به سادگی آن index را در یک node ذخیره کنیم، زیرا احتمالاً به یک bottleneck تبدیل می‌شود و هدف از partitioning را شکست می‌دهد. A global index نیز باید partition شود، اما می‌توان آن را متفاوت از primary key index partition کرد.
    </p>
<p>
        شکل 6-5 نشان می‌دهد که این می‌تواند چگونه به نظر برسد: ماشین‌های قرمز از همه partitions در زیر color:red در index ظاهر می‌شوند، اما index partition شده است به طوری که رنگ‌هایی که با حروف a تا r شروع می‌شوند در partition 0 و رنگ‌هایی که با s تا z شروع می‌شوند در parti‐tion 1 ظاهر می‌شوند. The index روی make از ماشین به طور مشابه partition شده است (با مرز partition بین f و h).
    </p>
<p>
        ما این نوع index را term-partitioned می‌نامیم، زیرا term که ما به دنبال آن هستیم، partition از index را تعیین می‌کند. در اینجا، به عنوان مثال، یک term می‌تواند color:red باشد. The name term از full-text indexes می‌آید (یک نوع خاص از secondary index)، که در آن terms همه کلماتی هستند که در یک document رخ می‌دهند.
    </p>
<p>
        همانطور که قبلاً گفته شد، ما می‌توانیم index را خود term یا با استفاده از یک hash از term partition کنیم.
        Partitioning by the term itself می‌تواند برای range scans مفید باشد (به عنوان مثال، روی یک property عددی، مانند قیمت درخواستی از ماشین)، در حالی که partitioning روی یک hash از term یک توزیع load even‌تری را ایجاد می‌کند.
    </p>
<p>
        مزیت یک global (term-partitioned) index نسبت به یک index document-partitioned این است که می‌تواند reads را کارآمدتر کند: به جای انجام scatter/gather در همه partitions، یک client فقط نیاز دارد که یک request را به partition که حاوی term است که آن می‌خواهد، ارسال کند. با این حال، downside از یک global index این است که writes کندتر و پیچیده‌تر هستند، زیرا یک write به یک document واحد ممکن است اکنون بر چندین
    </p>
<p>
        208 | Chapter 6: Partitioning
    </p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 230" src="page_0230/image_1.png"/></div>
</div>
                <div class="page-number">صفحه 0230</div>
            </div>
        </div>
        <!-- Page 0231 -->
        <div class="chapter" id="page-0231">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        partitions از index (هر term در document ممکن است در یک partition متفاوت، در یک node متفاوت، باشد).
    </p>
<p>
        In an ideal world، index همیشه up to date خواهد بود و هر document که به database نوشته می‌شود، بلافاصله در index منعکس می‌شود. با این حال، در یک term-partitioned index، این امر نیاز به یک transaction distributed در سراسر همه partitions که تحت تأثیر یک write قرار دارند، دارد که در همه databases پشتیبانی نمی‌شود (فصل 7 و Chap‐ter 9 را ببینید).
    </p>
<p>
        در عمل، updates به global secondary indexes اغلب asynchronous هستند (یعنی، اگر شما index را اندکی پس از یک write بخوانید، تغییراتی که شما تازه ایجاد کرده‌اید، ممکن است هنوز در index منعکس نشده باشد). به عنوان مثال، Amazon DynamoDB بیان می‌کند که global secon‐dary indexes آن در شرایط normal در عرض کسری از ثانیه به‌روزرسانی می‌شوند، اما ممکن است تاخیرهای انتشار طولانی‌تری را در موارد faults in the infrastructure تجربه کنند [20].
    </p>
<p>
        Other uses of global term-partitioned indexes شامل feature search از Riak [21] و data warehouse از Oracle می‌شود، که به شما اجازه می‌دهد بین indexing local و global انتخاب کنید [22]. ما در فصل 12 به موضوع پیاده‌سازی term-partitioned secondary indexes باز خواهیم گشت.
    </p>
<h4>Rebalancing Partitions</h4>
<p>
        Over time، things در یک database تغییر می‌کنند:
    </p>
<ul>
<li>The query throughput increases، بنابراین شما می‌خواهید CPUs بیشتری را برای handling load اضافه کنید.</li>
<li>The dataset size increases، بنابراین شما می‌خواهید دیسک‌ها و RAM بیشتری را برای ذخیره آن اضافه کنید.</li>
<li>A machine fails، و سایر machines نیاز دارند که مسئولیت‌های machine fail شده را بر عهده بگیرند.</li>
</ul>
<p>
        همه این تغییرات نیاز به انتقال داده‌ها و requests از یک node به node دیگر دارند.
        فرآیند انتقال load از یک node در cluster به node دیگر، reba‐lancing نامیده می‌شود.
    </p>
<p>
        مهم نیست که کدام partitioning scheme استفاده می‌شود، rebalancing معمولاً انتظار می‌رود که حداقل الزامات را برآورده کند:
    </p>
<ul>
<li>After rebalancing، the load (data storage، read و write requests) باید به طور منصفانه بین nodes در cluster به اشتراک گذاشته شود.</li>
<li>While rebalancing در حال انجام است، database باید به پذیرش reads و writes ادامه دهد.</li>
<li>No more data than necessary باید بین nodes منتقل شود، تا rebalanc‐ing سریع شود و network و disk I/O load به حداقل برسد.</li>
</ul>
<p>
        Rebalancing Partitions | 209
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0231</div>
            </div>
        </div>
        <!-- Page 0232 -->
        <div class="chapter" id="page-0232">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<h4>Strategies for Rebalancing</h4>
<p>
        راه‌های مختلفی برای اختصاص partitions به nodes وجود دارد [23]. بیایید هر کدام را به نوبه خود با هم بحث کنیم.
    </p>
<h4>How not to do it: hash mod N</h4>
<p>
        هنگام partitioning توسط hash از یک key، ما قبلاً گفتیم (شکل 6-3) که بهترین کار این است که hashes ممکن را به ranges تقسیم کنید و هر range را به یک partition اختصاص دهید (به عنوان مثال، key را به partition 0 اختصاص دهید اگر 0 ≤ hash(key) &lt; b0، به partition 1 اگر b0 ≤ hash(key) &lt; b1 و غیره).
    </p>
<p>
        شاید شما تعجب کرده باشید که چرا ما فقط از mod (عملگر %) در بسیاری از زبان‌های برنامه‌نویسی استفاده نمی‌کنیم. به عنوان مثال، hash(key) mod 10 یک عدد بین 0 و 9 را برمی‌گرداند (اگر ما hash را به عنوان یک عدد decimal بنویسیم، hash mod 10 رقمی خواهد بود). اگر ما 10 nodes داشته باشیم، که از 0 تا 9 شماره‌گذاری شده‌اند، این به نظر می‌رسد یک راه آسان برای اختصاص هر key به یک node باشد.
    </p>
<p>
        مشکل رویکرد mod N این است که اگر تعداد nodes N تغییر کند، اکثر keys نیاز به انتقال از یک node به node دیگر خواهند داشت. به عنوان مثال، فرض کنید hash(key) = 123456. اگر شما در ابتدا 10 nodes داشته باشید، آن key روی node 6 شروع می‌شود (زیرا 123456 mod 10 = 6). وقتی شما به 11 nodes رشد می‌کنید، key نیاز به انتقال به node 3 دارد (123456 mod 11 = 3)، و هنگامی که شما به 12 nodes رشد می‌کنید، نیاز به انتقال به node 0 دارد (123456 mod 12 = 0). این جابجایی‌های مکرر، rebalancing را بیش از حد گران می‌کند.
    </p>
<p>
        ما به یک رویکردی نیاز داریم که داده‌ها را بیش از حد لازم جابجا نکند.
    </p>
<h4>Fixed number of partitions</h4>
<p>
        خوشبختانه، یک راه‌حل نسبتاً ساده وجود دارد: partitions بیشتری را نسبت به nodes ایجاد کنید، و چندین partition را به هر node اختصاص دهید. به عنوان مثال، یک database که روی یک cluster از 10 nodes در حال اجرا است، ممکن است از ابتدا به 1000 partitions تقسیم شود، به طوری که تقریباً 100 partitions به هر node اختصاص داده شود.
    </p>
<p>
        اکنون، اگر یک node به cluster اضافه شود، node جدید می‌تواند چند partition را از هر node موجود بدزدد تا زمانی که partitions دوباره به طور منصفانه توزیع شوند. این فرآیند در شکل 6-6 نشان داده شده است. اگر یک node از cluster حذف شود، همین اتفاق برعکس می‌افتد.
    </p>
<p>
        Only entire partitions بین nodes منتقل می‌شوند. تعداد partitions تغییر نمی‌کند و همچنین نگاشت keys به partitions. تنها چیزی که تغییر می‌کند، تخصیص partitions به nodes است. این تغییر تخصیص فوری نیست—مدتی طول می‌کشد تا مقدار زیادی از داده‌ها از طریق شبکه منتقل شود—بنابراین تخصیص قدیمی از partitions برای هر reads و writes که در حالی که transfer در حال انجام است، استفاده می‌شود.
    </p>
<p>
        210 | Chapter 6: Partitioning
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0232</div>
            </div>
        </div>
        <!-- Page 0233 -->
        <div class="chapter" id="page-0233">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        شکل 6-6. افزودن یک node جدید به یک cluster database با multiple partitions per node.
    </p>
<p>
        In principle، شما حتی می‌توانید سخت‌افزار mismatch شده را در cluster خود در نظر بگیرید: با اختصاص دادن partitions بیشتری به nodes که قدرتمندتر هستند، شما می‌توانید آن nodes را مجبور کنید که سهم بیشتری از load را بر عهده بگیرند.
    </p>
<p>
        This approach to rebalancing در Riak [15]، Elasticsearch [24]، Couchbase [10] و Voldemort [25] استفاده می‌شود.
    </p>
<p>
        در این configuration، تعداد partitions معمولاً زمانی ثابت می‌شود که database برای اولین بار راه‌اندازی شود و بعداً تغییر نمی‌کند. اگرچه در اصل تقسیم و merge کردن partitions امکان‌پذیر است (بخش بعدی را ببینید)، یک تعداد ثابت از partitions از نظر عملیاتی ساده‌تر است، و بنابراین بسیاری از databases fixed-partition، انتخاب نمی‌کنند که partition splitting را پیاده‌سازی کنند. بنابراین، تعداد partitions که در ابتدا پیکربندی شده است، حداکثر تعداد nodes است که شما می‌توانید داشته باشید، بنابراین شما نیاز دارید که آن را به اندازه کافی بالا انتخاب کنید تا growth آینده را در خود جای دهد. با این حال، هر partition همچنین دارای management overhead است، بنابراین انتخاب یک عدد بیش از حد زیاد، نتیجه معکوس دارد.
    </p>
<p>
        انتخاب تعداد صحیح partitions دشوار است اگر اندازه کل dataset بسیار متغیر باشد (به عنوان مثال، اگر کوچک شروع شود اما ممکن است با گذشت زمان بسیار بزرگتر شود).
        از آنجایی که هر partition شامل یک fraction ثابت از کل data است، اندازه هر partition متناسب با کل مقدار داده‌ها در cluster رشد می‌کند. اگر partitions بسیار بزرگ باشند، rebalancing و recovery از node failures گران‌قیمت می‌شوند. اما اگر partitions خیلی کوچک باشند، آن‌ها overhead زیادی را متحمل می‌شوند. The best performance زمانی به دست می‌آید که اندازه partitions "just right" باشد، نه خیلی بزرگ و نه خیلی کوچک، که اگر تعداد partitions ثابت باشد، اما اندازه dataset متفاوت باشد، رسیدن به آن دشوار است.
    </p>
<p>
        Rebalancing Partitions | 211
    </p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 233" src="page_0233/image_1.png"/></div>
</div>
                <div class="page-number">صفحه 0233</div>
            </div>
        </div>
        <!-- Page 0234 -->
        <div class="chapter" id="page-0234">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<h4>Dynamic partitioning</h4>
<p>
        برای databases که از key range partitioning استفاده می‌کنند (به "Partitioning by Key Range" در صفحه 202 مراجعه کنید)، یک تعداد ثابت از partitions با مرزهای ثابت بسیار incon‐venient خواهد بود: اگر شما مرزها را اشتباه بگیرید، شما می‌توانید با تمام داده‌ها در یک partition و همه other partitions خالی به پایان برسید. پیکربندی مجدد the partition bound‐aries به صورت دستی بسیار خسته‌کننده خواهد بود.
    </p>
<p>
        به همین دلیل، databases key range–partitioned مانند HBase و RethinkDB، partitions را به صورت پویا ایجاد می‌کنند. هنگامی که یک partition به اندازه‌ای رشد می‌کند که از یک اندازه پیکربندی شده (در HBase، default 10 گیگابایت است) فراتر می‌رود، به دو partition تقسیم می‌شود، به طوری که تقریباً نیمی از data در هر طرف از split به پایان می‌رسد [26]. برعکس، اگر داده‌های زیادی حذف شوند و یک partition به زیر یک threshold برسد، می‌تواند با یک partition مجاور merge شود. این فرآیند مشابه چیزی است که در سطح بالای یک B-tree اتفاق می‌افتد ("B-Trees" در صفحه 79 را ببینید).
    </p>
<p>
        هر partition به یک node اختصاص داده می‌شود و هر node می‌تواند چندین partition را مدیریت کند، مانند مورد یک تعداد ثابت از partitions. پس از split شدن یک partition بزرگ، یکی از دو نیمه آن می‌تواند به node دیگری منتقل شود تا load را متعادل کند.
        در مورد HBase، انتقال فایل‌های partition از طریق HDFS، the underlying distributed filesystem [3] انجام می‌شود.
    </p>
<p>
        یک مزیت از dynamic partitioning این است که تعداد partitions با حجم کل data سازگار می‌شود. اگر مقدار کمی داده وجود داشته باشد، تعداد کمی از partitions کافی است، بنابراین overheads کوچک هستند. اگر مقدار زیادی داده وجود داشته باشد، اندازه هر partition مجزا به یک حداکثر قابل تنظیم محدود می‌شود [23].
    </p>
<p>
        با این حال، یک caveat این است که یک database خالی با یک partition واحد شروع می‌شود، زیرا هیچ a priori information در مورد اینکه در کجا باید partition boundaries را ترسیم کرد، وجود ندارد. در حالی که the dataset کوچک است—تا زمانی که به نقطه‌ای می‌رسد که اولین partition split می‌شود—همه writes باید توسط یک node واحد پردازش شوند در حالی که other nodes بیکار می‌نشینند. برای کاهش این issue، HBase و MongoDB به یک مجموعه اولیه از partitions اجازه می‌دهند که در یک database خالی (این pre-splitting نامیده می‌شود) تنظیم شوند. در مورد key-range partition‐ing، pre-splitting نیاز دارد که شما در حال حاضر بدانید که توزیع key قرار است چگونه به نظر برسد [4, 26].
    </p>
<p>
        Dynamic partitioning فقط برای data key range–partitioned مناسب نیست، بلکه می‌تواند به همان اندازه برای داده‌های hash-partitioned نیز استفاده شود. MongoDB از نسخه 2.4 هر دو partitioning key-range و hash را پشتیبانی می‌کند و partitions را در هر مورد به صورت پویا split می‌کند.
    </p>
<h4>Partitioning proportionally to nodes</h4>
<p>
        با dynamic partitioning، تعداد partitions متناسب با اندازه the dataset است، زیرا فرآیندهای splitting و merging، اندازه هر partition را بین مقداری minimum و maximum ثابت نگه می‌دارند. از سوی دیگر، با یک number ثابت از
    </p>
<p>
        212 | Chapter 6: Partitioning
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0234</div>
            </div>
        </div>
        <!-- Page 0235 -->
        <div class="chapter" id="page-0235">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        در هر دو مورد، تعداد partitions، اندازه هر partition متناسب با اندازه dataset است.
        یک گزینه سوم، که توسط Cassandra و Ketama استفاده می‌شود، این است که تعداد partitions را متناسب با تعداد nodes قرار دهید—به عبارت دیگر، یک تعداد ثابت از par‐titions per node داشته باشید [23, 27, 28]. در این حالت، اندازه هر partition متناسب با اندازه dataset رشد می‌کند در حالی که تعداد nodes بدون تغییر باقی می‌ماند، اما وقتی شما تعداد nodes را افزایش می‌دهید، partitions دوباره کوچکتر می‌شوند. از آنجایی که یک حجم داده بزرگتر به طور کلی نیاز به تعداد بیشتری از nodes برای ذخیره دارد، این رویکرد نیز اندازه هر partition را نسبتاً ثابت نگه می‌دارد.
    </p>
<p>
        When a new node joins the cluster، آن به طور تصادفی یک تعداد ثابت از partitions موجود را برای split کردن انتخاب می‌کند و سپس مالکیت یک نیمه از هر یک از آن split parti‐tions را می‌پذیرد در حالی که نیمه دیگر از هر partition را در جای خود باقی می‌گذارد. The randomization می‌تواند splits ناعدالتی را تولید کند، اما هنگامی که روی تعداد زیادی از partitions متوسط‌گیری می‌شود (در Cassandra، 256 partitions per node به طور پیش‌فرض)، node جدید در نهایت یک سهم منصفانه از load از nodes موجود دریافت می‌کند. Cassandra 3.0 یک الگوریتم rebalanc‐ing جایگزین را معرفی کرد که از splits ناعدالتی اجتناب می‌کند [29].
    </p>
<p>
        انتخاب partition boundaries به طور تصادفی نیاز دارد که hash-based partitioning استفاده شود (بنابراین boundaries می‌توانند از range از اعداد تولید شده توسط hash function انتخاب شوند). در واقع، این رویکرد بیشترین تطابق را با تعریف اصلی از consistent hashing [7] دارد ("Consistent Hashing" در صفحه 204 را ببینید). Hash functions جدیدتر می‌توانند یک effect مشابه را با overhead metadata کمتری به دست آورند [8].
    </p>
<h4>Operations: Automatic or Manual Rebalancing</h4>
<p>
        یک سؤال مهم در رابطه با rebalancing وجود دارد که ما از آن چشم‌پوشی کرده‌ایم: آیا rebalancing به طور خودکار انجام می‌شود یا دستی؟
    </p>
<p>
        یک gradient بین rebalancing کاملاً خودکار (سیستم به طور خودکار تصمیم می‌گیرد که چه زمانی partitions را از یک node به node دیگر منتقل کند، بدون هیچ تعامل administrator) و کاملاً دستی (تخصیص partitions به nodes به طور صریح توسط یک administrator پیکربندی می‌شود و فقط زمانی تغییر می‌کند که administrator به طور صریح آن را دوباره پیکربندی می‌کند) وجود دارد. به عنوان مثال، Couchbase، Riak و Voldemort یک تخصیص partition پیشنهادی را به طور خودکار ایجاد می‌کنند، اما نیاز به یک administrator دارند که آن را قبل از اینکه اجرا شود، committed کند.
    </p>
<p>
        Rebalancing کاملاً خودکار می‌تواند راحت باشد، زیرا برای maintenance عادی، کار عملیاتی کمتری وجود دارد. با این حال، می‌تواند غیرقابل پیش‌بینی باشد. Rebalancing یک operation گران قیمت است، زیرا نیاز به rerouting requests و انتقال مقدار زیادی داده از یک node به node دیگر دارد. اگر این کار با دقت انجام نشود، این فرآیند می‌تواند network یا nodes را overload کند و به performance از سایر requests در حین انجام rebalancing آسیب برساند.
    </p>
<p>
        Rebalancing Partitions | 213
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0235</div>
            </div>
        </div>
        <!-- Page 0236 -->
        <div class="chapter" id="page-0236">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        Such automation can be dangerous in combination with automatic failure detection.
        به عنوان مثال، فرض کنید یک node overloaded است و به طور موقت برای پاسخ به requests کند عمل می‌کند. The other nodes به این نتیجه می‌رسند که node overloaded مرده است و به طور خودکار cluster را rebalance می‌کنند تا load را از آن دور کنند. این load اضافی را بر روی node overloaded، other nodes و network قرار می‌دهد—و باعث می‌شود که وضعیت بدتر شود و به طور بالقوه باعث یک cascading failure شود.
    </p>
<p>
        به همین دلیل، داشتن یک human در loop برای rebalancing می‌تواند چیز خوبی باشد.
        این کار کندتر از یک فرآیند کاملاً اتوماتیک است، اما می‌تواند به جلوگیری از surprises operational کمک کند.
    </p>
<h4>Request Routing</h4>
<p>
        ما اکنون dataset خود را در سراسر multiple nodes که روی multiple machines در حال اجرا هستند، partition کرده‌ایم. اما یک سوال باز باقی می‌ماند: هنگامی که یک client می‌خواهد یک request ایجاد کند، چگونه می‌داند به کدام node متصل شود؟ همانطور که partitions rebalanced می‌شوند، تخصیص partitions به nodes تغییر می‌کند. یک نفر نیاز دارد که بالای آن تغییرات باقی بماند تا به این سؤال پاسخ دهد: اگر من می‌خواهم key "foo" را بخوانم یا بنویسم، به کدام IP address و port number نیاز دارم تا متصل شوم؟
    </p>
<p>
        این یک نمونه از یک مشکل عمومی‌تر است که service discovery نامیده می‌شود، که فقط به databases محدود نمی‌شود. هر قطعه از software که از طریق یک شبکه قابل دسترسی است، این مشکل را دارد، به خصوص اگر هدف آن high availability (اجرا در یک configuration redundant روی multiple machines) باشد. بسیاری از شرکت‌ها ابزارهای service discovery in-house خود را نوشته‌اند و بسیاری از آن‌ها به عنوان open source منتشر شده‌اند [30].
    </p>
<p>
        در یک سطح بالا، چند رویکرد مختلف برای این مشکل وجود دارد (که در شکل 6-7 نشان داده شده است):
    </p>
<ol>
<li>Allow clients to contact any node (به عنوان مثال، از طریق یک round-robin load balancer). If that node coincidence‐ally owns the partition to which the request applies, it can handle the request directly; otherwise, it forwards the request to the appropriate node, receives the reply, and passes the reply along to the client.</li>
<li>Send all requests from clients to a routing tier first, which determines the node that should handle each request and forwards it accordingly. This routing tier does not itself handle any requests; it only acts as a partition-aware load balancer.</li>
<li>Require that clients be aware of the partitioning and the assignment of partitions to nodes. In this case, a client can connect directly to the appropriate node, without any intermediary.</li>
</ol>
<p>
        In all cases, the key problem is: how does the component making the routing decision (which may be one of the nodes, or the routing tier, or the client) learn about changes in the assignment of partitions to nodes?
    </p>
<p>
        214 | Chapter 6: Partitioning
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0236</div>
            </div>
        </div>
        <!-- Page 0237 -->
        <div class="chapter" id="page-0237">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        شکل 6-7. Three different ways از هدایت یک request به node صحیح.
    </p>
<p>
        This is a challenging problem, because it is important that all participants agree—otherwise requests would be sent to the wrong nodes and not handled correctly.
    </p>
<p>
        پروتکل‌هایی برای دستیابی به consensus در یک سیستم distributed وجود دارد، اما پیاده‌سازی آن‌ها دشوار است (فصل 9 را ببینید).
    </p>
<p>
        Many data systems distributed به یک سرویس هماهنگی جداگانه مانند Zoo‐Keeper برای پیگیری این cluster metadata متکی هستند، همانطور که در شکل 6-8 نشان داده شده است. هر node خود را در ZooKeeper ثبت می‌کند و ZooKeeper نگاشت authoritative از partitions to nodes را حفظ می‌کند. other actors، مانند the routing tier یا client partitioning-aware، می‌توانند به این اطلاعات در ZooKeeper دسترسی داشته باشند. هر زمان که a partition تغییر ownership دهد، یا یک node اضافه یا حذف شود، ZooKeeper به the routing tier اطلاع می‌دهد تا بتواند اطلاعات routing خود را به روز نگه دارد.
    </p>
<p>
        شکل 6-8. Using ZooKeeper برای پیگیری تخصیص partitions به nodes.
    </p>
<p>
        Request Routing | 215
    </p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 237" src="page_0237/image_1.png"/></div>
<div class="page-image"><img alt="Image from page 237" src="page_0237/image_2.png"/></div>
</div>
                <div class="page-number">صفحه 0237</div>
            </div>
        </div>
        <!-- Page 0238 -->
        <div class="chapter" id="page-0238">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        به عنوان مثال، Espresso از LinkedIn از Helix [31] برای مدیریت cluster (که به نوبه خود به ZooKeeper متکی است) استفاده می‌کند و یک routing tier را همانطور که در شکل 6-8 نشان داده شده است، پیاده‌سازی می‌کند. HBase، SolrCloud و Kafka نیز از ZooKeeper برای پیگیری partition assignment استفاده می‌کنند.
    </p>
<p>
        MongoDB یک architecture مشابه دارد، اما به پیاده‌سازی config server خود و daemons mongos به عنوان the routing tier متکی است.
    </p>
<p>
        Cassandra و Riak یک رویکرد متفاوت را در پیش می‌گیرند: آن‌ها از یک gossip protocol بین nodes برای انتشار هرگونه تغییرات در cluster state استفاده می‌کنند. Requests را می‌توان به هر node ارسال کرد و آن node آن‌ها را به node مناسب برای the requested partition (رویکرد 1 در شکل 6-7) هدایت می‌کند. این model، پیچیدگی بیشتری را در database nodes قرار می‌دهد، اما از وابستگی به یک سرویس هماهنگی خارجی مانند ZooKeeper اجتناب می‌کند.
    </p>
<p>
        Couchbase به طور خودکار rebalance نمی‌کند، که طراحی را ساده می‌کند. به طور معمول با یک routing tier به نام moxi پیکربندی شده است، که در مورد تغییرات routing از cluster nodes یاد می‌گیرد [32].
    </p>
<p>
        هنگام استفاده از یک routing tier یا هنگامی که requests به یک node تصادفی ارسال می‌شود، clients هنوز هم نیاز به یافتن IP addresses برای اتصال دارند. این‌ها به اندازه تخصیص partitions به nodes سریع تغییر نمی‌کنند، بنابراین اغلب استفاده از DNS برای این منظور کافی است.
    </p>
<h4>Parallel Query Execution</h4>
<p>
        تاکنون ما بر روی queries بسیار ساده‌ای متمرکز شده‌ایم که یک key واحد را می‌خوانند یا می‌نویسند (به علاوه scatter/gather queries در مورد document-partitioned secondary indexes). این در مورد سطح دسترسی است که توسط اکثر datastores distributed NoSQL پشتیبانی می‌شود.
    </p>
<p>
        با این حال، محصولات massively parallel processing (MPP) relational database که اغلب برای analytics استفاده می‌شوند، در انواع queries که پشتیبانی می‌کنند، بسیار پیشرفته‌تر هستند.
    </p>
<p>
        یک query data warehouse معمولی شامل چندین join، filtering، grouping و operations aggregation است. The MPP query optimizer این query پیچیده را به تعدادی execution stages و partitions تقسیم می‌کند که بسیاری از آن‌ها می‌توانند به طور موازی بر روی nodes مختلف از cluster database اجرا شوند. Queries که شامل scanning بر روی بخش‌های بزرگی از dataset هستند، به ویژه از چنین execution parallel سود می‌برند.
    </p>
<p>
        Fast parallel execution از data warehouse queries یک موضوع تخصصی است و با توجه به اهمیت business از analytics، مورد توجه تجاری زیادی قرار می‌گیرد. ما در فصل 10 در مورد برخی از تکنیک‌ها برای execution query parallel بحث خواهیم کرد. برای یک overview دقیق‌تر از تکنیک‌های مورد استفاده در databases parallel، لطفاً به مراجع [1, 33] مراجعه کنید.
    </p>
<h4>Summary</h4>
<p>
        در این فصل ما راه‌های مختلفی از partitioning a large dataset را به زیرمجموعه‌های کوچکتر بررسی کردیم. Partitioning زمانی ضروری است که شما داده‌های زیادی دارید که ذخیره و پردازش آن در یک machine واحد دیگر امکان‌پذیر نیست.
    </p>
<p>
        216 | Chapter 6: Partitioning
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0238</div>
            </div>
        </div>
        <!-- Page 0239 -->
        <div class="chapter" id="page-0239">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<h3>هدف از Partitioning</h3>
<p>
        هدف از <strong>Partitioning</strong> این است که داده‌ها و بار درخواست‌ها را به طور مساوی در چندین machine توزیع کنیم و از نقاط داغ (nodes با بار بسیار زیاد) جلوگیری کنیم. این کار مستلزم انتخاب یک scheme مناسب برای داده‌های شما و <strong>Rebalancing</strong> partition ها زمانی که nodes به cluster اضافه یا از آن حذف می‌شوند، است.
    </p>
<p>
        ما در مورد دو رویکرد اصلی برای <strong>Partitioning</strong> بحث کردیم:
    </p>
<ul>
<li>
<strong>Key range partitioning</strong>، که در آن keys مرتب شده‌اند و یک partition مالک تمام keys از یک minimum تا یک maximum است. مرتب‌سازی این مزیت را دارد که <em>range queries</em> کارآمد ممکن است، اما اگر application اغلب به keys که در order مرتب‌شده به هم نزدیک هستند دسترسی داشته باشد، خطر نقاط داغ وجود دارد.
            <br/>
            در این رویکرد، partitions معمولاً به صورت <em>Dynamic</em> با تقسیم range به دو subranges زمانی که یک partition خیلی بزرگ می‌شود، <strong>Rebalanced</strong> می‌شوند.
        </li>
<li>
<strong>Hash partitioning</strong>، که در آن یک <em>Hash function</em> برای هر key اعمال می‌شود و یک partition مالک یک range از hashes است. این روش ترتیب keys را از بین می‌برد، range queries را ناکارآمد می‌کند، اما ممکن است بار را به طور مساوی‌تری توزیع کند.
            <br/>
            هنگام <strong>Partitioning</strong> با <strong>Hash</strong>، معمولاً از قبل تعداد ثابتی از partitions ایجاد می‌شود، چندین partition به هر node اختصاص داده می‌شود و زمانی که nodes اضافه یا حذف می‌شوند، کل partitions از یک node به node دیگر منتقل می‌شوند. <strong>Dynamic partitioning</strong> نیز می‌تواند مورد استفاده قرار گیرد.
        </li>
</ul>
<p>
        رویکردهای <strong>Hybrid</strong> نیز امکان‌پذیر هستند، به عنوان مثال با یک <strong>Compound key</strong>: استفاده از یک part از key برای شناسایی partition و part دیگر برای sort order.
    </p>
<p>
        ما همچنین در مورد تعامل بین <strong>Partitioning</strong> و <strong>Secondary indexes</strong> بحث کردیم. یک <strong>Secondary index</strong> نیز باید <strong>Partitioned</strong> شود و دو روش وجود دارد:
    </p>
<ul>
<li>
<strong>Document-partitioned indexes (local indexes)</strong>، که در آن <strong>Secondary indexes</strong> در همان partition به عنوان <strong>Primary key</strong> و value ذخیره می‌شوند. این بدان معناست که فقط یک partition نیاز به به‌روزرسانی در <em>write</em> دارد، اما یک <em>read</em> از <strong>Secondary index</strong> نیازمند یک <strong>Scatter/Gather</strong> در سراسر تمام partitions است.
        </li>
<li>
<strong>Term-partitioned indexes (global indexes)</strong>، که در آن <strong>Secondary indexes</strong> به‌طور جداگانه با استفاده از values index شده، <strong>Partitioned</strong> می‌شوند. یک entry در <strong>Secondary index</strong> ممکن است شامل records از تمام partitions از <strong>Primary key</strong> باشد. هنگامی که یک document نوشته می‌شود، چندین partitions از <strong>Secondary index</strong> نیاز به به‌روزرسانی دارند. با این حال، یک <em>read</em> می‌تواند از یک partition واحد انجام شود.
        </li>
</ul>
<p>
        در نهایت، ما در مورد تکنیک‌هایی برای <em>Routing queries</em> به partition مناسب بحث کردیم، که از <em>Simple partition-aware load balancing</em> تا <em>Sophisticated parallel query execution engines</em> متغیر است.
    </p>
<p>
        به‌طور طراحی شده، هر partition عمدتاً مستقل عمل می‌کند—این همان چیزی است که به یک <em>Partitioned database</em> اجازه می‌دهد تا به چندین machines مقیاس‌پذیر شود. با این حال، عملیاتی که نیاز به نوشتن دارند
        <br/>
        Summary
        <br/>
        |
        <br/>
        217
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0239</div>
            </div>
        </div>
        <!-- Page 0240 -->
        <div class="chapter" id="page-0240">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        نوشتن به چندین partition می‌تواند دشوار باشد: برای مثال، چه اتفاقی می‌افتد اگر write به یک partition موفق شود، اما دیگری شکست بخورد؟ ما به این سوال در فصل‌های بعدی پاسخ خواهیم داد.
    </p>
<h3>References</h3>
<ol>
<li>
            [1] David J. DeWitt and Jim N. Gray: “Parallel Database Systems: The Future of High
            Performance Database Systems,” Communications of the ACM, volume 35, number 6,
            pages 85–98, June 1992. doi:10.1145/129888.129894
        </li>
<li>
            [2] Lars George: “HBase vs. BigTable Comparison,” larsgeorge.com, November 2009.
        </li>
<li>
            [3] “The Apache HBase Reference Guide,” Apache Software Foundation,
            hbase.apache.org, 2014.
        </li>
<li>
            [4] MongoDB, Inc.: “New Hash-Based Sharding Feature in MongoDB 2.4,” blog.mon‐
            godb.org, April 10, 2013.
        </li>
<li>
            [5] Ikai Lan: “App Engine Datastore Tip: Monotonically Increasing Values Are Bad,”
            ikaisays.com, January 25, 2011.
        </li>
<li>
            [6] Martin Kleppmann: “Java’s hashCode Is Not Safe for Distributed Systems,” mar‐
            tin.kleppmann.com, June 18, 2012.
        </li>
<li>
            [7] David Karger, Eric Lehman, Tom Leighton, et al.: “Consistent Hashing and Ran‐
            dom Trees: Distributed Caching Protocols for Relieving Hot Spots on the World
            Wide Web,” at 29th Annual ACM Symposium on Theory of Computing (STOC),
            pages 654–663, 1997. doi:10.1145/258533.258660
        </li>
<li>
            [8] John Lamping and Eric Veach: “A Fast, Minimal Memory, Consistent Hash Algo‐
            rithm,” arxiv.org, June 2014.
        </li>
<li>
            [9] Eric Redmond: “A Little Riak Book,” Version 1.4.0, Basho Technologies, Septem‐
            ber 2013.
        </li>
<li>
            [10] “Couchbase 2.5 Administrator Guide,” Couchbase, Inc., 2014.
        </li>
<li>
            [11] Avinash Lakshman and Prashant Malik: “Cassandra – A Decentralized Struc‐
            tured Storage System,” at 3rd ACM SIGOPS International Workshop on Large Scale
            Distributed Systems and Middleware (LADIS), October 2009.
        </li>
<li>
            [12] Jonathan Ellis: “Facebook’s Cassandra Paper, Annotated and Compared to
            Apache Cassandra 2.0,” datastax.com, September 12, 2013.
        </li>
<li>
            [13] “Introduction to Cassandra Query Language,” DataStax, Inc., 2014.
        </li>
<li>
            [14] Samuel Axon: “3% of Twitter’s Servers Dedicated to Justin Bieber,” masha‐
            ble.com, September 7, 2010.
        </li>
<li>
            [15] “Riak 1.4.8 Docs,” Basho Technologies, Inc., 2014.
        </li>
</ol>
<p>
        218
        <br/>
        |
        <br/>
        Chapter 6: Partitioning
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0240</div>
            </div>
        </div>
        <!-- Page 0241 -->
        <div class="chapter" id="page-0241">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<ol>
<li>
            [16] Richard Low: “The Sweet Spot for Cassandra Secondary Indexing,” wentnet.com,
            October 21, 2013.
        </li>
<li>
            [17] Zachary Tong: “Customizing Your Document Routing,” elasticsearch.org, June
            3, 2013.
        </li>
<li>
            [18] “Apache Solr Reference Guide,” Apache Software Foundation, 2014.
        </li>
<li>
            [19] Andrew Pavlo: “H-Store Frequently Asked Questions,” hstore.cs.brown.edu,
            October 2013.
        </li>
<li>
            [20] “Amazon DynamoDB Developer Guide,” Amazon Web Services, Inc., 2014.
        </li>
<li>
            [21] Rusty Klophaus: “Difference Between 2I and Search,” email to riak-users mailing
            list, lists.basho.com, October 25, 2011.
        </li>
<li>
            [22] Donald K. Burleson: “Object Partitioning in Oracle,” dba-oracle.com, November
            8, 2000.
        </li>
<li>
            [23] Eric Evans: “Rethinking Topology in Cassandra,” at ApacheCon Europe, Novem‐
            ber 2012.
        </li>
<li>
            [24] Rafał Kuć: “Reroute API Explained,” elasticsearchserverbook.com, September 30,
            2013.
        </li>
<li>
            [25] “Project Voldemort Documentation,” project-voldemort.com.
        </li>
<li>
            [26] Enis Soztutar: “Apache HBase Region Splitting and Merging,” hortonworks.com,
            February 1, 2013.
        </li>
<li>
            [27] Brandon Williams: “Virtual Nodes in Cassandra 1.2,” datastax.com, December
            4, 2012.
        </li>
<li>
            [28] Richard Jones: “libketama: Consistent Hashing Library for Memcached Clients,”
            metabrew.com, April 10, 2007.
        </li>
<li>
            [29] Branimir Lambov: “New Token Allocation Algorithm in Cassandra 3.0,” data‐
            stax.com, January 28, 2016.
        </li>
<li>
            [30] Jason Wilder: “Open-Source Service Discovery,” jasonwilder.com, February
            2014.
        </li>
<li>
            [31] Kishore Gopalakrishna, Shi Lu, Zhen Zhang, et al.: “Untangling Cluster Manage‐
            ment with Helix,” at ACM Symposium on Cloud Computing (SoCC), October 2012.
            doi:10.1145/2391229.2391248
        </li>
<li>
            [32] “Moxi 1.8 Manual,” Couchbase, Inc., 2014.
        </li>
<li>
            [33] Shivnath Babu and Herodotos Herodotou: “Massively Parallel Databases and
            MapReduce Systems,” Foundations and Trends in Databases, volume 5, number 1,
            pages 1–104, November 2013. doi:10.1561/1900000036
        </li>
</ol>
<p>
        Summary
        <br/>
        |
        <br/>
        219
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0241</div>
            </div>
        </div>
        <!-- Page 0243 -->
        <div class="chapter" id="page-0243">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<h3>CHAPTER 7</h3>
<h4>Transactions</h4>
<p>
        برخی از نویسندگان ادعا کرده‌اند که <em>General two-phase commit</em> بیش از حد گران است و به دلیل مشکلات performance یا availability که به همراه دارد، نمی‌توان از آن پشتیبانی کرد. ما بر این باوریم که بهتر است برنامه‌نویسان application با مشکلات performance ناشی از استفاده بیش از حد از <strong>Transactions</strong> در زمان بروز bottleneck ها سروکار داشته باشند، تا اینکه همیشه به جای نداشتن <strong>Transactions</strong> کدنویسی کنند.
        <br/>
        —James Corbett et al., <em>Spanner: Google’s Globally-Distributed Database</em> (2012)
    </p>
<p>
        در واقعیت سخت‌گیرانه <em>data systems</em>، بسیاری از موارد می‌توانند اشتباه پیش بروند:
    </p>
<ul>
<li>
            نرم‌افزار یا سخت‌افزار database ممکن است در هر زمانی (از جمله در میان یک عملیات <em>write</em>) دچار خرابی شود.
        </li>
<li>
            application ممکن است در هر زمانی (از جمله در میانه یک سری از operations) <em>crash</em> کند.
        </li>
<li>
<em>Interruptions</em> در شبکه می‌تواند به طور غیرمنتظره‌ای application را از database یا یک node database را از node دیگر قطع کند.
        </li>
<li>
            چندین client ممکن است همزمان به database <em>write</em> کنند و تغییرات یکدیگر را بازنویسی کنند.
        </li>
<li>
            یک client ممکن است داده‌هایی را بخواند که منطقی نیستند، زیرا فقط به‌طور جزئی به‌روزرسانی شده‌اند.
        </li>
<li>
<em>Race conditions</em> بین clients می‌تواند باعث باگ‌های غافلگیرکننده شود.
        </li>
</ul>
<p>
        به منظور reliable بودن، یک system باید با این faults مقابله کند و اطمینان حاصل کند که باعث شکست فاجعه‌بار کل system نمی‌شوند. با این حال، پیاده‌سازی مکانیسم‌های <em>fault-tolerance</em> کار زیادی می‌طلبد. این امر مستلزم تفکر دقیق در مورد تمام مواردی است که می‌توانند اشتباه پیش بروند و همچنین آزمایش‌های فراوان برای اطمینان از عملکرد واقعی solution است.
    </p>
<p>
        221
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0243</div>
            </div>
        </div>
        <!-- Page 0244 -->
        <div class="chapter" id="page-0244">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        برای دهه‌ها، <strong>Transactions</strong> مکانیسم انتخابی برای ساده‌سازی این مسائل بوده است. یک <strong>Transaction</strong> راهی است برای اینکه یک application چندین <em>reads</em> و <em>writes</em> را با هم در یک واحد منطقی گروه‌بندی کند. از نظر مفهومی، تمام <em>reads</em> و <em>writes</em> در یک <strong>Transaction</strong> به عنوان یک operation اجرا می‌شوند: یا کل <strong>Transaction</strong> موفق می‌شود (commit) یا با شکست مواجه می‌شود (abort, rollback). اگر شکست بخورد، application می‌تواند با خیال راحت دوباره تلاش کند. با <strong>Transactions</strong>، مدیریت خطا برای یک application بسیار ساده‌تر می‌شود، زیرا نیازی نیست نگران failure های جزئی باشد—به عنوان مثال، موردی که در آن برخی از operations موفق می‌شوند و برخی شکست می‌خورند (به هر دلیلی).
    </p>
<p>
        اگر سال‌ها را صرف کار با <strong>Transactions</strong> کرده‌اید، ممکن است بدیهی به نظر برسند، اما نباید آنها را بدیهی بگیریم. <strong>Transactions</strong> یک قانون طبیعت نیستند. آنها با یک هدف ایجاد شدند، یعنی ساده‌سازی <em>programming model</em> برای applications که به یک database دسترسی دارند. با استفاده از <strong>Transactions</strong>، application آزاد است تا برخی از سناریوهای خطای احتمالی و مسائل <em>concurrency</em> را نادیده بگیرد، زیرا database به جای آن از آنها مراقبت می‌کند (ما اینها را safety guarantees می‌نامیم).
    </p>
<p>
        هر application به <strong>Transactions</strong> نیاز ندارد، و گاهی اوقات مزایایی در تضعیف <em>transactional guarantees</em> یا کنار گذاشتن کامل آنها وجود دارد (به عنوان مثال، برای دستیابی به <em>higher performance</em> یا <em>higher availability</em>). برخی از <em>safety properties</em> را می‌توان بدون <strong>Transactions</strong> به دست آورد.
    </p>
<p>
        چگونه متوجه می‌شوید که آیا به <strong>Transactions</strong> نیاز دارید؟ برای پاسخ به این سوال، ابتدا باید دقیقاً بفهمیم که <strong>Transactions</strong> چه <em>safety guarantees</em> را می‌توانند ارائه دهند و هزینه‌های مرتبط با آنها چیست. اگرچه <strong>Transactions</strong> در نگاه اول ساده به نظر می‌رسند، اما در واقع جزئیات ظریف اما مهمی وجود دارد که وارد بازی می‌شوند.
    </p>
<p>
        در این فصل، ما بسیاری از نمونه‌های مواردی را که می‌توانند اشتباه پیش بروند، بررسی خواهیم کرد و الگوریتم‌هایی را که databases برای محافظت در برابر آن مسائل استفاده می‌کنند، بررسی خواهیم کرد. ما به ویژه در زمینه <em>concurrency control</em> عمیق خواهیم شد و انواع مختلف <em>race conditions</em> که می‌توانند رخ دهند و نحوه پیاده‌سازی <em>isolation levels</em> مانند <em>read committed, snapshot isolation</em> و <em>serializability</em> توسط databases را مورد بحث قرار خواهیم داد.
    </p>
<p>
        این فصل برای هر دو database تک‌node و distributed databases اعمال می‌شود. در فصل 8 ما بحث را بر روی چالش‌های خاصی متمرکز خواهیم کرد که فقط در <em>distributed systems</em> بوجود می‌آیند.
    </p>
<h4>The Slippery Concept of a Transaction</h4>
<p>
        تقریباً تمام <em>relational databases</em> امروزی، و برخی <em>nonrelational databases</em>، از <strong>Transactions</strong> پشتیبانی می‌کنند. اکثر آنها از سبکی پیروی می‌کنند که در سال 1975 توسط IBM System R، اولین database <em>SQL</em>، معرفی شد [1, 2, 3]. اگرچه برخی از جزئیات پیاده‌سازی تغییر کرده‌اند، اما ایده کلی تقریباً 40 سال است که بدون تغییر باقی مانده است: پشتیبانی از <strong>Transaction</strong> در MySQL, PostgreSQL, Oracle, SQL Server و غیره، شباهت عجیبی به System R دارد.
    </p>
<p>
        222
        <br/>
        |
        <br/>
        Chapter 7: Transactions
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0244</div>
            </div>
        </div>
        <!-- Page 0245 -->
        <div class="chapter" id="page-0245">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        در اواخر دهه 2000، <em>nonrelational</em> (NoSQL) databases شروع به محبوبیت پیدا کردند. آنها با ارائه انتخاب مدل‌های داده جدید (به فصل 2 مراجعه کنید) و با گنجاندن <em>replication</em> (فصل 5) و <em>partitioning</em> (فصل 6) به صورت پیش‌فرض، به دنبال بهبود <em>relational status quo</em> بودند. <strong>Transactions</strong> قربانی اصلی این جنبش بود: بسیاری از این نسل جدید databases، <strong>Transactions</strong> را به‌طور کامل کنار گذاشتند، یا کلمه را دوباره تعریف کردند تا مجموعه‌ای بسیار ضعیف‌تر از تضمین‌ها را توصیف کنند [4].
    </p>
<p>
        با تبلیغات پیرامون این <em>new crop of distributed databases</em>، این باور رایج به وجود آمد که <strong>Transactions</strong> متضاد مقیاس‌پذیری هستند و هر system large-scale باید <strong>Transactions</strong> را کنار بگذارد تا عملکرد خوب و <em>high availability</em> را حفظ کند [5, 6]. از سوی دیگر، <em>transactional guarantees</em> گاهی توسط فروشندگان database به عنوان یک requirement ضروری برای "applications جدی" با "داده‌های ارزشمند" ارائه می‌شوند. هر دو دیدگاه، اغراق محض هستند.
    </p>
<p>
        حقیقت به این سادگی نیست: مانند هر انتخاب طراحی فنی دیگر، <strong>Transactions</strong> دارای مزایا و محدودیت‌هایی هستند. به منظور درک این trade-offs، بیایید به جزئیات <em>guarantees</em> بپردازیم که <strong>Transactions</strong> می‌توانند ارائه دهند—هم در operation های عادی و هم در شرایط extreme مختلف (اما واقع‌بینانه).
    </p>
<h4>The Meaning of ACID</h4>
<p>
<em>The safety guarantees</em> ارائه شده توسط <strong>Transactions</strong> اغلب توسط سرنام شناخته شده <strong>ACID</strong> توصیف می‌شوند که مخفف <em>Atomicity, Consistency, Isolation, and Durability</em> است. این اصطلاح در سال 1983 توسط Theo Härder و Andreas Reuter [7] ابداع شد تا اصطلاحات دقیقی برای مکانیسم‌های <em>fault-tolerance</em> در databases ایجاد کند.
    </p>
<p>
        با این حال، در عمل، پیاده‌سازی <strong>ACID</strong> در یک database با پیاده‌سازی در database دیگر برابر نیست. به عنوان مثال، همانطور که خواهیم دید، ابهام زیادی در مورد معنای <em>isolation</em> وجود دارد [8]. ایده سطح بالا درست است، اما <em>devil is in the details</em>. امروزه، وقتی یک system ادعا می‌کند که "ACID compliant" است، مشخص نیست که چه <em>guarantees</em> را واقعاً می‌توانید انتظار داشته باشید. متاسفانه ACID بیشتر به یک <em>marketing term</em> تبدیل شده است.
    </p>
<p>
        (سیستم‌هایی که معیارهای <strong>ACID</strong> را برآورده نمی‌کنند، گاهی اوقات <strong>BASE</strong> نامیده می‌شوند که مخفف <em>Basically Available, Soft state, and Eventual consistency</em> است [9]. این حتی مبهم‌تر از تعریف <strong>ACID</strong> است. به نظر می‌رسد که تنها تعریف منطقی <strong>BASE</strong> "not ACID" است. یعنی، می‌تواند تقریباً هر چیزی را که می‌خواهید، معنی دهد.)
    </p>
<p>
        بیایید به تعاریف atomicity, consistency, isolation, و durability بپردازیم، زیرا این به ما امکان می‌دهد تا ایده خود را در مورد <strong>Transactions</strong> اصلاح کنیم.
    </p>
<h4>Atomicity</h4>
<p>
        به طور کلی، atomic به چیزی اشاره دارد که نمی‌تواند به قسمت‌های کوچک‌تر تقسیم شود. این کلمه در شاخه‌های مختلف <em>comput</em> به معانی مشابه اما ظریف و متفاوتی اشاره دارد.
        <br/>
        The Slippery Concept of a Transaction
        <br/>
        |
        <br/>
        223
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0245</div>
            </div>
        </div>
        <!-- Page 0246 -->
        <div class="chapter" id="page-0246">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        به عنوان مثال، در <em>multi-threaded programming</em>، اگر یک <em>thread</em> یک <em>atomic operation</em> را اجرا کند، به این معنی است که هیچ راهی وجود ندارد که یک <em>thread</em> دیگر بتواند نتیجه ناتمام operation را ببیند. system فقط می‌تواند در حالتی باشد که قبل از operation بوده یا بعد از operation بوده است، نه چیزی در این بین.
    </p>
<p>
        در مقابل، در زمینه <strong>ACID</strong>، atomicity در مورد <em>concurrency</em> نیست. این توصیف نمی‌کند که اگر چندین <em>processes</em> سعی کنند همزمان به داده‌های یکسان دسترسی پیدا کنند، چه اتفاقی می‌افتد، زیرا این موضوع تحت حرف I قرار دارد، برای <em>isolation</em> (به "Isolation" در صفحه 225 مراجعه کنید).
    </p>
<p>
        بلکه، <em>ACID atomicity</em> توصیف می‌کند که اگر یک client بخواهد چندین <em>writes</em> انجام دهد، اما پس از پردازش برخی از <em>writes</em> یک fault رخ دهد—به عنوان مثال، یک <em>process</em> <em>crash</em> می‌کند، اتصال شبکه قطع می‌شود، یک دیسک پر می‌شود یا برخی از <em>integrity constraint</em> نقض می‌شود، چه اتفاقی می‌افتد. اگر <em>writes</em> با هم در یک <em>atomic transaction</em> گروه‌بندی شوند، و <em>transaction</em> به دلیل یک fault نتواند تکمیل (commit) شود، سپس <em>transaction</em> <em>aborted</em> می‌شود و database باید هر گونه <em>writes</em> را که تاکنون در آن <em>transaction</em> انجام داده است، دور بریزد یا لغو کند.
    </p>
<p>
        بدون atomicity، اگر یک error در میان انجام تغییرات متعدد رخ دهد، دانستن اینکه کدام تغییرات اعمال شده‌اند و کدام‌ها نشده‌اند، دشوار است. application می‌تواند دوباره تلاش کند، اما این خطر وجود دارد که همان تغییر را دو بار انجام دهید، که منجر به داده‌های تکراری یا نادرست می‌شود. Atomicity این مشکل را ساده می‌کند: اگر یک <em>transaction</em> <em>aborted</em> شد، application می‌تواند مطمئن باشد که چیزی را تغییر نداده است، بنابراین می‌تواند با خیال راحت دوباره امتحان شود.
    </p>
<p>
        توانایی <em>abort</em> کردن یک <em>transaction</em> در صورت error و دور ریختن تمام <em>writes</em> از آن <em>transaction</em>، ویژگی defining atomicity <strong>ACID</strong> است. شاید <em>abortability</em> اصطلاح بهتری نسبت به atomicity بود، اما ما به atomicity پایبند خواهیم بود، زیرا این کلمه رایج است.
    </p>
<h4>Consistency</h4>
<p>
        کلمه <em>consistency</em> بسیار بارگذاری شده است:
    </p>
<ul>
<li>
            در فصل 5 ما در مورد <em>replica consistency</em> و مسئله <em>eventual consis‐tency</em> که در سیستم‌های <em>asynchronously replicated</em> (به "Problems with Repli‐cation Lag" در صفحه 161 مراجعه کنید) مطرح می‌شود، بحث کردیم.
        </li>
<li>
<em>Consistent hashing</em> یک رویکرد برای <em>partitioning</em> است که برخی از system ها برای reba‐lancing استفاده می‌کنند (به "Consistent Hashing" در صفحه 204 مراجعه کنید).
        </li>
<li>
            در <em>CAP theorem</em> (به فصل 9 مراجعه کنید)، از کلمه <em>consistency</em> برای منظور <em>linear‐izability</em> استفاده می‌شود (به "Linearizability" در صفحه 324 مراجعه کنید).
        </li>
<li>
            در زمینه <strong>ACID</strong>، <em>consistency</em> به یک مفهوم application-specific از database که در یک "good state" است، اشاره دارد.
        </li>
</ul>
<p>
        متاسفم که از یک کلمه برای حداقل چهار معنی مختلف استفاده می‌شود.
    </p>
<p>
        224
        <br/>
        |
        <br/>
        Chapter 7: Transactions
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0246</div>
            </div>
        </div>
        <!-- Page 0247 -->
        <div class="chapter" id="page-0247">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        i. Joe Hellerstein اظهار داشته است که C در <strong>ACID</strong> "برای کارکردن سرنام، اضافه شد" در مقاله Härder و Reuter [7]، و در آن زمان مهم در نظر گرفته نشد.
    </p>
<p>
        ایده <strong>ACID consistency</strong> این است که شما عبارت‌هایی (invariants) در مورد داده‌های خود دارید که همیشه باید درست باشند—به عنوان مثال، در یک system حسابداری، اعتبارها و بدهی‌ها در تمام حساب‌ها همیشه باید متعادل باشند. اگر یک transaction با یک database شروع شود که با توجه به این <em>invariants</em> معتبر است، و هر <em>writes</em> در طول transaction اعتبار را حفظ کند، پس می‌توانید مطمئن باشید که <em>invariants</em> همیشه برآورده می‌شوند.
    </p>
<p>
        با این حال، این ایده <em>consistency</em> به مفهوم application از <em>invariants</em> بستگی دارد، و این مسئولیت application است که transactions خود را به درستی تعریف کند تا <em>consistency</em> را حفظ کند. این چیزی نیست که database بتواند تضمین کند: اگر داده‌های بدی بنویسید که <em>invariants</em> شما را نقض کند، database نمی‌تواند شما را متوقف کند. (برخی از انواع خاص <em>invariants</em> را می‌توان توسط database بررسی کرد، به عنوان مثال با استفاده از <em>foreign key constraints</em> یا <em>uniqueness constraints</em>. با این حال، به طور کلی، application تعریف می‌کند که چه داده‌هایی معتبر یا نامعتبر هستند—database فقط آن را ذخیره می‌کند.)
    </p>
<p>
<em>Atomicity, isolation</em> و <em>durability</em> خواص database هستند، در حالی که <em>consistency</em> (در مفهوم <strong>ACID</strong>) یک ویژگی از application است. application ممکن است برای دستیابی به <em>consistency</em> به خواص atomicity و <em>isolation</em> database متکی باشد، اما فقط به database بستگی ندارد. بنابراین، حرف C واقعاً به <strong>ACID</strong> تعلق ندارد.i
    </p>
<h4>Isolation</h4>
<p>
        اکثر databases توسط چندین client به طور همزمان دسترسی پیدا می‌کنند. اگر آنها در حال خواندن و نوشتن قسمت‌های مختلف database باشند، مشکلی نیست، اما اگر به <em>database records</em> یکسان دسترسی پیدا کنند، می‌توانید با مشکلات <em>concurrency</em> (<em>race conditions</em>) مواجه شوید.
    </p>
<p>
        شکل 7-1 یک مثال ساده از این نوع مشکل است. فرض کنید شما دو <em>client</em> دارید که به طور همزمان یک counter را که در database ذخیره شده است، افزایش می‌دهند. هر <em>client</em> باید مقدار فعلی را بخواند، 1 را اضافه کند و مقدار جدید را برگرداند (با فرض اینکه operation افزایشی در داخل database ساخته نشده است). در شکل 7-1، counter باید از 42 به 44 افزایش یافته باشد، زیرا دو افزایش رخ داده است، اما در واقع فقط به 43 رسید به دلیل <em>race condition</em>.
    </p>
<p>
<em>Isolation</em> در مفهوم <strong>ACID</strong> به این معنی است که <em>concurrently executing transactions</em> از یکدیگر جدا شده‌اند: آنها نمی‌توانند روی پاهای یکدیگر قدم بگذارند. کتاب‌های درسی database کلاسیک، <em>isolation</em> را به عنوان <em>serializability</em> رسمی می‌کنند، به این معنی که هر <em>transaction</em> می‌تواند وانمود کند که تنها <em>transaction</em> در حال اجرا در کل database است. database تضمین می‌کند که وقتی <em>transactions</em> <em>committed</em> شده‌اند، نتیجه مشابه زمانی است که آنها به صورت <em>serially</em> (یکی پس از دیگری) اجرا شده‌اند، حتی اگر در واقعیت ممکن است <em>concurrently</em> اجرا شده باشند [10].
    </p>
<p>
        The Slippery Concept of a Transaction
        <br/>
        |
        <br/>
        225
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0247</div>
            </div>
        </div>
        <!-- Page 0248 -->
        <div class="chapter" id="page-0248">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
<figure>
<img alt="Figure 7-1. A race condition between two clients concurrently incrementing a counter." src="figure7-1.png"/>
<figcaption>Figure 7-1. A race condition between two clients concurrently incrementing a counter.</figcaption>
</figure>
        با این حال، در عمل، <em>serializable isolation</em> به ندرت استفاده می‌شود، زیرا یک <em>performance penalty</em> به همراه دارد. برخی از databases های محبوب، مانند Oracle 11g، حتی آن را پیاده‌سازی نمی‌کنند.
        <br/>
        در Oracle یک <em>isolation level</em> وجود دارد به نام "<em>serializable</em>"، اما در واقع چیزی را پیاده‌سازی می‌کند که <em>snapshot isolation</em> نامیده می‌شود، که یک <em>guarantee</em> ضعیف‌تر از <em>serializability</em> است [8, 11]. ما <em>snapshot isolation</em> و سایر اشکال <em>isolation</em> را در "Weak Isolation Levels" در صفحه 233 بررسی خواهیم کرد.
    </p>
<h4>Durability</h4>
<p>
        هدف از یک <em>database system</em> ارائه یک مکان امن است که در آن داده‌ها را می‌توان بدون ترس از دست دادن آنها ذخیره کرد. <em>Durability</em> این قول است که پس از commit موفقیت‌آمیز یک transaction، هر داده‌ای که نوشته است، فراموش نخواهد شد، حتی اگر یک <em>hardware fault</em> یا database <em>crash</em> وجود داشته باشد.
    </p>
<p>
        در یک <em>single-node database</em>، <em>durability</em> به طور معمول به این معنی است که داده‌ها به <em>nonvolatile storage</em> مانند <em>hard drive</em> یا SSD نوشته شده‌اند. همچنین معمولاً شامل یک <em>write-ahead log</em> یا مشابه (به "Making B-trees reliable" در صفحه 82 مراجعه کنید) می‌شود، که امکان <em>recovery</em> را در صورت خراب شدن ساختارهای داده در دیسک فراهم می‌کند. در یک <em>replicated database</em>، <em>durability</em> ممکن است به این معنی باشد که داده‌ها با موفقیت به تعدادی از nodes کپی شده‌اند. به منظور ارائه یک <em>durability guarantee</em>، یک database باید منتظر بماند تا این <em>writes</em> یا <em>replications</em> قبل از گزارش یک <em>transaction</em> به عنوان <em>successfully committed</em> تکمیل شوند.
    </p>
<p>
        همانطور که در "Reliability" در صفحه 6 بحث شد، <em>perfect durability</em> وجود ندارد: اگر تمام <em>hard disks</em> و تمام backups شما همزمان از بین بروند، بدیهی است که database شما نمی‌تواند کاری برای نجات شما انجام دهد.
    </p>
<p>
        226
        <br/>
        |
        <br/>
        Chapter 7: Transactions
    </p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 248" src="page_0248/image_1.png"/></div>
</div>
                <div class="page-number">صفحه 0248</div>
            </div>
        </div>
        <!-- Page 0249 -->
        <div class="chapter" id="page-0249">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<h4>Replication and Durability</h4>
<p>
        از نظر تاریخی، <em>durability</em> به معنای نوشتن به یک <em>archive tape</em> بود. سپس به عنوان نوشتن به یک دیسک یا SSD درک شد. اخیراً، به معنای <em>replication</em> تطبیق داده شده است.
    </p>
<p>
        کدام پیاده‌سازی بهتر است؟
    </p>
<p>
        حقیقت این است که هیچ چیز کامل نیست:
    </p>
<ul>
<li>
            اگر شما به دیسک <em>write</em> کنید و machine از بین برود، حتی اگر داده‌های شما از دست نرود، تا زمانی که machine را تعمیر یا دیسک را به machine دیگری منتقل نکنید، غیرقابل دسترس است. <em>Replicated systems</em> می‌توانند در دسترس باقی بمانند.
        </li>
<li>
            یک <em>correlated fault</em> — یک <em>power outage</em> یا یک باگ که هر node را در یک ورودی خاص <em>crash</em> می‌کند—می‌تواند تمام <em>replicas</em> را به یکباره از کار بیندازد (به "Reliability" در صفحه 6 مراجعه کنید)، و هر داده‌ای را که فقط در حافظه است، از دست بدهد. بنابراین نوشتن به دیسک هنوز برای <em>in-memory databases</em> مرتبط است.
        </li>
<li>
            در یک <em>asynchronously replicated system</em>، <em>recent writes</em> ممکن است زمانی که <em>leader</em> در دسترس نیست، از بین بروند (به "Handling Node Outages" در صفحه 156 مراجعه کنید).
        </li>
<li>
            به ویژه نشان داده شده است که SSDها، زمانی که برق ناگهان قطع می‌شود، گاهی <em>guarantees</em> ای را که قرار است ارائه دهند، نقض می‌کنند: حتی <em>fsync</em> هم تضمین نمی‌شود که به درستی کار کند [12]. <em>Disk firmware</em> می‌تواند دارای باگ باشد، درست مانند هر نوع دیگری از software [13, 14].
        </li>
<li>
            تعاملات ظریف بین <em>storage engine</em> و پیاده‌سازی <em>filesystem</em> می‌تواند منجر به باگ‌هایی شود که ردیابی آنها دشوار است، و ممکن است باعث شود فایل‌ها روی دیسک پس از crash خراب شوند [15, 16].
        </li>
<li>
            داده‌ها روی دیسک می‌توانند به تدریج بدون اینکه این مسئله شناسایی شود، خراب شوند [17]. اگر داده‌ها برای مدتی خراب شده باشند، <em>replicas</em> و <em>recent backups</em> نیز ممکن است خراب شوند. در این حالت، باید سعی کنید داده‌ها را از یک <em>historical backup</em> بازیابی کنید.
        </li>
<li>
            یک مطالعه روی SSDها نشان داد که بین 30٪ تا 80٪ از درایوها در طول چهار سال اول عملیات، حداقل یک بلوک بد ایجاد می‌کنند [18]. هارد دیسک‌های مغناطیسی نرخ کمتری از سکتورهای بد، اما نرخ شکست کامل بالاتری نسبت به SSDها دارند.
        </li>
<li>
            اگر یک SSD از برق جدا شود، بسته به دما، می‌تواند در عرض چند هفته شروع به از دست دادن داده‌ها کند [19].
        </li>
</ul>
<p>
        در عمل، هیچ تکنیکی وجود ندارد که بتواند <em>absolute guarantees</em> ارائه دهد. فقط تکنیک‌های مختلف کاهش ریسک وجود دارد، از جمله نوشتن به دیسک، <em>replicating</em> به machine های remote، و <em>backups</em>—و آنها می‌توانند و باید با هم استفاده شوند. مانند همیشه، عاقلانه است که هر "guarantees" نظری را با کمی تردید در نظر بگیرید.
    </p>
<p>
        The Slippery Concept of a Transaction
        <br/>
        |
        <br/>
        227
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0249</div>
            </div>
        </div>
        <!-- Page 0250 -->
        <div class="chapter" id="page-0250">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        ii. به نظر می‌رسد، یک counter نادرست در یک application ایمیل یک مشکل خاص نیست. از طرف دیگر، به جای یک counter خوانده نشده، به موجودی حساب مشتری و به جای یک ایمیل، به یک <em>payment transaction</em> فکر کنید.
    </p>
<h4>Single-Object and Multi-Object Operations</h4>
<p>
        برای مرور، در <strong>ACID</strong>، atomicity و <em>isolation</em> توصیف می‌کنند که database باید در صورت انجام چندین <em>writes</em> توسط یک client در داخل همان <em>transaction</em>، چه کاری انجام دهد:
    </p>
<p>
        Atomicity
    </p>
<p>
        اگر یک <em>error</em> در میانه یک sequence از <em>writes</em> رخ دهد، transaction باید <em>aborted</em> شود، و <em>writes</em> انجام شده تا آن نقطه باید <em>discarded</em> شوند. به عبارت دیگر، database شما را از نگرانی در مورد <em>partial failure</em> نجات می‌دهد، با دادن یک <em>all-or-nothing guarantee</em>.
    </p>
<p>
        Isolation
    </p>
<p>
<em>Concurrently running transactions</em> نباید با یکدیگر تداخل داشته باشند. به عنوان مثال، اگر یک <em>transaction</em> چندین <em>writes</em> انجام دهد، transaction دیگری باید یا همه یا هیچ یک از آن <em>writes</em> را ببیند، اما نه یک زیرمجموعه.
    </p>
<p>
        این تعاریف فرض می‌کنند که شما می‌خواهید چندین object (rows, documents, records) را به طور همزمان تغییر دهید. چنین <em>multi-object transactions</em> اغلب مورد نیاز هستند اگر چندین قطعه از داده‌ها نیاز به همگام‌سازی داشته باشند. شکل 7-2 یک مثال از یک application ایمیل را نشان می‌دهد.
    </p>
<p>
        برای نمایش تعداد پیام‌های خوانده نشده برای یک user، می‌توانید چیزی شبیه به این را <em>query</em> کنید:
    </p>
<pre><code class="language-sql">SELECT COUNT(*) FROM emails WHERE recipient_id = 2 AND unread_flag = true
</code></pre>
<p>
        با این حال، ممکن است متوجه شوید که این <em>query</em> اگر ایمیل‌های زیادی وجود داشته باشد، خیلی کند است، و تصمیم بگیرید که تعداد پیام‌های خوانده نشده را در یک فیلد جداگانه ذخیره کنید (نوعی <em>denormalization</em>). اکنون، هر زمان که یک پیام جدید وارد می‌شود، باید counter خوانده نشده را نیز افزایش دهید، و هر زمان که یک پیام به عنوان خوانده شده علامت‌گذاری می‌شود، باید counter خوانده نشده را نیز کاهش دهید.
    </p>
<p>
        در شکل 7-2، user 2 یک <em>anomaly</em> را تجربه می‌کند: لیست صندوق پستی یک پیام خوانده نشده را نشان می‌دهد، اما counter صفر پیام خوانده نشده را نشان می‌دهد زیرا increment counter هنوز اتفاق نیفتاده است.ii Isolation این مسئله را با اطمینان از اینکه user 2 یا ایمیل درج شده و counter به‌روزرسانی شده را می‌بیند، یا هیچ‌کدام را، اما نه یک <em>inconsistent halfway point</em>، جلوگیری می‌کرد.
    </p>
<p>
        228
        <br/>
        |
        <br/>
        Chapter 7: Transactions
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0250</div>
            </div>
        </div>
        <!-- Page 0251 -->
        <div class="chapter" id="page-0251">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        iii. این ایده‌آل نیست. اگر اتصال TCP قطع شود، transaction باید <em>aborted</em> شود. اگر <em>interruption</em> پس از درخواست commit توسط client رخ دهد، اما قبل از اینکه server تأیید کند که commit رخ داده است، client نمی‌داند که آیا transaction <em>committed</em> شده است یا خیر. برای حل این مشکل، یک <em>transaction manager</em> می‌تواند operations را با یک <em>unique transaction identifier</em> گروه‌بندی کند که به یک اتصال TCP خاص مرتبط نیست. ما در "The End-to-End Argument for Databases" در صفحه 516 به این موضوع باز خواهیم گشت.
    </p>
<figure>
<img alt="Figure 7-2. Violating isolation: one transaction reads another transaction’s uncommitted writes (a “dirty read”)." src="figure7-2.png"/>
<figcaption>Figure 7-2. Violating isolation: one transaction reads another transaction’s uncommitted writes (a “dirty read”).</figcaption>
</figure>
<p>
        شکل 7-3 نیاز به atomicity را نشان می‌دهد: اگر یک <em>error</em> در جایی در طول transaction رخ دهد، محتویات صندوق پستی و counter خوانده نشده ممکن است از حالت <em>sync</em> خارج شوند. در یک <em>atomic transaction</em>، اگر <em>update</em> به counter شکست بخورد، transaction <em>aborted</em> می‌شود و ایمیل درج شده <em>rolled back</em> می‌شود.
    </p>
<figure>
<img alt="Figure 7-3. Atomicity ensures that if an error occurs any prior writes from that transaction are undone, to avoid an inconsistent state." src="figure7-3.png"/>
<figcaption>Figure 7-3. Atomicity ensures that if an error occurs any prior writes from that transaction are undone, to avoid an inconsistent state.</figcaption>
</figure>
<p>
<em>Multi-object transactions</em> نیاز به راهی برای تعیین دارند که کدام operations خواندن و نوشتن به همان <em>transaction</em> تعلق دارند. در relational databases، این کار معمولاً بر اساس اتصال TCP client به database server انجام می‌شود: در هر اتصال خاص، همه چیز بین یک BEGIN TRANSACTION و یک دستور COMMIT به عنوان بخشی از همان <em>transaction</em> در نظر گرفته می‌شود.iii
    </p>
<p>
        The Slippery Concept of a Transaction
        <br/>
        |
        <br/>
        229
    </p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 251" src="page_0251/image_1.png"/></div>
<div class="page-image"><img alt="Image from page 251" src="page_0251/image_2.png"/></div>
</div>
                <div class="page-number">صفحه 0251</div>
            </div>
        </div>
        <!-- Page 0252 -->
        <div class="chapter" id="page-0252">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        iv. به طور دقیق، اصطلاح atomic increment از کلمه atomic در مفهوم <em>multi-threaded programming</em> استفاده می‌کند. در زمینه <strong>ACID</strong>، در واقع باید <em>isolated</em> یا <em>serializable increment</em> نامیده شود. اما این در حال باریک بینی است.
    </p>
<p>
        از سوی دیگر، بسیاری از <em>nonrelational databases</em> چنین راهی برای گروه‌بندی operations با هم ندارند. حتی اگر یک <em>multi-object API</em> وجود داشته باشد (به عنوان مثال، یک <em>key-value store</em> ممکن است یک <em>multi-put operation</em> داشته باشد که چندین کلید را در یک operation به‌روزرسانی می‌کند)، این لزوماً به این معنی نیست که دارای <em>transaction semantics</em> است: ممکن است command برای برخی از کلیدها موفق شود و برای دیگران شکست بخورد و database را در یک حالت <em>partially updated</em> قرار دهد.
    </p>
<h4>Single-object writes</h4>
<p>
<em>Atomicity</em> و <em>isolation</em> همچنین زمانی اعمال می‌شوند که یک object واحد در حال تغییر است. به عنوان مثال، تصور کنید که شما در حال نوشتن یک document 20 کیلوبایتی <em>JSON</em> به یک database هستید:
    </p>
<ul>
<li>
            اگر اتصال شبکه پس از ارسال 10 کیلوبایت اول قطع شود، آیا database آن fragment 10 کیلوبایتی غیرقابل تجزیه <em>JSON</em> را ذخیره می‌کند؟
        </li>
<li>
            اگر برق در حالی که database در میانه بازنویسی مقدار قبلی روی دیسک است، قطع شود، آیا در نهایت مقادیر قدیمی و جدید با هم ترکیب می‌شوند؟
        </li>
<li>
            اگر client دیگری آن document را در حالی که <em>write</em> در حال انجام است، بخواند، آیا یک مقدار <em>partially updated</em> را می‌بیند؟
        </li>
</ul>
<p>
        این مسائل بسیار گیج‌کننده خواهند بود، بنابراین <em>storage engines</em> تقریباً جهانی به دنبال ارائه atomicity و <em>isolation</em> در سطح یک object واحد (مانند یک <em>key-value pair</em>) در یک node هستند. <em>Atomicity</em> را می‌توان با استفاده از یک <em>log</em> برای <em>crash recovery</em> (به "Making B-trees reliable" در صفحه 82 مراجعه کنید) و <em>isolation</em> را می‌توان با استفاده از یک lock بر روی هر object (فقط به یک thread اجازه می‌دهد تا در هر زمان به یک object دسترسی داشته باشد) پیاده‌سازی کرد.
    </p>
<p>
        برخی از databases ها همچنین operations atomic پیچیده‌تری،iv مانند یک <em>increment operation</em>، ارائه می‌دهند، که نیاز به یک <em>read-modify-write cycle</em> مانند آنچه در شکل 7-1 وجود دارد را از بین می‌برد. به طور مشابه، <em>compare-and-set operation</em> محبوب است، که به یک <em>write</em> اجازه می‌دهد فقط در صورتی اتفاق بیفتد که مقدار به طور همزمان توسط شخص دیگری تغییر نکرده باشد (به "Compare-and-set" در صفحه 245 مراجعه کنید).
    </p>
<p>
        این <em>single-object operations</em> مفید هستند، زیرا می‌توانند از <em>lost updates</em> جلوگیری کنند زمانی که چندین clients سعی می‌کنند به طور همزمان به یک object یکسان <em>write</em> کنند (به "Preventing Lost Updates" در صفحه 242 مراجعه کنید). با این حال، آنها <strong>Transactions</strong> در مفهوم معمول این کلمه نیستند. <em>Compare-and-set</em> و سایر <em>single-object operations</em> برای اهداف بازاریابی "lightweight transactions" یا حتی "ACID" نامیده شده‌اند [20, 21, 22]، اما این اصطلاحات گمراه‌کننده است. یک <strong>Transaction</strong> معمولاً به عنوان یک مکانیسم برای گروه‌بندی multiple operations بر روی multiple objects در یک واحد execution درک می‌شود.
    </p>
<p>
        230
        <br/>
        |
        <br/>
        Chapter 7: Transactions
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0252</div>
            </div>
        </div>
        <!-- Page 0253 -->
        <div class="chapter" id="page-0253">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<h4>The need for multi-object transactions</h4>
<p>
        بسیاری از <em>distributed datastores</em> <em>multi-object transactions</em> را کنار گذاشته‌اند زیرا پیاده‌سازی آنها در سراسر partitions دشوار است، و در برخی از سناریوها که <em>very high availability</em> یا performance بسیار بالایی مورد نیاز است، می‌توانند مانع شوند. با این حال، هیچ چیز اساساً <em>transactions</em> را در یک <em>distributed database</em> منع نمی‌کند، و ما پیاده‌سازی <em>distributed transactions</em> را در فصل 9 مورد بحث قرار خواهیم داد.
    </p>
<p>
        اما آیا اصلاً به <em>multi-object transactions</em> نیاز داریم؟ آیا می‌توان هر application را فقط با یک <em>key-value data model</em> و operations تک object پیاده‌سازی کرد؟
    </p>
<p>
        در برخی موارد استفاده، درج، به‌روزرسانی و حذف‌های تک object کافی هستند. با این حال، در بسیاری از موارد دیگر، <em>writes</em> به چندین object مختلف باید هماهنگ شوند:
    </p>
<ul>
<li>
            در یک <em>relational data model</em>، یک <em>row</em> در یک table اغلب یک <em>foreign key reference</em> به یک <em>row</em> در table دیگری دارد. (به طور مشابه، در یک <em>graph-like data model</em>، یک <em>vertex</em> دارای <em>edges</em> به <em>vertices</em> دیگر است.) <em>Multi-object transactions</em> به شما این امکان را می‌دهند که اطمینان حاصل کنید که این <em>references</em> معتبر باقی می‌مانند: هنگام درج چندین رکورد که به یکدیگر اشاره می‌کنند، <em>foreign keys</em> باید صحیح و به‌روز باشند، در غیر این صورت داده‌ها بی‌معنی می‌شوند.
        </li>
<li>
            در یک <em>document data model</em>، فیلدهایی که باید با هم به‌روزرسانی شوند، اغلب در همان document قرار دارند، که به عنوان یک object واحد در نظر گرفته می‌شود - هنگام به‌روزرسانی یک document واحد، نیازی به <em>multi-object transactions</em> نیست. با این حال، <em>document databases</em> فاقد قابلیت <em>join</em> نیز <em>denormalization</em> را تشویق می‌کنند (به "Relational Versus Document Databases Today" در صفحه 38 مراجعه کنید). وقتی اطلاعات <em>denormalized</em> باید به‌روزرسانی شود، مانند مثال شکل 7-2، شما باید چندین documents را یکجا به‌روزرسانی کنید. Transactions در این شرایط برای جلوگیری از خارج شدن داده‌های <em>denormalized</em> از <em>sync</em> بسیار مفید هستند.
        </li>
<li>
            در databases با <em>secondary indexes</em> (تقریباً همه چیز به جز <em>pure key-value stores</em>)، <em>indexes</em> نیز باید هر بار که مقداری را تغییر می‌دهید، به‌روزرسانی شوند. این <em>indexes</em> از دیدگاه یک <em>transaction</em> object های database متفاوتی هستند: به عنوان مثال، بدون <em>transaction isolation</em>، این امکان وجود دارد که یک رکورد در یک <em>index</em> ظاهر شود اما در دیگری نه، زیرا <em>update</em> به <em>index</em> دوم هنوز اتفاق نیفتاده است.
        </li>
</ul>
<p>
        چنین applications همچنان می‌توانند بدون <em>transactions</em> پیاده‌سازی شوند. با این حال، مدیریت خطا بدون atomicity بسیار پیچیده‌تر می‌شود، و عدم <em>isolation</em> می‌تواند باعث مشکلات <em>concurrency</em> شود. ما در "Weak Isolation Levels" در صفحه 233 در مورد آنها بحث خواهیم کرد، و رویکردهای جایگزین را در فصل 12 بررسی خواهیم کرد.
    </p>
<h4>Handling errors and aborts</h4>
<p>
        ویژگی کلیدی یک <em>transaction</em> این است که اگر یک <em>error</em> رخ داد، می‌توان آن را <em>aborted</em> و با خیال راحت دوباره امتحان کرد. databases های <strong>ACID</strong> بر اساس این فلسفه هستند: اگر database در خطر
        <br/>
        The Slippery Concept of a Transaction
        <br/>
        |
        <br/>
        231
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0253</div>
            </div>
        </div>
        <!-- Page 0254 -->
        <div class="chapter" id="page-0254">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        of violating its guarantee of atomicity, isolation, or durability، ترجیح می‌دهد که <em>transaction</em> را به طور کامل رها کند تا اینکه اجازه دهد ناتمام باقی بماند.
    </p>
<p>
        با این حال، همه سیستم‌ها از این فلسفه پیروی نمی‌کنند. به طور خاص، <em>datastores</em> با <em>leaderless replication</em> (به "Leaderless Replication" در صفحه 177 مراجعه کنید) بیشتر بر اساس یک "<em>best effort</em>" عمل می‌کنند، که می‌توان آن را به این صورت خلاصه کرد که "database تا جایی که می‌تواند انجام می‌دهد، و اگر به یک <em>error</em> برخورد کند، چیزی را که قبلاً انجام داده است، undo نخواهد کرد"—بنابراین این مسئولیت application است که از <em>errors</em> بازیابی کند.
    </p>
<p>
<em>Errors</em> اجتناب‌ناپذیر هستند، اما بسیاری از توسعه‌دهندگان نرم‌افزار ترجیح می‌دهند فقط در مورد مسیر شاد فکر کنند تا پیچیدگی‌های مدیریت خطا. به عنوان مثال، فریم‌ورک‌های <em>object-relational mapping</em> (ORM) محبوب مانند ActiveRecord و Django از Rails، transactions های <em>aborted</em> را دوباره تلاش نمی‌کنند—<em>error</em> معمولاً منجر به یک استثنا می‌شود که <em>stack</em> را بالا می‌برد، بنابراین هر ورودی user دور ریخته می‌شود و user یک پیام <em>error</em> دریافت می‌کند. این یک شرم‌آور است، زیرا کل نکته <em>aborts</em> این است که امکان retries ایمن را فراهم می‌کند.
    </p>
<p>
        اگرچه <em>retrying</em> یک <em>aborted transaction</em> یک مکانیسم مدیریت خطای ساده و مؤثر است، اما کامل نیست:
    </p>
<ul>
<li>
            اگر <em>transaction</em> در واقع موفقیت‌آمیز بود، اما شبکه در حالی که server سعی داشت <em>successful commit</em> را به client تایید کند، شکست خورد (بنابراین client فکر می‌کند که شکست خورده است)، سپس <em>retrying</em> transaction باعث می‌شود که دو بار انجام شود—مگر اینکه شما یک مکانیسم <em>deduplication</em> در سطح application داشته باشید.
        </li>
<li>
            اگر <em>error</em> به دلیل <em>overload</em> باشد، <em>retrying</em> transaction مشکل را بدتر می‌کند، نه بهتر. برای جلوگیری از چنین <em>feedback cycles</em>، می‌توانید تعداد <em>retries</em> را محدود کنید، از <em>exponential backoff</em> استفاده کنید، و <em>overload-related errors</em> را متفاوت از سایر <em>errors</em> مدیریت کنید (در صورت امکان).
        </li>
<li>
            فقط پس از <em>transient errors</em> (به عنوان مثال به دلیل <em>deadlock, isolation violation, temporary network interruptions, and failover</em>) ارزش <em>retrying</em> را دارد. پس از یک <em>permanent error</em> (به عنوان مثال، <em>constraint violation</em>) یک <em>retry</em> بی‌فایده خواهد بود.
        </li>
<li>
            اگر <em>transaction</em> همچنین دارای <em>side effects</em> در خارج از database باشد، آن <em>side effects</em> ممکن است حتی اگر <em>transaction</em> <em>aborted</em> شود، رخ دهند. به عنوان مثال، اگر شما در حال ارسال یک ایمیل هستید، نمی‌خواهید ایمیل را دوباره هر بار که <em>transaction</em> را <em>retry</em> می‌کنید، ارسال کنید. اگر می‌خواهید اطمینان حاصل کنید که چندین system مختلف با هم commit یا <em>abort</em> می‌شوند، <em>two-phase commit</em> می‌تواند کمک کند (ما این را در "Atomic Commit and Two-Phase Commit (2PC)" در صفحه 354 مورد بحث قرار خواهیم داد).
        </li>
<li>
            اگر <em>client process</em> در هنگام <em>retrying</em> شکست بخورد، هر داده‌ای که سعی در نوشتن آن به database داشت، از دست می‌رود.
        </li>
</ul>
<p>
        232
        <br/>
        |
        <br/>
        Chapter 7: Transactions
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0254</div>
            </div>
        </div>
        <!-- Page 0255 -->
        <div class="chapter" id="page-0255">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<h4>Weak Isolation Levels</h4>
<p>
        اگر دو <strong>Transactions</strong> به داده‌های یکسان دست نزنند، می‌توانند با خیال راحت به صورت موازی اجرا شوند، زیرا هیچ‌کدام به دیگری وابسته نیستند. مشکلات <em>concurrency</em> (<em>race conditions</em>) فقط زمانی مطرح می‌شوند که یک <strong>Transaction</strong> داده‌ای را می‌خواند که همزمان توسط <strong>Transaction</strong> دیگری اصلاح می‌شود، یا زمانی که دو <strong>Transactions</strong> سعی می‌کنند همزمان داده‌های یکسانی را اصلاح کنند.
    </p>
<p>
        یافتن باگ‌های <em>concurrency</em> با تست دشوار است، زیرا چنین باگ‌هایی فقط زمانی ایجاد می‌شوند که شما در زمان‌بندی بدشانس باشید. این مسائل زمان‌بندی ممکن است بسیار به ندرت رخ دهند، و معمولاً بازتولید آنها دشوار است. همچنین استدلال در مورد <em>concurrency</em> بسیار دشوار است، به خصوص در یک application بزرگ که در آن لزوماً نمی‌دانید کدام بخش‌های دیگر کد در حال دسترسی به database هستند. <em>Application development</em> به اندازه کافی دشوار است اگر فقط یک user در یک زمان داشته باشید. داشتن بسیاری از users همزمان، کار را هنوز هم بسیار دشوارتر می‌کند، زیرا هر قطعه از داده می‌تواند به طور غیرمنتظره‌ای در هر زمانی تغییر کند.
    </p>
<p>
        به همین دلیل، databases ها مدت‌هاست که سعی کرده‌اند مشکلات <em>concurrency</em> را با ارائه <em>transaction isolation</em> از توسعه‌دهندگان application پنهان کنند. از نظر تئوری، <em>isolation</em> باید زندگی شما را آسان‌تر کند با اجازه دادن به شما برای تظاهر به اینکه هیچ <em>concurrency</em> رخ نمی‌دهد: <em>serializable isolation</em> به این معنی است که database تضمین می‌کند که <strong>Transactions</strong> همان اثر را دارند، انگار که به صورت <em>serially</em> (به عنوان مثال، یکی در یک زمان، بدون هیچ <em>concurrency</em>) اجرا شده‌اند.
    </p>
<p>
        در عمل، <em>isolation</em> متاسفانه به آن سادگی نیست. <em>Serializable isolation</em> دارای یک <em>performance cost</em> است، و بسیاری از databases ها نمی‌خواهند این هزینه را بپردازند [8]. بنابراین معمول است که سیستم‌ها از سطوح ضعیف‌تری از <em>isolation</em> استفاده کنند، که در برابر برخی از مشکلات <em>concurrency</em> محافظت می‌کنند، اما نه همه. درک این سطوح <em>isolation</em> بسیار سخت‌تر است، و آنها می‌توانند منجر به باگ‌های ظریف شوند، اما با این وجود در عمل استفاده می‌شوند [23].
    </p>
<p>
        باگ‌های <em>concurrency</em> ناشی از <em>weak transaction isolation</em> فقط یک مشکل نظری نیستند. آنها باعث از دست رفتن قابل توجه پول شده‌اند [24, 25]، منجر به تحقیقات توسط ممیزهای مالی [26] شده‌اند، و باعث خراب شدن داده‌های مشتری شده‌اند [27]. یک نظر محبوب در مورد آشکار شدن چنین مشکلاتی این است: "اگر در حال مدیریت داده‌های مالی هستید، از یک database <strong>ACID</strong> استفاده کنید!"—اما این نکته را از دست می‌دهد. حتی بسیاری از <em>relational database systems</em> محبوب (که معمولاً "ACID" در نظر گرفته می‌شوند) از <em>weak isolation</em> استفاده می‌کنند، بنابراین لزوماً از وقوع این باگ‌ها جلوگیری نمی‌کردند.
    </p>
<p>
        به جای تکیه کورکورانه به ابزارها، ما باید یک درک خوب از انواع مشکلات <em>concurrency</em> که وجود دارد، و چگونگی جلوگیری از آنها، ایجاد کنیم. سپس می‌توانیم applications هایی را ایجاد کنیم که قابل اعتماد و صحیح هستند، با استفاده از ابزارهای در دسترس خود.
    </p>
<p>
        در این بخش ما به چندین سطح <em>weak</em> (<em>nonserializable</em>) <em>isolation</em> که در عمل استفاده می‌شوند نگاه خواهیم کرد، و به تفصیل در مورد انواع <em>race conditions</em> که می‌توانند و نمی‌توانند رخ دهند بحث خواهیم کرد، تا بتوانید تصمیم بگیرید که چه سطحی برای application شما مناسب است. هنگامی که این کار را انجام دادیم، <em>serializability</em> را با جزئیات مورد بحث قرار خواهیم داد (به "Serializability" در صفحه
        <br/>
        Weak Isolation Levels
        <br/>
        |
        <br/>
        233
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0255</div>
            </div>
        </div>
        <!-- Page 0256 -->
        <div class="chapter" id="page-0256">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        v. برخی از databases ها از یک <em>isolation level</em> ضعیف‌تر به نام <em>read uncommitted</em> پشتیبانی می‌کنند. این از <em>dirty writes</em> جلوگیری می‌کند، اما از <em>dirty reads</em> جلوگیری نمی‌کند.
    </p>
<p>
        251). بحث ما در مورد <em>isolation levels</em> غیررسمی خواهد بود، با استفاده از مثال‌ها. اگر می‌خواهید تعاریف و تحلیل‌های دقیق از ویژگی‌های آنها داشته باشید، می‌توانید آنها را در منابع علمی پیدا کنید [28, 29, 30].
    </p>
<h4>Read Committed</h4>
<p>
        پایه‌ای‌ترین سطح <em>transaction isolation</em>، <em>read committed</em> است.v این دو <em>guarantees</em> را ایجاد می‌کند:
    </p>
<ol>
<li>
            هنگام خواندن از database، فقط داده‌هایی را خواهید دید که <em>committed</em> شده‌اند (no dirty reads).
        </li>
<li>
            هنگام نوشتن به database، فقط داده‌هایی را بازنویسی می‌کنید که <em>committed</em> شده‌اند (no dirty writes).
        </li>
</ol>
<p>
        بیایید این دو <em>guarantees</em> را با جزئیات بیشتری مورد بحث قرار دهیم.
    </p>
<h4>No dirty reads</h4>
<p>
        تصور کنید یک <em>transaction</em> مقداری داده را به database نوشته است، اما <em>transaction</em> هنوز <em>committed</em> یا <em>aborted</em> نشده است. آیا یک <em>transaction</em> دیگر می‌تواند آن داده‌های <em>uncommitted</em> را ببیند؟ اگر بله، به آن <em>dirty read</em> می‌گویند [2].
    </p>
<p>
        Transactions های در حال اجرا در سطح <em>read committed isolation</em> باید از <em>dirty reads</em> جلوگیری کنند. این بدان معناست که هر <em>writes</em> توسط یک <em>transaction</em> فقط زمانی برای دیگران قابل مشاهده می‌شود که آن <em>transaction</em> <em>commits</em> شود (و سپس همه <em>writes</em> آن به یکباره قابل مشاهده می‌شوند). این در شکل 7-4 نشان داده شده است، جایی که user 1 مقدار x = 3 را تنظیم کرده است، اما get x کاربر 2 هنوز مقدار قدیمی 2 را برمی‌گرداند، در حالی که user 1 هنوز <em>committed</em> نکرده است.
    </p>
<figure>
<img alt="Figure 7-4. No dirty reads: user 2 sees the new value for x only after user 1’s transaction has committed." src="figure7-4.png"/>
<figcaption>Figure 7-4. No dirty reads: user 2 sees the new value for x only after user 1’s transaction has committed.</figcaption>
</figure>
<p>
        234
        <br/>
        |
        <br/>
        Chapter 7: Transactions
    </p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 256" src="page_0256/image_1.png"/></div>
</div>
                <div class="page-number">صفحه 0256</div>
            </div>
        </div>
        <!-- Page 0257 -->
        <div class="chapter" id="page-0257">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        چند دلیل وجود دارد که چرا جلوگیری از <em>dirty reads</em> مفید است:
    </p>
<ul>
<li>
            اگر یک <em>transaction</em> نیاز به <em>update</em> چندین object دارد، یک <em>dirty read</em> به این معنی است که یک <em>transaction</em> دیگر ممکن است برخی از <em>updates</em> را ببیند اما بقیه را نه. به عنوان مثال، در شکل 7-2، user ایمیل خوانده نشده جدید را می‌بیند، اما counter به‌روزرسانی شده را نمی‌بیند. این یک <em>dirty read</em> از ایمیل است. دیدن database در یک حالت <em>partially updated</em> برای کاربران گیج‌کننده است و ممکن است باعث شود <em>transactions</em> دیگر تصمیمات نادرستی بگیرند.
        </li>
<li>
            اگر یک <em>transaction aborts</em> شود، هر <em>writes</em> که انجام داده است باید <em>rolled back</em> شود (مانند شکل 7-3). اگر database به <em>dirty reads</em> اجازه دهد، این بدان معنی است که یک <em>transaction</em> ممکن است داده‌هایی را ببیند که بعداً <em>rolled back</em> می‌شوند - به عنوان مثال، که هرگز واقعاً به database <em>committed</em> نمی‌شوند. استدلال در مورد پیامدها به سرعت ذهن را منحرف می‌کند.
        </li>
</ul>
<h4>No dirty writes</h4>
<p>
        اگر دو <strong>Transactions</strong> همزمان سعی کنند یک object یکسان را در یک database <em>update</em> کنند، چه اتفاقی می‌افتد؟ ما نمی‌دانیم <em>writes</em> به چه ترتیبی اتفاق می‌افتند، اما معمولاً فرض می‌کنیم که <em>write</em> بعدی، <em>write</em> قبلی را بازنویسی می‌کند.
    </p>
<p>
        با این حال، اگر <em>write</em> قبلی بخشی از یک <em>transaction</em> باشد که هنوز <em>committed</em> نشده است، چه اتفاقی می‌افتد، بنابراین <em>write</em> بعدی یک مقدار <em>uncommitted</em> را بازنویسی می‌کند؟ به این <em>dirty write</em> می‌گویند [28]. <strong>Transactions</strong> های در حال اجرا در <em>read committed isolation level</em> باید از <em>dirty writes</em> جلوگیری کنند، معمولاً با تاخیر انداختن <em>write</em> دوم تا زمانی که <em>transaction write</em> اول <em>committed</em> یا <em>aborted</em> شود.
    </p>
<p>
        با جلوگیری از <em>dirty writes</em>، این سطح <em>isolation</em> از برخی از انواع مشکلات <em>concurrency</em> جلوگیری می‌کند:
    </p>
<ul>
<li>
            اگر transactions چندین object را <em>update</em> کنند، <em>dirty writes</em> می‌توانند منجر به نتیجه بدی شوند. به عنوان مثال، شکل 7-5 را در نظر بگیرید، که یک وب‌سایت فروش اتومبیل‌های کارکرده را نشان می‌دهد که در آن دو نفر، آلیس و باب، به طور همزمان در حال تلاش برای خرید یک ماشین یکسان هستند. خرید یک ماشین به دو <em>database writes</em> نیاز دارد: لیست در وب‌سایت باید به‌روزرسانی شود تا خریدار را منعکس کند، و فاکتور فروش باید برای خریدار ارسال شود.
            <br/>
            در مورد شکل 7-5، فروش به باب اعطا می‌شود (زیرا او <em>update</em> برنده را به جدول فهرست‌ها انجام می‌دهد)، اما فاکتور برای آلیس ارسال می‌شود (زیرا او <em>update</em> برنده را به جدول فاکتورها انجام می‌دهد). <em>Read committed</em> از این حوادث ناگوار جلوگیری می‌کند.
        </li>
<li>
            با این حال، <em>read committed</em> از <em>race condition</em> بین دو increment counter در شکل 7-1 جلوگیری نمی‌کند. در این مورد، <em>write</em> دوم پس از <em>transaction</em> اول <em>committed</em> اتفاق می‌افتد، بنابراین این یک <em>dirty write</em> نیست. هنوز هم نادرست است، اما به دلیل دیگری—در "Preventing Lost Updates" در صفحه 242، ما در مورد چگونگی ایمن کردن چنین increment counter بحث خواهیم کرد.
        </li>
</ul>
<p>
        Weak Isolation Levels
        <br/>
        |
        <br/>
        235
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0257</div>
            </div>
        </div>
        <!-- Page 0258 -->
        <div class="chapter" id="page-0258">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<figure>
<img alt="Figure 7-5. With dirty writes, conflicting writes from different transactions can be mixed up." src="figure7-5.png"/>
<figcaption>Figure 7-5. With dirty writes, conflicting writes from different transactions can be mixed up.</figcaption>
</figure>
<p>
        با <em>dirty writes</em>، <em>writes</em> های متناقض از <strong>Transactions</strong> های مختلف را می‌توان با هم مخلوط کرد.
    </p>
<h4>Implementing read committed</h4>
<p>
<em>Read committed</em> یک <em>isolation level</em> بسیار محبوب است. این تنظیم پیش‌فرض در Oracle 11g، PostgreSQL، SQL Server 2012، MemSQL و بسیاری دیگر از databases ها است [8].
    </p>
<p>
        متداول‌ترین، databases ها از <em>row-level locks</em> برای جلوگیری از <em>dirty writes</em> استفاده می‌کنند: وقتی یک transaction می‌خواهد یک object خاص (row یا document) را اصلاح کند، ابتدا باید یک lock روی آن object به دست آورد. سپس باید آن <em>lock</em> را تا زمانی که <em>transaction</em> <em>committed</em> یا <em>aborted</em> شود، نگه دارد. فقط یک <em>transaction</em> می‌تواند <em>lock</em> را برای هر object معینی نگه دارد. اگر یک <em>transaction</em> دیگر بخواهد به همان object بنویسد، باید منتظر بماند تا <em>transaction</em> اول <em>committed</em> یا <em>aborted</em> شود قبل از اینکه بتواند <em>lock</em> را به دست آورد و ادامه دهد. این <em>locking</em> به طور خودکار توسط databases در حالت <em>read committed</em> (یا سطوح <em>isolation</em> قوی‌تر) انجام می‌شود.
    </p>
<p>
        چگونه از <em>dirty reads</em> جلوگیری کنیم؟ یک گزینه این است که از همان <em>lock</em> استفاده کنیم، و از هر <em>transaction</em> که می‌خواهد یک object را بخواند، بخواهیم که به طور خلاصه <em>lock</em> را به دست آورد و سپس بلافاصله پس از خواندن آن را دوباره آزاد کند. این امر اطمینان حاصل می‌کند که یک <em>read</em> نمی‌تواند در حالی که یک object دارای یک مقدار <em>dirty, uncommitted</em> است، اتفاق بیفتد (زیرا در آن زمان <em>lock</em> توسط <em>transaction</em> که <em>write</em> را انجام داده است، نگه داشته می‌شود).
    </p>
<p>
        با این حال، رویکرد نیاز به <em>read locks</em> در عمل خوب جواب نمی‌دهد، زیرا یک <em>long-running write transaction</em> می‌تواند <em>read-only transactions</em> های زیادی را مجبور به انتظار کند تا <em>long-running transaction</em> تکمیل شود. این به زمان پاسخگویی <em>read-only transactions</em> آسیب می‌رساند و برای operability بد است: یک کاهش سرعت در یک part از یک application می‌تواند یک اثر ضربه‌ای در یک part کاملاً متفاوت از application داشته باشد، به دلیل انتظار برای locks.
    </p>
<p>
        236
        <br/>
        |
        <br/>
        Chapter 7: Transactions
    </p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 258" src="page_0258/image_1.png"/></div>
</div>
                <div class="page-number">صفحه 0258</div>
            </div>
        </div>
        <!-- Page 0259 -->
        <div class="chapter" id="page-0259">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        vi. در زمان نگارش، تنها databases های اصلی که از <em>locks</em> برای <em>read committed isolation</em> استفاده می‌کنند، IBM DB2 و Microsoft SQL Server در پیکربندی <em>read_committed_snapshot=off</em> هستند [23, 36].
    </p>
<p>
        به همین دلیل، اکثر databases vii از <em>dirty reads</em> با استفاده از رویکرد نشان داده شده در شکل 7-4 جلوگیری می‌کنند: برای هر object که نوشته می‌شود، database هم مقدار قدیمی <em>committed</em> و هم مقدار جدید تنظیم شده توسط transaction که در حال حاضر <em>write lock</em> را نگه داشته است را به خاطر می‌آورد. در حالی که <em>transaction</em> در حال انجام است، هر <em>transaction</em> دیگری که object را می‌خواند، به سادگی مقدار قدیمی را دریافت می‌کند. فقط زمانی که مقدار جدید <em>committed</em> می‌شود، transactions به خواندن مقدار جدید تغییر می‌یابند.
    </p>
<h4>Snapshot Isolation and Repeatable Read</h4>
<p>
        اگر شما به <em>read committed isolation</em> سطحی نگاه کنید، ممکن است بخشیده شوید اگر فکر کنید که این کار همه کارهایی را که یک <em>transaction</em> باید انجام دهد، انجام می‌دهد: به <em>aborts</em> اجازه می‌دهد (برای atomicity مورد نیاز است)، از خواندن نتایج ناقص <em>transactions</em> جلوگیری می‌کند، و از <em>concurrent writes</em> جلوگیری می‌کند. در واقع، اینها ویژگی‌های مفیدی هستند، و <em>guarantees</em> بسیار قوی‌تر از آنچه می‌توانید از یک سیستم که هیچ <em>transactions</em> ندارد، دریافت کنید.
    </p>
<p>
        با این حال، هنوز راه‌های زیادی وجود دارد که می‌توانید هنگام استفاده از این <em>isolation level</em> باگ‌های <em>concurrency</em> داشته باشید. به عنوان مثال، شکل 7-6 مشکلی را نشان می‌دهد که می‌تواند با <em>read committed</em> رخ دهد.
    </p>
<figure>
<img alt="Figure 7-6. Read skew: Alice observes the database in an inconsistent state." src="figure7-6.png"/>
<figcaption>Figure 7-6. Read skew: Alice observes the database in an inconsistent state.</figcaption>
</figure>
<p>
        فرض کنید آلیس 1000 دلار پس‌انداز در یک بانک دارد که در دو حساب با 500 دلار تقسیم شده است.
        <br/>
        حالا یک <em>transaction</em> 100 دلار از یکی از حساب‌های او به حساب دیگرش منتقل می‌کند. اگر او به اندازه کافی بدشانس باشد که در همان لحظه به لیست موجودی حساب‌هایش نگاه کند که آن <em>transaction</em> در حال پردازش است، ممکن است موجودی یک حساب را در یک زمان قبل از
        <br/>
        Weak Isolation Levels
        <br/>
        |
        <br/>
        237
    </p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 259" src="page_0259/image_1.png"/></div>
</div>
                <div class="page-number">صفحه 0259</div>
            </div>
        </div>
        <!-- Page 0260 -->
        <div class="chapter" id="page-0260">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
<em>incoming payment</em> (با موجودی 500 دلار) رسیده است، و حساب دیگر پس از انجام <em>outgoing transfer</em> (موجودی جدید 400 دلار) است. در حال حاضر به نظر می‌رسد که آلیس فقط 900 دلار در حساب‌هایش دارد—به نظر می‌رسد که 100 دلار ناپدید شده است.
    </p>
<p>
        این <em>anomaly</em> یک <em>nonrepeatable read</em> یا <em>read skew</em> نامیده می‌شود: اگر آلیس بخواهد موجودی حساب 1 را دوباره در پایان <em>transaction</em> بخواند، مقدار متفاوتی (600 دلار) را نسبت به query قبلی خود می‌بیند. <em>Read skew</em> تحت <em>read committed isolation</em> قابل قبول است: موجودی حساب‌هایی که آلیس دید در واقع در زمانی که آنها را خواند، <em>committed</em> شده بودند.
    </p>
<p>
        متأسفانه اصطلاح <em>skew</em> بارگذاری شده است: ما قبلاً از آن به معنای workload نامتعادل با <em>hot spots</em> استفاده کردیم (به "Skewed Workloads and Relieving Hot Spots" در صفحه 205 مراجعه کنید)، در حالی که در اینجا به معنای <em>timing anomaly</em> است.
    </p>
<p>
        در مورد آلیس، این یک مشکل ماندگار نیست، زیرا او به احتمال زیاد موجودی حساب‌های سازگاری را می‌بیند اگر چند ثانیه بعد وب‌سایت بانکداری آنلاین را دوباره بارگیری کند. با این حال، برخی از شرایط نمی‌توانند چنین <em>inconsistency</em> موقتی را تحمل کنند:
    </p>
<h4>Backups</h4>
<p>
        تهیه یک <em>backup</em> نیاز به کپی کردن کل database دارد، که ممکن است ساعت‌ها در یک database بزرگ طول بکشد. در طول زمانی که <em>backup process</em> در حال اجرا است، <em>writes</em> همچنان به database انجام می‌شوند. بنابراین، شما ممکن است با برخی از قسمت‌های <em>backup</em> با یک نسخه قدیمی‌تر از داده‌ها و سایر قسمت‌ها با یک نسخه جدیدتر روبرو شوید. اگر نیاز به بازیابی از چنین <em>backup</em> دارید، ناهمگونی‌ها (مانند ناپدید شدن پول) دائمی می‌شوند.
    </p>
<h4>Analytic queries and integrity checks</h4>
<p>
        گاهی اوقات، ممکن است بخواهید یک query را اجرا کنید که بخش‌های بزرگی از داده‌ها را اسکن می‌کند. چنین <em>queries</em> در <em>analytics</em> (به "Transaction Processing or Analytics?" در صفحه 90 مراجعه کنید) رایج هستند، یا ممکن است بخشی از یک <em>integrity check</em> دوره‌ای باشند که همه چیز در order است (نظارت بر داده‌ها). این <em>queries</em> احتمالاً نتایج بی‌معنی را برمی‌گردانند اگر آنها بخش‌هایی از database را در زمان‌های مختلف مشاهده کنند.
    </p>
<p>
<em>Snapshot isolation</em> [28] رایج‌ترین راه‌حل برای این مشکل است. ایده این است که هر transaction از یک <em>consistent snapshot</em> از database می‌خواند—یعنی، <em>transaction</em> تمام داده‌هایی را می‌بیند که در ابتدای <em>transaction</em> در database <em>committed</em> شده است. حتی اگر داده‌ها متعاقباً توسط یک <em>transaction</em> دیگر تغییر داده شوند، هر <em>transaction</em> فقط داده‌های قدیمی را از آن نقطه زمانی خاص می‌بیند.
    </p>
<p>
<em>Snapshot isolation</em> یک مزیت برای <em>long-running, read-only queries</em> مانند <em>backups</em> و <em>analytics</em> است. استدلال در مورد معنای یک query اگر داده‌هایی که در آن
        <br/>
        Weak Isolation Levels
        <br/>
        |
        <br/>
        238
    </p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 260" src="page_0260/image_1.png"/></div>
</div>
                <div class="page-number">صفحه 0260</div>
            </div>
        </div>
        <!-- Page 0261 -->
        <div class="chapter" id="page-0261">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        vii. به طور دقیق، <em>transaction IDs</em> اعداد صحیح 32 بیتی هستند، بنابراین پس از تقریباً 4 میلیارد transactions سرریز می‌شوند. <em>Vacuum process</em> از PostgreSQL یک <em>cleanup</em> را انجام می‌دهد که اطمینان حاصل می‌کند که سرریز بر داده‌ها تأثیر نمی‌گذارد.
    </p>
<p>
        که <em>it operates</em> در حال تغییر همزمان با اجرای <em>query</em> است. هنگامی که یک transaction می‌تواند یک <em>consistent snapshot</em> از database را ببیند، در یک نقطه زمانی خاص منجمد شده است، درک آن بسیار آسان‌تر است.
    </p>
<p>
<em>Snapshot isolation</em> یک ویژگی محبوب است: توسط PostgreSQL، MySQL با <em>InnoDB storage engine</em>، Oracle، SQL Server و دیگران پشتیبانی می‌شود [23, 31, 32].
    </p>
<h4>Implementing snapshot isolation</h4>
<p>
        مانند <em>read committed isolation</em>، پیاده‌سازی‌های <em>snapshot isolation</em> معمولاً از <em>write locks</em> برای جلوگیری از <em>dirty writes</em> استفاده می‌کنند (به "Implementing read committed" در صفحه 236 مراجعه کنید)، به این معنی که یک <em>transaction</em> که <em>write</em> انجام می‌دهد می‌تواند پیشرفت <em>transaction</em> دیگری را که به همان object <em>writes</em> می‌کند، مسدود کند. با این حال، <em>reads</em> نیازی به هیچ <em>locks</em> ندارند.
    </p>
<p>
        از نظر <em>performance</em>، یک اصل کلیدی <em>snapshot isolation</em> این است که <em>readers</em> هرگز <em>writers</em> را مسدود نمی‌کنند، و <em>writers</em> هرگز <em>readers</em> را مسدود نمی‌کنند. این به database اجازه می‌دهد تا <em>long-running read queries</em> را روی یک <em>consistent snapshot</em> در همان زمان پردازش <em>writes</em> به طور معمول، بدون هیچ گونه <em>lock contention</em> بین این دو، مدیریت کند.
    </p>
<p>
        برای پیاده‌سازی <em>snapshot isolation</em>، databases ها از یک تعمیم از مکانیسمی که برای جلوگیری از <em>dirty reads</em> در شکل 7-4 دیدیم، استفاده می‌کنند. database باید به طور بالقوه چندین نسخه <em>committed</em> مختلف از یک object را نگه دارد، زیرا <em>transactions</em> در حال انجام مختلف ممکن است نیاز داشته باشند که وضعیت database را در زمان‌های مختلف ببینند. از آنجایی که چندین نسخه از یک object را در کنار هم حفظ می‌کند، این تکنیک به عنوان <em>multi-version concurrency control (MVCC)</em> شناخته می‌شود.
    </p>
<p>
        اگر یک database فقط نیاز به ارائه <em>read committed isolation</em> داشته باشد، اما نه <em>snapshot isolation</em>، کافی است که دو نسخه از یک object را نگه دارد: نسخه <em>committed</em> و نسخه <em>overwritten-but-not-yet-committed</em>. با این حال، <em>storage engines</em> که از <em>snapshot isolation</em> پشتیبانی می‌کنند، معمولاً از MVCC برای سطح <em>read committed isolation</em> خود نیز استفاده می‌کنند. یک رویکرد معمول این است که <em>read committed</em> از یک <em>snapshot</em> جداگانه برای هر <em>query</em> استفاده می‌کند، در حالی که <em>snapshot isolation</em> از همان <em>snapshot</em> برای یک <em>transaction</em> کامل استفاده می‌کند.
    </p>
<p>
        شکل 7-7 نحوه پیاده‌سازی <em>MVCC-based snapshot isolation</em> در PostgreSQL [31] را نشان می‌دهد (پیاده‌سازی‌های دیگر مشابه هستند). هنگامی که یک <em>transaction</em> شروع می‌شود، یک <em>unique, always-increasing</em> vii <em>transaction ID (txid)</em> به آن داده می‌شود. هر زمان که یک <em>transaction</em> چیزی را به database <em>writes</em> می‌کند، داده‌هایی که می‌نویسد با <em>transaction ID</em> نویسنده برچسب‌گذاری می‌شوند.
        <br/>
        Weak Isolation Levels
        <br/>
        |
        <br/>
        239
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0261</div>
            </div>
        </div>
        <!-- Page 0262 -->
        <div class="chapter" id="page-0262">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<figure>
<img alt="Figure 7-7. Implementing snapshot isolation using multi-version objects." src="figure7-7.png"/>
<figcaption>Figure 7-7. Implementing snapshot isolation using multi-version objects.</figcaption>
</figure>
<p>
        پیاده‌سازی <em>snapshot isolation</em> با استفاده از <em>multi-version objects</em>.
    </p>
<p>
        هر <em>row</em> در یک table دارای یک فیلد <em>created_by</em> است که حاوی ID <em>transaction</em> است که این <em>row</em> را در table درج کرده است. علاوه بر این، هر <em>row</em> دارای یک فیلد <em>deleted_by</em> است که در ابتدا خالی است. اگر یک <em>transaction</em> یک <em>row</em> را حذف کند، <em>row</em> در واقع از database حذف نمی‌شود، اما با تنظیم فیلد <em>deleted_by</em> روی ID <em>transaction</em> که درخواست حذف را داده است، برای حذف علامت‌گذاری می‌شود. در زمانی دیگر، هنگامی که مشخص شد که هیچ <em>transaction</em> دیگری نمی‌تواند به داده‌های حذف شده دسترسی داشته باشد، یک فرآیند <em>garbage collection</em> در database هر <em>row</em> را که برای حذف علامت‌گذاری شده است حذف می‌کند و فضای آنها را آزاد می‌کند.
    </p>
<p>
        یک <em>update</em> در داخل به یک <em>delete</em> و یک <em>create</em> ترجمه می‌شود. به عنوان مثال، در شکل 7-7، <em>transaction</em> 13 مبلغ 100 دلار از حساب 2 کم می‌کند و balance را از 500 دلار به 400 دلار تغییر می‌دهد. table accounts در حال حاضر در واقع شامل دو <em>rows</em> برای حساب 2 است: یک <em>row</em> با موجودی 500 دلار که توسط <em>transaction</em> 13 علامت‌گذاری شده است، و یک <em>row</em> با موجودی 400 دلار که توسط <em>transaction</em> 13 ایجاد شده است.
    </p>
<h4>Visibility rules for observing a consistent snapshot</h4>
<p>
        هنگامی که یک <em>transaction</em> از database می‌خواند، از <em>transaction IDs</em> برای تصمیم‌گیری در مورد اینکه کدام objects را می‌تواند ببیند و کدام یک نامرئی هستند، استفاده می‌شود. با تعریف دقیق <em>visibility rules</em>،
    </p>
<p>
        240
        <br/>
        |
        <br/>
        Chapter 7: Transactions
    </p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 262" src="page_0262/image_1.png"/></div>
</div>
                <div class="page-number">صفحه 0262</div>
            </div>
        </div>
        <!-- Page 0263 -->
        <div class="chapter" id="page-0263">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        the database می‌تواند یک <em>consistent snapshot</em> از database را به application ارائه دهد. این به شرح زیر عمل می‌کند:
    </p>
<ol>
<li>
            در ابتدای هر <em>transaction</em>، database فهرستی از تمام <em>transactions</em> های دیگری که در حال انجام هستند (هنوز <em>committed</em> یا <em>aborted</em> نشده‌اند) در آن زمان تهیه می‌کند. هر <em>writes</em> که آن <em>transactions</em> انجام داده‌اند نادیده گرفته می‌شوند، حتی اگر transactions متعاقباً <em>commit</em> شوند.
        </li>
<li>
            هر <em>writes</em> که توسط <em>aborted transactions</em> انجام شده است، نادیده گرفته می‌شود.
        </li>
<li>
            هر <em>writes</em> که توسط <em>transactions</em> با <em>transaction ID</em> بعدی (یعنی که پس از شروع <em>transaction</em> فعلی شروع شده‌اند) انجام شده است، نادیده گرفته می‌شود، صرف نظر از اینکه آن <em>transactions</em> <em>committed</em> شده‌اند یا خیر.
        </li>
<li>
            همه <em>writes</em> های دیگر برای <em>queries</em> application قابل مشاهده هستند.
        </li>
</ol>
<p>
        این قوانین برای ایجاد و حذف objects اعمال می‌شود. در شکل 7-7، هنگامی که <em>transaction</em> 12 از حساب 2 می‌خواند، موجودی 500 دلار را می‌بیند زیرا حذف موجودی 500 دلاری توسط <em>transaction</em> 13 انجام شده است (طبق قانون 3، <em>transaction</em> 12 نمی‌تواند یک حذف انجام شده توسط <em>transaction</em> 13 را ببیند)، و ایجاد موجودی 400 دلاری هنوز قابل مشاهده نیست (با همان قانون).
    </p>
<p>
        به عبارت دیگر، یک object در صورت درست بودن هر دو شرط زیر قابل مشاهده است:
    </p>
<ul>
<li>
            در زمانی که <em>transaction</em> خواننده شروع شد، <em>transaction</em> که object را ایجاد کرد، قبلاً <em>committed</em> شده بود.
        </li>
<li>
            object برای حذف علامت‌گذاری نشده است، یا اگر شده است، <em>transaction</em> که درخواست حذف را داده بود، هنوز در زمانی که <em>transaction</em> خواننده شروع شد، <em>committed</em> نشده بود.
        </li>
</ul>
<p>
        یک <em>long-running transaction</em> ممکن است برای مدت طولانی به استفاده از یک <em>snapshot</em> ادامه دهد، و همچنان به خواندن values هایی ادامه دهد که (از دیدگاه other transactions) مدت‌هاست بازنویسی یا حذف شده‌اند. با هرگز <em>updating values in place</em> اما در عوض ایجاد یک نسخه جدید هر بار که یک value تغییر می‌کند، database می‌تواند یک <em>consistent snapshot</em> ارائه دهد در حالی که فقط یک <em>small overhead</em> ایجاد می‌کند.
    </p>
<h4>Indexes and snapshot isolation</h4>
<p>
        چگونه <em>indexes</em> در یک database چند نسخه کار می‌کنند؟ یک گزینه این است که <em>index</em> به سادگی به تمام نسخه‌های یک object اشاره کند و از یک <em>index query</em> بخواهیم که هر نسخه‌های object را که برای <em>transaction</em> فعلی قابل مشاهده نیستند، فیلتر کند. هنگامی که <em>garbage collection</em> نسخه‌های قدیمی object را که دیگر برای هیچ <em>transaction</em> قابل مشاهده نیستند، حذف می‌کند، ورودی‌های <em>index</em> مربوطه نیز می‌توانند حذف شوند.
    </p>
<p>
        در عمل، بسیاری از جزئیات پیاده‌سازی، <em>performance</em> از <em>multi-version concurrency control</em> را تعیین می‌کنند. به عنوان مثال، PostgreSQL دارای بهینه‌سازی‌هایی برای جلوگیری از <em>index updates</em> است اگر نسخه‌های مختلف از یک object یکسان بتوانند در یک صفحه قرار گیرند [31].
    </p>
<p>
        Weak Isolation Levels
        <br/>
        |
        <br/>
        241
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0263</div>
            </div>
        </div>
        <!-- Page 0264 -->
        <div class="chapter" id="page-0264">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        یک رویکرد دیگر در CouchDB، Datomic و LMDB استفاده می‌شود. اگرچه آنها همچنین از B-trees استفاده می‌کنند (به "B-Trees" در صفحه 79 مراجعه کنید)، اما آنها از یک <em>append-only/copy-on-write variant</em> استفاده می‌کنند که صفحات tree را هنگام <em>updated</em> شدن بازنویسی نمی‌کند، بلکه یک کپی جدید از هر صفحه اصلاح شده ایجاد می‌کند. صفحات parent، تا ریشه tree، کپی شده و برای اشاره به نسخه‌های جدید صفحات child خود <em>updated</em> می‌شوند. هر صفحه‌ای که تحت تأثیر یک <em>write</em> قرار نمی‌گیرد، نیازی به کپی شدن ندارد و <em>immutable</em> باقی می‌ماند [33, 34, 35].
    </p>
<p>
        با <em>append-only B-trees</em>، هر <em>write transaction</em> (یا دسته ای از transactions) یک ریشه جدید B-tree ایجاد می‌کند، و یک ریشه خاص یک <em>consistent snapshot</em> از database در نقطه‌ای است که ایجاد شده است. نیازی به فیلتر کردن objects بر اساس <em>transaction IDs</em> نیست زیرا <em>writes</em> بعدی نمی‌توانند یک B-tree موجود را تغییر دهند. آنها فقط می‌توانند ریشه‌های جدید tree را ایجاد کنند. با این حال، این رویکرد همچنین به یک فرآیند پس‌زمینه برای compaction و <em>garbage collection</em> نیاز دارد.
    </p>
<h4>Repeatable read and naming confusion</h4>
<p>
<em>Snapshot isolation</em> یک <em>isolation level</em> مفید است، به ویژه برای <em>read-only transactions</em>. با این حال، بسیاری از databases هایی که آن را پیاده‌سازی می‌کنند، آن را با نام‌های مختلف می‌نامند. در Oracle، <em>serializable</em> نامیده می‌شود، و در PostgreSQL و MySQL، <em>repeatable read</em> نامیده می‌شود [23].
    </p>
<p>
        دلیل این سردرگمی نام‌گذاری این است که <em>SQL standard</em> مفهوم <em>snapshot isolation</em> را ندارد، زیرا این استاندارد مبتنی بر تعریف 1975 System R از <em>isolation levels</em> است [2] و <em>snapshot isolation</em> هنوز اختراع نشده بود.
    </p>
<p>
        در عوض، <em>repeatable read</em> را تعریف می‌کند، که ظاهراً شبیه <em>snapshot isolation</em> است. PostgreSQL و MySQL سطح <em>snapshot isolation</em> خود را <em>repeatable read</em> می‌نامند زیرا الزامات استاندارد را برآورده می‌کند، و بنابراین آنها می‌توانند ادعای انطباق با استانداردها را داشته باشند.
    </p>
<p>
        متأسفانه، تعریف <em>isolation levels</em> از <em>SQL standard</em> ناقص است - مبهم، نادرست و به اندازه کافی مستقل از پیاده‌سازی نیست که یک استاندارد باید باشد [28]. اگرچه چندین databases <em>repeatable read</em> را پیاده‌سازی می‌کنند، تفاوت‌های زیادی در <em>guarantees</em> که آنها واقعاً ارائه می‌دهند وجود دارد، علیرغم اینکه ظاهراً استاندارد شده‌اند [23]. یک تعریف رسمی از <em>repeatable read</em> در <em>research literature</em> وجود داشته است [29, 30]، اما اکثر پیاده‌سازی‌ها آن تعریف رسمی را برآورده نمی‌کنند. و علاوه بر این، IBM DB2 از "<em>repeatable read</em>" برای اشاره به <em>serializability</em> استفاده می‌کند [8].
    </p>
<p>
        در نتیجه، هیچ‌کس واقعاً نمی‌داند <em>repeatable read</em> به چه معناست.
    </p>
<h4>Preventing Lost Updates</h4>
<p>
<em>Read committed</em> و <em>snapshot isolation levels</em> که تاکنون مورد بحث قرار دادیم، در درجه اول در مورد <em>guarantees</em> در مورد آنچه که یک <em>read-only transaction</em> می‌تواند در حضور <em>concurrent writes</em> ببیند، بوده‌اند. ما بیشتر مسئله دو <strong>Transactions</strong> را که به طور همزمان <em>writing</em> می‌کنند نادیده گرفته‌ایم—ما فقط در مورد <em>dirty writes</em> (به "No dirty writes" در صفحه 235 مراجعه کنید)، یک نوع خاص از تداخل <em>write-write</em> که می‌تواند رخ دهد، بحث کرده‌ایم.
    </p>
<p>
        242
        <br/>
        |
        <br/>
        Chapter 7: Transactions
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0264</div>
            </div>
        </div>
        <!-- Page 0265 -->
        <div class="chapter" id="page-0265">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        viii. اگرچه بیان ویرایش یک document متنی به عنوان یک stream از <em>atomic mutations</em> امکان‌پذیر است، اما کاملاً پیچیده است. برای برخی از اشاره‌گرها، به "Automatic Conflict Resolution" در صفحه 174 مراجعه کنید.
    </p>
<p>
        چندین نوع جالب دیگر از <em>conflicts</em> وجود دارد که می‌تواند بین <em>concurrently writing transactions</em> رخ دهد. شناخته‌شده‌ترین آنها، مشکل <em>lost update</em> است، که در شکل 7-1 با مثال دو <em>counter increments</em> همزمان نشان داده شده است.
    </p>
<p>
        مشکل <em>lost update</em> می‌تواند رخ دهد اگر یک application مقداری value را از database می‌خواند، آن را اصلاح می‌کند، و مقدار اصلاح شده را دوباره می‌نویسد (یک <em>read-modify-write cycle</em>). اگر دو <em>transactions</em> این کار را به طور همزمان انجام دهند، یکی از اصلاحات ممکن است از دست برود، زیرا <em>write</em> دوم شامل <em>modification</em> اول نیست. (ما گاهی اوقات می‌گوییم که <em>write</em> بعدی، <em>write</em> قبلی را <em>clobbers</em> می‌کند.) این الگو در سناریوهای مختلفی رخ می‌دهد:
    </p>
<ul>
<li>
            افزایش یک <em>counter</em> یا به‌روزرسانی موجودی حساب (نیاز به خواندن مقدار فعلی، محاسبه مقدار جدید و نوشتن مجدد مقدار <em>updated</em> دارد)
        </li>
<li>
            ایجاد یک تغییر محلی در یک value پیچیده، به عنوان مثال، افزودن یک عنصر به یک list در یک document <em>JSON</em> (نیاز به تجزیه document، ایجاد تغییر، و نوشتن مجدد document اصلاح شده)
        </li>
<li>
            دو user به طور همزمان یک صفحه ویکی را ویرایش می‌کنند، جایی که هر user تغییرات خود را با ارسال کل محتوای صفحه به server ذخیره می‌کند، و هر چیزی را که در حال حاضر در database وجود دارد، بازنویسی می‌کند.
        </li>
</ul>
<p>
        از آنجایی که این یک مشکل بسیار رایج است، راه‌حل‌های مختلفی توسعه یافته است.
    </p>
<h4>Atomic write operations</h4>
<p>
        بسیاری از databases ها operations update atomic را ارائه می‌دهند، که نیاز به پیاده‌سازی <em>read-modify-write cycles</em> را در کد application حذف می‌کند. اگر کد شما را بتوان بر حسب آن operations بیان کرد، آنها معمولاً بهترین راه‌حل هستند. به عنوان مثال، دستورالعمل زیر در اکثر relational databases ها <em>concurrency-safe</em> است:
    </p>
<pre><code class="language-sql">UPDATE counters SET value = value + 1 WHERE key = 'foo';
</code></pre>
<p>
        به طور مشابه، <em>document databases</em> مانند MongoDB operations atomic را برای ایجاد <em>local modifications</em> در بخشی از یک document <em>JSON</em> ارائه می‌دهند، و Redis operations atomic را برای اصلاح ساختارهای داده مانند <em>priority queues</em> ارائه می‌دهد. همه <em>writes</em> را نمی‌توان به راحتی بر حسب operations atomic بیان کرد—به عنوان مثال، <em>updates</em> به یک صفحه ویکی شامل <em>text editing</em> دلخواه است viii—اما در شرایطی که operations atomic قابل استفاده هستند، آنها معمولاً بهترین انتخاب هستند.
    </p>
<p>
        Operations atomic معمولاً با گرفتن یک <em>exclusive lock</em> روی object هنگام خواندن آن پیاده‌سازی می‌شوند تا هیچ <em>transaction</em> دیگری نتواند آن را تا زمانی که <em>update</em> انجام نشده است، بخواند.
        <br/>
        Weak Isolation Levels
        <br/>
        |
        <br/>
        243
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0265</div>
            </div>
        </div>
        <!-- Page 0266 -->
        <div class="chapter" id="page-0266">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        This technique is sometimes known as <em>cursor stability</em> [36, 37]. Another option is to simply force all atomic operations to be executed on a single thread.
    </p>
<p>
        متاسفانه، فریم‌ورک‌های <em>object-relational mapping</em>، نوشتن کد را که به طور تصادفی چرخه‌های <em>read-modify-write</em> ناامن را انجام می‌دهد، آسان می‌کنند به جای استفاده از <em>atomic operations</em> ارائه شده توسط database [38]. اگر بدانید چه می‌کنید، این یک مشکل نیست، اما به طور بالقوه منبع باگ‌های ظریفی است که یافتن آنها با تست دشوار است.
    </p>
<h4>Explicit locking</h4>
<p>
        اگر operations atomic داخلی database عملکرد لازم را ارائه ندهند، یک گزینه دیگر برای جلوگیری از <em>lost updates</em>، این است که application objects را که قرار است <em>updated</em> شوند، صریحاً lock کند. سپس application می‌تواند یک <em>read-modify-write cycle</em> را انجام دهد، و اگر هر <em>transaction</em> دیگری همزمان سعی کند همان object را بخواند، مجبور می‌شود منتظر بماند تا <em>read-modify-write cycle</em> اول کامل شود.
    </p>
<p>
        به عنوان مثال، یک بازی چندنفره را در نظر بگیرید که در آن چندین player می‌توانند به طور همزمان یک شکل یکسان را حرکت دهند. در این حالت، یک operation atomic ممکن است کافی نباشد، زیرا application همچنین باید اطمینان حاصل کند که حرکت player از قوانین بازی پیروی می‌کند، که شامل برخی از logic است که شما نمی‌توانید آن را به طور منطقی به عنوان یک <em>database query</em> پیاده‌سازی کنید. در عوض، ممکن است از یک lock برای جلوگیری از حرکت همزمان دو player روی یک قطعه یکسان استفاده کنید، همانطور که در مثال 7-1 نشان داده شده است.
    </p>
<p>
        Example 7-1. Explicitly locking rows to prevent lost updates
    </p>
<pre><code class="language-sql">BEGIN TRANSACTION;
SELECT * FROM figures
  WHERE name = 'robot' AND game_id = 222
  FOR UPDATE; 
-- Check whether move is valid, then update the position
-- of the piece that was returned by the previous SELECT.
UPDATE figures SET position = 'c4' WHERE id = 1234;
COMMIT;
</code></pre>
<p>
        عبارت <em>FOR UPDATE</em> نشان می‌دهد که database باید یک <em>lock</em> روی تمام <em>rows</em> برگشت داده شده توسط این query اعمال کند.
    </p>
<p>
        این کار می‌کند، اما برای درست انجام دادن آن، باید با دقت در مورد logic application خود فکر کنید. فراموش کردن افزودن یک <em>lock</em> لازم در جایی از کد آسان است، و بنابراین یک <em>race condition</em> ایجاد می‌شود.
    </p>
<p>
        244
        <br/>
        |
        <br/>
        Chapter 7: Transactions
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0266</div>
            </div>
        </div>
        <!-- Page 0267 -->
        <div class="chapter" id="page-0267">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<h4>Automatically detecting lost updates</h4>
<p>
<em>Atomic operations</em> و <em>locks</em> راه‌هایی برای جلوگیری از <em>lost updates</em> هستند با مجبور کردن چرخه‌های <em>read-modify-write</em> برای انجام به صورت متوالی. یک جایگزین این است که به آنها اجازه دهیم به صورت موازی اجرا شوند و، اگر <em>transaction manager</em> یک <em>lost update</em> را تشخیص دهد، transaction را <em>abort</em> کند و آن را مجبور به تکرار چرخه <em>read-modify-write</em> خود کند.
    </p>
<p>
        یک مزیت این رویکرد این است که databases ها می‌توانند این بررسی را به طور مؤثر در ارتباط با <em>snapshot isolation</em> انجام دهند. در واقع، <em>repeatable read</em> از PostgreSQL، <em>serializable</em> از Oracle، و <em>snapshot isolation levels</em> از SQL Server به طور خودکار زمانی را که یک <em>lost update</em> رخ داده است، تشخیص می‌دهند و <em>transaction</em> مقصر را <em>abort</em> می‌کنند. با این حال، <em>repeatable read</em> از MySQL/InnoDB، <em>lost updates</em> را تشخیص نمی‌دهد [23]. برخی از نویسندگان [28, 30] استدلال می‌کنند که یک database باید از <em>lost updates</em> جلوگیری کند تا واجد شرایط ارائه <em>snapshot isolation</em> باشد، بنابراین MySQL تحت این تعریف <em>snapshot isolation</em> را ارائه نمی‌دهد.
    </p>
<p>
        تشخیص <em>lost update</em> یک ویژگی عالی است، زیرا نیازی به استفاده از هیچ ویژگی database خاصی در کد application ندارد—شما ممکن است استفاده از یک lock یا یک <em>atomic operation</em> را فراموش کنید و در نتیجه یک باگ را معرفی کنید، اما تشخیص <em>lost update</em> به طور خودکار اتفاق می‌افتد و بنابراین کمتر مستعد خطا است.
    </p>
<h4>Compare-and-set</h4>
<p>
        در databases هایی که <strong>Transactions</strong> را ارائه نمی‌دهند، گاهی اوقات یک operation <em>atomic compare-and-set</em> پیدا می‌کنید (قبلاً در "Single-object writes" در صفحه 230 ذکر شده است). هدف از این operation جلوگیری از <em>lost updates</em> با اجازه دادن به <em>update</em> فقط در صورتی است که value از زمانی که شما آن را خوانده‌اید، تغییر نکرده باشد. اگر مقدار فعلی با آنچه قبلاً خوانده‌اید مطابقت نداشته باشد، <em>update</em> هیچ تاثیری ندارد، و چرخه <em>read-modify-write</em> باید دوباره امتحان شود.
    </p>
<p>
        به عنوان مثال، برای جلوگیری از <em>concurrently updating</em> کردن دو user صفحه ویکی یکسان، ممکن است چیزی شبیه به این را امتحان کنید، و انتظار داشته باشید که <em>update</em> فقط در صورتی رخ دهد که محتوای صفحه از زمانی که user شروع به ویرایش آن کرده است، تغییر نکرده باشد:
    </p>
<pre><code class="language-sql">-- This may or may not be safe, depending on the database implementation
UPDATE wiki_pages SET content = 'new content'
  WHERE id = 1234 AND content = 'old content';
</code></pre>
<p>
        اگر محتوا تغییر کرده باشد و دیگر با 'old content' مطابقت نداشته باشد، این <em>update</em> هیچ تاثیری نخواهد داشت، بنابراین باید بررسی کنید که آیا <em>update</em> انجام شده است یا خیر و در صورت لزوم دوباره امتحان کنید. با این حال، اگر database به clause WHERE اجازه دهد از یک <em>old snapshot</em> بخواند، این statement ممکن است از <em>lost updates</em> جلوگیری نکند، زیرا شرط ممکن است درست باشد حتی اگر یک <em>write</em> همزمان دیگر در حال انجام باشد. قبل از تکیه بر آن، بررسی کنید که آیا operation <em>compare-and-set</em> database شما امن است یا خیر.
    </p>
<p>
        Weak Isolation Levels
        <br/>
        |
        <br/>
        245
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0267</div>
            </div>
        </div>
        <!-- Page 0268 -->
        <div class="chapter" id="page-0268">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<h4>Conflict resolution and replication</h4>
<p>
        در databases های replicated (به فصل 5 مراجعه کنید)، جلوگیری از <em>lost updates</em> بعد دیگری به خود می‌گیرد: از آنجایی که آنها کپی‌هایی از داده‌ها را در چندین node دارند، و داده‌ها به طور بالقوه می‌توانند به طور همزمان در nodes مختلف اصلاح شوند، برای جلوگیری از <em>lost updates</em> باید مراحل اضافی انجام شود.
    </p>
<p>
<em>Locks</em> و operations <em>compare-and-set</em> فرض می‌کنند که یک کپی واحد و به‌روز از داده‌ها وجود دارد. با این حال، databases ها با <em>multi-leader</em> یا <em>leaderless replication</em> معمولاً به چندین <em>writes</em> اجازه می‌دهند تا به طور همزمان اتفاق بیفتند و آنها را به‌صورت ناهمزمان <em>replicate</em> می‌کنند، بنابراین آنها نمی‌توانند تضمین کنند که یک کپی واحد و به‌روز از داده‌ها وجود دارد. بنابراین، تکنیک‌های مبتنی بر <em>locks</em> یا <em>compare-and-set</em> در این زمینه اعمال نمی‌شوند. (ما این موضوع را با جزئیات بیشتر در "Linearizability" در صفحه 324 دوباره بررسی خواهیم کرد.)
    </p>
<p>
        در عوض، همانطور که در "Detecting Concurrent Writes" در صفحه 184 مورد بحث قرار گرفت، یک رویکرد رایج در چنین databases های <em>replicated</em> این است که به <em>concurrent writes</em> اجازه دهیم چندین نسخه متناقض از یک value ایجاد کنند (که به عنوان <em>siblings</em> نیز شناخته می‌شوند)، و از کد application یا ساختارهای داده ویژه برای حل و ادغام این نسخه‌ها پس از fact استفاده شود.
    </p>
<p>
        Operations Atomic می‌توانند در یک context <em>replicated</em> به خوبی کار کنند، به خصوص اگر <em>commutative</em> باشند (یعنی، شما می‌توانید آنها را به ترتیب متفاوتی در <em>replicas</em> های مختلف اعمال کنید، و همچنان همان نتیجه را بگیرید). به عنوان مثال، افزایش یک counter یا افزودن یک عنصر به یک set عملیات <em>commutative</em> هستند. این ایده پشت <em>datatypes</em> از Riak 2.0 است، که از <em>lost updates</em> در سراسر replicas جلوگیری می‌کند. هنگامی که یک value به طور همزمان توسط clients مختلف به‌روزرسانی می‌شود، Riak به طور خودکار <em>updates</em> را به گونه‌ای ادغام می‌کند که هیچ <em>updates</em> از دست نرود [39].
    </p>
<p>
        از سوی دیگر، روش <em>last write wins (LWW) conflict resolution</em> مستعد <em>lost updates</em> است، همانطور که در "Last write wins (discarding concurrent writes)" در صفحه 186 مورد بحث قرار گرفت. متأسفانه، LWW پیش‌فرض در بسیاری از databases های replicated است.
    </p>
<h4>Write Skew and Phantoms</h4>
<p>
        در بخش‌های قبلی ما <em>dirty writes</em> و <em>lost updates</em> را دیدیم، دو نوع از <em>race conditions</em> که می‌توانند زمانی رخ دهند که <strong>Transactions</strong> های مختلف به طور همزمان سعی در <em>write</em> به یک object یکسان داشته باشند. به منظور جلوگیری از <em>data corruption</em>، باید از آن <em>race conditions</em> جلوگیری شود—یا به طور خودکار توسط database، یا با اقدامات احتیاطی دستی مانند استفاده از <em>locks</em> یا operations atomic <em>write</em>.
    </p>
<p>
        با این حال، این پایان لیست <em>potential race conditions</em> که می‌تواند بین <em>concurrent writes</em> رخ دهد، نیست. در این بخش ما به برخی از مثال‌های ظریف‌تر از <em>conflicts</em> خواهیم پرداخت.
    </p>
<p>
        برای شروع، این مثال را تصور کنید: شما در حال نوشتن یک application برای پزشکان هستید تا شیفت‌های <em>on-call</em> خود را در یک بیمارستان مدیریت کنند. بیمارستان معمولاً سعی می‌کند در هر زمانی چندین پزشک را در <em>on-call</em> داشته باشد، اما قطعاً باید حداقل یک پزشک در <em>on-call</em> داشته باشد. پزشکان
        <br/>
        246
        <br/>
        |
        <br/>
        Chapter 7: Transactions
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0268</div>
            </div>
        </div>
        <!-- Page 0269 -->
        <div class="chapter" id="page-0269">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        می‌توانند شیفت‌های خود را (به عنوان مثال، اگر خودشان بیمار هستند) رها کنند، به شرط اینکه حداقل یک همکار در آن شیفت <em>on call</em> باقی بماند [40, 41].
    </p>
<p>
        حالا تصور کنید که آلیس و باب دو پزشک <em>on-call</em> برای یک شیفت خاص هستند.
        <br/>
        هر دو احساس ناخوشی می‌کنند، بنابراین هر دو تصمیم می‌گیرند که درخواست مرخصی بدهند. متاسفانه، آنها تقریباً در یک زمان به دکمه رفتن از <em>on call</em> کلیک می‌کنند. آنچه در ادامه رخ می‌دهد در شکل 7-8 نشان داده شده است.
    </p>
<figure>
<img alt="Figure 7-8. Example of write skew causing an application bug." src="figure7-8.png"/>
<figcaption>Figure 7-8. Example of write skew causing an application bug.</figcaption>
</figure>
<p>
        در هر transaction، application شما ابتدا بررسی می‌کند که دو یا چند پزشک در حال حاضر <em>on call</em> هستند. اگر بله، فرض می‌کند که برای یک پزشک بی‌خطر است که <em>off call</em> برود. از آنجایی که database از <em>snapshot isolation</em> استفاده می‌کند، هر دو بررسی 2 را برمی‌گردانند، بنابراین هر دو <em>transactions</em> به مرحله بعد ادامه می‌دهند. آلیس رکورد خودش را <em>update</em> می‌کند تا خود را از <em>on call</em> خارج کند، و باب نیز رکورد خود را <em>update</em> می‌کند. هر دو <em>transactions commit</em> می‌کنند، و اکنون هیچ پزشکی در <em>on call</em> نیست.
    </p>
<p>
        requirement شما مبنی بر داشتن حداقل یک پزشک در <em>on call</em> نقض شده است.
    </p>
<h4>Characterizing write skew</h4>
<p>
        این <em>anomaly</em>، <em>write skew</em> نامیده می‌شود [28]. این نه یک <em>dirty write</em> است و نه یک <em>lost update</em>، زیرا دو <em>transactions</em> در حال به‌روزرسانی دو object مختلف (به ترتیب رکوردهای <em>on-call</em> آلیس و باب) هستند. کمتر مشخص است که یک conflict در اینجا رخ داده است، اما قطعاً یک <em>race condition</em> است: اگر دو <em>transactions</em> یکی پس از دیگری اجرا می‌شدند،
        <br/>
        Weak Isolation Levels
        <br/>
        |
        <br/>
        247
    </p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 269" src="page_0269/image_1.png"/></div>
</div>
                <div class="page-number">صفحه 0269</div>
            </div>
        </div>
        <!-- Page 0270 -->
        <div class="chapter" id="page-0270">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        doctor از رفتن از <em>on call</em> جلوگیری می‌شد. رفتار ناهنجار فقط به این دلیل ممکن بود که <em>transactions</em> به طور همزمان اجرا می‌شدند.
    </p>
<p>
        شما می‌توانید به <em>write skew</em> به عنوان یک تعمیم از مشکل <em>lost update</em> فکر کنید. <em>Write skew</em> می‌تواند رخ دهد اگر دو <em>transactions</em> یک object های یکسان را بخوانند، و سپس برخی از آن object ها را <em>update</em> کنند (<em>transactions</em> های مختلف ممکن است object های مختلف را <em>update</em> کنند). در مورد خاصی که <em>transactions</em> های مختلف، object یکسانی را <em>update</em> می‌کنند، شما یک <em>dirty write</em> یا <em>lost update anomaly</em> (بسته به زمان‌بندی) دریافت می‌کنید.
    </p>
<p>
        ما دیدیم که راه‌های مختلفی برای جلوگیری از <em>lost updates</em> وجود دارد. با <em>write skew</em>، گزینه‌های ما محدودتر هستند:
    </p>
<ul>
<li>
            Operations Atomic تک object کمکی نمی‌کند، زیرا چندین object درگیر هستند.
        </li>
<li>
            تشخیص خودکار <em>lost updates</em> که در برخی از پیاده‌سازی‌های <em>snapshot isolation</em> پیدا می‌کنید، متاسفانه کمکی هم نمی‌کند: <em>write skew</em> به طور خودکار در <em>repeatable read</em> از PostgreSQL، <em>repeatable read</em> از MySQL/InnoDB، <em>serializable</em> از Oracle، یا <em>snapshot isolation level</em> از SQL Server تشخیص داده نمی‌شود [23]. جلوگیری خودکار از <em>write skew</em> نیازمند <em>true serializable isolation</em> است (به "Serializability" در صفحه 251 مراجعه کنید).
        </li>
<li>
            برخی از databases ها به شما اجازه می‌دهند تا <em>constraints</em> را پیکربندی کنید، که سپس توسط database اعمال می‌شوند (به عنوان مثال، <em>uniqueness, foreign key constraints</em>، یا محدودیت‌هایی برای یک value خاص). با این حال، برای تعیین اینکه حداقل یک پزشک باید در <em>on call</em> باشد، شما به یک <em>constraint</em> نیاز دارید که شامل multiple objects می‌شود. اکثر databases ها پشتیبانی داخلی از این <em>constraints</em> را ندارند، اما ممکن است بتوانید آنها را با <em>triggers</em> یا <em>materialized views</em> پیاده‌سازی کنید، بسته به database [42].
        </li>
<li>
            اگر نمی‌توانید از یک سطح <em>serializable isolation</em> استفاده کنید، بهترین گزینه دوم در این مورد احتمالاً این است که <em>rows</em> هایی را که <em>transaction</em> به آنها وابسته است، صریحاً lock کنید. در مثال پزشکان، می‌توانید چیزی شبیه به این را بنویسید:
            <pre><code class="language-sql">BEGIN TRANSACTION;
SELECT * FROM doctors
  WHERE on_call = true
  AND shift_id = 1234 FOR UPDATE; 
UPDATE doctors
  SET on_call = false
  WHERE name = 'Alice'
  AND shift_id = 1234;
COMMIT;
</code></pre>
            همانطور که قبلاً، <em>FOR UPDATE</em> به database می‌گوید که تمام <em>rows</em> های برگشت داده شده توسط این query را <em>lock</em> کند.
        </li>
</ul>
<p>
        248
        <br/>
        |
        <br/>
        Chapter 7: Transactions
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0270</div>
            </div>
        </div>
        <!-- Page 0271 -->
        <div class="chapter" id="page-0271">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        ix. در PostgreSQL می‌توانید این کار را با استفاده از <em>range types</em> ظریف‌تر انجام دهید، اما آنها به طور گسترده در databases های دیگر پشتیبانی نمی‌شوند.
    </p>
<h4>More examples of write skew</h4>
<p>
<em>Write skew</em> ممکن است در ابتدا یک مسئله باطنی به نظر برسد، اما هنگامی که از آن آگاه شدید، ممکن است موقعیت‌های بیشتری را که می‌تواند رخ دهد، متوجه شوید. در اینجا چند نمونه دیگر آورده شده است:
    </p>
<h4>Meeting room booking system</h4>
<p>
        فرض کنید می‌خواهید اجرا کنید که نمی‌تواند دو رزرو برای یک اتاق جلسه یکسان در یک زمان یکسان وجود داشته باشد [43]. وقتی شخصی می‌خواهد رزرو کند، ابتدا هر گونه رزرو متناقض (یعنی، رزرو برای همان اتاق با یک بازه زمانی همپوشانی) را بررسی می‌کنید، و اگر هیچ‌کدام پیدا نشد، جلسه را ایجاد می‌کنید (به مثال 7-2 مراجعه کنید).ix
    </p>
<p>
        Example 7-2. A meeting room booking system tries to avoid double-booking (not
        safe under snapshot isolation)
    </p>
<pre><code class="language-sql">BEGIN TRANSACTION;
-- Check for any existing bookings that overlap with the period of noon-1pm
SELECT COUNT(*) FROM bookings
  WHERE room_id = 123 AND
    end_time &gt; '2015-01-01 12:00' AND start_time &lt; '2015-01-01 13:00';
-- If the previous query returned zero:
INSERT INTO bookings
  (room_id, start_time, end_time, user_id)
  VALUES (123, '2015-01-01 12:00', '2015-01-01 13:00', 666);
COMMIT;
</code></pre>
<p>
        متاسفانه، <em>snapshot isolation</em> از اینکه یک user دیگر به طور همزمان یک جلسه متناقض را درج کند، جلوگیری نمی‌کند. به منظور تضمین اینکه شما تداخل برنامه‌ریزی نخواهید داشت، شما دوباره به <em>serializable isolation</em> نیاز دارید.
    </p>
<h4>Multiplayer game</h4>
<p>
        در مثال 7-1، ما از یک <em>lock</em> برای جلوگیری از <em>lost updates</em> استفاده کردیم (یعنی، اطمینان از اینکه دو player نمی‌توانند همزمان یک شکل یکسان را حرکت دهند). با این حال، <em>lock</em> از اینکه player ها دو شکل مختلف را به یک موقعیت یکسان روی تخته حرکت دهند، یا به طور بالقوه انجام حرکتی که قوانین بازی را نقض می‌کند، جلوگیری نمی‌کند. بسته به نوع rule که شما در حال اجرا هستید، ممکن است بتوانید از یک <em>unique constraint</em> استفاده کنید، اما در غیر این صورت شما در برابر <em>write skew</em> آسیب‌پذیر هستید.
    </p>
<p>
        Weak Isolation Levels
        <br/>
        |
        <br/>
        249
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0271</div>
            </div>
        </div>
        <!-- Page 0272 -->
        <div class="chapter" id="page-0272">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<h4>Claiming a username</h4>
<p>
        در یک وب‌سایت که هر user دارای یک username <em>unique</em> است، دو user ممکن است همزمان سعی کنند اکانت‌هایی را با همان username ایجاد کنند. شما می‌توانید از یک <em>transaction</em> برای بررسی اینکه آیا نامی گرفته شده است یا خیر استفاده کنید و، اگر نه، یک اکانت با آن نام ایجاد کنید.
    </p>
<p>
        با این حال، مانند مثال‌های قبلی، این کار تحت <em>snapshot isolation</em> ایمن نیست. خوشبختانه، یک <em>unique constraint</em> یک راه‌حل ساده در اینجا است (<em>transaction</em> دوم که سعی می‌کند username را ثبت کند، به دلیل نقض <em>constraint</em>، <em>aborted</em> می‌شود).
    </p>
<h4>Preventing double-spending</h4>
<p>
        یک <em>service</em> که به users اجازه می‌دهد تا پول یا امتیاز خرج کنند، باید بررسی کند که user بیش از آنچه دارند، خرج نکند. شما ممکن است این را با وارد کردن یک <em>spending item tentative</em> در حساب user، فهرست کردن تمام آیتم‌ها در حساب، و بررسی اینکه مجموع مثبت است [44] پیاده‌سازی کنید. با <em>write skew</em>، می‌تواند اتفاق بیفتد که دو <em>spending items</em> به طور همزمان وارد می‌شوند که با هم باعث می‌شوند balance منفی شود، اما هیچ‌کدام از <em>transactions</em> متوجه دیگری نمی‌شوند.
    </p>
<h4>Phantoms causing write skew</h4>
<p>
        همه این مثال‌ها از یک الگوی مشابه پیروی می‌کنند:
    </p>
<ol>
<li>
            یک query SELECT بررسی می‌کند که آیا الزامی با جستجوی <em>rows</em> هایی که با یک <em>search condition</em> مطابقت دارند، برآورده می‌شود (حداقل دو پزشک در <em>on call</em> هستند، هیچ رزروی برای آن اتاق در آن زمان وجود ندارد، موقعیت روی تخته قبلاً شکل دیگری روی آن ندارد، username قبلاً گرفته نشده است، هنوز پول در حساب وجود دارد).
        </li>
<li>
            بسته به نتیجه <em>query</em> اول، کد application تصمیم می‌گیرد که چگونه ادامه دهد (شاید برای ادامه عملیات، یا شاید برای گزارش یک <em>error</em> به user و <em>abort</em>).
        </li>
<li>
            اگر application تصمیم به ادامه کار بگیرد، یک <em>write</em> (INSERT, UPDATE, or DELETE) به database انجام می‌دهد و <em>transaction</em> را commit می‌کند.
        </li>
</ol>
<p>
        اثر این <em>write</em> پیش‌شرط تصمیم مرحله 2 را تغییر می‌دهد. به عبارت دیگر، اگر قرار بود <em>SELECT query</em> را از مرحله 1 پس از <em>committing</em> <em>write</em> تکرار کنید، نتیجه متفاوتی خواهید گرفت، زیرا <em>write</em>، مجموعه <em>rows</em> هایی را که با <em>search condition</em> مطابقت دارند، تغییر داد (اکنون یک پزشک کمتر در <em>on call</em> است، اتاق جلسه اکنون برای آن زمان رزرو شده است، موقعیت روی تخته اکنون توسط شکل جابجا شده گرفته شده است، username اکنون گرفته شده است، اکنون پول کمتری در حساب وجود دارد).
    </p>
<p>
        مراحل ممکن است به ترتیب متفاوتی رخ دهند. به عنوان مثال، شما می‌توانید ابتدا <em>write</em> را انجام دهید، سپس <em>SELECT query</em> را انجام دهید، و در نهایت بر اساس نتیجه <em>query</em> تصمیم بگیرید که آیا <em>abort</em> کنید یا <em>commit</em>.
        <br/>
        250
        <br/>
        |
        <br/>
        Chapter 7: Transactions
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0272</div>
            </div>
        </div>
        <!-- Page 0273 -->
        <div class="chapter" id="page-0273">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        در مورد مثال پزشک <em>on call</em>، <em>row</em> که در مرحله 3 اصلاح می‌شود یکی از <em>rows</em> های برگشتی در مرحله 1 بود، بنابراین ما می‌توانستیم transaction را ایمن کنیم و با <em>locking</em> <em>rows</em> در مرحله 1 (SELECT FOR UPDATE) از <em>write skew</em> جلوگیری کنیم. با این حال، چهار مثال دیگر متفاوت هستند: آنها نبود <em>rows</em> های منطبق با برخی از <em>search condition</em> را بررسی می‌کنند، و <em>write</em> یک <em>row</em> منطبق با همان <em>condition</em> را اضافه می‌کند. اگر <em>query</em> در مرحله 1 هیچ <em>rows</em> ای را برنگرداند، SELECT FOR UPDATE نمی‌تواند هیچ <em>locks</em> ای را به چیزی متصل کند.
    </p>
<p>
        این اثر، که در آن یک <em>write</em> در یک <em>transaction</em> نتیجه یک query جستجو را در یک <em>transaction</em> دیگر تغییر می‌دهد، یک <em>phantom</em> نامیده می‌شود [3]. <em>Snapshot isolation</em> از phantoms در <em>read-only queries</em> اجتناب می‌کند، اما در <em>read-write transactions</em> مانند مثال‌هایی که ما بحث کردیم، <em>phantoms</em> می‌تواند منجر به موارد به‌ویژه دشواری از <em>write skew</em> شود.
    </p>
<h4>Materializing conflicts</h4>
<p>
        اگر مشکل phantoms این است که هیچ object ای وجود ندارد که بتوانیم <em>locks</em> را به آن متصل کنیم، شاید بتوانیم به طور مصنوعی یک object <em>lock</em> را وارد database کنیم؟
    </p>
<p>
        به عنوان مثال، در مورد booking اتاق جلسه می‌توانید جدول زمان‌بندی‌ها و اتاق‌ها را تصور کنید. هر <em>row</em> در این table با یک اتاق خاص برای یک دوره زمانی خاص (مثلاً 15 دقیقه) مطابقت دارد. شما <em>rows</em> را برای تمام ترکیبات ممکن اتاق‌ها و دوره‌های زمانی از قبل ایجاد می‌کنید، به عنوان مثال، برای شش ماه آینده.
    </p>
<p>
        حالا یک <em>transaction</em> که می‌خواهد یک رزرو ایجاد کند می‌تواند <em>rows</em> در table را که مربوط به اتاق و دوره زمانی مورد نظر است <em>lock</em> کند (SELECT FOR UPDATE). پس از اینکه <em>locks</em> را به دست آورد، می‌تواند رزروهای همپوشانی را بررسی کند و یک رزرو جدید را مانند قبل درج کند. توجه داشته باشید که از table اضافی برای ذخیره اطلاعات در مورد رزرو استفاده نمی‌شود—این فقط یک مجموعه از <em>locks</em> است که برای جلوگیری از اصلاح همزمان رزروها در همان اتاق و بازه زمانی استفاده می‌شود.
    </p>
<p>
        این رویکرد، <em>materializing conflicts</em> نامیده می‌شود، زیرا یک <em>phantom</em> را می‌گیرد و آن را به یک <em>lock conflict</em> در یک مجموعه مشخص از <em>rows</em> که در database وجود دارد، تبدیل می‌کند [11]. متاسفانه، فهمیدن چگونگی <em>materialize conflicts</em> می‌تواند دشوار و مستعد خطا باشد، و اجازه دادن به یک مکانیسم <em>concurrency control</em> برای نفوذ به <em>application data model</em> زشت است.
    </p>
<p>
        به همین دلیل، <em>materializing conflicts</em> باید به عنوان آخرین راه‌حل در نظر گرفته شود اگر هیچ جایگزینی امکان‌پذیر نباشد. یک سطح <em>serializable isolation</em> در اکثر موارد بسیار ترجیح داده می‌شود.
    </p>
<h4>Serializability</h4>
<p>
        در این فصل ما چندین مثال از <strong>Transactions</strong> را دیده‌ایم که مستعد <em>race conditions</em> هستند. برخی از <em>race conditions</em> با <em>read committed</em> و <em>snapshot isolation levels</em> جلوگیری می‌شوند، اما برخی دیگر نه. ما به برخی از مثال‌های به‌ویژه دشوار با <em>write skew</em> و <em>phantoms</em> برخورد کردیم. این یک موقعیت غم‌انگیز است:
    </p>
<ul>
<li>
<em>Isolation levels</em> درک آنها دشوار است، و به طور ناهمگون در databases های مختلف پیاده‌سازی شده‌اند (به عنوان مثال، معنای "<em>repeatable read</em>" به طور قابل توجهی متفاوت است).
        </li>
<br/>
        Serializability
        <br/>
        |
        <br/>
        251
    </ul>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0273</div>
            </div>
        </div>
        <!-- Page 0274 -->
        <div class="chapter" id="page-0274">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<ul>
<li>
            اگر به کد application خود نگاه کنید، گفتن اینکه آیا اجرای آن در یک <em>isolation level</em> خاص ایمن است یا خیر دشوار است—به خصوص در یک application بزرگ، که در آن ممکن است از تمام چیزهایی که ممکن است به طور همزمان اتفاق بیفتند، آگاه نباشید.
        </li>
<li>
            هیچ ابزار خوبی برای کمک به ما در تشخیص <em>race conditions</em> وجود ندارد. در اصل، <em>static analysis</em> ممکن است کمک کند [26]، اما تکنیک‌های تحقیقاتی هنوز راه خود را به سمت استفاده عملی پیدا نکرده‌اند. تست برای مسائل <em>concurrency</em> دشوار است، زیرا آنها معمولاً <em>nondeterministic</em> هستند—مشکلات فقط در صورتی رخ می‌دهند که شما با زمان‌بندی بدشانس باشید.
        </li>
</ul>
<p>
        این یک مشکل جدید نیست—از دهه 1970 که <em>weak isolation levels</em> برای اولین بار معرفی شدند، اینگونه بوده است [2]. در تمام این مدت، پاسخ محققان ساده بوده است: از <em>serializable isolation</em> استفاده کنید!
    </p>
<p>
<em>Serializable isolation</em> معمولاً به عنوان قوی‌ترین <em>isolation level</em> در نظر گرفته می‌شود. این تضمین می‌کند که حتی اگر <strong>Transactions</strong> به صورت موازی اجرا شوند، نتیجه نهایی یکسان است، انگار که آنها یک بار در یک زمان، به صورت متوالی، بدون هیچ <em>concurrency</em> اجرا شده‌اند. بنابراین، database تضمین می‌کند که اگر <strong>Transactions</strong> در صورت اجرای جداگانه به درستی رفتار کنند، هنگامی که به طور همزمان اجرا می‌شوند، همچنان درست عمل می‌کنند—به عبارت دیگر، database از تمام <em>race conditions</em> های ممکن جلوگیری می‌کند.
    </p>
<p>
        اما اگر <em>serializable isolation</em> بسیار بهتر از آشفتگی <em>weak isolation levels</em> است، پس چرا همه از آن استفاده نمی‌کنند؟ برای پاسخ به این سوال، ما باید به گزینه‌های پیاده‌سازی <em>serializability</em>، و نحوه عملکرد آنها نگاهی بیندازیم. اکثر databases هایی که امروزه <em>serializability</em> را ارائه می‌دهند، از یکی از سه تکنیک استفاده می‌کنند، که ما در ادامه این فصل به بررسی آنها می‌پردازیم:
    </p>
<ul>
<li>
            به معنای واقعی کلمه اجرای <strong>Transactions</strong> به ترتیب سریال (به "Actual Serial Execution" در صفحه 252 مراجعه کنید)
        </li>
<li>
<em>Two-phase locking (2PL)</em> (به "Two-Phase Locking (2PL)" در صفحه 257 مراجعه کنید)، که برای چندین دهه تنها گزینه مناسب بود
        </li>
<li>
            تکنیک‌های <em>Optimistic concurrency control</em> مانند <em>serializable snapshot isolation</em> (به "Serializable Snapshot Isolation (SSI)" در صفحه 261 مراجعه کنید)
        </li>
</ul>
<p>
        در حال حاضر، ما این تکنیک‌ها را در درجه اول در زمینه databases های تک‌node مورد بحث قرار خواهیم داد. در فصل 9 ما بررسی خواهیم کرد که چگونه می‌توان آنها را به <strong>Transactions</strong> که شامل چندین node در یک system <em>distributed</em> هستند، تعمیم داد.
    </p>
<h4>Actual Serial Execution</h4>
<p>
        ساده‌ترین راه برای جلوگیری از مشکلات <em>concurrency</em>، حذف کامل <em>concurrency</em> است: فقط یک <strong>Transaction</strong> را در یک زمان، به ترتیب سریال، در یک <em>single thread</em> اجرا کنید.
        <br/>
        با انجام این کار، ما کاملاً از مشکل تشخیص و جلوگیری از conflicts بین <strong>Transactions</strong> اجتناب می‌کنیم: <em>isolation</em> حاصل، با تعریف <em>serializable</em> است.
        <br/>
        252
        <br/>
        |
        <br/>
        Chapter 7: Transactions
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0274</div>
            </div>
        </div>
        <!-- Page 0275 -->
        <div class="chapter" id="page-0275">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        اگرچه این یک ایده بدیهی به نظر می‌رسد، طراحان database، فقط اخیراً—حدود سال 2007—تصمیم گرفتند که یک حلقه تک رشته‌ای برای اجرای <strong>Transactions</strong> امکان‌پذیر است [45]. اگر <em>multi-threaded concurrency</em> برای به دست آوردن عملکرد خوب در طول 30 سال گذشته ضروری تلقی می‌شد، چه چیزی تغییر کرد تا اجرای تک رشته‌ای را ممکن کند؟
    </p>
<p>
        دو پیشرفت باعث این بازنگری شد:
    </p>
<ul>
<li>
            RAM به اندازه‌ای ارزان شد که برای بسیاری از موارد استفاده، اکنون امکان نگه داشتن کل <em>active dataset</em> در حافظه وجود دارد (به "Keeping everything in memory" در صفحه 88 مراجعه کنید). وقتی تمام داده‌هایی که یک <strong>Transaction</strong> نیاز به دسترسی به آنها دارد در حافظه است، <strong>Transactions</strong> می‌توانند بسیار سریع‌تر از زمانی که مجبور به انتظار برای بارگذاری داده‌ها از دیسک هستند، اجرا شوند.
        </li>
<li>
            طراحان database متوجه شدند که <strong>OLTP transactions</strong> معمولاً کوتاه هستند و فقط تعداد کمی <em>reads</em> و <em>writes</em> انجام می‌دهند (به "Transaction Processing or Analytics?" در صفحه 90 مراجعه کنید). در مقابل، <em>long-running analytic queries</em> معمولاً <em>read-only</em> هستند، بنابراین می‌توانند در یک <em>consistent snapshot</em> (با استفاده از <em>snapshot isolation</em>) خارج از حلقه اجرای سریال اجرا شوند.
        </li>
</ul>
<p>
        رویکرد اجرای <strong>Transactions</strong> به صورت سریال در VoltDB/H-Store، Redis، و Datomic پیاده‌سازی شده است [46, 47, 48]. یک سیستم طراحی شده برای اجرای تک رشته‌ای گاهی اوقات می‌تواند بهتر از یک سیستم که از <em>concurrency</em> پشتیبانی می‌کند، عمل کند، زیرا می‌تواند از سربار هماهنگی <em>locking</em> اجتناب کند. با این حال، <em>throughput</em> آن به <em>core</em> تک CPU محدود می‌شود. به منظور استفاده حداکثری از آن <em>single thread</em>، <strong>Transactions</strong> ها باید متفاوت از فرم سنتی خود ساختاردهی شوند.
    </p>
<h4>Encapsulating transactions in stored procedures</h4>
<p>
        در روزهای اولیه databases ها، هدف این بود که یک <em>database transaction</em> بتواند یک جریان کامل از فعالیت user را در بر گیرد. به عنوان مثال، رزرو بلیط هواپیما یک فرآیند چند مرحله‌ای است (جستجوی مسیرها، کرایه‌ها، و صندلی‌های موجود. تصمیم‌گیری در مورد یک برنامه سفر. رزرو صندلی‌ها در هر یک از پروازهای برنامه سفر. وارد کردن جزئیات مسافر. پرداخت). طراحان database فکر می‌کردند که خوب است اگر کل این فرآیند یک <strong>Transaction</strong> بود تا بتوان آن را به صورت <em>atomically committed</em> کرد.
    </p>
<p>
        متاسفانه، انسان‌ها در تصمیم‌گیری و پاسخگویی بسیار کند هستند. اگر یک <em>database transaction</em> نیاز به انتظار ورودی از یک user داشته باشد، database باید از تعداد بالقوه زیادی از <strong>Transactions</strong> همزمان، که اکثر آنها بیکار هستند، پشتیبانی کند. اکثر databases ها نمی‌توانند این کار را به طور مؤثر انجام دهند، و بنابراین تقریباً تمام applications های <strong>OLTP</strong> با اجتناب از انتظار تعاملی برای یک user در یک <strong>Transaction</strong>، <strong>Transactions</strong> ها را کوتاه نگه می‌دارند. در وب، این بدان معنی است که یک <strong>Transaction</strong> در همان درخواست <em>HTTP</em> <em>committed</em> می‌شود—یک <strong>Transaction</strong> چندین درخواست را پوشش نمی‌دهد. یک درخواست <em>HTTP</em> جدید، یک <strong>Transaction</strong> جدید را شروع می‌کند.
    </p>
<p>
        حتی اگر انسان از مسیر بحرانی خارج شده باشد، <strong>Transactions</strong> ها همچنان به سبک client/server تعاملی، یک statement در یک زمان اجرا می‌شوند.
        <br/>
        Serializability
        <br/>
        |
        <br/>
        253
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0275</div>
            </div>
        </div>
        <!-- Page 0276 -->
        <div class="chapter" id="page-0276">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        یک application یک query ایجاد می‌کند، نتیجه را می‌خواند، شاید query دیگری را بسته به نتیجه query اول ایجاد می‌کند، و به همین ترتیب. <em>Queries</em> و نتایج بین کد application (که روی یک machine اجرا می‌شود) و database server (روی machine دیگری) ارسال می‌شوند.
    </p>
<p>
        در این سبک <em>interactive</em> از <strong>Transaction</strong>، زمان زیادی صرف ارتباطات شبکه بین application و database می‌شود. اگر قرار بود <em>concurrency</em> را در database ممنوع کنید و فقط یک <strong>Transaction</strong> را در یک زمان پردازش کنید، <em>throughput</em> وحشتناک خواهد بود زیرا database بیشتر وقت خود را صرف انتظار برای صدور query بعدی توسط application برای <strong>Transaction</strong> فعلی می‌کند. در این نوع database، پردازش چندین <strong>Transactions</strong> به طور همزمان برای به دست آوردن <em>reasonable performance</em> ضروری است.
    </p>
<p>
        به همین دلیل، systems با <em>single-threaded serial transaction processing</em>، <em>interactive multi-statement transactions</em> را مجاز نمی‌دانند. در عوض، application باید کل کد <strong>Transaction</strong> را از قبل، به عنوان یک <em>stored procedure</em>، به database ارسال کند. تفاوت‌های بین این رویکردها در شکل 7-9 نشان داده شده است. با این شرط که تمام داده‌های مورد نیاز یک <strong>Transaction</strong> در حافظه باشد، <em>stored procedure</em> می‌تواند بسیار سریع اجرا شود، بدون اینکه منتظر هیچ <em>network</em> یا <em>disk I/O</em> باشد.
    </p>
<figure>
<img alt="Figure 7-9. The difference between an interactive transaction and a stored procedure (using the example transaction of Figure 7-8)." src="figure7-9.png"/>
<figcaption>Figure 7-9. The difference between an interactive transaction and a stored procedure (using the example transaction of Figure 7-8).</figcaption>
</figure>
<p>
        254
        <br/>
        |
        <br/>
        Chapter 7: Transactions
    </p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 276" src="page_0276/image_1.png"/></div>
</div>
                <div class="page-number">صفحه 0276</div>
            </div>
        </div>
        <!-- Page 0277 -->
        <div class="chapter" id="page-0277">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<h4>Pros and cons of stored procedures</h4>
<p>
<em>Stored procedures</em> از مدتی پیش در relational databases وجود داشته‌اند، و از سال 1999 بخشی از <em>SQL standard</em> (SQL/PSM) بوده‌اند. آنها به دلایل مختلفی به یک <em>bad reputation</em> رسیده‌اند:
    </p>
<ul>
<li>
            هر vendor database زبان خود را برای <em>stored procedures</em> دارد (Oracle دارای PL/SQL است، SQL Server دارای T-SQL است، PostgreSQL دارای PL/pgSQL است، و غیره). این زبان‌ها با پیشرفت‌های زبان‌های برنامه‌نویسی عمومی همگام نبوده‌اند، بنابراین از دیدگاه امروزی بسیار زشت و کهنه به نظر می‌رسند، و فاقد اکوسیستم کتابخانه‌هایی هستند که در اکثر زبان‌های برنامه‌نویسی یافت می‌شود.
        </li>
<li>
            کد در حال اجرا در یک database مدیریت آن دشوار است: در مقایسه با یک application server، <em>debug</em> کردن آن سخت‌تر است، نگهداری آن در کنترل version و <em>deploy</em> کردن آن مشکل‌تر است، تست کردن آن سخت‌تر است، و ادغام آن با یک system جمع‌آوری <em>metrics</em> برای <em>monitoring</em> دشوار است.
        </li>
<li>
            یک database اغلب بسیار نسبت به performance حساس‌تر از یک application server است، زیرا یک نمونه database واحد اغلب توسط بسیاری از application servers به اشتراک گذاشته می‌شود. یک <em>stored procedure</em> که به درستی نوشته نشده است (به عنوان مثال، استفاده از مقدار زیادی حافظه یا زمان CPU) در یک database می‌تواند مشکلات بیشتری نسبت به کد که به درستی در یک application server نوشته نشده است، ایجاد کند.
        </li>
</ul>
<p>
        با این حال، می‌توان بر این مسائل غلبه کرد. پیاده‌سازی‌های مدرن <em>stored procedures</em>، PL/SQL را کنار گذاشته‌اند و به جای آن از زبان‌های برنامه‌نویسی عمومی موجود استفاده می‌کنند: VoltDB از Java یا Groovy استفاده می‌کند، Datomic از Java یا Clojure استفاده می‌کند، و Redis از Lua استفاده می‌کند.
    </p>
<p>
        با <em>stored procedures</em> و داده‌های <em>in-memory</em>، اجرای تمام <strong>Transactions</strong> در یک <em>single thread</em> امکان‌پذیر می‌شود. از آنجایی که آنها نیازی به انتظار برای I/O ندارند و از سربار سایر مکانیسم‌های <em>concurrency control</em> اجتناب می‌کنند، می‌توانند <em>throughput</em> بسیار خوبی را در یک <em>single thread</em> به دست آورند.
    </p>
<p>
        VoltDB همچنین از <em>stored procedures</em> برای <em>replication</em> استفاده می‌کند: به جای کپی کردن <em>writes</em> یک <em>transaction</em> از یک node به دیگری، همان <em>stored procedure</em> را در هر <em>replica</em> اجرا می‌کند. بنابراین VoltDB مستلزم است که <em>stored procedures</em> <em>deterministic</em> باشند (هنگامی که در nodes مختلف اجرا می‌شوند، باید نتیجه یکسانی تولید کنند). به عنوان مثال، اگر یک <strong>Transaction</strong> نیاز به استفاده از تاریخ و زمان فعلی دارد، باید این کار را از طریق <em>APIs deterministic</em> خاص انجام دهد.
    </p>
<h4>Partitioning</h4>
<p>
        اجرای تمام <strong>Transactions</strong> به صورت سریال، <em>concurrency control</em> را بسیار ساده‌تر می‌کند، اما <em>transaction throughput</em> database را به سرعت یک <em>CPU core</em> واحد در یک machine واحد محدود می‌کند. <em>Read-only transactions</em> ممکن است در جای دیگری، با استفاده از <em>snapshot isolation</em>، اجرا شوند، اما برای applications با <em>high write throughput</em>، <em>transaction processor</em> تک رشته‌ای می‌تواند به یک bottleneck جدی تبدیل شود.
    </p>
<p>
        Serializability
        <br/>
        |
        <br/>
        255
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0277</div>
            </div>
        </div>
        <!-- Page 0278 -->
        <div class="chapter" id="page-0278">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        x. اگر یک transaction نیاز به دسترسی به داده‌هایی دارد که در حافظه نیستند، بهترین راه‌حل ممکن است <em>abort</em> کردن <em>transaction</em> باشد، داده‌ها را به‌طور ناهمزمان در حافظه واکشی کنید در حالی که به پردازش <strong>Transactions</strong> های دیگر ادامه می‌دهید، و سپس <strong>Transaction</strong> را هنگامی که داده‌ها بارگیری شده‌اند، راه‌اندازی مجدد کنید. این رویکرد به عنوان <em>anti-caching</em> شناخته می‌شود، همانطور که قبلاً در "Keeping everything in memory" در صفحه 88 ذکر شد.
    </p>
<p>
        به منظور مقیاس‌پذیری به چندین <em>CPU core</em> و چندین node، شما به طور بالقوه می‌توانید داده‌های خود را <em>partition</em> کنید (به فصل 6 مراجعه کنید)، که در VoltDB پشتیبانی می‌شود. اگر می‌توانید راهی برای <em>partitioning</em> dataset خود پیدا کنید به طوری که هر <strong>Transaction</strong> فقط نیاز به خواندن و نوشتن داده‌ها در یک partition واحد داشته باشد، در این صورت هر partition می‌تواند thread پردازش <strong>Transaction</strong> خود را داشته باشد که به طور مستقل از بقیه اجرا می‌شود. در این حالت، شما می‌توانید به هر <em>CPU core</em> <em>partition</em> خود را بدهید، که به <em>transaction throughput</em> شما اجازه می‌دهد تا با تعداد <em>CPU cores</em> به‌صورت خطی مقیاس‌پذیر شود [47].
    </p>
<p>
        با این حال، برای هر <strong>Transaction</strong> که نیاز به دسترسی به چندین partition دارد، database باید <strong>Transaction</strong> را در سراسر تمام partitions هایی که لمس می‌کند، هماهنگ کند. <em>Stored procedure</em> باید به‌صورت <em>lock-step</em> در سراسر تمام partitions انجام شود تا از <em>serializability</em> در سراسر کل system اطمینان حاصل شود.
    </p>
<p>
        از آنجایی که <em>cross-partition transactions</em> دارای سربار هماهنگی اضافی هستند، بسیار کندتر از <em>single-partition transactions</em> هستند. VoltDB <em>throughput</em> حدود 1000 <em>cross-partition writes</em> در ثانیه را گزارش می‌دهد، که چندین مرتبه پایین‌تر از <em>single-partition throughput</em> آن است و نمی‌تواند با افزودن machine های بیشتر افزایش یابد [49].
    </p>
<p>
        اینکه آیا <strong>Transactions</strong> می‌تواند <em>single-partition</em> باشد یا نه، بسیار به ساختار داده‌های مورد استفاده توسط application بستگی دارد. داده‌های <em>key-value</em> ساده اغلب می‌توانند خیلی راحت <em>partitioned</em> شوند، اما داده‌ها با چندین <em>secondary indexes</em> احتمالاً به هماهنگی <em>cross-partition</em> زیادی نیاز دارند (به "Partitioning and Secondary Indexes" در صفحه 206 مراجعه کنید).
    </p>
<h4>Summary of serial execution</h4>
<p>
        اجرای سریال <strong>Transactions</strong> به یک روش مناسب برای دستیابی به <em>serializable isolation</em> در محدودیت‌های خاص تبدیل شده است:
    </p>
<ul>
<li>
            هر <strong>Transaction</strong> باید کوچک و سریع باشد، زیرا فقط یک <strong>Transaction</strong> کند برای متوقف کردن همه پردازش <strong>Transactions</strong> طول می‌کشد.
        </li>
<li>
            به موارد استفاده‌ای محدود می‌شود که dataset فعال می‌تواند در حافظه جا شود. داده‌های که به ندرت به آنها دسترسی می‌شود، به طور بالقوه می‌توانند به دیسک منتقل شوند، اما اگر نیاز به دسترسی به آنها در یک <em>single-threaded transaction</em> باشد، system بسیار کند می‌شود.x
        </li>
<li>
<em>Write throughput</em> باید به اندازه کافی کم باشد که در یک <em>CPU core</em> واحد مدیریت شود، یا <em>transactions</em> باید بدون نیاز به هماهنگی <em>cross-partition</em> <em>partitioned</em> شوند.
        </li>
<li>
<em>Cross-partition transactions</em> امکان‌پذیر هستند، اما یک محدودیت سخت برای میزان استفاده از آنها وجود دارد.
        </li>
</ul>
<p>
        256
        <br/>
        |
        <br/>
        Chapter 7: Transactions
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0278</div>
            </div>
        </div>
        <!-- Page 0279 -->
        <div class="chapter" id="page-0279">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        xi. گاهی اوقات <em>strong strict two-phase locking (SS2PL)</em> نامیده می‌شود تا آن را از سایر <em>variants</em> 2PL متمایز کند.
    </p>
<h4>Two-Phase Locking (2PL)</h4>
<p>
        تقریباً 30 سال، فقط یک الگوریتم به طور گسترده برای <em>serializability</em> در databases استفاده می‌شد: <em>two-phase locking (2PL)</em>.
    </p>
<h4>2PL is not 2PC</h4>
<p>
        توجه داشته باشید که در حالی که <em>two-phase locking (2PL)</em> بسیار شبیه به <em>two-phase commit (2PC)</em> به نظر می‌رسد، آنها کاملاً متفاوت هستند. ما 2PC را در فصل 9 مورد بحث قرار خواهیم داد.
    </p>
<p>
        ما قبلاً دیدیم که <em>locks</em> اغلب برای جلوگیری از <em>dirty writes</em> استفاده می‌شوند (به "No dirty writes" در صفحه 235 مراجعه کنید): اگر دو <strong>Transactions</strong> به طور همزمان سعی کنند به یک object یکسان <em>write</em> کنند، lock تضمین می‌کند که <em>writer</em> دوم باید منتظر بماند تا <em>transaction</em> اول کار خود را تمام کند (<em>aborted</em> یا <em>committed</em>) قبل از اینکه بتواند ادامه دهد.
    </p>
<p>
<em>Two-phase locking</em> مشابه است، اما الزامات lock را بسیار قوی‌تر می‌کند. به چندین <strong>Transactions</strong> اجازه داده می‌شود که به طور همزمان object یکسانی را بخوانند تا زمانی که هیچ‌کس به آن نمی‌نویسد. اما به محض اینکه کسی بخواهد به یک object بنویسد (اصلاح یا حذف)، دسترسی انحصاری مورد نیاز است:
    </p>
<ul>
<li>
            اگر <em>transaction</em> A یک object را خوانده باشد و <em>transaction</em> B بخواهد به آن object بنویسد، B باید منتظر بماند تا A <em>commits</em> یا <em>aborts</em> شود قبل از اینکه بتواند ادامه دهد. (این اطمینان می‌دهد که B نمی‌تواند object را به طور غیرمنتظره‌ای پشت سر A تغییر دهد.)
        </li>
<li>
            اگر <em>transaction</em> A یک object را <em>written</em> کرده باشد و <em>transaction</em> B بخواهد آن object را بخواند، B باید منتظر بماند تا A <em>commits</em> یا <em>aborts</em> شود قبل از اینکه بتواند ادامه دهد. (خواندن یک نسخه قدیمی از object، مانند شکل 7-1، تحت 2PL قابل قبول نیست.)
        </li>
</ul>
<p>
        در 2PL، <em>writers</em> نه تنها <em>writers</em> های دیگر را مسدود می‌کنند. آنها همچنین <em>readers</em> را مسدود می‌کنند و بالعکس. <em>Snapshot isolation</em> دارای شعار <em>readers</em> هرگز <em>writers</em> را مسدود نمی‌کنند، و <em>writers</em> هرگز <em>readers</em> را مسدود نمی‌کنند (به "Implementing snapshot isolation" در صفحه 239 مراجعه کنید)، که این تفاوت کلیدی بین <em>snapshot isolation</em> و <em>two-phase locking</em> را نشان می‌دهد. از سوی دیگر، از آنجایی که 2PL <em>serializability</em> را ارائه می‌دهد، در برابر تمام <em>race conditions</em> های مورد بحث قبلی، از جمله <em>lost updates</em> و <em>write skew</em>، محافظت می‌کند.
    </p>
<h4>Implementation of two-phase locking</h4>
<p>
        2PL توسط سطح <em>serializable isolation</em> در MySQL (InnoDB) و SQL Server، و سطح <em>repeatable read isolation</em> در DB2 استفاده می‌شود [23, 36].
        <br/>
        Serializability
        <br/>
        |
        <br/>
        257
    </p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 279" src="page_0279/image_1.png"/></div>
</div>
                <div class="page-number">صفحه 0279</div>
            </div>
        </div>
        <!-- Page 0280 -->
        <div class="chapter" id="page-0280">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        مسدود کردن <em>readers</em> و <em>writers</em> با داشتن یک <em>lock</em> روی هر object در database پیاده‌سازی می‌شود. <em>Lock</em> می‌تواند در حالت shared یا در حالت <em>exclusive</em> باشد. <em>Lock</em> به شرح زیر استفاده می‌شود:
    </p>
<ul>
<li>
            اگر یک <em>transaction</em> می‌خواهد یک object را بخواند، ابتدا باید <em>lock</em> را در حالت <em>shared</em> به دست آورد. به چندین <strong>Transactions</strong> اجازه داده می‌شود که <em>lock</em> را در حالت <em>shared</em> به طور همزمان نگه دارند، اما اگر یک <em>transaction</em> دیگر در حال حاضر دارای یک <em>exclusive lock</em> روی object است، این <strong>Transactions</strong> ها باید منتظر بمانند.
        </li>
<li>
            اگر یک <em>transaction</em> می‌خواهد به یک object بنویسد، ابتدا باید <em>lock</em> را در حالت <em>exclusive</em> به دست آورد. هیچ <strong>Transaction</strong> دیگری نباید همزمان <em>lock</em> را نگه دارد (چه در حالت <em>shared</em> و چه در حالت <em>exclusive</em>)، بنابراین اگر هر <em>lock</em> موجودی روی object وجود داشته باشد، <em>transaction</em> باید منتظر بماند.
        </li>
<li>
            اگر یک <em>transaction</em> ابتدا object را می‌خواند و سپس به آن <em>writes</em> می‌کند، ممکن است <em>shared lock</em> خود را به یک <em>exclusive lock</em> ارتقا دهد. ارتقا به همان صورت که مستقیماً یک <em>exclusive lock</em> دریافت می‌کند، عمل می‌کند.
        </li>
<li>
            پس از اینکه یک <em>transaction</em> <em>lock</em> را به دست آورد، باید <em>lock</em> را تا پایان <strong>Transaction</strong> (<em>commit</em> یا <em>abort</em>) نگه دارد. این جایی است که نام "دو فاز" از آن می‌آید: فاز اول (در حالی که <strong>Transaction</strong> در حال اجرا است) زمانی است که <em>locks</em> به دست می‌آیند، و فاز دوم (در پایان <strong>Transaction</strong>) زمانی است که تمام <em>locks</em> آزاد می‌شوند.
        </li>
</ul>
<p>
        از آنجایی که <em>locks</em> زیادی در حال استفاده هستند، ممکن است به راحتی اتفاق بیفتد که <em>transaction</em> A در انتظار <em>transaction</em> B برای آزاد کردن <em>lock</em> خود گیر کند، و بالعکس. این وضعیت <em>deadlock</em> نامیده می‌شود. database به طور خودکار <em>deadlocks</em> را بین <strong>Transactions</strong> تشخیص می‌دهد و یکی از آنها را <em>aborts</em> می‌کند تا دیگران بتوانند پیشرفت کنند. <strong>Transaction</strong> <em>aborted</em> شده نیاز به تکرار توسط application دارد.
    </p>
<h4>Performance of two-phase locking</h4>
<p>
<em>Downside</em> بزرگ <em>two-phase locking</em>، و دلیل اینکه چرا همه از دهه 1970 از آن استفاده نکرده‌اند، <em>performance</em> است: <em>transaction throughput</em> و زمان پاسخگویی <em>queries</em> تحت <em>two-phase locking</em> به طور قابل توجهی بدتر از <em>weak isolation</em> است.
    </p>
<p>
        این تا حدی به دلیل سربار به دست آوردن و آزاد کردن تمام آن <em>locks</em> است، اما مهمتر از آن به دلیل کاهش <em>concurrency</em> است. با طراحی، اگر دو <strong>Transactions</strong> همزمان سعی کنند کاری را انجام دهند که ممکن است به هر نحوی منجر به یک <em>race condition</em> شود، یکی باید منتظر بماند تا دیگری تکمیل شود.
    </p>
<p>
        relational databases سنتی، مدت زمان یک <strong>Transaction</strong> را محدود نمی‌کنند، زیرا برای applications تعاملی طراحی شده‌اند که منتظر ورودی انسان هستند. در نتیجه، وقتی یک <strong>Transaction</strong> باید منتظر دیگری باشد، محدودیتی در مورد مدت زمانی که ممکن است منتظر بماند وجود ندارد. حتی اگر مطمئن شوید که همه <strong>Transactions</strong> خود را کوتاه نگه می‌دارید،
        <br/>
        258
        <br/>
        |
        <br/>
        Chapter 7: Transactions
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0280</div>
            </div>
        </div>
        <!-- Page 0281 -->
        <div class="chapter" id="page-0281">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        queue ممکن است ایجاد شود اگر چندین <strong>Transactions</strong> بخواهند به یک object یکسان دسترسی داشته باشند، بنابراین یک <strong>Transaction</strong> ممکن است مجبور شود منتظر بماند تا چندین <strong>Transaction</strong> دیگر تکمیل شوند قبل از اینکه بتواند کاری انجام دهد.
    </p>
<p>
        به همین دلیل، databases هایی که 2PL را اجرا می‌کنند، می‌توانند <em>latencies</em> کاملاً ناپایداری داشته باشند، و در <em>high percentiles</em> (به "Describing Performance" در صفحه 13 مراجعه کنید) اگر در workload رقابت وجود داشته باشد، می‌توانند بسیار کند باشند. ممکن است فقط یک <strong>Transaction</strong> کند، یا یک <strong>Transaction</strong> که به داده‌های زیادی دسترسی دارد و <em>locks</em> زیادی را به دست می‌آورد، طول بکشد تا بقیه system متوقف شوند. این بی‌ثباتی زمانی مشکل‌ساز است که <em>robust operation</em> مورد نیاز باشد.
    </p>
<p>
        اگرچه <em>deadlocks</em> می‌توانند با سطح <em>lock-based read committed isolation</em> رخ دهند، اما آنها بسیار مکررتر در زیر 2PL <em>serializable isolation</em> رخ می‌دهند (بسته به الگوهای دسترسی <strong>Transaction</strong> شما). این می‌تواند یک مشکل performance اضافی باشد: وقتی یک <strong>Transaction</strong> به دلیل <em>deadlock</em> <em>aborted</em> می‌شود و دوباره تلاش می‌شود، باید کار خود را دوباره انجام دهد. اگر <em>deadlocks</em> مکرر باشند، این می‌تواند به معنای تلاش قابل توجهی باشد که به هدر رفته است.
    </p>
<h4>Predicate locks</h4>
<p>
        در توصیف قبلی <em>locks</em>، ما یک جزئیات ظریف اما مهم را نادیده گرفتیم.
    </p>
<p>
        در "Phantoms causing write skew" در صفحه 250 ما در مورد مشکل <em>phantoms</em> بحث کردیم—یعنی، یک <em>transaction</em> نتایج یک query جستجوی <em>transaction</em> دیگر را تغییر می‌دهد. یک database با <em>serializable isolation</em> باید از <em>phantoms</em> جلوگیری کند.
    </p>
<p>
        در مثال booking اتاق جلسه، این بدان معنی است که اگر یک <strong>Transaction</strong> برای رزروهای موجود برای یک اتاق در یک بازه زمانی مشخص جستجو کرده باشد (به مثال 7-2 مراجعه کنید)، <strong>Transaction</strong> دیگری مجاز به درج یا <em>update</em> همزمان رزرو دیگری برای همان اتاق و بازه زمانی نیست. (درج همزمان رزرو برای اتاق‌های دیگر، یا برای همان اتاق در زمان دیگری که بر رزرو پیشنهادی تأثیری ندارد، اشکالی ندارد.)
    </p>
<p>
        چگونه این را پیاده‌سازی می‌کنیم؟ از نظر مفهومی، ما به یک <em>predicate lock</em> [3] نیاز داریم. این به طور مشابه با <em>shared/exclusive lock</em> که قبلاً توضیح داده شد عمل می‌کند، اما به جای تعلق داشتن به یک object خاص (به عنوان مثال، یک <em>row</em> در یک table)، به تمام object هایی که با یک <em>search condition</em> مطابقت دارند، مانند:
    </p>
<pre><code class="language-sql">SELECT * FROM bookings
  WHERE room_id = 123 AND
    end_time   &gt; '2018-01-01 12:00' AND
    start_time &lt; '2018-01-01 13:00';
</code></pre>
<p>
        یک <em>predicate lock</em> دسترسی را به شرح زیر محدود می‌کند:
    </p>
<ul>
<li>
            اگر <em>transaction</em> A می‌خواهد object هایی را که با یک condition مطابقت دارند، مانند آن query SELECT، بخواند، باید یک <em>shared-mode predicate lock</em> را روی شرایط query به دست آورد. اگر یک <em>transaction</em> B دیگر در حال حاضر دارای یک <em>exclusive lock</em> روی هر object است که با آن شرایط مطابقت دارد، A باید منتظر بماند تا B <em>lock</em> خود را آزاد کند قبل از اینکه اجازه داشته باشد <em>query</em> خود را انجام دهد.
            <br/>
            Serializability
            <br/>
            |
            <br/>
            259
        </li>
</ul>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0281</div>
            </div>
        </div>
        <!-- Page 0282 -->
        <div class="chapter" id="page-0282">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<ul>
<li>
            اگر <em>transaction</em> A می‌خواهد هر object را درج، <em>update</em> یا حذف کند، ابتدا باید بررسی کند که آیا value قدیمی یا جدید با هر <em>predicate lock</em> موجود مطابقت دارد یا خیر. اگر یک <em>predicate lock</em> منطبق توسط <em>transaction</em> B نگهداری می‌شود، سپس A باید منتظر بماند تا B <em>committed</em> یا <em>aborted</em> شود قبل از اینکه بتواند ادامه دهد.
        </li>
</ul>
<p>
        ایده اصلی در اینجا این است که یک <em>predicate lock</em> حتی برای object هایی که هنوز در database وجود ندارند، اما ممکن است در آینده اضافه شوند (<em>phantoms</em>)، اعمال می‌شود. اگر <em>two-phase locking</em> شامل <em>predicate locks</em> باشد، database از همه اشکال <em>write skew</em> و سایر <em>race conditions</em> جلوگیری می‌کند، و بنابراین <em>isolation</em> آن به <em>serializable</em> تبدیل می‌شود.
    </p>
<h4>Index-range locks</h4>
<p>
        متاسفانه، <em>predicate locks</em> عملکرد خوبی ندارند: اگر <em>locks</em> زیادی توسط <em>active transactions</em> وجود داشته باشد، بررسی برای <em>matching locks</em> زمان‌بر می‌شود. به همین دلیل، اکثر databases ها با 2PL در واقع <em>index-range locking</em> (همچنین به عنوان <em>next-key locking</em> شناخته می‌شود) را پیاده‌سازی می‌کنند، که یک تقریب ساده شده از <em>predicate locking</em> است [41, 50].
    </p>
<p>
        تسهیل یک <em>predicate</em> با تطبیق آن با مجموعه بزرگ‌تری از objects، ایمن است. به عنوان مثال، اگر شما یک <em>predicate lock</em> برای رزروهای اتاق 123 بین ظهر و 1 بعد از ظهر دارید، می‌توانید آن را با <em>locking</em> رزروهای اتاق 123 در هر زمان، یا می‌توانید آن را با <em>locking</em> تمام اتاق‌ها (نه فقط اتاق 123) بین ظهر و 1 بعد از ظهر تخمین بزنید.
    </p>
<p>
        این ایمن است، زیرا هر <em>write</em> که با <em>predicate</em> اصلی مطابقت داشته باشد، قطعاً با تقریب‌ها نیز مطابقت خواهد داشت.
    </p>
<p>
        در database رزرو اتاق، احتمالاً شما یک <em>index</em> روی ستون room_id، و/یا <em>indexes</em> روی start_time و end_time دارید (در غیر این صورت query قبلی در یک database بزرگ بسیار کند خواهد بود):
    </p>
<ul>
<li>
            فرض کنید <em>index</em> شما روی room_id است، و database از این <em>index</em> برای یافتن رزروهای موجود برای اتاق 123 استفاده می‌کند. اکنون database می‌تواند به سادگی یک <em>shared lock</em> را به این <em>index entry</em> متصل کند، که نشان می‌دهد یک <em>transaction</em> برای رزروهای اتاق 123 جستجو کرده است.
        </li>
<li>
            از طرف دیگر، اگر database از یک <em>time-based index</em> برای یافتن رزروهای موجود استفاده می‌کند، می‌تواند یک <em>shared lock</em> را به یک range از values در آن <em>index</em> متصل کند، که نشان می‌دهد یک <em>transaction</em> برای رزروهایی که با دوره زمانی ظهر تا 1 بعد از ظهر در 1 ژانویه 2018 همپوشانی دارند، جستجو کرده است.
        </li>
</ul>
<p>
        در هر صورت، یک تقریب از <em>search condition</em> به یکی از <em>indexes</em> متصل می‌شود. اکنون، اگر یک <em>transaction</em> دیگر بخواهد یک رزرو را برای همان اتاق و/یا یک دوره زمانی همپوشانی درج، <em>update</em> یا حذف کند، باید بخش یکسانی از index را <em>update</em> کند. در این فرآیند، با <em>shared lock</em> مواجه خواهد شد، و مجبور می‌شود منتظر بماند تا <em>lock</em> آزاد شود.
    </p>
<p>
        این حفاظت مؤثری را در برابر <em>phantoms</em> و <em>write skew</em> ارائه می‌دهد. <em>Index-range locks</em> به اندازه <em>predicate locks</em> دقیق نیستند (ممکن است یک range بزرگتر از
        <br/>
        260
        <br/>
        |
        <br/>
        Chapter 7: Transactions
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0282</div>
            </div>
        </div>
        <!-- Page 0283 -->
        <div class="chapter" id="page-0283">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        objects than is strictly necessary to maintain serializability)، اما از آنجایی که سربار بسیار کمتری دارند، یک compromise خوب هستند.
    </p>
<p>
        اگر هیچ <em>index</em> مناسبی وجود نداشته باشد که یک <em>range lock</em> را بتوان به آن متصل کرد، database می‌تواند به یک <em>shared lock</em> روی کل table بازگردد. این برای <em>performance</em> خوب نخواهد بود، زیرا همه <strong>Transactions</strong> های دیگر را که به table <em>write</em> می‌کنند، متوقف می‌کند، اما این یک موقعیت fallback ایمن است.
    </p>
<h4>Serializable Snapshot Isolation (SSI)</h4>
<p>
        این فصل تصویری تیره از <em>concurrency control</em> در databases ها به تصویر کشیده است. از یک سو، ما پیاده‌سازی‌هایی از <em>serializability</em> را داریم که عملکرد خوبی ندارند (<em>two-phase locking</em>) یا به خوبی مقیاس‌پذیر نیستند (اجرای سریال). از سوی دیگر، ما <em>weak isolation levels</em> را داریم که <em>good performance</em> دارند، اما مستعد race conditions مختلفی هستند (<em>lost updates, write skew, phantoms</em>، و غیره). آیا <em>serializable isolation</em> و <em>good performance</em> اساساً با یکدیگر در تضاد هستند؟
    </p>
<p>
        شاید نه: یک الگوریتم به نام <em>serializable snapshot isolation (SSI)</em> بسیار امیدوارکننده است. این <em>full serializability</em> را ارائه می‌دهد، اما در مقایسه با <em>snapshot isolation</em>، فقط یک <em>performance penalty</em> کوچک دارد. SSI نسبتاً جدید است: برای اولین بار در سال 2008 [40] توضیح داده شد و موضوع پایان‌نامه دکترای مایکل Cahill [51] است.
    </p>
<p>
        امروزه SSI هم در databases های تک‌node (سطح <em>serializable isolation</em> در PostgreSQL از نسخه 9.1 [41]) و هم در databases های distributed (FoundationDB از یک الگوریتم مشابه استفاده می‌کند) استفاده می‌شود. از آنجایی که SSI در مقایسه با سایر مکانیسم‌های <em>concurrency control</em> بسیار جوان است، هنوز عملکرد خود را در عمل ثابت می‌کند، اما این امکان را دارد که در آینده به default جدید تبدیل شود.
    </p>
<h4>Pessimistic versus optimistic concurrency control</h4>
<p>
<em>Two-phase locking</em> یک مکانیسم <em>pessimistic concurrency control</em> است: این بر این اصل استوار است که اگر هر چیزی احتمالاً اشتباه پیش برود (همانطور که توسط یک <em>lock</em> که توسط یک <strong>Transaction</strong> دیگر نگهداری می‌شود نشان داده می‌شود)، بهتر است منتظر بمانیم تا وضعیت دوباره ایمن شود قبل از انجام هر کاری. این شبیه به <em>mutual exclusion</em> است، که برای محافظت از ساختارهای داده در <em>multi-threaded programming</em> استفاده می‌شود.
    </p>
<p>
        اجرای سریال، به معنایی، <em>pessimistic</em> است: اساساً معادل این است که هر <strong>Transaction</strong> یک <em>exclusive lock</em> روی کل database (یا یک partition از database) را برای مدت زمان <strong>Transaction</strong> دارد. ما <em>pessimism</em> را با اجرای بسیار سریع هر <strong>Transaction</strong> جبران می‌کنیم، بنابراین فقط نیاز دارد که "lock" را برای مدت کوتاهی نگه دارد.
    </p>
<p>
        در مقابل، <em>serializable snapshot isolation</em> یک تکنیک <em>optimistic concurrency control</em> است. <em>Optimistic</em> در این زمینه به این معنی است که به جای مسدود کردن اگر اتفاقی بالقوه خطرناک رخ دهد، <strong>Transactions</strong> ها به هر حال ادامه می‌دهند، به این امید که همه چیز درست می‌شود. هنگامی که یک <strong>Transaction</strong> می‌خواهد <em>commit</em> شود، database بررسی می‌کند که آیا اتفاق بدی افتاده است یا خیر (یعنی، آیا <em>isolation</em> نقض شده است). اگر چنین است، the trans-
        <br/>
        Serializability
        <br/>
        |
        <br/>
        261
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0283</div>
            </div>
        </div>
        <!-- Page 0284 -->
        <div class="chapter" id="page-0284">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
<em>action</em> <em>aborted</em> می‌شود و باید دوباره امتحان شود. فقط <strong>Transactions</strong> هایی که به طور <em>serializably</em> اجرا شده‌اند، مجاز به <em>commit</em> هستند.
    </p>
<p>
<em>Optimistic concurrency control</em> یک ایده قدیمی است [52]، و مزایا و معایب آن برای مدت طولانی مورد بحث قرار گرفته است [53]. اگر <em>contention</em> بالایی وجود داشته باشد (بسیاری از <strong>Transactions</strong> سعی در دسترسی به object های یکسان دارند)، عملکرد ضعیفی دارد، زیرا این امر منجر به نیاز به <em>abort</em> کردن proportion بالایی از <strong>Transactions</strong> می‌شود. اگر system قبلاً به <em>maximum throughput</em> خود نزدیک شده باشد، بار <strong>Transaction</strong> اضافی از <strong>Transactions</strong> های تکراری می‌تواند performance را بدتر کند.
    </p>
<p>
        با این حال، اگر ظرفیت اضافی کافی وجود داشته باشد، و اگر <em>contention</em> بین <strong>Transactions</strong> خیلی زیاد نباشد، تکنیک‌های <em>optimistic concurrency control</em> تمایل به عملکرد بهتری نسبت به <em>pessimistic</em> دارند. <em>Contention</em> می‌تواند با operations atomic <em>commutative</em> کاهش یابد: به عنوان مثال، اگر چندین <strong>Transactions</strong> به طور همزمان می‌خواهند یک counter را افزایش دهند، مهم نیست که <em>increments</em> به چه ترتیبی اعمال می‌شوند (تا زمانی که counter در همان <strong>Transaction</strong> خوانده نشود)، بنابراین همه <em>increments</em> های همزمان را می‌توان بدون تداخل اعمال کرد.
    </p>
<p>
        همانطور که از نام آن پیداست، SSI بر اساس <em>snapshot isolation</em> است—یعنی، تمام <em>reads</em> در یک <strong>Transaction</strong> از یک <em>consistent snapshot</em> از database انجام می‌شوند (به "Snapshot Isolation and Repeatable Read" در صفحه 237 مراجعه کنید). این تفاوت اصلی در مقایسه با تکنیک‌های <em>optimistic concurrency control</em> قبلی است. علاوه بر <em>snapshot isolation</em>، SSI یک الگوریتم برای تشخیص <em>serialization conflicts</em> در بین <em>writes</em> و تعیین اینکه کدام <strong>Transactions</strong> را باید <em>abort</em> کرد، اضافه می‌کند.
    </p>
<h4>Decisions based on an outdated premise</h4>
<p>
        هنگامی که ما قبلاً در مورد <em>write skew</em> در <em>snapshot isolation</em> (به "Write Skew and Phantoms" در صفحه 246 مراجعه کنید) بحث کردیم، یک الگوی تکرارشونده را مشاهده کردیم: یک <strong>Transaction</strong> مقداری داده را از database می‌خواند، نتیجه query را بررسی می‌کند، و تصمیم می‌گیرد که بر اساس نتیجه‌ای که دید، اقدامی (<em>write</em> به database) انجام دهد. با این حال، تحت <em>snapshot isolation</em>، نتیجه query اصلی ممکن است دیگر در زمان <em>commit</em> شدن <strong>Transaction</strong> به‌روز نباشد، زیرا داده‌ها ممکن است در این مدت تغییر کرده باشند.
    </p>
<p>
        به عبارت دیگر، <em>transaction</em> در حال انجام یک action بر اساس یک premise (یک واقعیت که در ابتدای <strong>Transaction</strong> درست بود، به عنوان مثال، "در حال حاضر دو پزشک <em>on call</em> هستند") است. بعداً، وقتی <em>transaction</em> می‌خواهد <em>commit</em> شود، داده‌های اصلی ممکن است تغییر کرده باشند—premise ممکن است دیگر درست نباشد.
    </p>
<p>
        وقتی application یک <em>query</em> (به عنوان مثال، "تعداد پزشکانی که در حال حاضر <em>on call</em> هستند، چقدر است؟") انجام می‌دهد، database نمی‌داند که logic application چگونه از نتیجه آن <em>query</em> استفاده می‌کند. برای ایمن بودن، database باید فرض کند که هر تغییری در نتیجه <em>query</em> (premise) به این معنی است که <em>writes</em> در آن <strong>Transaction</strong> ممکن است نامعتبر باشد. به عبارت دیگر، ممکن است یک <em>causal dependency</em> بین <em>queries</em> و <em>writes</em> در <strong>Transaction</strong> وجود داشته باشد. به منظور ارائه <em>serializable isolation</em>، database باید موقعیت‌هایی را در
        <br/>
        262
        <br/>
        |
        <br/>
        Chapter 7: Transactions
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0284</div>
            </div>
        </div>
        <!-- Page 0285 -->
        <div class="chapter" id="page-0285">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        که یک <strong>Transaction</strong> ممکن است بر اساس یک premise منسوخ شده عمل کرده باشد و در آن صورت <em>transaction</em> را <em>abort</em> کند.
    </p>
<p>
        چگونه database می‌داند که آیا نتیجه یک query ممکن است تغییر کرده باشد؟ دو مورد وجود دارد که باید در نظر گرفت:
    </p>
<ul>
<li>
            تشخیص <em>reads</em> از یک <em>stale MVCC object version</em> (<em>uncommitted write</em> قبل از <em>read</em> رخ داده است)
        </li>
<li>
            تشخیص <em>writes</em> که بر <em>reads</em> قبلی تأثیر می‌گذارند (<em>write</em> پس از <em>read</em> رخ می‌دهد)
        </li>
</ul>
<h4>Detecting stale MVCC reads</h4>
<p>
        به یاد بیاورید که <em>snapshot isolation</em> معمولاً با <em>multi-version concurrency control (MVCC)</em> پیاده‌سازی می‌شود (به شکل 7-10 مراجعه کنید). هنگامی که یک <strong>Transaction</strong> از یک <em>consistent snapshot</em> در یک database MVCC می‌خواند، <em>writes</em> هایی را که توسط هر <strong>Transactions</strong> دیگری که هنوز در زمان ایجاد <em>snapshot</em>، <em>committed</em> نشده بودند، نادیده می‌گیرد. در شکل 7-10، <em>transaction</em> 43 آلیس را با on_call = true می‌بیند، زیرا <em>transaction</em> 42 (که وضعیت <em>on-call</em> آلیس را تغییر داد) <em>uncommitted</em> است. با این حال، تا زمانی که <em>transaction</em> 43 می‌خواهد <em>commit</em> شود، <em>transaction</em> 42 قبلاً <em>committed</em> شده است. این بدان معناست که <em>write</em> ای که هنگام خواندن از <em>consistent snapshot</em> نادیده گرفته شد، اکنون تأثیر گذاشته است، و premise <em>transaction</em> 43 دیگر درست نیست.
    </p>
<figure>
<img alt="Figure 7-10. Detecting when a transaction reads outdated values from an MVCC snapshot." src="figure7-10.png"/>
<figcaption>Figure 7-10. Detecting when a transaction reads outdated values from an MVCC snapshot.</figcaption>
</figure>
<p>
        Serializability
        <br/>
        |
        <br/>
        263
    </p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 285" src="page_0285/image_1.png"/></div>
</div>
                <div class="page-number">صفحه 0285</div>
            </div>
        </div>
        <!-- Page 0286 -->
        <div class="chapter" id="page-0286">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        به منظور جلوگیری از این <em>anomaly</em>، database باید پیگیری کند که چه زمانی یک <strong>Transaction</strong> <em>writes</em> های <strong>Transaction</strong> دیگری را به دلیل قوانین <em>MVCC visibility</em> نادیده می‌گیرد. وقتی <strong>Transaction</strong> می‌خواهد <em>commit</em> شود، database بررسی می‌کند که آیا هر یک از <em>writes</em> های نادیده گرفته شده در حال حاضر <em>committed</em> شده‌اند یا خیر. اگر چنین است، <strong>Transaction</strong> باید <em>aborted</em> شود.
    </p>
<p>
        چرا باید تا زمان <em>committing</em> صبر کنیم؟ چرا <em>transaction</em> 43 را بلافاصله هنگامی که <em>stale read</em> تشخیص داده شد، <em>abort</em> نکنیم؟ خب، اگر <em>transaction</em> 43 یک <em>read-only transaction</em> بود، نیازی به <em>aborted</em> شدن نداشت، زیرا هیچ خطری از <em>write skew</em> وجود ندارد. در زمانی که <em>transaction</em> 43 <em>read</em> خود را انجام می‌دهد، database هنوز نمی‌داند که آیا آن <strong>Transaction</strong> قرار است بعداً یک <em>write</em> را انجام دهد یا خیر. علاوه بر این، <em>transaction</em> 42 ممکن است هنوز <em>abort</em> شود یا ممکن است هنوز در زمان <em>committing</em> <em>transaction</em> 43 <em>uncommitted</em> باشد، و بنابراین <em>read</em> ممکن است اصلاً <em>stale</em> نباشد. با اجتناب از <em>aborts</em> های غیرضروری، SSI از پشتیبانی <em>snapshot isolation</em> برای <em>long-running reads</em> از یک <em>consistent snapshot</em> محافظت می‌کند.
    </p>
<h4>Detecting writes that affect prior reads</h4>
<p>
        مورد دوم که باید در نظر گرفت این است که <strong>Transaction</strong> دیگری داده‌ها را پس از خواندن آن تغییر می‌دهد. این مورد در شکل 7-11 نشان داده شده است.
    </p>
<figure>
<img alt="Figure 7-11. In serializable snapshot isolation, detecting when one transaction modifies another transaction’s reads." src="figure7-11.png"/>
<figcaption>Figure 7-11. In serializable snapshot isolation, detecting when one transaction modifies another transaction’s reads.</figcaption>
</figure>
<p>
        در زمینه <em>two-phase locking</em>، ما در مورد <em>index-range locks</em> بحث کردیم (به "Index-range locks" در صفحه 260 مراجعه کنید)، که به database اجازه می‌دهد تا دسترسی به تمام <em>rows</em> هایی که با یک query جستجوی خاص، مانند WHERE shift_id = 1234، مطابقت دارند، را <em>lock</em> کند. ما می‌توانیم از یک تکنیک مشابه در اینجا استفاده کنیم، با این تفاوت که <em>SSI locks</em>، <em>transactions</em> های دیگر را مسدود نمی‌کنند.
        <br/>
        264
        <br/>
        |
        <br/>
        Chapter 7: Transactions
    </p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 286" src="page_0286/image_1.png"/></div>
</div>
                <div class="page-number">صفحه 0286</div>
            </div>
        </div>
        <!-- Page 0287 -->
        <div class="chapter" id="page-0287">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        در شکل 7-11، <em>transactions</em> 42 و 43 هر دو به دنبال پزشکان <em>on-call</em> در طول شیفت 1234 هستند. اگر یک <em>index</em> روی shift_id وجود داشته باشد، database می‌تواند از ورودی <em>index</em> 1234 برای ثبت این واقعیت استفاده کند که <em>transactions</em> 42 و 43 این داده‌ها را خوانده‌اند. (اگر هیچ <em>index</em> ای وجود نداشته باشد، این اطلاعات را می‌توان در سطح table ردیابی کرد.) این اطلاعات فقط برای مدتی باید نگهداری شوند: پس از اینکه یک <strong>Transaction</strong> به پایان رسید (<em>committed</em> یا <em>aborted</em>)، و همه <strong>Transactions</strong> های همزمان به پایان رسیده‌اند، database می‌تواند آنچه را که خوانده است، فراموش کند.
    </p>
<p>
        وقتی یک <strong>Transaction</strong> به database <em>writes</em> می‌کند، باید در <em>indexes</em> ها به دنبال هر <strong>Transactions</strong> دیگری باشد که اخیراً داده‌های تحت تأثیر را خوانده‌اند. این فرآیند شبیه به به دست آوردن یک <em>write lock</em> روی <em>key range</em> تحت تأثیر است، اما به جای مسدود کردن تا زمانی که <em>readers</em> <em>committed</em> شده‌اند، <em>lock</em> به عنوان یک <em>tripwire</em> عمل می‌کند: به سادگی به <strong>Transactions</strong> اطلاع می‌دهد که داده‌هایی که خوانده‌اند، ممکن است دیگر به‌روز نباشند.
    </p>
<p>
        در شکل 7-11، <em>transaction</em> 43 به <em>transaction</em> 42 اطلاع می‌دهد که <em>read</em> قبلی آن منسوخ شده است، و بالعکس. <em>Transaction</em> 42 ابتدا <em>commit</em> می‌شود، و موفقیت‌آمیز است: اگرچه <em>write</em> <em>transaction</em> 43 بر 42 تأثیر گذاشت، 43 هنوز <em>committed</em> نشده است، بنابراین <em>write</em> هنوز اعمال نشده است. با این حال، هنگامی که <em>transaction</em> 43 می‌خواهد <em>commit</em> شود، <em>write</em> متناقض از 42 قبلاً <em>committed</em> شده است، بنابراین 43 باید <em>abort</em> شود.
    </p>
<h4>Performance of serializable snapshot isolation</h4>
<p>
        همانطور که همیشه، بسیاری از جزئیات مهندسی بر چگونگی عملکرد خوب یک الگوریتم در عمل تأثیر می‌گذارند.
        <br/>
        به عنوان مثال، یک trade-off، <em>granularity</em> است که در آن <em>reads</em> و <em>writes</em> <strong>Transactions</strong> ها پیگیری می‌شوند. اگر database فعالیت هر <strong>Transaction</strong> را با جزئیات زیادی پیگیری کند، می‌تواند در مورد اینکه کدام <strong>Transactions</strong> باید <em>abort</em> شوند، دقیق باشد، اما سربار حسابداری می‌تواند قابل توجه شود. پیگیری با جزئیات کمتر سریع‌تر است، اما ممکن است منجر به <em>aborted</em> شدن <strong>Transactions</strong> های بیشتری از آنچه که لزوماً مورد نیاز است، شود.
    </p>
<p>
        در برخی موارد، برای یک <strong>Transaction</strong> مشکلی ندارد که اطلاعاتی را که توسط <strong>Transaction</strong> دیگری بازنویسی شده است، بخواند: بسته به اینکه چه اتفاق دیگری افتاده است، گاهی اوقات می‌توان ثابت کرد که نتیجه اجرا با این وجود <em>serializable</em> است. PostgreSQL از این تئوری برای کاهش تعداد <em>aborts</em> های غیرضروری استفاده می‌کند [11, 41].
    </p>
<p>
        در مقایسه با <em>two-phase locking</em>، مزیت بزرگ <em>serializable snapshot isolation</em> این است که یک <strong>Transaction</strong> نیازی به مسدود کردن در انتظار <em>locks</em> که توسط <strong>Transaction</strong> دیگری نگهداری می‌شود، ندارد. مانند <em>snapshot isolation</em>، <em>writers</em>، <em>readers</em> را مسدود نمی‌کنند، و بالعکس. این اصل طراحی باعث می‌شود که <em>query latency</em> بسیار قابل پیش‌بینی‌تر و کمتر متغیر باشد. به طور خاص، <em>read-only queries</em> می‌توانند روی یک <em>consistent snapshot</em> بدون نیاز به هیچ <em>locks</em> اجرا شوند، که برای workloads های <em>read-heavy</em> بسیار جذاب است.
    </p>
<p>
        در مقایسه با اجرای سریال، <em>serializable snapshot isolation</em> به <em>throughput</em> از یک <em>CPU core</em> واحد محدود نمی‌شود: FoundationDB تشخیص <em>serialization conflicts</em> را در سراسر چندین machine توزیع می‌کند، که به آن اجازه می‌دهد تا به <em>throughput</em> بسیار بالایی مقیاس‌پذیر شود. حتی اگر داده‌ها ممکن است در سراسر چندین machine <em>partitioned</em> شوند، <strong>Transactions</strong> می‌توانند داده‌ها را در چندین partition بخوانند و <em>write</em> کنند و در عین حال <em>serializable isolation</em> را تضمین کنند [54].
        <br/>
        Serializability
        <br/>
        |
        <br/>
        265
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0287</div>
            </div>
        </div>
        <!-- Page 0288 -->
        <div class="chapter" id="page-0288">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
<em>The rate of aborts</em> به طور قابل توجهی بر <em>overall performance</em> از SSI تأثیر می‌گذارد. به عنوان مثال، یک <strong>Transaction</strong> که داده‌ها را برای مدت طولانی می‌خواند و می‌نویسد، احتمالاً با <em>conflicts</em> مواجه می‌شود و <em>aborted</em> می‌شود، بنابراین SSI نیاز دارد که <em>read-write transactions</em> نسبتاً کوتاه باشند (<em>long-running read-only transactions</em> ممکن است اشکالی نداشته باشد). با این حال، SSI احتمالاً نسبت به <em>slow transactions</em>، کمتر از <em>two-phase locking</em> یا اجرای سریال حساس است.
    </p>
<h4>Summary</h4>
<p>
<strong>Transactions</strong> یک <em>abstraction layer</em> هستند که به یک application اجازه می‌دهند تا وانمود کند که مشکلات <em>concurrency</em> خاص و انواع خاصی از <em>hardware</em> و <em>software faults</em> وجود ندارند. یک کلاس بزرگ از <em>errors</em> به یک <em>transaction abort</em> ساده کاهش می‌یابد، و application فقط باید دوباره تلاش کند.
    </p>
<p>
        در این فصل ما مثال‌های زیادی از مشکلاتی را که <strong>Transactions</strong> به جلوگیری از آنها کمک می‌کنند، دیدیم.
        <br/>
        همه applications ها در معرض این مشکلات نیستند: یک application با الگوهای دسترسی بسیار ساده، مانند خواندن و نوشتن فقط یک رکورد، احتمالاً می‌تواند بدون <strong>Transactions</strong> مدیریت کند. با این حال، برای الگوهای دسترسی پیچیده‌تر، <strong>Transactions</strong> می‌توانند تعداد موارد <em>error</em> بالقوه را که نیاز دارید به آنها فکر کنید، بسیار کاهش دهند.
    </p>
<p>
        بدون <strong>Transactions</strong>، سناریوهای مختلف <em>error</em> (<em>processes crashing, network interruptions, power outages, disk full, unexpected concurrency</em>، و غیره) به این معنی است که داده‌ها می‌توانند به روش‌های مختلفی ناسازگار شوند. به عنوان مثال، داده‌های <em>denormalized</em> می‌توانند به راحتی از داده‌های منبع خارج از <em>sync</em> شوند. بدون <strong>Transactions</strong>، استدلال در مورد تأثیراتی که دسترسی‌های متقابل پیچیده می‌توانند بر database داشته باشند، بسیار دشوار می‌شود.
    </p>
<p>
        در این فصل، ما به طور خاص در مورد <em>concurrency control</em> عمیق شدیم. ما چندین <em>isolation levels</em> که به طور گسترده استفاده می‌شوند، به ویژه <em>read committed</em>، <em>snapshot isolation</em> (که گاهی اوقات <em>repeatable read</em> نامیده می‌شود) و <em>serializable</em> را مورد بحث قرار دادیم. ما آن <em>isolation levels</em> را با بحث در مورد مثال‌های مختلف <em>race conditions</em> مشخص کردیم:
    </p>
<ul>
<li>
            Dirty reads
            <br/>
            یک client داده‌های <em>writes</em> یک client دیگر را قبل از اینکه <em>committed</em> شده باشند، می‌خواند. سطح <em>read committed isolation</em> و سطوح قوی‌تر از <em>dirty reads</em> جلوگیری می‌کنند.
        </li>
<li>
            Dirty writes
            <br/>
            یک client داده‌هایی را که client دیگری نوشته است، اما هنوز <em>committed</em> نکرده است، بازنویسی می‌کند. تقریباً تمام پیاده‌سازی‌های <strong>Transaction</strong> از <em>dirty writes</em> جلوگیری می‌کنند.
        </li>
<li>
            Read skew (nonrepeatable reads)
            <br/>
            یک client قسمت‌های مختلف database را در زمان‌های مختلف می‌بیند. این مسئله معمولاً با <em>snapshot isolation</em>، که به یک <strong>Transaction</strong> اجازه می‌دهد از یک <em>consistent snapshot</em> در یک نقطه زمانی بخواند، جلوگیری می‌شود. معمولاً با <em>multi-version concurrency control (MVCC)</em> پیاده‌سازی می‌شود.
            <br/>
            266
            <br/>
            |
            <br/>
            Chapter 7: Transactions
        </li>
</ul>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0288</div>
            </div>
        </div>
        <!-- Page 0289 -->
        <div class="chapter" id="page-0289">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<ul>
<li>
            Lost updates
            <br/>
            دو client به طور همزمان یک <em>read-modify-write cycle</em> را انجام می‌دهند. یکی <em>write</em> دیگری را بدون ترکیب تغییراتش بازنویسی می‌کند، بنابراین داده‌ها از دست می‌روند. برخی از پیاده‌سازی‌های <em>snapshot isolation</em> از این <em>anomaly</em> به طور خودکار جلوگیری می‌کنند، در حالی که برخی دیگر به یک <em>manual lock</em> (SELECT FOR UPDATE) نیاز دارند.
        </li>
<li>
            Write skew
            <br/>
            یک <strong>Transaction</strong> چیزی را می‌خواند، بر اساس value که دید تصمیم می‌گیرد، و تصمیم را در database می‌نویسد. با این حال، تا زمانی که <em>write</em> انجام شود، premise تصمیم دیگر درست نیست. فقط <em>serializable isolation</em> از این <em>anomaly</em> جلوگیری می‌کند.
        </li>
<li>
            Phantom reads
            <br/>
            یک <strong>Transaction</strong> object هایی را می‌خواند که با یک <em>search condition</em> مطابقت دارند. client دیگری یک <em>write</em> انجام می‌دهد که بر نتایج آن جستجو تأثیر می‌گذارد. <em>Snapshot isolation</em> از <em>straightforward phantom reads</em> جلوگیری می‌کند، اما phantoms در context of <em>write skew</em> نیاز به درمان ویژه دارند، مانند <em>index-range locks</em>.
        </li>
</ul>
<p>
<em>Weak isolation levels</em> در برابر برخی از آن <em>anomalies</em> محافظت می‌کنند اما شما را، توسعه‌دهنده application، برای مدیریت دیگران به صورت دستی (به عنوان مثال، با استفاده از <em>explicit locking</em>) رها می‌کنند. فقط <em>serializable isolation</em> از همه این مسائل محافظت می‌کند. ما سه رویکرد مختلف برای پیاده‌سازی <em>serializable transactions</em> را مورد بحث قرار دادیم:
    </p>
<ul>
<li>
            Literally executing transactions in a serial order
            <br/>
            اگر می‌توانید اجرای هر <strong>Transaction</strong> را بسیار سریع کنید، و <em>transaction throughput</em> به اندازه کافی کم است که بتوان آن را در یک <em>CPU core</em> واحد پردازش کرد، این یک گزینه ساده و مؤثر است.
        </li>
<li>
            Two-phase locking
            <br/>
            برای دهه‌ها این روش استاندارد برای پیاده‌سازی <em>serializability</em> بوده است، اما بسیاری از applications ها از استفاده از آن به دلیل <em>performance characteristics</em> آن اجتناب می‌کنند.
        </li>
<li>
            Serializable snapshot isolation (SSI)
            <br/>
            یک الگوریتم نسبتاً جدید که از بیشتر <em>downsides</em> رویکردهای قبلی اجتناب می‌کند. این از یک رویکرد <em>optimistic</em> استفاده می‌کند و به <strong>Transactions</strong> اجازه می‌دهد بدون مسدود کردن ادامه دهند. هنگامی که یک <strong>Transaction</strong> می‌خواهد <em>commit</em> شود، بررسی می‌شود، و اگر اجرا <em>serializable</em> نبود، <em>aborted</em> می‌شود.
        </li>
</ul>
<p>
        مثال‌های این فصل از یک <em>relational data model</em> استفاده می‌کردند. با این حال، همانطور که در "The need for multi-object transactions" در صفحه 231 مورد بحث قرار گرفت، <strong>Transactions</strong> یک ویژگی database ارزشمند هستند، مهم نیست از کدام <em>data model</em> استفاده شود.
    </p>
<p>
        در این فصل، ما ایده‌ها و الگوریتم‌ها را بیشتر در زمینه database ای که روی یک machine واحد اجرا می‌شود، بررسی کردیم. <strong>Transactions</strong> در databases های <em>distributed</em> مجموعه جدیدی از چالش‌های دشوار را باز می‌کند، که ما در دو فصل آینده در مورد آنها بحث خواهیم کرد.
        <br/>
        Summary
        <br/>
        |
        <br/>
        267
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0289</div>
            </div>
        </div>
        <!-- Page 0290 -->
        <div class="chapter" id="page-0290">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<h3>References</h3>
<ol>
<li>
            [1] Donald D. Chamberlin, Morton M. Astrahan, Michael W. Blasgen, et al.: “A His‐
            tory and Evaluation of System R,” Communications of the ACM, volume 24, number
            10, pages 632–646, October 1981. doi:10.1145/358769.358784
        </li>
<li>
            [2] Jim N. Gray, Raymond A. Lorie, Gianfranco R. Putzolu, and Irving L. Traiger:
            “Granularity of Locks and Degrees of Consistency in a Shared Data Base,” in Model‐
            ling in Data Base Management Systems: Proceedings of the IFIP Working Conference
            on Modelling in Data Base Management Systems, edited by G. M. Nijssen, pages 364–
            394, Elsevier/North Holland Publishing, 1976. Also in Readings in Database Systems,
            4th edition, edited by Joseph M. Hellerstein and Michael Stonebraker, MIT Press,
            2005. ISBN: 978-0-262-69314-1
        </li>
<li>
            [3] Kapali P. Eswaran, Jim N. Gray, Raymond A. Lorie, and Irving L. Traiger: “The
            Notions of Consistency and Predicate Locks in a Database System,” Communications
            of the ACM, volume 19, number 11, pages 624–633, November 1976.
        </li>
<li>
            [4] “ACID Transactions Are Incredibly Helpful,” FoundationDB, LLC, 2013.
        </li>
<li>
            [5] John D. Cook: “ACID Versus BASE for Database Transactions,” johndcook.com,
            July 6, 2009.
        </li>
<li>
            [6] Gavin Clarke: “NoSQL’s CAP Theorem Busters: We Don’t Drop ACID,” theregis‐
            ter.co.uk, November 22, 2012.
        </li>
<li>
            [7] Theo Härder and Andreas Reuter: “Principles of Transaction-Oriented Database
            Recovery,” ACM Computing Surveys, volume 15, number 4, pages 287–317, Decem‐
            ber 1983. doi:10.1145/289.291
        </li>
<li>
            [8] Peter Bailis, Alan Fekete, Ali Ghodsi, et al.: “HAT, not CAP: Towards Highly
            Available Transactions,” at 14th USENIX Workshop on Hot Topics in Operating Sys‐
            tems (HotOS), May 2013.
        </li>
<li>
            [9] Armando Fox, Steven D. Gribble, Yatin Chawathe, et al.: “Cluster-Based Scalable
            Network Services,” at 16th ACM Symposium on Operating Systems Principles (SOSP),
            October 1997.
        </li>
<li>
            [10] Philip A. Bernstein, Vassos Hadzilacos, and Nathan Goodman: Concurrency
            Control and Recovery in Database Systems. Addison-Wesley, 1987. ISBN:
            978-0-201-10715-9, available online at research.microsoft.com.
        </li>
<li>
            [11] Alan Fekete, Dimitrios Liarokapis, Elizabeth O’Neil, et al.: “Making Snapshot
            Isolation Serializable,” ACM Transactions on Database Systems, volume 30, number
            2, pages 492–528, June 2005. doi:10.1145/1071610.1071615
        </li>
</ol>
<p>
        268
        <br/>
        |
        <br/>
        Chapter 7: Transactions
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0290</div>
            </div>
        </div>
        <!-- Page 0291 -->
        <div class="chapter" id="page-0291">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<h3>References</h3>
<ol>
<li>
            [12] Mai Zheng, Joseph Tucek, Feng Qin, and Mark Lillibridge: “Understanding the
            Robustness of SSDs Under Power Fault,” at 11th USENIX Conference on File and
            Storage Technologies (FAST), February 2013.
        </li>
<li>
            [13] Laurie Denness: “SSDs: A Gift and a Curse,” laur.ie, June 2, 2015.
        </li>
<li>
            [14] Adam Surak: “When Solid State Drives Are Not That Solid,” blog.algolia.com,
            June 15, 2015.
        </li>
<li>
            [15] Thanumalayan Sankaranarayana Pillai, Vijay Chidambaram, Ramnatthan Ala‐
            gappan, et al.: “All File Systems Are Not Created Equal: On the Complexity of Craft‐
            ing Crash-Consistent Applications,” at 11th USENIX Symposium on Operating
            Systems Design and Implementation (OSDI), October 2014.
        </li>
<li>
            [16] Chris Siebenmann: “Unix’s File Durability Problem,” utcc.utoronto.ca, April 14,
            2016.
        </li>
<li>
            [17] Lakshmi N. Bairavasundaram, Garth R. Goodson, Bianca Schroeder, et al.: “An
            Analysis of Data Corruption in the Storage Stack,” at 6th USENIX Conference on File
            and Storage Technologies (FAST), February 2008.
        </li>
<li>
            [18] Bianca Schroeder, Raghav Lagisetty, and Arif Merchant: “Flash Reliability in
            Production: The Expected and the Unexpected,” at 14th USENIX Conference on File
            and Storage Technologies (FAST), February 2016.
        </li>
<li>
            [19] Don Allison: “SSD Storage – Ignorance of Technology Is No Excuse,” blog.kore‐
            logic.com, March 24, 2015.
        </li>
<li>
            [20] Dave Scherer: “Those Are Not Transactions (Cassandra 2.0),” blog.founda‐
            tiondb.com, September 6, 2013.
        </li>
<li>
            [21] Kyle Kingsbury: “Call Me Maybe: Cassandra,” aphyr.com, September 24, 2013.
        </li>
<li>
            [22] “ACID Support in Aerospike,” Aerospike, Inc., June 2014.
        </li>
<li>
            [23] Martin Kleppmann: “Hermitage: Testing the ‘I’ in ACID,” martin.klepp‐
            mann.com, November 25, 2014.
        </li>
<li>
            [24] Tristan D’Agosta: “BTC Stolen from Poloniex,” bitcointalk.org, March 4, 2014.
        </li>
<li>
            [25] bitcointhief2: “How I Stole Roughly 100 BTC from an Exchange and How I
            Could Have Stolen More!,” reddit.com, February 2, 2014.
        </li>
<li>
            [26] Sudhir Jorwekar, Alan Fekete, Krithi Ramamritham, and S. Sudarshan: “Auto‐
            mating the Detection of Snapshot Isolation Anomalies,” at 33rd International Confer‐
            ence on Very Large Data Bases (VLDB), September 2007.
        </li>
<li>
            [27] Michael Melanson: “Transactions: The Limits of Isolation,” michaelmelan‐
            son.net, March 20, 2014.
        </li>
</ol>
<p>
        Summary
        <br/>
        |
        <br/>
        269
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0291</div>
            </div>
        </div>
        <!-- Page 0292 -->
        <div class="chapter" id="page-0292">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<ol>
<li>
            [28] Hal Berenson, Philip A. Bernstein, Jim N. Gray, et al.: “A Critique of ANSI SQL
            Isolation Levels,” at ACM International Conference on Management of Data (SIG‐
            MOD), May 1995.
        </li>
<li>
            [29] Atul Adya: “Weak Consistency: A Generalized Theory and Optimistic Imple‐
            mentations for Distributed Transactions,” PhD Thesis, Massachusetts Institute of
            Technology, March 1999.
        </li>
<li>
            [30] Peter Bailis, Aaron Davidson, Alan Fekete, et al.: “Highly Available Transactions:
            Virtues and Limitations (Extended Version),” at 40th International Conference on
            Very Large Data Bases (VLDB), September 2014.
        </li>
<li>
            [31] Bruce Momjian: “MVCC Unmasked,” momjian.us, July 2014.
        </li>
<li>
            [32] Annamalai Gurusami: “Repeatable Read Isolation Level in InnoDB – How Con‐
            sistent Read View Works,” blogs.oracle.com, January 15, 2013.
        </li>
<li>
            [33] Nikita Prokopov: “Unofficial Guide to Datomic Internals,” tonsky.me, May 6,
            2014.
        </li>
<li>
            [34] Baron Schwartz: “Immutability, MVCC, and Garbage Collection,” xaprb.com,
            December 28, 2013.
        </li>
<li>
            [35] J. Chris Anderson, Jan Lehnardt, and Noah Slater: CouchDB: The Definitive
            Guide. O’Reilly Media, 2010. ISBN: 978-0-596-15589-6
        </li>
<li>
            [36] Rikdeb Mukherjee: “Isolation in DB2 (Repeatable Read, Read Stability, Cursor
            Stability, Uncommitted Read) with Examples,” mframes.blogspot.co.uk, July 4, 2013.
        </li>
<li>
            [37] Steve Hilker: “Cursor Stability (CS) – IBM DB2 Community,” toadworld.com,
            March 14, 2013.
        </li>
<li>
            [38] Nate Wiger: “An Atomic Rant,” nateware.com, February 18, 2010.
        </li>
<li>
            [39] Joel Jacobson: “Riak 2.0: Data Types,” blog.joeljacobson.com, March 23, 2014.
        </li>
<li>
            [40] Michael J. Cahill, Uwe Röhm, and Alan Fekete: “Serializable Isolation for Snap‐
            shot Databases,” at ACM International Conference on Management of Data (SIG‐
            MOD), June 2008. doi:10.1145/1376616.1376690
        </li>
<li>
            [41] Dan R. K. Ports and Kevin Grittner: “Serializable Snapshot Isolation in Post‐
            greSQL,” at 38th International Conference on Very Large Databases (VLDB), August
            2012.
        </li>
<li>
            [42] Tony Andrews: “Enforcing Complex Constraints in Oracle,” tonyandrews.blog‐
            spot.co.uk, October 15, 2004.
        </li>
<li>
            [43] Douglas B. Terry, Marvin M. Theimer, Karin Petersen, et al.: “Managing Update
            Conflicts in Bayou, a Weakly Connected Replicated Storage System,” at 15th ACM
            270
            <br/>
            |
            <br/>
            Chapter 7: Transactions
        </li>
</ol>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0292</div>
            </div>
        </div>
        <!-- Page 0293 -->
        <div class="chapter" id="page-0293">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<ol>
<li>
            [28] Hal Berenson, Philip A. Bernstein, Jim N. Gray, et al.: “A Critique of ANSI SQL
            Isolation Levels,” at ACM International Conference on Management of Data (SIG‐
            MOD), May 1995.
        </li>
<li>
            [29] Atul Adya: “Weak Consistency: A Generalized Theory and Optimistic Imple‐
            mentations for Distributed Transactions,” PhD Thesis, Massachusetts Institute of
            Technology, March 1999.
        </li>
<li>
            [30] Peter Bailis, Aaron Davidson, Alan Fekete, et al.: “Highly Available Transactions:
            Virtues and Limitations (Extended Version),” at 40th International Conference on
            Very Large Data Bases (VLDB), September 2014.
        </li>
<li>
            [31] Bruce Momjian: “MVCC Unmasked,” momjian.us, July 2014.
        </li>
<li>
            [32] Annamalai Gurusami: “Repeatable Read Isolation Level in InnoDB – How Con‐
            sistent Read View Works,” blogs.oracle.com, January 15, 2013.
        </li>
<li>
            [33] Nikita Prokopov: “Unofficial Guide to Datomic Internals,” tonsky.me, May 6,
            2014.
        </li>
<li>
            [34] Baron Schwartz: “Immutability, MVCC, and Garbage Collection,” xaprb.com,
            December 28, 2013.
        </li>
<li>
            [35] J. Chris Anderson, Jan Lehnardt, and Noah Slater: CouchDB: The Definitive
            Guide. O’Reilly Media, 2010. ISBN: 978-0-596-15589-6
        </li>
<li>
            [36] Rikdeb Mukherjee: “Isolation in DB2 (Repeatable Read, Read Stability, Cursor
            Stability, Uncommitted Read) with Examples,” mframes.blogspot.co.uk, July 4, 2013.
        </li>
<li>
            [37] Steve Hilker: “Cursor Stability (CS) – IBM DB2 Community,” toadworld.com,
            March 14, 2013.
        </li>
<li>
            [38] Nate Wiger: “An Atomic Rant,” nateware.com, February 18, 2010.
        </li>
<li>
            [39] Joel Jacobson: “Riak 2.0: Data Types,” blog.joeljacobson.com, March 23, 2014.
        </li>
<li>
            [40] Michael J. Cahill, Uwe Röhm, and Alan Fekete: “Serializable Isolation for Snap‐
            shot Databases,” at ACM International Conference on Management of Data (SIG‐
            MOD), June 2008. doi:10.1145/1376616.1376690
        </li>
<li>
            [41] Dan R. K. Ports and Kevin Grittner: “Serializable Snapshot Isolation in Post‐
            greSQL,” at 38th International Conference on Very Large Databases (VLDB), August
            2012.
        </li>
<li>
            [42] Tony Andrews: “Enforcing Complex Constraints in Oracle,” tonyandrews.blog‐
            spot.co.uk, October 15, 2004.
        </li>
<li>
            [43] Douglas B. Terry, Marvin M. Theimer, Karin Petersen, et al.: “Managing Update
            Conflicts in Bayou, a Weakly Connected Replicated Storage System,” at 15th ACM
            270
            <br/>
            |
            <br/>
            Chapter 7: Transactions
        </li>
</ol>
<ol start="44">
<li>
            [44] Gary Fredericks: “Postgres Serializability Bug,” github.com, September 2015.
        </li>
<li>
            [45] Michael Stonebraker, Samuel Madden, Daniel J. Abadi, et al.: “The End of an
            Architectural Era (It’s Time for a Complete Rewrite),” at 33rd International Confer‐
            ence on Very Large Data Bases (VLDB), September 2007.
        </li>
<li>
            [46] John Hugg: “H-Store/VoltDB Architecture vs. CEP Systems and Newer Stream‐
            ing Architectures,” at Data @Scale Boston, November 2014.
        </li>
<li>
            [47] Robert Kallman, Hideaki Kimura, Jonathan Natkins, et al.: “H-Store: A High-
            Performance, Distributed Main Memory Transaction Processing System,” Proceed‐
            ings of the VLDB Endowment, volume 1, number 2, pages 1496–1499, August 2008.
        </li>
<li>
            [48] Rich Hickey: “The Architecture of Datomic,” infoq.com, November 2, 2012.
        </li>
<li>
            [49] John Hugg: “Debunking Myths About the VoltDB In-Memory Database,”
            voltdb.com, May 12, 2014.
        </li>
<li>
            [50] Joseph M. Hellerstein, Michael Stonebraker, and James Hamilton: “Architecture
            of a Database System,” Foundations and Trends in Databases, volume 1, number 2,
            pages 141–259, November 2007. doi:10.1561/1900000002
        </li>
<li>
            [51] Michael J. Cahill: “Serializable Isolation for Snapshot Databases,” PhD Thesis,
            University of Sydney, July 2009.
        </li>
<li>
            [52] D. Z. Badal: “Correctness of Concurrency Control and Implications in Dis‐
            tributed Databases,” at 3rd International IEEE Computer Software and Applications
            Conference (COMPSAC), November 1979.
        </li>
<li>
            [53] Rakesh Agrawal, Michael J. Carey, and Miron Livny: “Concurrency Control Per‐
            formance Modeling: Alternatives and Implications,” ACM Transactions on Database
            Systems (TODS), volume 12, number 4, pages 609–654, December 1987. doi:
            10.1145/32204.32220
        </li>
<li>
            [54] Dave Rosenthal: “Databases at 14.4MHz,” blog.foundationdb.com, December 10,
            2014.
        </li>
</ol>
<p>
        Summary
        <br/>
        |
        <br/>
        271
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0293</div>
            </div>
        </div>
        <!-- Page 0295 -->
        <div class="chapter" id="page-0295">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        i. با یک استثنا: ما فرض خواهیم کرد که <em>faults</em> ها غیر-<em>Byzantine</em> هستند (به "Byzantine Faults" در صفحه 304 مراجعه کنید).
    </p>
<h3>CHAPTER 8</h3>
<h4>The Trouble with Distributed Systems</h4>
<p>
        Hey I just met you
        <br/>
        The network’s laggy
        <br/>
        But here’s my data
        <br/>
        So store it maybe
        <br/>
        —Kyle Kingsbury, Carly Rae Jepsen and the Perils of Network Partitions (2013)
    </p>
<p>
        یک موضوع تکرارشونده در چند فصل گذشته این بوده است که چگونه سیستم‌ها مواردی را که اشتباه پیش می‌روند، مدیریت می‌کنند. به عنوان مثال، ما در مورد <em>replica failover</em> ("Handling Node Outages" در صفحه 156)، <em>replication lag</em> ("Problems with Replication Lag" در صفحه 161)، و <em>concurrency control</em> برای <strong>Transactions</strong> ("Weak Isolation Levels" در صفحه 233) بحث کردیم. همانطور که ما موارد <em>edge cases</em> مختلف را که می‌تواند در سیستم‌های واقعی رخ دهد، درک می‌کنیم، در مدیریت آنها بهتر می‌شویم.
    </p>
<p>
        با این حال، حتی اگر ما در مورد <em>faults</em> زیاد صحبت کرده باشیم، چند فصل گذشته هنوز هم بیش از حد خوش‌بینانه بوده‌اند. واقعیت حتی تاریک‌تر است. ما اکنون بدبینی خود را به حداکثر خواهیم رساند و فرض می‌کنیم که هر چیزی که می‌تواند اشتباه شود، اشتباه خواهد شد.i (<em>Experienced systems operators</em> به شما خواهند گفت که این یک فرض منطقی است. اگر مودبانه بپرسید، ممکن است در حالی که زخم‌های نبردهای گذشته خود را التیام می‌دهند، برخی از داستان‌های ترسناک را برای شما تعریف کنند.)
    </p>
<p>
        کار با <em>distributed systems</em> اساساً با نوشتن نرم‌افزار روی یک کامپیوتر واحد متفاوت است—و تفاوت اصلی این است که راه‌های جدید و هیجان‌انگیز زیادی برای اشتباه پیش رفتن چیزها وجود دارد [1, 2]. در این فصل، ما طعم مشکلات را که در عمل ایجاد می‌شوند، خواهیم چشید، و درکی از چیزهایی که می‌توانیم و نمی‌توانیم به آنها تکیه کنیم، خواهیم داشت.
    </p>
<p>
        273
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0295</div>
            </div>
        </div>
        <!-- Page 0296 -->
        <div class="chapter" id="page-0296">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        در پایان، وظیفه ما به عنوان مهندسان این است که system هایی بسازیم که کار خود را انجام دهند (یعنی، <em>guarantees</em> هایی را که کاربران انتظار دارند، برآورده کنند)، علیرغم اینکه همه چیز اشتباه پیش می‌رود. در فصل 9، ما به برخی از نمونه‌های الگوریتم‌هایی نگاه خواهیم کرد که می‌توانند چنین <em>guarantees</em> هایی را در یک system <em>distributed</em> ارائه دهند. اما ابتدا، در این فصل، باید بفهمیم با چه چالش‌هایی روبرو هستیم.
    </p>
<p>
        این فصل یک نمای کلی کاملاً بدبینانه و دلسردکننده از چیزهایی است که ممکن است در یک <em>distributed system</em> اشتباه پیش برود. ما به مشکلات شبکه‌ها ("Unreliable Networks" در صفحه 277) نگاه خواهیم کرد. ساعت‌ها و مسائل زمان‌بندی ("Unreliable Clocks" در صفحه 287)؛ و ما در مورد میزان اجتناب از آنها بحث خواهیم کرد. عواقب همه این مسائل، گیج‌کننده هستند، بنابراین ما بررسی خواهیم کرد که چگونه در مورد وضعیت یک <em>distributed system</em> فکر کنیم و چگونه در مورد چیزهایی که اتفاق افتاده‌اند استدلال کنیم ("Knowledge, Truth, and Lies" در صفحه 300).
    </p>
<h4>Faults and Partial Failures</h4>
<p>
        وقتی شما در حال نوشتن یک برنامه روی یک کامپیوتر واحد هستید، معمولاً به روشی نسبتاً قابل پیش‌بینی رفتار می‌کند: یا کار می‌کند یا نمی‌کند. نرم‌افزار باگ‌دار ممکن است این‌طور به نظر برسد که کامپیوتر گاهی اوقات "روز بدی دارد" (مشکلی که اغلب با راه‌اندازی مجدد برطرف می‌شود)، اما این عمدتاً فقط یک نتیجه از نرم‌افزار بد نوشته‌شده است.
    </p>
<p>
        هیچ دلیل اساسی وجود ندارد که چرا نرم‌افزار روی یک کامپیوتر واحد باید ناپایدار باشد: وقتی سخت‌افزار به درستی کار می‌کند، operation یکسان همیشه نتیجه یکسانی را تولید می‌کند (<em>it is deterministic</em>). اگر یک مشکل سخت‌افزاری وجود داشته باشد (به عنوان مثال، <em>memory corruption</em> یا یک کانکتور شل)، عواقب آن معمولاً یک <em>total system failure</em> است (به عنوان مثال، <em>kernel panic</em>، "<em>blue screen of death</em>"، عدم راه‌اندازی). یک کامپیوتر منفرد با نرم‌افزار خوب معمولاً یا کاملاً کاربردی است یا کاملاً خراب است، اما نه چیزی در این بین.
    </p>
<p>
        این یک انتخاب عمدی در طراحی کامپیوترها است: اگر یک <em>internal fault</em> رخ دهد، ما ترجیح می‌دهیم که یک کامپیوتر به طور کامل <em>crash</em> کند تا اینکه یک نتیجه اشتباه را برگرداند، زیرا نتایج اشتباه مدیریت آنها دشوار و گیج‌کننده است. بنابراین، کامپیوترها واقعیت فیزیکی مبهم را که بر روی آنها پیاده‌سازی می‌شوند، پنهان می‌کنند و یک مدل <em>idealized system</em> را ارائه می‌دهند که با کمال ریاضی عمل می‌کند. یک <em>CPU instruction</em> همیشه یک کار یکسان را انجام می‌دهد. اگر شما مقداری داده را به حافظه یا دیسک <em>write</em> می‌کنید، آن داده‌ها دست‌نخورده باقی می‌مانند و به طور تصادفی خراب نمی‌شوند. این هدف طراحی از محاسبه همیشه صحیح به تمام راه‌های اولیه از اولین کامپیوتر دیجیتال برمی‌گردد [3].
    </p>
<p>
        وقتی شما در حال نوشتن نرم‌افزاری هستید که روی چندین کامپیوتر اجرا می‌شود، که توسط یک شبکه متصل شده‌اند، وضعیت اساساً متفاوت است. در <em>distributed systems</em>، ما دیگر در یک مدل <em>idealized system</em> کار نمی‌کنیم—ما چاره‌ای نداریم جز اینکه با واقعیت درهم و برهم دنیای فیزیکی روبرو شویم. و در دنیای فیزیکی، طیف وسیعی از چیزها می‌توانند اشتباه پیش بروند، همانطور که توسط این حکایت نشان داده شده است [4]:
        <br/>
        274
        <br/>
        |
        <br/>
        Chapter 8: The Trouble with Distributed Systems
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0296</div>
            </div>
        </div>
        <!-- Page 0297 -->
        <div class="chapter" id="page-0297">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        In my limited experience I’ve dealt with long-lived network partitions in a single data
        center (DC), PDU [power distribution unit] failures, switch failures, accidental power
        cycles of whole racks, whole-DC backbone failures, whole-DC power failures, and a
        hypoglycemic driver smashing his Ford pickup truck into a DC’s HVAC [heating, ven‐
        tilation, and air conditioning] system. And I’m not even an ops guy.
        <br/>
        —Coda Hale
    </p>
<p>
        در یک <em>distributed system</em>، ممکن است بخش‌هایی از system وجود داشته باشند که به روشی غیرقابل پیش‌بینی خراب شده‌اند، حتی اگر بخش‌های دیگر system خوب کار کنند. این به عنوان <em>partial failure</em> شناخته می‌شود. مشکل این است که <em>partial failures</em>، <em>nondeterministic</em> هستند: اگر شما سعی کنید کاری را که شامل چندین node و شبکه می‌شود انجام دهید، ممکن است گاهی اوقات کار کند و گاهی اوقات به طور غیرقابل پیش‌بینی شکست بخورد. همانطور که خواهیم دید، شما ممکن است حتی ندانید که آیا چیزی موفق شده است یا نه، زیرا زمانی که طول می‌کشد تا یک پیام از طریق شبکه عبور کند نیز <em>nondeterministic</em> است!
    </p>
<p>
        این <em>nondeterminism</em> و احتمال <em>partial failures</em> است که کار با <em>distributed systems</em> را دشوار می‌کند [5].
    </p>
<h4>Cloud Computing and Supercomputing</h4>
<p>
        یک طیف از فلسفه‌ها در مورد نحوه ساختن سیستم‌های محاسباتی در مقیاس بزرگ وجود دارد:
    </p>
<ul>
<li>
            در یک انتهای مقیاس، زمینه <em>high-performance computing (HPC)</em> قرار دارد. <em>Supercomputers</em> با هزاران <em>CPUs</em> معمولاً برای کارهای محاسباتی فشرده علمی، مانند پیش‌بینی آب و هوا یا <em>molecular dynamics</em> (شبیه‌سازی حرکت اتم‌ها و مولکول‌ها) استفاده می‌شوند.
        </li>
<li>
            در انتهای دیگر، <em>cloud computing</em> قرار دارد، که به خوبی تعریف نشده است [6] اما اغلب با <em>multi-tenant datacenters</em>، کامپیوترهای <em>commodity</em> متصل شده با یک شبکه IP (اغلب اترنت)، تخصیص منابع <em>elastic/on-demand</em> و صورت‌حساب <em>metered</em> مرتبط است.
        </li>
<li>
<em>Traditional enterprise datacenters</em> در جایی بین این دو <em>extremes</em> قرار دارند.
        </li>
</ul>
<p>
        با این فلسفه‌ها رویکردهای بسیار متفاوتی برای رسیدگی به <em>faults</em> وجود دارد. در یک supercomputer، یک <em>job</em> معمولاً وضعیت محاسبات خود را هر از چند گاهی به ذخیره‌سازی <em>durable</em> <em>checkpoints</em> می‌کند. اگر یک node شکست بخورد، یک راه‌حل رایج این است که به سادگی کل workload cluster را متوقف کنید. پس از تعمیر node معیوب، محاسبات از آخرین <em>checkpoint</em> راه‌اندازی مجدد می‌شود [7, 8]. بنابراین، یک <em>supercomputer</em> بیشتر شبیه یک کامپیوتر تک node است تا یک <em>distributed system</em>: این <em>partial failure</em> را با اجازه دادن به آن که به <em>total failure</em> تبدیل شود، مدیریت می‌کند—اگر هر بخشی از system شکست بخورد، فقط اجازه دهید همه چیز خراب شود (مانند یک <em>kernel panic</em> روی یک machine واحد).
    </p>
<p>
        در این کتاب ما بر system هایی متمرکز هستیم که برای پیاده‌سازی سرویس‌های اینترنتی استفاده می‌شوند، که معمولاً بسیار متفاوت از <em>supercomputers</em> به نظر می‌رسند:
        <br/>
        Faults and Partial Failures
        <br/>
        |
        <br/>
        275
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0297</div>
            </div>
        </div>
        <!-- Page 0298 -->
        <div class="chapter" id="page-0298">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<ul>
<li>
            بسیاری از applications های مرتبط با اینترنت، آنلاین هستند، به این معنا که آنها باید بتوانند در هر زمانی به users با <em>low latency</em> سرویس ارائه دهند. غیرقابل دسترس کردن سرویس—به عنوان مثال، متوقف کردن cluster برای تعمیر—قابل قبول نیست. در مقابل، کارهای <em>offline</em> (<em>batch</em>) مانند شبیه‌سازی‌های آب و هوا را می‌توان متوقف و با تأثیر نسبتاً کمی راه‌اندازی مجدد کرد.
        </li>
<li>
<em>Supercomputers</em> معمولاً از سخت‌افزار تخصصی ساخته می‌شوند، که در آن هر node کاملاً قابل اعتماد است، و nodes از طریق <em>shared memory</em> و <em>remote direct memory access (RDMA)</em> ارتباط برقرار می‌کنند. از سوی دیگر، nodes در سرویس‌های <em>cloud</em> از machine های <em>commodity</em> ساخته شده‌اند، که می‌توانند عملکرد معادل را با هزینه کمتری به دلیل صرفه‌جویی در مقیاس ارائه دهند، اما همچنین نرخ شکست بالاتری دارند.
        </li>
<li>
            شبکه‌های بزرگ <em>datacenter</em> اغلب بر اساس IP و اترنت هستند، که در <em>Clos topologies</em> برای ارائه <em>high bisection bandwidth</em> مرتب شده‌اند [9]. <em>Supercomputers</em> ها اغلب از توپولوژی‌های شبکه تخصصی، مانند <em>multi-dimensional meshes</em> و <em>toruses</em> استفاده می‌کنند [10]، که عملکرد بهتری را برای <em>HPC workloads</em> با الگوهای ارتباطی شناخته شده به ارمغان می‌آورند.
        </li>
<li>
            هر چه یک system بزرگتر می‌شود، احتمال بیشتری وجود دارد که یکی از اجزای آن خراب شود. با گذشت زمان، موارد خراب شده تعمیر می‌شوند و موارد جدید خراب می‌شوند، اما در یک system با هزاران nodes، این منطقی است که فرض کنیم همیشه چیزی خراب است [7]. هنگامی که استراتژی مدیریت خطا شامل تسلیم شدن ساده است، یک system بزرگ می‌تواند زمان زیادی را صرف بازیابی از <em>faults</em> به جای انجام کار مفید کند [8].
        </li>
<li>
            اگر system بتواند nodes خراب را تحمل کند و همچنان به عنوان یک کل کار کند، این یک ویژگی بسیار مفید برای operations و maintenance است: به عنوان مثال، شما می‌توانید یک <em>rolling upgrade</em> را انجام دهید (به فصل 4 مراجعه کنید)، با راه‌اندازی مجدد یک node در یک زمان، در حالی که سرویس به ارائه سرویس به users بدون وقفه ادامه می‌دهد. در محیط‌های <em>cloud</em>، اگر یک <em>virtual machine</em> عملکرد خوبی ندارد، شما می‌توانید به سادگی آن را <em>kill</em> کنید و یک <em>new</em> (با این امید که جدید سریع‌تر باشد) را درخواست کنید.
        </li>
<li>
            در یک استقرار <em>geographically distributed</em> (نگه‌داشتن داده‌ها در نزدیکی جغرافیایی به users شما برای کاهش <em>access latency</em>)، ارتباط به احتمال زیاد از طریق اینترنت انجام می‌شود، که در مقایسه با شبکه‌های محلی کند و غیرقابل اعتماد است. <em>Supercomputers</em> ها عموماً فرض می‌کنند که همه nodes آنها نزدیک به هم هستند.
        </li>
</ul>
<p>
        اگر می‌خواهیم <em>distributed systems</em> را به کار بگیریم، باید امکان <em>partial failure</em> را بپذیریم و مکانیسم‌های <em>fault-tolerance</em> را در نرم‌افزار بسازیم. به عبارت دیگر، ما باید یک system قابل اعتماد از اجزای غیرقابل اعتماد بسازیم. (همانطور که در "Reliability" در صفحه 6 مورد بحث قرار گرفت، چیزی به نام قابلیت اطمینان کامل وجود ندارد، بنابراین ما باید محدودیت‌های آنچه را که می‌توانیم به طور واقع‌بینانه وعده دهیم، درک کنیم.)
    </p>
<p>
        حتی در سیستم‌های کوچکتر متشکل از تنها چند node، مهم است که در مورد <em>partial failure</em> فکر کنیم. در یک system کوچک، احتمال دارد که اکثر اجزا در بیشتر مواقع به درستی کار کنند. با این حال، دیر یا زود، بخشی از system
        <br/>
        276
        <br/>
        |
        <br/>
        Chapter 8: The Trouble with Distributed Systems
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0298</div>
            </div>
        </div>
        <!-- Page 0299 -->
        <div class="chapter" id="page-0299">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        در نهایت، یک <em>faulty</em> خواهد شد، و نرم‌افزار باید به نحوی آن را مدیریت کند. <em>Fault han‐dling</em> باید بخشی از طراحی نرم‌افزار باشد، و شما (به عنوان <em>operator</em> نرم‌افزار) باید بدانید که چه رفتاری را از نرم‌افزار در صورت بروز <em>fault</em> انتظار داشته باشید.
    </p>
<p>
        نادیده گرفتن <em>faults</em> و به سادگی امیدوار بودن به بهترین‌ها، عاقلانه نیست. مهم است که طیف وسیعی از <em>faults</em> های ممکن—حتی موارد نسبتاً بعید—را در نظر بگیرید و به طور مصنوعی چنین موقعیت‌هایی را در محیط تست خود ایجاد کنید تا ببینید چه اتفاقی می‌افتد.
    </p>
<p>
        در <em>distributed systems</em>، سوء ظن، بدبینی، و پارانویا نتیجه می‌دهد.
    </p>
<h4>Building a Reliable System from Unreliable Components</h4>
<p>
        ممکن است تعجب کنید که آیا این منطقی است—شهودی به نظر می‌رسد که یک system فقط می‌تواند به اندازه کمترین component قابل اعتماد خود (ضعیف‌ترین پیوند آن) قابل اعتماد باشد. اینطور نیست: در واقع، این یک ایده قدیمی در <em>computing</em> است که یک system قابل اعتمادتر از یک base اساسی کمتر قابل اعتماد بسازیم [11]. به عنوان مثال:
    </p>
<ul>
<li>
<em>Error-correcting codes</em> به داده‌های دیجیتال اجازه می‌دهند تا با دقت در یک <em>communication channel</em> که گاهی اوقات بیت‌های خاصی را اشتباه می‌گیرد، منتقل شوند، به عنوان مثال به دلیل <em>radio interference</em> در یک شبکه بی‌سیم [12].
        </li>
<li>
            IP (<em>the Internet Protocol</em>) غیرقابل اعتماد است: ممکن است <em>packets</em> را <em>drop, delay, duplicate, or reorder</em> کند. TCP (<em>the Transmission Control Protocol</em>) یک <em>transport layer</em> قابل اعتمادتر را بر روی IP فراهم می‌کند: این اطمینان حاصل می‌کند که <em>packets</em> های گم شده <em>retransmitted</em> شوند، <em>duplicates</em> حذف می‌شوند، و <em>packets</em> به ترتیبی که ارسال شده‌اند، <em>reassembled</em> می‌شوند.
        </li>
</ul>
<p>
        اگرچه system می‌تواند قابل اعتمادتر از بخش‌های اساسی خود باشد، اما همیشه محدودیتی برای میزان قابل اعتمادتر بودن آن وجود دارد. به عنوان مثال، <em>error-correcting codes</em> می‌توانند با تعداد کمی از <em>single-bit errors</em> مقابله کنند، اما اگر سیگنال شما توسط <em>interference</em> فراگیر شود، یک محدودیت اساسی برای مقدار داده‌ای که می‌توانید از طریق <em>communication channel</em> خود دریافت کنید، وجود دارد [13]. TCP می‌تواند از دست دادن <em>packet</em>، تکثیر، و <em>reordering</em> را از شما پنهان کند، اما نمی‌تواند جادویی تأخیرها را در شبکه حذف کند.
    </p>
<p>
        اگرچه system سطح بالاتر قابل اعتمادتر کامل نیست، اما هنوز هم مفید است زیرا از برخی از <em>faults</em> های سطح پایین <em>tricky</em> مراقبت می‌کند، و بنابراین معمولاً استدلال در مورد <em>faults</em> باقی‌مانده آسان‌تر است. ما این موضوع را بیشتر در "The end-to-end argument" در صفحه 519 بررسی خواهیم کرد.
    </p>
<h4>Unreliable Networks</h4>
<p>
        همانطور که در مقدمه قسمت II مورد بحث قرار گرفت، <em>distributed systems</em> که ما در این کتاب روی آنها تمرکز می‌کنیم، <em>shared-nothing systems</em> هستند: یعنی، مجموعه‌ای از machine ها که توسط یک شبکه متصل شده‌اند.
        <br/>
        شبکه تنها راهی است که آن machine ها می‌توانند با یکدیگر ارتباط برقرار کنند—ما فرض می‌کنیم که هر
        <br/>
        Unreliable Networks
        <br/>
        |
        <br/>
        277
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0299</div>
            </div>
        </div>
        <!-- Page 0300 -->
        <div class="chapter" id="page-0300">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        machine خود حافظه و دیسک مخصوص به خود را دارد، و یک machine نمی‌تواند به حافظه یا دیسک machine دیگری دسترسی داشته باشد (به جز با ارسال درخواست به یک service از طریق شبکه).
        <br/>
        Shared-nothing تنها راه ساختن system ها نیست، اما به دلایل مختلف، رویکرد غالب برای ساختن سرویس‌های اینترنتی شده است: این نسبتاً ارزان است زیرا به سخت‌افزار خاصی نیاز ندارد، می‌تواند از سرویس‌های محاسباتی <em>commoditized cloud</em> استفاده کند، و می‌تواند قابلیت اطمینان بالایی را از طریق <em>redundancy</em> در سراسر چندین <em>geographically distributed datacenters</em> به دست آورد.
    </p>
<p>
        اینترنت و اکثر شبکه‌های داخلی در datacenters (اغلب اترنت) شبکه‌های <em>asynchronous packet</em> هستند. در این نوع شبکه، یک node می‌تواند یک پیام (یک <em>packet</em>) را به یک node دیگر ارسال کند، اما شبکه هیچ تضمینی نمی‌دهد که چه زمانی می‌رسد، یا اصلاً می‌رسد یا خیر. اگر شما یک درخواست ارسال کنید و انتظار پاسخ داشته باشید، بسیاری از موارد می‌توانند اشتباه پیش بروند (برخی از آنها در شکل 8-1 نشان داده شده است):
    </p>
<ol>
<li>
            درخواست شما ممکن است از دست رفته باشد (شاید کسی کابل شبکه را جدا کرده باشد).
        </li>
<li>
            درخواست شما ممکن است در یک queue منتظر باشد و بعداً تحویل داده شود (شاید شبکه یا گیرنده بیش از حد بارگذاری شده باشد).
        </li>
<li>
            node از راه دور ممکن است شکست خورده باشد (شاید <em>crash</em> کرده باشد یا خاموش شده باشد).
        </li>
<li>
            node از راه دور ممکن است به طور موقت از پاسخگویی متوقف شده باشد (شاید در حال تجربه یک <em>long garbage collection pause</em> باشد؛ به "Process Pauses" در صفحه 295 مراجعه کنید)، اما بعداً دوباره شروع به پاسخگویی می‌کند.
        </li>
<li>
            node از راه دور ممکن است درخواست شما را پردازش کرده باشد، اما پاسخ در شبکه از دست رفته است (شاید یک <em>network switch</em> اشتباه پیکربندی شده باشد).
        </li>
<li>
            node از راه دور ممکن است درخواست شما را پردازش کرده باشد، اما پاسخ به تأخیر افتاده است و بعداً تحویل داده می‌شود (شاید شبکه یا machine خود شما بیش از حد بارگذاری شده باشد).
        </li>
</ol>
<figure>
<img alt="Figure 8-1. If you send a request and don’t get a response, it’s not possible to distinguish whether (a) the request was lost, (b) the remote node is down, or (c) the response was lost." src="figure8-1.png"/>
<figcaption>Figure 8-1. If you send a request and don’t get a response, it’s not possible to distinguish whether (a) the request was lost, (b) the remote node is down, or (c) the response was lost.</figcaption>
</figure>
<p>
        اگر شما یک درخواست ارسال کنید و پاسخی دریافت نکنید، تشخیص اینکه (a) درخواست از دست رفته است، (b) node از راه دور down است، یا (c) پاسخ از دست رفته است، غیرممکن است.
        <br/>
        278
        <br/>
        |
        <br/>
        Chapter 8: The Trouble with Distributed Systems
    </p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 300" src="page_0300/image_1.png"/></div>
</div>
                <div class="page-number">صفحه 0300</div>
            </div>
        </div>
        <!-- Page 0301 -->
        <div class="chapter" id="page-0301">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        فرستنده حتی نمی‌تواند بگوید که آیا <em>packet</em> تحویل داده شده است یا خیر: تنها گزینه این است که گیرنده یک پیام پاسخ ارسال کند، که ممکن است به نوبه خود از دست برود یا به تأخیر بیفتد. این مسائل در یک شبکه <em>asynchronous</em> غیرقابل تشخیص هستند: تنها اطلاعاتی که شما دارید این است که هنوز پاسخی دریافت نکرده‌اید. اگر شما یک درخواست به یک node دیگر ارسال کنید و پاسخی دریافت نکنید، غیرممکن است که بدانید چرا.
    </p>
<p>
        روش معمول برای رسیدگی به این مسئله، یک <em>timeout</em> است: پس از مدتی شما از انتظار دست می‌کشید و فرض می‌کنید که پاسخ قرار نیست برسد. با این حال، وقتی یک <em>timeout</em> رخ می‌دهد، شما هنوز هم نمی‌دانید که آیا node از راه دور درخواست شما را دریافت کرده است یا خیر (و اگر درخواست هنوز در جایی در صف است، ممکن است هنوز هم به گیرنده تحویل داده شود، حتی اگر فرستنده آن را رها کرده باشد).
    </p>
<h4>Network Faults in Practice</h4>
<p>
        ما دهه‌هاست که شبکه‌های کامپیوتری را می‌سازیم—ممکن است امیدوار باشیم که تا کنون فهمیده باشیم که چگونه آنها را قابل اعتماد کنیم. با این حال، به نظر می‌رسد که ما هنوز موفق نشده‌ایم.
    </p>
<p>
        برخی از مطالعات سیستمی و شواهد فراوان حکایتی وجود دارد که نشان می‌دهد مشکلات شبکه می‌توانند به طرز شگفت‌آوری رایج باشند، حتی در محیط‌های کنترل‌شده مانند یک <em>datacenter</em> که توسط یک شرکت اداره می‌شود [14]. یک مطالعه در یک <em>datacenter</em> متوسط ​​تعداد 12 <em>network faults</em> در ماه را نشان داد، که نیمی از آنها یک machine واحد را قطع کردند، و نیمی یک کل rack را قطع کردند [15]. مطالعه دیگری میزان خرابی اجزایی مانند <em>top-of-rack switches</em>، <em>aggregation switches</em> و <em>load bal‐ancers</em> را اندازه‌گیری کرد [16]. مشخص شد که افزودن تجهیزات شبکه redundant، <em>faults</em> را به همان اندازه که ممکن است امیدوار باشید کاهش نمی‌دهد، زیرا از خطای انسانی (به عنوان مثال، <em>misconfigured switches</em>) محافظت نمی‌کند، که دلیل اصلی <em>outages</em> است.
    </p>
<p>
        سرویس‌های <em>cloud public</em> مانند EC2 به دلیل داشتن <em>network glitches transient</em> مکرر بدنام هستند [14]، و شبکه‌های <em>private datacenter</em> خصوصی که به خوبی مدیریت می‌شوند، می‌توانند محیط‌های پایدارتری باشند. با این وجود، هیچ‌کس از مشکلات شبکه مصون نیست: به عنوان مثال، یک مشکل در طول یک <em>software upgrade</em> برای یک <em>switch</em> می‌تواند یک <em>network topology reconfiguration</em> را راه‌اندازی کند، که در طی آن <em>network packets</em> می‌توانند برای بیش از یک دقیقه به تأخیر بیفتند [17]. کوسه‌ها ممکن است کابل‌های زیر دریا را گاز بگیرند و به آنها آسیب برسانند [18]. سایر <em>faults</em> های تعجب‌آور شامل یک <em>network interface</em> است که گاهی اوقات تمام <em>inbound packets</em> را <em>drops</em> می‌کند اما <em>outbound packets</em> را با موفقیت ارسال می‌کند [19]: فقط به این دلیل که یک <em>network link</em> در یک جهت کار می‌کند، تضمین نمی‌کند که در جهت مخالف نیز کار می‌کند.
    </p>
<h4>Network partitions</h4>
<p>
        وقتی یک part از شبکه به دلیل یک <em>network fault</em> از بقیه جدا می‌شود، گاهی به آن <em>network partition</em> یا <em>netsplit</em> می‌گویند.
        <br/>
        در این کتاب ما عموماً با اصطلاح کلی‌تر <em>network fault</em> می‌چسبیم، تا از سردرگمی با <em>partitions</em> (shards) یک <em>storage system</em>، همانطور که در فصل 6 مورد بحث قرار گرفت، جلوگیری کنیم.
        <br/>
        Unreliable Networks
        <br/>
        |
        <br/>
        279
    </p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 301" src="page_0301/image_1.png"/></div>
</div>
                <div class="page-number">صفحه 0301</div>
            </div>
        </div>
        <!-- Page 0302 -->
        <div class="chapter" id="page-0302">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        حتی اگر <em>network faults</em> در محیط شما نادر باشد، این واقعیت که <em>faults</em> می‌توانند رخ دهند، به این معنی است که نرم‌افزار شما باید قادر به مدیریت آنها باشد. هر زمان که ارتباطی از طریق شبکه انجام می‌شود، ممکن است شکست بخورد—هیچ راهی برای دور زدن آن وجود ندارد.
    </p>
<p>
        اگر مدیریت خطای <em>network faults</em> تعریف و آزمایش نشود، اتفاقات بد به طور دلخواه ممکن است رخ دهد: به عنوان مثال، <em>cluster</em> می‌تواند <em>deadlocked</em> شود و به‌طور دائمی نتواند به درخواست‌ها سرویس دهد، حتی زمانی که شبکه بازیابی می‌شود [20]، یا حتی می‌تواند تمام داده‌های شما را حذف کند [21]. اگر نرم‌افزار در یک موقعیت غیرمنتظره قرار گیرد، ممکن است کارهای غیرمنتظره‌ای را انجام دهد.
    </p>
<p>
        مدیریت <em>network faults</em> لزوماً به معنای تحمل آنها نیست: اگر شبکه شما معمولاً نسبتاً قابل اعتماد است، یک رویکرد معتبر ممکن است این باشد که به سادگی یک پیام <em>error</em> را به users نشان دهید در حالی که شبکه شما با مشکل مواجه است. با این حال، شما باید بدانید که نرم‌افزار شما چگونه به مشکلات شبکه واکنش نشان می‌دهد و اطمینان حاصل کنید که system می‌تواند از آنها بازیابی شود. این ممکن است منطقی باشد که عمداً مشکلات شبکه را راه‌اندازی کنید و پاسخ system را آزمایش کنید (این ایده پشت <em>Chaos Monkey</em> است؛ به "Reliability" در صفحه 6 مراجعه کنید).
    </p>
<h4>Detecting Faults</h4>
<p>
        بسیاری از سیستم‌ها نیاز به تشخیص خودکار nodes های <em>faulty</em> دارند. به عنوان مثال:
    </p>
<ul>
<li>
            یک <em>load balancer</em> باید ارسال درخواست‌ها را به یک node که <em>dead</em> است متوقف کند (یعنی، آن را از چرخش خارج کند).
        </li>
<li>
            در یک <em>distributed database</em> با <em>single-leader replication</em>، اگر leader شکست بخورد، یکی از followers ها باید به عنوان leader جدید ارتقا یابد (به "Handling Node Outages" در صفحه 156 مراجعه کنید).
        </li>
</ul>
<p>
        متاسفانه، عدم اطمینان در مورد شبکه، تشخیص اینکه آیا یک node در حال کار است یا خیر را دشوار می‌کند. در برخی شرایط خاص شما ممکن است بازخوردی دریافت کنید که به طور صریح به شما بگوید که چیزی کار نمی‌کند:
    </p>
<ul>
<li>
            اگر شما می‌توانید به machine که node باید روی آن در حال اجرا باشد دسترسی پیدا کنید، اما هیچ پروسه‌ای در پورت مقصد گوش نمی‌دهد (به عنوان مثال، به دلیل اینکه <em>process</em> <em>crashed</em>)، operating system با ارسال یک <em>RST</em> یا <em>FIN packet</em> در پاسخ، اتصالات TCP را <em>close</em> یا رد می‌کند. با این حال، اگر node در حالی که در حال رسیدگی به درخواست شما بود <em>crashed</em> شد، شما هیچ راهی برای دانستن مقدار داده‌ای که در واقع توسط node از راه دور پردازش شده است ندارید [22].
        </li>
<li>
            اگر یک <em>node process</em> <em>crashed</em> (یا توسط یک مدیر کشته شد) اما <em>operating system</em> node همچنان در حال اجرا است، یک <em>script</em> می‌تواند nodes های دیگر را در مورد <em>crash</em> مطلع کند تا یک node دیگر بتواند به سرعت بدون نیاز به انتظار برای <em>timeout</em>، آن را به دست گیرد. به عنوان مثال، HBase این کار را انجام می‌دهد [23].
            <br/>
            280
            <br/>
            |
            <br/>
            Chapter 8: The Trouble with Distributed Systems
        </li>
</ul>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0302</div>
            </div>
        </div>
        <!-- Page 0303 -->
        <div class="chapter" id="page-0303">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<ul>
<li>
            اگر شما به رابط مدیریت <em>network switches</em> در <em>datacenter</em> خود دسترسی دارید، می‌توانید از آنها query بگیرید تا <em>link failures</em> را در سطح سخت‌افزار تشخیص دهید (به عنوان مثال، اگر <em>remote machine</em> خاموش شده باشد). این گزینه رد می‌شود اگر شما از طریق اینترنت متصل می‌شوید، یا اگر در یک <em>datacenter shared</em> هستید که به خود <em>switches</em> دسترسی ندارید، یا اگر به دلیل یک مشکل شبکه نمی‌توانید به رابط مدیریت برسید.
        </li>
<li>
            اگر یک <em>router</em> مطمئن است که آدرس IP که شما در حال تلاش برای اتصال به آن هستید، غیرقابل دسترس است، ممکن است به شما با یک بسته ICMP Destination Unreachable پاسخ دهد. با این حال، <em>router</em> نیز دارای یک قابلیت تشخیص <em>failure</em> جادویی نیست—آن تحت همان محدودیت‌ها به عنوان سایر شرکت‌کنندگان در شبکه است.
        </li>
</ul>
<p>
        بازخورد سریع در مورد اینکه یک node از راه دور down است، مفید است، اما شما نمی‌توانید روی آن حساب کنید. حتی اگر TCP تأیید کند که یک <em>packet</em> تحویل داده شده است، application ممکن است قبل از handling آن، <em>crashed</em> شده باشد. اگر شما می‌خواهید مطمئن شوید که یک درخواست موفقیت‌آمیز بوده است، شما نیاز به یک پاسخ مثبت از خود application دارید [24].
    </p>
<p>
        برعکس، اگر چیزی اشتباه پیش رفته است، ممکن است یک پاسخ <em>error</em> در سطحی از <em>stack</em> دریافت کنید، اما به طور کلی شما باید فرض کنید که اصلاً پاسخی دریافت نخواهید کرد. شما می‌توانید چند بار دوباره امتحان کنید (TCP به طور شفاف دوباره امتحان می‌کند، اما شما همچنین ممکن است در سطح application دوباره امتحان کنید)، منتظر بمانید تا یک <em>timeout</em> سپری شود، و در نهایت اگر در مدت <em>timeout</em> پاسخی دریافت نکردید، node را <em>dead</em> اعلام کنید.
    </p>
<h4>Timeouts and Unbounded Delays</h4>
<p>
        اگر یک <em>timeout</em> تنها راه مطمئن برای تشخیص <em>fault</em> است، پس <em>timeout</em> باید چقدر طول بکشد؟ متاسفانه هیچ پاسخ ساده‌ای وجود ندارد.
    </p>
<p>
        یک <em>long timeout</em> به معنای انتظار طولانی تا زمانی است که یک node <em>dead</em> اعلام شود (و در این مدت، کاربران ممکن است مجبور به انتظار یا دیدن پیام‌های <em>error</em> باشند). یک <em>short timeout</em> <em>faults</em> را سریع‌تر تشخیص می‌دهد، اما خطر بالاتری از اعلام نادرست یک node <em>dead</em> را به همراه دارد در حالی که در واقع فقط دچار یک <em>slowdown</em> موقتی شده است (به عنوان مثال، به دلیل <em>load spike</em> روی node یا شبکه).
    </p>
<p>
<em>Prematurely declaring</em> یک node <em>dead</em> مشکل‌ساز است: اگر node واقعاً زنده باشد و در حال انجام کاری باشد (به عنوان مثال، ارسال یک ایمیل)، و یک node دیگر کنترل را به دست گیرد، action ممکن است دو بار انجام شود. ما این مسئله را با جزئیات بیشتر در "Knowledge, Truth, and Lies" در صفحه 300، و در فصل‌های 9 و 11 مورد بحث قرار خواهیم داد.
    </p>
<p>
        وقتی یک node <em>dead</em> اعلام می‌شود، مسئولیت‌های آن باید به nodes های دیگر منتقل شود، که بار اضافی را روی nodes های دیگر و شبکه قرار می‌دهد. اگر system در حال حاضر با <em>high load</em> دست و پنجه نرم می‌کند، اعلام nodes ها <em>dead</em> قبل از موعد می‌تواند مشکل را بدتر کند. به طور خاص، ممکن است اتفاق بیفتد که node واقعاً <em>dead</em> نبوده است، بلکه فقط به دلیل <em>overload</em> در پاسخگویی کند بوده است. انتقال بار آن به nodes های دیگر می‌تواند باعث یک <em>cascading failure</em> شود (در موارد شدید، همه nodes یکدیگر را <em>dead</em> اعلام می‌کنند، و همه چیز متوقف می‌شود).
        <br/>
        Unreliable Networks
        <br/>
        |
        <br/>
        281
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0303</div>
            </div>
        </div>
        <!-- Page 0304 -->
        <div class="chapter" id="page-0304">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        تصور کنید یک system فرضی با یک شبکه که حداکثر تأخیر را برای <em>packets</em> تضمین می‌کند—هر <em>packet</em> یا در زمان d تحویل داده می‌شود، یا از دست می‌رود، اما تحویل هرگز بیشتر از d طول نمی‌کشد. علاوه بر این، فرض کنید که شما می‌توانید تضمین کنید که یک node غیر <em>failed</em> همیشه یک درخواست را در زمان r مدیریت می‌کند. در این حالت، شما می‌توانید تضمین کنید که هر درخواست موفقیت‌آمیز در زمان 2d + r پاسخی دریافت می‌کند—و اگر شما در این مدت پاسخی دریافت نکردید، می‌دانید که یا شبکه یا node از راه دور کار نمی‌کند. اگر این درست بود، 2d + r یک <em>timeout</em> مناسب برای استفاده خواهد بود.
    </p>
<p>
        متاسفانه، اکثر systems هایی که ما با آنها کار می‌کنیم، هیچ یک از آن تضمین‌ها را ندارند: شبکه‌های <em>asynchronous</em>، تأخیرهای نامحدود دارند (یعنی، آنها سعی می‌کنند <em>packets</em> را در اسرع وقت تحویل دهند، اما هیچ محدودیتی برای مدت زمانی که ممکن است طول بکشد تا یک <em>packet</em> برسد، وجود ندارد)، و اکثر پیاده‌سازی‌های server نمی‌توانند تضمین کنند که می‌توانند درخواست‌ها را در یک زمان حداکثر مدیریت کنند (به "Response time guarantees" در صفحه 298 مراجعه کنید).
    </p>
<p>
        برای تشخیص <em>failure</em>، کافی نیست که system در اکثر مواقع سریع باشد: اگر <em>timeout</em> شما کم باشد، فقط یک <em>transient spike</em> در <em>round-trip times</em> لازم است تا system از تعادل خارج شود.
    </p>
<h4>Network congestion and queueing</h4>
<p>
        هنگام رانندگی با ماشین، زمان سفر در شبکه‌های جاده‌ای اغلب بیشتر به دلیل <em>traffic congestion</em> متفاوت است. به طور مشابه، تغییرپذیری تأخیر <em>packet</em> در شبکه‌های کامپیوتری اغلب به دلیل <em>queueing</em> است [25]:
    </p>
<ul>
<li>
            اگر چندین node مختلف به طور همزمان سعی کنند <em>packets</em> را به یک مقصد یکسان ارسال کنند، <em>network switch</em> باید آنها را در صف قرار دهد و آنها را یکی یکی به <em>destination network link</em> تغذیه کند (همانطور که در شکل 8-2 نشان داده شده است). در یک <em>busy network link</em>، یک <em>packet</em> ممکن است مجبور شود مدتی صبر کند تا بتواند یک slot دریافت کند (این <em>network congestion</em> نامیده می‌شود). اگر داده‌های ورودی آنقدر زیاد باشد که صف <em>switch</em> پر شود، <em>packet</em> <em>dropped</em> می‌شود، بنابراین باید دوباره ارسال شود—حتی اگر شبکه به خوبی کار کند.
        </li>
<li>
            وقتی یک <em>packet</em> به machine مقصد می‌رسد، اگر تمام <em>CPU cores</em> در حال حاضر مشغول باشند، درخواست ورودی از شبکه توسط <em>operating system</em> در صف قرار می‌گیرد تا زمانی که application آماده handling آن شود. بسته به load روی machine، این ممکن است زمان دلخواه را بگیرد.
        </li>
<li>
            در محیط‌های <em>virtualized</em>، یک operating system در حال اجرا اغلب برای ده‌ها میلی‌ثانیه متوقف می‌شود در حالی که یک <em>virtual machine</em> دیگر از یک <em>CPU core</em> استفاده می‌کند. در این مدت، VM نمی‌تواند هیچ داده‌ای را از شبکه مصرف کند، بنابراین داده‌های ورودی توسط <em>virtual machine monitor</em> در صف قرار می‌گیرند (<em>buffered</em>)، که بیشتر باعث افزایش تغییرپذیری تأخیر شبکه می‌شود.
        </li>
<li>
            TCP <em>flow control</em> را انجام می‌دهد (همچنین به عنوان <em>congestion avoidance</em> یا <em>backpressure</em> شناخته می‌شود)، که در آن یک node، نرخ ارسال خود را محدود می‌کند تا از <em>overloading</em> یک
            <br/>
            282
            <br/>
            |
            <br/>
            Chapter 8: The Trouble with Distributed Systems
        </li>
</ul>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0304</div>
            </div>
        </div>
        <!-- Page 0305 -->
        <div class="chapter" id="page-0305">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
<em>network link</em> یا node دریافت‌کننده را بارگذاری می‌کند [27]. این به معنای <em>queueing</em> اضافی در فرستنده قبل از اینکه داده‌ها وارد شبکه شوند، است.
    </p>
<figure>
<img alt="Figure 8-2. If several machines send network traffic to the same destination, its switch queue can fill up. Here, ports 1, 2, and 4 are all trying to send packets to port 3." src="figure8-2.png"/>
<figcaption>Figure 8-2. If several machines send network traffic to the same destination, its switch queue can fill up. Here, ports 1, 2, and 4 are all trying to send packets to port 3.</figcaption>
</figure>
<p>
        علاوه بر این، TCP یک <em>packet</em> را از دست رفته در نظر می‌گیرد اگر در یک <em>timeout</em> تأیید نشود (که از <em>round-trip times</em> مشاهده شده محاسبه می‌شود)، و <em>lost packets</em> به طور خودکار دوباره ارسال می‌شوند. اگرچه application، <em>packet loss</em> و <em>retransmission</em> را نمی‌بیند، اما تأخیر حاصل را می‌بیند (منتظر ماندن برای انقضای <em>timeout</em>، و سپس منتظر ماندن برای تأیید <em>retransmitted packet</em>).
    </p>
<h4>TCP Versus UDP</h4>
<p>
        برخی از applications های حساس به <em>latency</em>، مانند <em>videoconferencing</em> و <em>Voice over IP (VoIP)</em>، از UDP به جای TCP استفاده می‌کنند. این یک trade-off بین قابلیت اطمینان و تغییرپذیری تأخیرها است: از آنجایی که UDP، <em>flow control</em> را انجام نمی‌دهد و <em>lost packets</em> را دوباره ارسال نمی‌کند، از برخی دلایل تأخیرهای شبکه متغیر اجتناب می‌کند (اگرچه همچنان مستعد <em>switch queues</em> و <em>scheduling delays</em> است).
    </p>
<p>
        UDP یک انتخاب خوب در شرایطی است که داده‌های با تأخیر بی‌ارزش هستند. به عنوان مثال، در یک تماس تلفنی VoIP، احتمالاً زمان کافی برای <em>retransmit</em> یک <em>lost packet</em> قبل از اینکه داده‌های آن باید از طریق بلندگو پخش شوند، وجود ندارد. در این حالت، هیچ فایده‌ای در <em>retransmitting</em> <em>packet</em> وجود ندارد—به جای آن، application باید زمان <em>slot</em> <em>packet</em> از دست رفته را با سکوت پر کند (ایجاد یک وقفه کوتاه در صدا) و به جریان ادامه دهد. <em>retry</em> به جای آن در <em>human layer</em> اتفاق می‌افتد. ("آیا می‌توانید لطفاً تکرار کنید؟ صدا برای لحظه‌ای قطع شد.")
    </p>
<p>
        همه این عوامل به تغییرپذیری تأخیرهای شبکه کمک می‌کنند. <em>Queueing delays</em> دارای طیف وسیعی هستند، به‌خصوص زمانی که یک system به حداکثر ظرفیت خود نزدیک است: یک sys-
        <br/>
        Unreliable Networks
        <br/>
        |
        <br/>
        283
    </p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 305" src="page_0305/image_1.png"/></div>
</div>
                <div class="page-number">صفحه 0305</div>
            </div>
        </div>
        <!-- Page 0306 -->
        <div class="chapter" id="page-0306">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        system با ظرفیت اضافی می‌تواند به راحتی صفوف را تخلیه کند، در حالی که در یک system با <em>highly utilized</em>، صفوف طولانی می‌توانند خیلی سریع ایجاد شوند.
    </p>
<p>
        در <em>public clouds</em> و <em>multi-tenant datacenters</em>، منابع بین بسیاری از مشتریان به اشتراک گذاشته می‌شوند: <em>network links</em> و <em>switches</em>، و حتی <em>network interface</em> و <em>CPUs</em> هر machine (هنگام اجرا روی <em>virtual machines</em>)، به اشتراک گذاشته می‌شوند. <em>Batch workloads</em> مانند MapReduce (به فصل 10 مراجعه کنید) می‌تواند به راحتی <em>network links</em> را اشباع کند. از آنجایی که شما هیچ کنترلی بر استفاده دیگر مشتریان از منابع مشترک ندارید، تأخیرهای شبکه می‌توانند بسیار متغیر باشند اگر کسی در نزدیکی شما (یک همسایه پر سر و صدا) از منابع زیادی استفاده می‌کند [28, 29].
    </p>
<p>
        در چنین محیط‌هایی، شما فقط می‌توانید <em>timeouts</em> را به صورت تجربی انتخاب کنید: توزیع زمان‌های <em>network round-trip</em> را در یک دوره طولانی و در چندین machine اندازه‌گیری کنید، تا تغییرپذیری مورد انتظار تأخیرها را تعیین کنید. سپس، با در نظر گرفتن ویژگی‌های application خود، شما می‌توانید یک <em>trade-off</em> مناسب بین تأخیر تشخیص <em>failure</em> و خطر <em>premature timeouts</em> را تعیین کنید.
    </p>
<p>
        حتی بهتر است، به جای استفاده از <em>configured constant timeouts</em>، systems می‌توانند به طور مداوم زمان‌های پاسخگویی و تغییرپذیری آنها (<em>jitter</em>) را اندازه‌گیری کنند، و <em>timeouts</em> را به طور خودکار با توجه به توزیع زمان پاسخگویی مشاهده شده تنظیم کنند. این کار را می‌توان با یک <em>Phi Accrual failure detector</em> [30] انجام داد، که به عنوان مثال در Akka و Cassandra استفاده می‌شود [31]. <em>TCP retransmission timeouts</em> نیز به طور مشابه عمل می‌کنند [27].
    </p>
<h4>Synchronous Versus Asynchronous Networks</h4>
<p>
        اگر ما می‌توانستیم به شبکه اعتماد کنیم تا <em>packets</em> را با مقداری تأخیر ثابت حداکثر تحویل دهد، و <em>packets</em> را <em>drop</em> نکند، <em>distributed systems</em> بسیار ساده‌تر می‌شدند. چرا نمی‌توانیم این را در سطح سخت‌افزار حل کنیم و شبکه را قابل اعتماد کنیم تا نرم‌افزار نیازی به نگرانی در مورد آن نداشته باشد؟
    </p>
<p>
        برای پاسخ به این سوال، مقایسه شبکه‌های <em>datacenter</em> با شبکه تلفن ثابت سنتی (غیر سلولی، غیر VoIP) جالب است، که بسیار قابل اعتماد است: <em>delayed audio frames</em> و <em>dropped calls</em> بسیار نادر هستند. یک تماس تلفنی به طور مداوم نیاز به <em>low end-to-end latency</em> و پهنای باند کافی برای انتقال نمونه‌های صوتی صدای شما دارد. آیا داشتن قابلیت اطمینان و قابلیت پیش‌بینی مشابه در شبکه‌های کامپیوتری خوب نخواهد بود؟
    </p>
<p>
        وقتی شما از طریق شبکه تلفن تماس می‌گیرید، یک <em>circuit</em> ایجاد می‌کند: یک مقدار ثابت، تضمین شده از پهنای باند برای تماس، در کل مسیر بین دو تماس‌گیرنده اختصاص داده شده است. این <em>circuit</em> تا زمانی که تماس پایان یابد، در جای خود باقی می‌ماند [32]. به عنوان مثال، یک شبکه ISDN با نرخ ثابتی از 4000 فریم در ثانیه اجرا می‌شود. هنگامی که یک تماس برقرار می‌شود، 16 بیت فضا در هر فریم (در هر جهت) به آن اختصاص داده می‌شود. بنابراین، برای مدت زمان تماس، به هر طرف تضمین می‌شود که بتواند دقیقاً 16 بیت داده صوتی را هر 250 میکروثانیه ارسال کند [33, 34].
        <br/>
        284
        <br/>
        |
        <br/>
        Chapter 8: The Trouble with Distributed Systems
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0306</div>
            </div>
        </div>
        <!-- Page 0307 -->
        <div class="chapter" id="page-0307">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        ii. به جز شاید یک <em>keepalive packet</em> گاه به گاه، اگر <em>TCP keepalive</em> فعال باشد.
    </p>
<p>
        iii. <em>Asynchronous Transfer Mode (ATM)</em> یک رقیب برای اترنت در دهه 1980 بود [32]، اما پذیرش زیادی در خارج از <em>telephone network core switches</em> به دست نیاورد. این هیچ ارتباطی با دستگاه‌های خودپرداز (همچنین به عنوان دستگاه‌های خودپرداز شناخته می‌شوند) ندارد، علیرغم به اشتراک گذاشتن یک سرنام. شاید، در برخی از جهان‌های موازی، اینترنت مبتنی بر چیزی شبیه ATM است—در آن جهان، تماس‌های ویدیویی اینترنتی احتمالاً بسیار قابل اعتمادتر از ما هستند، زیرا از <em>dropped and delayed packets</em> رنج نمی‌برند.
    </p>
<p>
        این نوع شبکه <em>synchronous</em> است: حتی با عبور داده‌ها از چندین <em>routers</em>، از <em>queueing</em> رنج نمی‌برد، زیرا 16 بیت فضا برای تماس در <em>next hop</em> شبکه از قبل رزرو شده است. و از آنجایی که هیچ <em>queueing</em> وجود ندارد، حداکثر <em>end-to-end latency</em> شبکه ثابت است. ما این را <em>bounded delay</em> می‌نامیم.
    </p>
<p>
        آیا نمی‌توانیم به سادگی تأخیرهای شبکه را قابل پیش‌بینی کنیم؟
    </p>
<p>
        توجه داشته باشید که یک <em>circuit</em> در یک شبکه تلفن بسیار متفاوت از یک اتصال TCP است: یک <em>circuit</em> مقدار ثابتی از پهنای باند رزرو شده است که هیچ‌کس دیگری نمی‌تواند از آن استفاده کند در حالی که <em>circuit</em> برقرار است، در حالی که <em>packets</em> یک اتصال TCP به طور <em>opportunistically</em> از هر پهنای باند شبکه موجود استفاده می‌کنند. شما می‌توانید به TCP یک بلوک داده با اندازه متغیر (به عنوان مثال، یک ایمیل یا یک صفحه وب) بدهید، و آن را در کوتاه‌ترین زمان ممکن منتقل می‌کند. در حالی که یک اتصال TCP بیکار است، از هیچ پهنای باندی استفاده نمی‌کند.ii
    </p>
<p>
        اگر شبکه‌های <em>datacenter</em> و اینترنت شبکه‌های <em>circuit-switched</em> بودند، برقراری یک <em>guaranteed maximum round-trip time</em> هنگام راه‌اندازی یک <em>circuit</em> امکان‌پذیر بود. با این حال، آنها نیستند: اترنت و IP پروتکل‌های <em>packet-switched</em> هستند، که از <em>queueing</em> رنج می‌برند و بنابراین تأخیرهای نامحدودی در شبکه دارند. این پروتکل‌ها مفهوم یک <em>circuit</em> را ندارند.
    </p>
<p>
        چرا شبکه‌های <em>datacenter</em> و اینترنت از <em>packet switching</em> استفاده می‌کنند؟ پاسخ این است که آنها برای ترافیک bursty بهینه شده‌اند. یک <em>circuit</em> برای یک تماس صوتی یا تصویری خوب است، که نیاز دارد تعداد نسبتاً ثابتی از بیت‌ها را در هر ثانیه برای مدت زمان تماس منتقل کند. از سوی دیگر، درخواست یک صفحه وب، ارسال یک ایمیل، یا انتقال یک فایل هیچ نیازی به پهنای باند خاصی ندارد—ما فقط می‌خواهیم که تا حد امکان سریع تکمیل شود.
    </p>
<p>
        اگر شما می‌خواستید یک فایل را از طریق یک <em>circuit</em> منتقل کنید، باید یک تخصیص پهنای باند را حدس بزنید. اگر خیلی کم حدس بزنید، انتقال به طور غیرضروری کند است، که ظرفیت شبکه را بدون استفاده می‌گذارد. اگر بیش از حد حدس بزنید، <em>circuit</em> را نمی‌توان تنظیم کرد (زیرا شبکه نمی‌تواند به یک <em>circuit</em> اجازه ایجاد دهد اگر تخصیص پهنای باند آن را نمی‌توان تضمین کرد). بنابراین، استفاده از <em>circuits</em> برای <em>bursty data transfers</em> باعث هدر رفتن ظرفیت شبکه می‌شود و انتقال‌ها را به‌طور غیرضروری کند می‌کند. در مقابل، TCP به صورت پویا نرخ انتقال داده را با ظرفیت شبکه موجود تنظیم می‌کند.
    </p>
<p>
        تلاش‌هایی برای ساخت شبکه‌های <em>hybrid</em> که از هر دو <em>circuit switching</em> و <em>packet switching</em> پشتیبانی می‌کنند، مانند ATM وجود داشته است. iii InfiniBand دارای برخی شباهت‌ها است [35]: این کنترل جریان <em>end-to-end</em> را در لایه link پیاده‌سازی می‌کند، که نیاز به
        <br/>
        Unreliable Networks
        <br/>
        |
        <br/>
        285
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0307</div>
            </div>
        </div>
        <!-- Page 0308 -->
        <div class="chapter" id="page-0308">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
<em>queueing</em> در شبکه، اگرچه همچنان می‌تواند از تأخیرها به دلیل <em>link conges‐tion</em> رنج ببرد [36]. با استفاده دقیق از <em>quality of service (QoS, prioritization and scheduling of packets)</em> و <em>admission control (rate-limiting senders)</em>، می‌توان <em>circuit switching</em> را در شبکه‌های <em>packet</em> شبیه‌سازی کرد، یا تأخیر <em>statistically bounded</em> را ارائه داد [25, 32].
    </p>
<h4>Latency and Resource Utilization</h4>
<p>
        به طور کلی، شما می‌توانید به تأخیرهای متغیر به عنوان یک نتیجه از <em>dynamic resource partitioning</em> فکر کنید.
    </p>
<p>
        فرض کنید شما یک سیم بین دو <em>telephone switches</em> دارید که می‌تواند تا 10000 تماس همزمان را حمل کند. هر <em>circuit</em> که از طریق این سیم سوئیچ می‌شود، یکی از آن slots های call را اشغال می‌کند. بنابراین، شما می‌توانید به سیم به عنوان یک <em>resource</em> فکر کنید که می‌تواند توسط حداکثر 10000 کاربر همزمان به اشتراک گذاشته شود. <em>resource</em> به روشی <em>static</em> تقسیم می‌شود: حتی اگر شما در حال حاضر تنها تماس روی سیم هستید، و تمام 9999 slot دیگر استفاده نشده‌اند، <em>circuit</em> شما هنوز هم به همان مقدار ثابت پهنای باند اختصاص داده شده است که سیم کاملاً <em>utilized</em> است.
    </p>
<p>
        در مقابل، اینترنت پهنای باند شبکه را به صورت پویا به اشتراک می‌گذارد. فرستنده‌ها با یکدیگر فشار می‌آورند تا <em>packets</em> خود را در اسرع وقت از طریق سیم عبور دهند، و <em>network switches</em> تصمیم می‌گیرند که کدام <em>packet</em> را ارسال کنند (یعنی، تخصیص پهنای باند) از یک لحظه به لحظه دیگر. این رویکرد دارای <em>downside</em> <em>queueing</em> است، اما مزیت این است که <em>utilization</em> سیم را به حداکثر می‌رساند. سیم دارای یک هزینه ثابت است، بنابراین اگر شما آن را بهتر <em>utilize</em> کنید، هر بایت که از طریق سیم ارسال می‌کنید ارزان‌تر است.
    </p>
<p>
        یک موقعیت مشابه با <em>CPUs</em> ایجاد می‌شود: اگر شما هر <em>CPU core</em> را به طور پویا بین چندین thread به اشتراک بگذارید، یک thread گاهی اوقات باید در صف اجرای <em>operating system’s</em> منتظر بماند در حالی که یک thread دیگر در حال اجرا است، بنابراین یک thread می‌تواند برای مدت زمان متفاوتی متوقف شود. با این حال، این سخت‌افزار را بهتر از زمانی استفاده می‌کند که شما تعداد ثابتی از چرخه‌های CPU را به هر thread اختصاص دهید (به "Response time guarantees" در صفحه 298 مراجعه کنید). <em>Better hardware utilization</em> همچنین یک انگیزه مهم برای استفاده از <em>virtual machines</em> است.
    </p>
<p>
<em>Latency guarantees</em> در محیط‌های خاصی قابل دستیابی هستند، اگر منابع به صورت <em>statically partitioned</em> (به عنوان مثال، سخت‌افزار اختصاصی و تخصیص پهنای باند انحصاری) باشند. با این حال، این با هزینه کاهش <em>utilization</em> همراه است—به عبارت دیگر، گران‌تر است. از سوی دیگر، <em>multi-tenancy</em> با <em>dynamic resource partitioning</em>، <em>better utilization</em> را ارائه می‌دهد، بنابراین ارزان‌تر است، اما <em>downside</em> تأخیرهای متغیر را دارد.
    </p>
<p>
        تأخیرهای متغیر در شبکه‌ها یک قانون طبیعت نیستند، بلکه به سادگی نتیجه یک <em>cost/benefit trade-off</em> هستند.
        <br/>
        286
        <br/>
        |
        <br/>
        Chapter 8: The Trouble with Distributed Systems
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0308</div>
            </div>
        </div>
        <!-- Page 0309 -->
        <div class="chapter" id="page-0309">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        iv. به جز شاید <em>keepalive packet</em> گاه به گاه، اگر TCP keepalive فعال باشد.
    </p>
<p>
<em>Peering agreements</em> بین <em>internet service providers</em> و ایجاد routes از طریق <em>the Border Gateway Protocol (BGP)</em>، شباهت بیشتری به <em>circuit switching</em> نسبت به خود IP دارد. در این سطح، می‌توان پهنای باند اختصاصی را خریداری کرد. با این حال، <em>internet routing</em> در سطح شبکه‌ها عمل می‌کند، نه اتصالات فردی بین <em>hosts</em>، و در یک بازه زمانی بسیار طولانی‌تر.
    </p>
<p>
        با این حال، این نوع <em>quality of service</em> در حال حاضر در <em>multi-tenant datacenters</em> و <em>public clouds</em>، یا هنگام برقراری ارتباط از طریق اینترنت فعال نیست.iv تکنولوژی که در حال حاضر مستقر شده است، به ما اجازه نمی‌دهد هیچ تضمینی در مورد تأخیر یا قابلیت اطمینان شبکه ارائه دهیم: ما باید فرض کنیم که <em>network congestion, queueing, and unbounded delays</em> اتفاق خواهد افتاد. در نتیجه، هیچ value "صحیحی" برای <em>timeouts</em> وجود ندارد—آنها باید به طور تجربی تعیین شوند.
    </p>
<h4>Unreliable Clocks</h4>
<p>
        ساعت‌ها و زمان مهم هستند. Applications ها به راه‌های مختلفی به ساعت‌ها متکی هستند تا به سؤالاتی مانند موارد زیر پاسخ دهند:
    </p>
<ol>
<li>
            آیا این درخواست هنوز <em>timed out</em> شده است؟
        </li>
<li>
<em>99th percentile response time</em> از این service چقدر است؟
        </li>
<li>
            این service به طور متوسط در 5 دقیقه گذشته چند query در ثانیه را مدیریت کرده است؟
        </li>
<li>
            user چقدر در سایت ما گذرانده است؟
        </li>
<li>
            این مقاله چه زمانی منتشر شده است؟
        </li>
<li>
            ایمیل یادآوری چه زمانی باید ارسال شود؟
        </li>
<li>
            ورود به این cache entry چه زمانی منقضی می‌شود؟
        </li>
<li>
<em>timestamp</em> در این <em>error message</em> در فایل log چیست؟
        </li>
</ol>
<p>
        مثال‌های 1–4 <em>durations</em> را اندازه‌گیری می‌کنند (به عنوان مثال، فاصله زمانی بین ارسال یک درخواست و دریافت یک پاسخ)، در حالی که مثال‌های 5–8 نقاطی در زمان (رویدادهایی که در یک تاریخ خاص، در یک زمان خاص رخ می‌دهند) را توصیف می‌کنند.
    </p>
<p>
        در یک <em>distributed system</em>، زمان یک مسئله دشوار است، زیرا ارتباط فوری نیست: زمان می‌برد تا یک پیام از طریق شبکه از یک machine به machine دیگر منتقل شود. زمان دریافت یک پیام همیشه دیرتر از زمان ارسال آن است، اما به دلیل تأخیرهای متغیر در شبکه، ما نمی‌دانیم چقدر دیرتر است. این واقعیت گاهی اوقات تعیین ترتیبی که در آن اتفاقات رخ داده‌اند را زمانی که چندین machine درگیر هستند، دشوار می‌کند.
    </p>
<p>
        علاوه بر این، هر machine در شبکه ساعت خاص خود را دارد، که یک <em>hardware device</em> واقعی است: معمولاً یک <em>quartz crystal oscillator</em>. این دستگاه‌ها کاملاً دقیق نیستند، بنابراین هر machine تصور خاص خود از زمان را دارد، که ممکن است کمی سریع‌تر یا
        <br/>
        Unreliable Clocks
        <br/>
        |
        <br/>
        287
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0309</div>
            </div>
        </div>
        <!-- Page 0310 -->
        <div class="chapter" id="page-0310">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        v. اگرچه به این ساعت <em>real-time</em> گفته می‌شود، اما هیچ ربطی به <em>real-time operating systems</em>، همانطور که در "Response time guarantees" در صفحه 298 مورد بحث قرار گرفت، ندارد.
    </p>
<p>
        slow است. تا حدودی همگام‌سازی ساعت‌ها امکان‌پذیر است: رایج‌ترین مکانیسم مورد استفاده، <em>the Network Time Protocol (NTP)</em> است، که به ساعت کامپیوتر اجازه می‌دهد تا با توجه به زمان گزارش شده توسط یک گروه از سرورها، تنظیم شود [37]. سرورها به نوبه خود زمان خود را از یک منبع زمان دقیق‌تر، مانند یک گیرنده GPS، دریافت می‌کنند.
    </p>
<h4>Monotonic Versus Time-of-Day Clocks</h4>
<p>
        کامپیوترهای مدرن حداقل دو نوع ساعت مختلف دارند: a <em>time-of-day clock</em> و a <em>monotonic clock</em>. اگرچه هر دو زمان را اندازه‌گیری می‌کنند، اما تمایز بین این دو مهم است، زیرا آنها اهداف متفاوتی را دنبال می‌کنند.
    </p>
<h4>Time-of-day clocks</h4>
<p>
        a <em>time-of-day clock</em> کاری را انجام می‌دهد که شما به طور شهودی از یک ساعت انتظار دارید: تاریخ و زمان فعلی را طبق یک تقویم برمی‌گرداند (همچنین به عنوان <em>wall-clock time</em> شناخته می‌شود). به عنوان مثال، clock_gettime(CLOCK_REALTIME) روی Linuxv و System.currentTimeMillis() در Java، تعداد ثانیه‌ها (یا میلی‌ثانیه‌ها) را از زمان epoch برمی‌گرداند: نیمه‌شب UTC در 1 ژانویه 1970، طبق تقویم میلادی، بدون احتساب <em>leap seconds</em>. برخی از system ها از تاریخ‌های دیگر به عنوان نقطه مرجع خود استفاده می‌کنند.
    </p>
<p>
<em>Time-of-day clocks</em> معمولاً با NTP همگام‌سازی می‌شوند، که به این معنی است که یک timestamp از یک machine (در حالت ایده‌آل) به همان معنای یک timestamp در machine دیگری است. با این حال، <em>time-of-day clocks</em> نیز دارای موارد عجیب مختلفی هستند، همانطور که در بخش بعد توضیح داده شده است. به طور خاص، اگر ساعت محلی خیلی جلوتر از سرور NTP باشد، ممکن است به‌زور <em>reset</em> شود و به یک نقطه زمانی قبلی بازگردد. این جهش‌ها، و همچنین این واقعیت که آنها اغلب <em>leap seconds</em> را نادیده می‌گیرند، <em>time-of-day clocks</em> را برای اندازه‌گیری زمان سپری‌شده نامناسب می‌کند [38].
    </p>
<p>
<em>Time-of-day clocks</em> از نظر تاریخی نیز دارای <em>coarse-grained resolution</em> بوده‌اند، به عنوان مثال، حرکت به جلو در مراحل 10 میلی‌ثانیه در system های قدیمی ویندوز [39]. در system های اخیر، این مشکل کمتری دارد.
    </p>
<h4>Monotonic clocks</h4>
<p>
        a <em>monotonic clock</em> برای اندازه‌گیری a <em>duration</em> (فاصله زمانی)، مانند a <em>timeout</em> یا زمان پاسخگویی یک service مناسب است: clock_gettime(CLOCK_MONOTONIC) روی Linux و System.nanoTime() در Java، به عنوان مثال، <em>monotonic clocks</em> هستند. این نام از این واقعیت می‌آید که آنها همیشه تضمین می‌کنند که به سمت جلو حرکت می‌کنند (در حالی که a <em>time-of-day clock</em> ممکن است به عقب برگردد).
        <br/>
        288
        <br/>
        |
        <br/>
        Chapter 8: The Trouble with Distributed Systems
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0310</div>
            </div>
        </div>
        <!-- Page 0311 -->
        <div class="chapter" id="page-0311">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        شما می‌توانید value از <em>monotonic clock</em> را در یک نقطه زمانی بررسی کنید، کاری انجام دهید، و سپس ساعت را دوباره در یک زمان بعدی بررسی کنید. تفاوت بین دو value به شما می‌گوید که چه مقدار زمان بین دو بررسی سپری شده است. با این حال، <em>absolute value</em> ساعت بی‌معنی است: ممکن است تعداد نانوثانیه‌ها از زمانی که کامپیوتر راه‌اندازی شده است، یا چیزی به همین ترتیب، اختیاری باشد. به طور خاص، مقایسه <em>monotonic clock values</em> از دو کامپیوتر مختلف منطقی ندارد، زیرا آنها به یک معنا نیستند.
    </p>
<p>
        در یک server با چندین <em>CPU sockets</em>، ممکن است یک <em>timer</em> جداگانه برای هر CPU وجود داشته باشد، که لزوماً با سایر CPUs همگام‌سازی نشده است. <em>Operating systems</em>، هر گونه اختلاف را جبران می‌کنند و سعی می‌کنند یک دیدگاه <em>monotonic</em> از ساعت را به <em>application threads</em> ارائه دهند، حتی در حالی که آنها در سراسر <em>CPUs</em> های مختلف زمان‌بندی می‌شوند. با این حال، عاقلانه است که این تضمین از <em>monotonicity</em> را با کمی احتیاط در نظر بگیرید [40].
    </p>
<p>
        NTP ممکن است فرکانسی را که <em>monotonic clock</em> به سمت جلو حرکت می‌کند، تنظیم کند (این به عنوان <em>slewing the clock</em> شناخته می‌شود) اگر تشخیص دهد که <em>quartz</em> محلی کامپیوتر سریع‌تر یا کندتر از سرور NTP حرکت می‌کند. به طور پیش‌فرض، NTP به نرخ ساعت اجازه می‌دهد تا تا 0.05٪ سرعت یا کند شود، اما NTP نمی‌تواند باعث شود که <em>monotonic clock</em> به جلو یا عقب بپرد. <em>Resolution</em> از <em>monotonic clocks</em> معمولاً بسیار خوب است: در اکثر systems ها آنها می‌توانند فواصل زمانی را در میکروثانیه یا کمتر اندازه‌گیری کنند.
    </p>
<p>
        در یک <em>distributed system</em>، استفاده از یک <em>monotonic clock</em> برای اندازه‌گیری زمان سپری‌شده (به عنوان مثال، <em>timeouts</em>) معمولاً خوب است، زیرا هیچ همگام‌سازی بین ساعت‌های node های مختلف را فرض نمی‌کند و به بی‌دقتی‌های جزئی اندازه‌گیری حساس نیست.
    </p>
<h4>Clock Synchronization and Accuracy</h4>
<p>
<em>Monotonic clocks</em> نیازی به همگام‌سازی ندارند، اما <em>time-of-day clocks</em> نیاز دارند که با توجه به یک سرور NTP یا منبع زمان خارجی دیگر تنظیم شوند تا مفید باشند.
        <br/>
        متاسفانه، روش‌های ما برای دریافت یک ساعت برای گفتن زمان صحیح، تقریباً به اندازه‌ای که ممکن است امیدوار باشید قابل اعتماد یا دقیق نیستند—ساعت‌های سخت‌افزاری و NTP می‌توانند <em>fickle beasts</em> باشند. برای ارائه فقط چند نمونه:
    </p>
<ul>
<li>
            ساعت <em>quartz</em> در یک کامپیوتر بسیار دقیق نیست: منحرف می‌شود (سریع‌تر یا کندتر از آنچه باید اجرا می‌شود). <em>Clock drift</em> بسته به دمای machine متفاوت است. Google فرض می‌کند یک <em>clock drift</em> از 200 ppm (<em>parts per million</em>) برای servers های خود [41]، که معادل 6 میلی‌ثانیه drift برای یک ساعت است که هر 30 ثانیه با یک server همگام‌سازی می‌شود، یا 17 ثانیه drift برای یک ساعت است که یک بار در روز همگام‌سازی می‌شود. این <em>drift</em> دقت بهترین ممکن را که می‌توانید به دست آورید، حتی اگر همه چیز به درستی کار کند، محدود می‌کند.
        </li>
<li>
            اگر ساعت یک کامپیوتر با سرور NTP بیش از حد متفاوت باشد، ممکن است از همگام‌سازی خودداری کند، یا ساعت محلی به اجبار <em>reset</em> می‌شود [37]. هر application ای که زمان را قبل و بعد از این <em>reset</em> مشاهده می‌کند، ممکن است ببیند که زمان به عقب برمی‌گردد یا ناگهان به جلو می‌پرد.
            <br/>
            Unreliable Clocks
            <br/>
            |
            <br/>
            289
        </li>
</ul>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0311</div>
            </div>
        </div>
        <!-- Page 0312 -->
        <div class="chapter" id="page-0312">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<ul>
<li>
            اگر یک node به طور تصادفی از سرورهای NTP <em>firewalled off</em> شود، <em>misconfiguration</em> ممکن است برای مدتی نامحسوس باقی بماند. شواهد حکایتی نشان می‌دهد که این در عمل اتفاق می‌افتد.
        </li>
<li>
            همگام‌سازی NTP تنها به اندازه تأخیر شبکه خوب است، بنابراین وقتی شما در یک شبکه شلوغ با تأخیرهای متغیر <em>packet</em> هستید، محدودیتی برای دقت آن وجود دارد. یک آزمایش نشان داد که حداقل <em>error</em> از 35 میلی‌ثانیه هنگام همگام‌سازی از طریق اینترنت قابل دستیابی است [42]، اگرچه <em>spikes</em> های گاه به گاه در تأخیر شبکه منجر به <em>errors</em> در حدود یک ثانیه می‌شوند. بسته به <em>configuration</em>، تأخیرهای زیاد شبکه می‌توانند باعث شوند که client NTP به طور کامل رها کند.
        </li>
<li>
            برخی از سرورهای NTP اشتباه یا <em>misconfigured</em> هستند و زمانی را گزارش می‌کنند که ساعت‌ها خاموش است [43, 44]. <em>NTP clients</em> بسیار قوی هستند، زیرا آنها از چندین سرور query می‌گیرند و <em>outliers</em> را نادیده می‌گیرند. با این وجود، شرط بستن درستی system شما بر روی زمانی که توسط یک غریبه در اینترنت به شما گفته شد، تا حدودی نگران‌کننده است.
        </li>
<li>
<em>Leap seconds</em> منجر به یک دقیقه می‌شود که 59 ثانیه یا 61 ثانیه طول دارد، که فرضیات زمان‌بندی در سیستم‌هایی که با <em>leap seconds</em> در نظر گرفته نشده‌اند را بهم می‌ریزد [45]. این واقعیت که <em>leap seconds</em>، بسیاری از سیستم‌های بزرگ را <em>crashed</em> کرده‌اند [38, 46] نشان می‌دهد که چقدر آسان است که فرضیات نادرست در مورد ساعت‌ها به یک system وارد شوند. بهترین راه برای مدیریت <em>leap seconds</em> ممکن است این باشد که سرورهای NTP "<em>lie</em>" کنند، با انجام تنظیم <em>leap second</em> به تدریج در طول یک روز (این به عنوان <em>smearing</em> شناخته می‌شود) [47, 48]، اگرچه رفتار سرور NTP واقعی در عمل متفاوت است [49].
        </li>
<li>
            در <em>virtual machines</em>، ساعت سخت‌افزاری <em>virtualized</em> می‌شود، که چالش‌های اضافی را برای applications هایی که نیاز به <em>accurate timekeeping</em> دارند، ایجاد می‌کند [50]. هنگامی که یک <em>CPU core</em> بین <em>virtual machines</em> به اشتراک گذاشته می‌شود، هر VM برای ده‌ها میلی‌ثانیه متوقف می‌شود در حالی که VM دیگری در حال اجرا است. از دیدگاه application، این توقف خود را به عنوان ساعت نشان می‌دهد که ناگهان به جلو می‌پرد [26].
        </li>
<li>
            اگر شما نرم‌افزاری را روی دستگاه‌هایی اجرا می‌کنید که کاملاً کنترل ندارید (به عنوان مثال، دستگاه‌های mobile یا embedded)، احتمالاً نمی‌توانید به ساعت سخت‌افزاری دستگاه اعتماد کنید. برخی از users ها عمداً ساعت سخت‌افزاری خود را روی یک تاریخ و زمان نادرست تنظیم می‌کنند، به عنوان مثال برای دور زدن محدودیت‌های زمان‌بندی در بازی‌ها. در نتیجه، ساعت ممکن است به زمانی به شدت در گذشته یا آینده تنظیم شود.
        </li>
</ul>
<p>
        اگر شما به اندازه کافی به آن اهمیت می‌دهید که منابع قابل توجهی را سرمایه‌گذاری کنید، می‌توان به دقت بسیار خوبی در ساعت دست یافت. به عنوان مثال، پیش‌نویس مقررات اروپایی MiFID II برای مؤسسات مالی، از تمام funds های <em>high-frequency trading</em> می‌خواهد تا ساعت‌های خود را در 100 میکروثانیه از UTC همگام‌سازی کنند، تا به اشکال‌زدایی <em>market anomalies</em> مانند "<em>flash crashes</em>" و کمک به تشخیص <em>market manipulation</em> کمک کند [51].
    </p>
<p>
        چنین دقتی را می‌توان با استفاده از گیرنده‌های GPS، <em>the Precision Time Protocol (PTP)</em> [52] و <em>careful deployment and monitoring</em> به دست آورد. با این حال، این نیازمند تلاش و تخصص قابل توجهی است، و راه‌های زیادی وجود دارد که همگام‌سازی ساعت می‌تواند اشتباه پیش برود
        <br/>
        290
        <br/>
        |
        <br/>
        Chapter 8: The Trouble with Distributed Systems
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0312</div>
            </div>
        </div>
        <!-- Page 0313 -->
        <div class="chapter" id="page-0313">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        اشتباه است. اگر <em>NTP daemon</em> شما <em>misconfigured</em> شده باشد، یا یک <em>firewall</em> ترافیک NTP را مسدود کند، خطای ساعت به دلیل <em>drift</em> می‌تواند به سرعت بزرگ شود.
    </p>
<h4>Relying on Synchronized Clocks</h4>
<p>
        مشکل ساعت‌ها این است که در حالی که به نظر می‌رسند ساده و آسان برای استفاده هستند، تعداد شگفت‌آوری از <em>pitfalls</em> ها دارند: یک روز ممکن است دقیقاً 86400 ثانیه نداشته باشد، <em>time-of-day clocks</em> ممکن است در زمان به عقب حرکت کنند، و زمان در یک node ممکن است کاملاً متفاوت از زمان در node دیگری باشد.
    </p>
<p>
        در اوایل این فصل ما در مورد شبکه‌ها و <em>packets</em> که به طور دلخواه تأخیر دارند، بحث کردیم. اگرچه شبکه‌ها در اکثر مواقع رفتار خوبی دارند، اما نرم‌افزار باید با این فرض طراحی شود که شبکه گاهی اوقات <em>faulty</em> خواهد بود، و نرم‌افزار باید این <em>faults</em> را به خوبی مدیریت کند. این در مورد ساعت‌ها نیز صادق است: اگرچه آنها در بیشتر مواقع به خوبی کار می‌کنند، اما نرم‌افزار <em>robust</em> باید برای مقابله با ساعت‌های نادرست آماده باشد.
    </p>
<p>
        بخشی از مشکل این است که ساعت‌های نادرست به راحتی مورد توجه قرار نمی‌گیرند. اگر <em>CPU</em> یک machine معیوب باشد یا شبکه آن <em>misconfigured</em> باشد، به احتمال زیاد اصلاً کار نخواهد کرد، بنابراین به سرعت مورد توجه قرار می‌گیرد و برطرف می‌شود. از سوی دیگر، اگر ساعت <em>quartz</em> آن معیوب باشد یا <em>NTP client</em> آن <em>misconfigured</em> باشد، اکثر چیزها خوب به نظر می‌رسند، حتی اگر ساعت آن به تدریج از واقعیت دورتر و دورتر شود. اگر برخی از نرم‌افزارها به یک ساعت با دقت همگام‌سازی شده متکی باشند، نتیجه بیشتر از یک <em>crash</em> چشمگیر، <em>data loss</em> خاموش و ظریف خواهد بود [53, 54].
    </p>
<p>
        بنابراین، اگر شما از نرم‌افزاری استفاده می‌کنید که نیاز به ساعت‌های همگام‌سازی شده دارد، ضروری است که شما نیز با دقت <em>clock offsets</em> را بین تمام machines نظارت کنید. هر node که ساعت آن بیش از حد از دیگران منحرف می‌شود، باید <em>dead</em> اعلام شود و از cluster حذف شود. چنین نظارتی تضمین می‌کند که شما ساعت‌های خراب را قبل از اینکه بتوانند آسیب زیادی وارد کنند، متوجه شوید.
    </p>
<h4>Timestamps for ordering events</h4>
<p>
        بیایید یک موقعیت خاص را در نظر بگیریم که در آن تکیه بر ساعت‌ها وسوسه‌انگیز است، اما خطرناک است: سفارش رویدادها در سراسر چندین nodes. به عنوان مثال، اگر دو client به یک database <em>distributed</em> می‌نویسند، چه کسی اول به آن رسید؟ کدام <em>write</em> جدیدتر است؟
    </p>
<figure>
<img alt="Figure 8-3. Example of a race condition caused by relying on time-of-day clocks to order events." src="figure8-3.png"/>
<figcaption>Figure 8-3. Example of a race condition caused by relying on time-of-day clocks to order events.</figcaption>
</figure>
<p>
        شکل 8-3 یک استفاده خطرناک از <em>time-of-day clocks</em> در یک database با <em>multi-leader replication</em> را نشان می‌دهد (مثال مشابه شکل 5-9 است). Client A در node 1 مقدار x = 1 را <em>writes</em> می‌کند. <em>write</em> به node 3 <em>replicated</em> می‌شود. client B مقدار x را در node 3 افزایش می‌دهد (اکنون داریم x = 2). و در نهایت، هر دو <em>writes</em> به node 2 <em>replicated</em> می‌شوند.
        <br/>
        Unreliable Clocks
        <br/>
        |
        <br/>
        291
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0313</div>
            </div>
        </div>
        <!-- Page 0314 -->
        <div class="chapter" id="page-0314">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<figure>
<img alt="Figure 8-3. The write by client B is causally later than the write by client A, but B’s write has an earlier timestamp." src="figure8-3.png"/>
<figcaption>Figure 8-3. The write by client B is causally later than the write by client A, but B’s write has an earlier timestamp.</figcaption>
</figure>
<p>
        در شکل 8-3، <em>write</em> توسط client B از نظر علّی بعد از <em>write</em> توسط client A است، اما <em>write</em> B دارای <em>timestamp</em> قبلی است.
    </p>
<p>
        در شکل 8-3، وقتی یک <em>write</em> به سایر nodes <em>replicated</em> می‌شود، با یک <em>timestamp</em> با توجه به <em>time-of-day clock</em> روی node که <em>write</em> از آنجا منشأ گرفته است، برچسب‌گذاری می‌شود. <em>Clock synchronization</em> در این مثال بسیار خوب است: <em>skew</em> بین node 1 و node 3 کمتر از 3 میلی‌ثانیه است، که احتمالاً بهتر از چیزی است که شما در عمل انتظار دارید.
    </p>
<p>
        با این وجود، <em>timestamps</em> ها در شکل 8-3 در مرتب‌سازی رویدادها به درستی شکست می‌خورند: <em>write</em> x = 1 دارای <em>timestamp</em> از 42.004 ثانیه است، اما <em>write</em> x = 2 دارای <em>timestamp</em> از 42.003 ثانیه است، حتی اگر x = 2 به طور غیرقابل‌انکاری بعداً رخ داده باشد. هنگامی که node 2 این دو رویداد را دریافت می‌کند، به اشتباه نتیجه می‌گیرد که x = 1 value جدیدتر است و <em>write</em> x = 2 را <em>drop</em> می‌کند. در واقع، operation <em>increment</em> از client B از دست می‌رود.
    </p>
<p>
        این استراتژی <em>conflict resolution</em>، <em>last write wins (LWW)</em> نامیده می‌شود، و به طور گسترده در هر دو <em>multi-leader replication</em> و databases های leaderless مانند Cassandra [53] و Riak [54] استفاده می‌شود (به "Last write wins (discarding concurrent writes)" در صفحه 186 مراجعه کنید). برخی از پیاده‌سازی‌ها <em>timestamps</em> ها را در client به جای سرور ایجاد می‌کنند، اما این مشکلات اساسی را با LWW تغییر نمی‌دهد:
    </p>
<ul>
<li>
            Database <em>writes</em> می‌توانند به طور مرموزی ناپدید شوند: یک node با ساعت تأخیر، قادر به بازنویسی values هایی که قبلاً توسط یک node با ساعت سریع نوشته شده‌اند، نیست تا زمانی که <em>clock skew</em> بین nodes ها منقضی شود [54, 55]. این سناریو می‌تواند باعث شود که مقادیر دلخواه داده‌ها به‌طور پنهانی <em>dropped</em> شوند بدون اینکه هیچ خطایی به application گزارش شود.
        </li>
<li>
            LWW نمی‌تواند بین <em>writes</em> که به ترتیب سریع رخ داده‌اند (در شکل 8-3، <em>increment</em> client B قطعاً پس از <em>write</em> client A رخ می‌دهد) و <em>writes</em> هایی که واقعاً همزمان بودند (هیچ‌کدام از <em>writer</em> ها از دیگری آگاه نبودند) تمایز قائل شود. مکانیسم‌های ردیابی <em>causality</em> اضافی، مانند <em>version vectors</em>، هستند
        </li>
</ul>
<p>
        292
        <br/>
        |
        <br/>
        Chapter 8: The Trouble with Distributed Systems
    </p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 314" src="page_0314/image_1.png"/></div>
</div>
                <div class="page-number">صفحه 0314</div>
            </div>
        </div>
        <!-- Page 0315 -->
        <div class="chapter" id="page-0315">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<ul>
<li>
            برای جلوگیری از تخلف‌های <em>causality</em> (به "Detecting Concurrent Writes" در صفحه 184 مراجعه کنید) مورد نیاز است.
        </li>
<li>
            ممکن است دو node به طور مستقل <em>writes</em> هایی را با همان <em>timestamp</em> ایجاد کنند، به خصوص وقتی که ساعت فقط دارای <em>millisecond resolution</em> است. یک value <em>tiebreaker</em> اضافی (که می‌تواند به سادگی یک عدد تصادفی بزرگ باشد) برای حل این <em>conflicts</em> مورد نیاز است، اما این رویکرد نیز می‌تواند منجر به تخلف‌های <em>causality</em> شود [53].
        </li>
</ul>
<p>
        بنابراین، حتی اگر وسوسه‌انگیز است که <em>conflicts</em> را با حفظ بیشترین value "recent" و دور انداختن دیگران حل کنیم، مهم است که آگاه باشیم که تعریف "recent" به یک <em>local time-of-day clock</em> بستگی دارد، که ممکن است اشتباه باشد. حتی با ساعت‌های NTP-synchronized دقیق، شما می‌توانید یک <em>packet</em> را در timestamp 100 ms (طبق ساعت فرستنده) ارسال کنید و آن را در timestamp 99 ms (طبق ساعت گیرنده) دریافت کنید—بنابراین به نظر می‌رسد که <em>packet</em> قبل از ارسال آن رسیده است، که غیرممکن است.
    </p>
<p>
        آیا می‌توان <em>NTP synchronization</em> را به اندازه‌ای دقیق کرد که چنین orderings های نادرستی رخ ندهند؟ احتمالاً نه، زیرا دقت همگام‌سازی NTP خود به <em>network round-trip time</em>، علاوه بر سایر منابع <em>error</em> مانند <em>quartz drift</em>، محدود می‌شود. برای <em>correct ordering</em>، شما نیاز دارید که منبع ساعت به طور قابل توجهی دقیق‌تر از چیزی باشد که اندازه‌گیری می‌کنید (یعنی تأخیر شبکه).
    </p>
<p>
<em>So-called logical clocks</em> [56, 57]، که بر اساس <em>incrementing counters</em> هستند تا یک <em>oscillating quartz crystal</em>، یک جایگزین ایمن‌تر برای سفارش رویدادها هستند (به "Detecting Concurrent Writes" در صفحه 184 مراجعه کنید). <em>Logical clocks</em> زمان روز یا تعداد ثانیه‌های سپری شده را اندازه‌گیری نمی‌کنند، فقط ترتیب نسبی رویدادها (اینکه آیا یک رویداد قبل یا بعد از رویداد دیگری رخ داده است) را اندازه‌گیری می‌کنند. در مقابل، <em>time-of-day</em> و <em>monotonic clocks</em>، که زمان سپری‌شده واقعی را اندازه‌گیری می‌کنند، به عنوان <em>physical clocks</em> نیز شناخته می‌شوند. ما در مورد ordering کمی بیشتر در "Ordering Guarantees" در صفحه 339 نگاه خواهیم کرد.
    </p>
<h4>Clock readings have a confidence interval</h4>
<p>
        شما ممکن است بتوانید <em>time-of-day clock</em> یک machine را با <em>microsecond</em> یا حتی <em>nanosecond resolution</em> بخوانید. اما حتی اگر شما می‌توانید چنین اندازه‌گیری با <em>fine-grained</em> انجام دهید، این بدان معنا نیست که value در واقع تا آن دقت دقیق است. در واقع، به احتمال زیاد اینطور نیست—همانطور که قبلاً ذکر شد، <em>drift</em> در یک ساعت <em>quartz imprecise</em> می‌تواند به راحتی چندین میلی‌ثانیه باشد، حتی اگر شما هر دقیقه با یک سرور NTP در شبکه محلی همگام‌سازی کنید. با یک سرور NTP در اینترنت عمومی، بهترین دقت ممکن احتمالاً ده‌ها میلی‌ثانیه است، و <em>error</em> ممکن است به راحتی به بیش از 100 میلی‌ثانیه برسد زمانی که <em>network congestion</em> وجود دارد [57].
    </p>
<p>
        بنابراین، منطقی نیست که به یک خواندن ساعت به عنوان یک نقطه در زمان فکر کنیم—این بیشتر شبیه یک range از زمان‌ها است، در یک <em>confidence interval</em>: به عنوان مثال، یک system ممکن است 95٪
        <br/>
        Unreliable Clocks
        <br/>
        |
        <br/>
        293
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0315</div>
            </div>
        </div>
        <!-- Page 0316 -->
        <div class="chapter" id="page-0316">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        نمی‌داند که دقیق‌تر از این است [58]. اگر ما فقط زمان +/– 100 ms را بدانیم، ارقام میکروثانیه در <em>timestamp</em> اساساً بی‌معنی هستند.
    </p>
<p>
        حدود عدم قطعیت را می‌توان بر اساس منبع زمان شما محاسبه کرد. اگر شما یک گیرنده GPS یا یک ساعت اتمی (سزیم) که مستقیماً به کامپیوتر شما متصل است، داشته باشید، بازه <em>error</em> مورد انتظار توسط سازنده گزارش می‌شود. اگر شما زمان را از یک server دریافت می‌کنید، عدم قطعیت بر اساس <em>quartz drift</em> مورد انتظار از زمان آخرین همگام‌سازی شما با سرور، به اضافه عدم قطعیت سرور NTP، به اضافه زمان <em>network round-trip</em> به سرور است (برای یک تقریب اول، و با فرض اینکه شما به سرور اعتماد دارید).
    </p>
<p>
        متاسفانه، اکثر system ها این عدم قطعیت را نشان نمی‌دهند: به عنوان مثال، وقتی شما clock_gettime() را فراخوانی می‌کنید، <em>return value</em>، <em>error</em> مورد انتظار از <em>timestamp</em> را به شما نمی‌گوید، بنابراین شما نمی‌دانید که آیا <em>confidence interval</em> آن پنج میلی‌ثانیه است یا پنج سال.
    </p>
<p>
        یک استثنا جالب، <em>API</em> TrueTime از Google در Spanner است [41]، که صریحاً <em>confidence interval</em> را روی ساعت محلی گزارش می‌دهد. وقتی از آن زمان فعلی را می‌پرسید، دو value دریافت می‌کنید: [earliest, latest]، که اولین و آخرین <em>timestamp</em> ممکن است. بر اساس محاسبات عدم قطعیت خود، ساعت می‌داند که زمان فعلی واقعی در جایی در آن <em>interval</em> است. عرض <em>interval</em>، از جمله، به این بستگی دارد که از آخرین همگام‌سازی ساعت <em>quartz</em> محلی با یک منبع ساعت دقیق‌تر، چقدر گذشته است.
    </p>
<h4>Synchronized clocks for global snapshots</h4>
<p>
        در "Snapshot Isolation and Repeatable Read" در صفحه 237 ما در مورد <em>snapshot iso‐lation</em> بحث کردیم، که یک ویژگی بسیار مفید در databases ها است که نیاز به پشتیبانی از <strong>Transactions</strong> های <em>read-write</em> کوچک و سریع و <em>large, long-running read-only transactions</em> (به عنوان مثال، برای <em>backups</em> یا <em>analytics</em>) دارند. به <strong>Transactions</strong> های <em>read-only</em> اجازه می‌دهد تا database را در یک حالت <em>consistent</em> در یک نقطه زمانی خاص، بدون <em>locking</em> و تداخل با <em>read-write transactions</em>، ببینند.
    </p>
<p>
        رایج‌ترین پیاده‌سازی <em>snapshot isolation</em> به یک <em>monotonically increasing transaction ID</em> نیاز دارد. اگر یک <em>write</em> بعد از <em>snapshot</em> اتفاق افتاد (یعنی، <em>write</em> دارای یک <em>transaction ID</em> بزرگتر از <em>snapshot</em> است)، آن <em>write</em> برای <em>snapshot transaction</em> نامرئی است. در یک database تک node، یک counter ساده برای تولید <em>transaction IDs</em> کافی است.
    </p>
<p>
        با این حال، وقتی یک database در سراسر machine های زیادی، به‌طور بالقوه در چندین <em>datacenters</em>، توزیع می‌شود، ایجاد یک <em>transaction ID</em> <em>monotonically increasing</em> (در سراسر تمام partitions) دشوار است، زیرا به هماهنگی نیاز دارد. <em>Transaction ID</em> باید <em>causality</em> را منعکس کند: اگر <em>transaction</em> B یک value را می‌خواند که توسط <em>transaction</em> A نوشته شده است، سپس B باید <em>transaction ID</em> بالاتری نسبت به A داشته باشد—در غیر این صورت، <em>snapshot</em>
<br/>
        294
        <br/>
        |
        <br/>
        Chapter 8: The Trouble with Distributed Systems
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0316</div>
            </div>
        </div>
        <!-- Page 0317 -->
        <div class="chapter" id="page-0317">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        به منظور جلوگیری از تخلف‌های <em>causality</em> (به "Detecting Concurrent Writes" در صفحه 184 مراجعه کنید) مورد نیاز است.
    </p>
<ul>
<li>
            ممکن است یک <em>transaction</em> را در <em>timestamp</em> با توجه به ساعت node منشأ داده‌ها نشانه‌گذاری کنند.
        </li>
<li>
            ممکن است دو <strong>Transactions</strong> را با هم داشته باشند که <em>timestamp</em> یکسانی تولید کنند.
        </li>
</ul>
<p>
        بهتر است که <em>timestamps</em> را از ساعت‌های <em>monotonic</em> (که <em>actual elapsed time</em> را اندازه‌گیری می‌کنند) یا <em>logical clocks</em> (که فقط ordering نسبی events را نشان می‌دهند) را در نظر گرفت، از آنجایی که این ساعت‌ها به <em>clock skew</em> حساس نیستند.
    </p>
<p>
        در Spanner این <em>snapshot isolation</em> را در سراسر <em>datacenters</em> به این روش پیاده‌سازی می‌کند [59, 60]. این از <em>confidence interval</em> ساعت همانطور که توسط <em>the TrueTime API</em> گزارش شده است، استفاده می‌کند، و مبتنی بر این مشاهده است: اگر شما دو <em>confidence intervals</em> داشته باشید، که هر کدام از یک <em>timestamp</em> احتمالی earliest و latest (A = [Aearliest, Alatest] و B = [Bearliest, Blatest]) تشکیل شده‌اند، و آن دو <em>intervals</em> با هم همپوشانی ندارند (یعنی Aearliest &lt; Alatest &lt; Bearliest &lt; Blatest)، پس B قطعاً بعد از A رخ داده است—هیچ شکی نمی‌تواند وجود داشته باشد. تنها در صورتی که <em>intervals</em> ها همپوشانی داشته باشند، ما در مورد اینکه A و B به چه ترتیبی رخ داده‌اند، مطمئن نیستیم.
    </p>
<p>
        به منظور اطمینان از اینکه <em>transaction timestamps</em>، <em>causality</em> را منعکس می‌کنند، Spanner عمداً به اندازه <em>confidence interval</em> قبل از <em>committing</em> یک <em>read-write transaction</em> منتظر می‌ماند. با انجام این کار، اطمینان حاصل می‌کند که هر <strong>Transaction</strong> که ممکن است داده‌ها را بخواند، در یک زمان به اندازه کافی later است، بنابراین <em>confidence intervals</em> آنها همپوشانی ندارند. به منظور کوتاه نگه داشتن زمان انتظار، Spanner باید <em>clock uncertainty</em> را تا حد امکان کوچک نگه دارد؛ برای این منظور، Google یک گیرنده GPS یا ساعت اتمی را در هر <em>datacenter</em> مستقر می‌کند، که به ساعت‌ها اجازه می‌دهد تا در حدود 7 میلی‌ثانیه همگام‌سازی شوند [41].
    </p>
<p>
        استفاده از <em>clock synchronization</em> برای <em>distributed transaction semantics</em> یک حوزه تحقیقاتی فعال است [57, 61, 62]. این ایده‌ها جالب هستند، اما هنوز در databases های جریان اصلی خارج از Google پیاده‌سازی نشده‌اند.
    </p>
<h4>Process Pauses</h4>
<p>
        بیایید مثال دیگری از استفاده خطرناک ساعت در یک <em>distributed system</em> را در نظر بگیریم. فرض کنید شما یک database با یک leader واحد در هر partition دارید. فقط leader مجاز به پذیرش <em>writes</em> است. چگونه یک node می‌داند که هنوز leader است (که توسط دیگران <em>dead</em> اعلام نشده است)، و اینکه آیا می‌تواند با خیال راحت <em>writes</em> را بپذیرد؟
    </p>
<p>
        یک گزینه این است که leader یک <em>lease</em> از سایر nodes دریافت کند، که شبیه به یک <em>lock</em> با یک <em>timeout</em> است [63]. فقط یک node می‌تواند <em>lease</em> را در هر زمان نگه دارد—بنابراین، هنگامی که یک node یک <em>lease</em> را به دست می‌آورد، می‌داند که برای مدتی leader است، تا زمانی که <em>lease</em> منقضی شود. به منظور باقی ماندن leader، node باید به طور دوره‌ای
        <br/>
        Unreliable Clocks
        <br/>
        |
        <br/>
        295
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0317</div>
            </div>
        </div>
        <!-- Page 0318 -->
        <div class="chapter" id="page-0318">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
<em>the lease</em> قبل از انقضا. اگر node شکست بخورد، دیگر تمدید <em>lease</em> را متوقف می‌کند، بنابراین node دیگری می‌تواند هنگامی که منقضی می‌شود، کنترل را در دست گیرد.
    </p>
<p>
        شما می‌توانید حلقه مدیریت درخواست را شبیه به این تصور کنید:
    </p>
<pre><code class="language-java">while (true) {
    request = getIncomingRequest();
    // Ensure that the lease always has at least 10 seconds remaining
    if (lease.expiryTimeMillis - System.currentTimeMillis() &lt; 10000) {
        lease = lease.renew();
    }
    if (lease.isValid()) {
        process(request);
    }
}
</code></pre>
<p>
        چه چیزی در این کد اشتباه است؟ اولاً، به ساعت‌های همگام‌سازی شده متکی است: زمان انقضای <em>lease</em> توسط machine متفاوتی تنظیم می‌شود (جایی که انقضا ممکن است به عنوان زمان فعلی به اضافه 30 ثانیه محاسبه شود، به عنوان مثال)، و با ساعت system محلی مقایسه می‌شود. اگر ساعت‌ها بیش از چند ثانیه از همگام‌سازی خارج شوند، این کد شروع به انجام کارهای عجیبی می‌کند.
    </p>
<p>
        ثانیاً، حتی اگر پروتکل را طوری تغییر دهیم که فقط از ساعت <em>monotonic</em> محلی استفاده کند، یک مشکل دیگر وجود دارد: کد فرض می‌کند که زمان بسیار کمی بین نقطه‌ای که زمان را بررسی می‌کند (System.currentTimeMillis()) و زمانی که درخواست پردازش می‌شود (process(request)) می‌گذرد. به‌طور معمول این کد خیلی سریع اجرا می‌شود، بنابراین بافر 10 ثانیه‌ای برای اطمینان از اینکه <em>lease</em> در اواسط پردازش یک درخواست منقضی نمی‌شود، کافی است.
    </p>
<p>
        با این حال، اگر یک مکث غیرمنتظره در اجرای برنامه وجود داشته باشد، چه؟ به عنوان مثال، تصور کنید که <em>thread</em> حدود 15 ثانیه در اطراف خط lease.isValid() متوقف می‌شود قبل از اینکه در نهایت ادامه یابد. در این صورت، احتمالاً <em>lease</em> تا زمانی که درخواست پردازش می‌شود، منقضی شده است، و node دیگری قبلاً به عنوان leader کنترل را در دست گرفته است. با این حال، هیچ چیز به این <em>thread</em> نمی‌گوید که برای مدت طولانی متوقف شده است، بنابراین این کد متوجه نخواهد شد که <em>lease</em> تا زمان تکرار بعدی حلقه منقضی شده است—که در آن زمان ممکن است قبلاً با پردازش درخواست، کاری ناایمن انجام داده باشد.
    </p>
<p>
        آیا فرض اینکه یک <em>thread</em> ممکن است برای مدت طولانی متوقف شود، دیوانگی است؟ متاسفانه نه.
        <br/>
        دلایل مختلفی وجود دارد که چرا این می‌تواند اتفاق بیفتد:
    </p>
<ul>
<li>
            بسیاری از <em>programming language runtimes</em> (مانند <em>the Java Virtual Machine</em>) دارای یک <em>garbage collector (GC)</em> هستند که گه‌گاه نیاز به توقف تمام <em>running threads</em> دارد. این توقف‌های <em>“stop-the-world” GC</em> گاهی اوقات شناخته شده‌اند که برای چندین دقیقه طول می‌کشند [64]! حتی <em>“concurrent” garbage collectors</em> نامیده می‌شوند مانند CMS از HotSpot JVM نمی‌توانند کاملاً همزمان با کد application اجرا شوند—حتی آنها نیاز دارند که گاهی اوقات دنیا را متوقف کنند [65]. اگرچه توقف‌ها اغلب می‌توانند
            <br/>
            296
            <br/>
            |
            <br/>
            Chapter 8: The Trouble with Distributed Systems
        </li>
</ul>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0318</div>
            </div>
        </div>
        <!-- Page 0319 -->
        <div class="chapter" id="page-0319">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        کاهش داده می‌شود—با تغییر الگوهای تخصیص یا تنظیم تنظیمات GC [66]، ما باید بدترین حالت را در نظر بگیریم اگر می‌خواهیم <em>guarantees</em> های <em>robust</em> ارائه دهیم.
    </p>
<ul>
<li>
            در محیط‌های <em>virtualized</em>، یک <em>virtual machine</em> می‌تواند <em>suspended</em> شود (توقف اجرای تمام <em>processes</em> و ذخیره محتویات حافظه در دیسک) و <em>resumed</em> (بازیابی محتویات حافظه و ادامه اجرا). این مکث می‌تواند در هر زمانی در اجرای یک <em>process</em> رخ دهد و می‌تواند برای مدت زمان دلخواه ادامه داشته باشد. این ویژگی گاهی اوقات برای <em>live migration</em> از <em>virtual machines</em> از یک <em>host</em> به دیگری بدون <em>reboot</em> استفاده می‌شود، که در این صورت مدت مکث به میزان نوشتن <em>processes</em> به حافظه بستگی دارد [67].
        </li>
<li>
            روی دستگاه‌های end-user مانند لپ‌تاپ‌ها، اجرا ممکن است به طور دلخواه <em>suspended</em> و <em>resumed</em> شود، به عنوان مثال، زمانی که user درب لپ‌تاپ خود را می‌بندد.
        </li>
<li>
            وقتی <em>operating system context-switches</em> به <em>thread</em> دیگری، یا زمانی که <em>hypervisor</em> به یک <em>virtual machine</em> متفاوت سوئیچ می‌کند (هنگام اجرا در یک <em>virtual machine</em>)، <em>thread</em> در حال اجرا می‌تواند در هر نقطه‌ای دلخواه در کد متوقف شود. در مورد یک <em>virtual machine</em>، زمان <em>CPU</em> که در <em>virtual machines</em> های دیگر صرف می‌شود، <em>steal time</em> نامیده می‌شود. اگر machine تحت <em>heavy load</em> است—یعنی اگر صف طولانی از <em>threads</em> در انتظار اجرا وجود داشته باشد—ممکن است مدتی طول بکشد تا <em>thread</em> متوقف شده دوباره اجرا شود.
        </li>
<li>
            اگر application به <em>synchronous disk access</em> می‌پردازد، یک thread ممکن است منتظر تکمیل یک عملیات <em>slow disk I/O</em>، متوقف شود [68]. در بسیاری از زبان‌ها، <em>disk access</em> می‌تواند به طور شگفت‌انگیزی اتفاق بیفتد، حتی اگر کد به صراحت به دسترسی به فایل اشاره نکند—به عنوان مثال، <em>the Java classloader</em> فایل‌های class را <em>lazily loads</em> می‌کند زمانی که برای اولین بار از آنها استفاده می‌شود، که می‌تواند در هر زمانی در اجرای برنامه اتفاق بیفتد. توقف‌های I/O و GC ممکن است حتی برای ترکیب تأخیرهای خود هم‌دست شوند [69]. اگر دیسک در واقع یک <em>network filesystem</em> یا <em>network block device</em> (مانند EBS آمازون) باشد، <em>I/O latency</em> بیشتر در معرض تغییرپذیری تأخیرهای شبکه قرار دارد [29].
        </li>
<li>
            اگر <em>operating system</em> برای اجازه دادن به <em>swapping to disk (paging)</em> پیکربندی شده باشد، یک <em>memory access</em> ساده ممکن است منجر به <em>page fault</em> شود که نیاز به بارگذاری یک صفحه از دیسک به حافظه دارد. <em>Thread</em> در حالی که این <em>slow I/O operation</em> در حال انجام است، متوقف می‌شود. اگر <em>memory pressure</em> بالا باشد، این ممکن است به نوبه خود به یک صفحه متفاوت نیاز داشته باشد که به دیسک <em>swapped out</em> شود. در شرایط شدید، <em>operating system</em> ممکن است بیشتر وقت خود را صرف <em>swapping pages in and out of memory</em> کند و کار واقعی کمی انجام دهد (این به عنوان <em>thrashing</em> شناخته می‌شود). برای جلوگیری از این مشکل، <em>paging</em> اغلب روی machine های server غیرفعال می‌شود (اگر شما ترجیح می‌دهید یک <em>process</em> را برای آزاد کردن mem‐ory <em>kill</em> کنید تا اینکه خطر <em>thrashing</em> را بپذیرید).
        </li>
<li>
            یک <em>Unix process</em> را می‌توان با ارسال سیگنال SIGSTOP متوقف کرد، به عنوان مثال با فشار دادن Ctrl-Z در یک shell. این سیگنال فوراً از دریافت چرخه‌های <em>CPU</em> بیشتر توسط <em>process</em> جلوگیری می‌کند تا زمانی که با SIGCONT از سر گرفته شود، که در آن نقطه اجرای خود را از سر می‌گیرد. حتی اگر محیط شما معمولاً از SIGSTOP استفاده نمی‌کند، ممکن است به طور تصادفی توسط یک مهندس operations ارسال شود.
        </li>
</ul>
<p>
        Unreliable Clocks
        <br/>
        |
        <br/>
        297
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0319</div>
            </div>
        </div>
        <!-- Page 0320 -->
        <div class="chapter" id="page-0320">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        تمام این رخدادها می‌توانند <em>running thread</em> را در هر نقطه‌ای <em>preempt</em> کنند و آن را در زمانی بعدی از سر بگیرند، بدون اینکه <em>thread</em> حتی متوجه شود. این مشکل شبیه به <em>thread-safe</em> کردن کد <em>multi-threaded</em> در یک machine واحد است: شما نمی‌توانید در مورد زمان‌بندی چیزی را فرض کنید، زیرا <em>context switches</em> و <em>parallelism</em> دلخواه ممکن است رخ دهد.
    </p>
<p>
        هنگام نوشتن کد <em>multi-threaded</em> روی یک machine واحد، ما ابزارهای نسبتاً خوبی برای <em>thread-safe</em> کردن آن داریم: <em>mutexes, semaphores, atomic counters, lock-free data structures, blocking queues</em>، و غیره. متاسفانه، این ابزارها مستقیماً به <em>distributed systems</em> ترجمه نمی‌شوند، زیرا یک <em>distributed system</em> دارای حافظه مشترک نیست—فقط پیام‌هایی که از طریق یک شبکه غیرقابل اعتماد ارسال می‌شوند.
    </p>
<p>
        یک node در یک <em>distributed system</em> باید فرض کند که اجرای آن می‌تواند برای یک مدت زمان قابل توجهی در هر نقطه‌ای، حتی در میانه یک <em>function</em>، متوقف شود. در طول مکث، بقیه جهان به حرکت خود ادامه می‌دهد و حتی ممکن است node متوقف شده را <em>dead</em> اعلام کند زیرا پاسخگو نیست. سرانجام، node متوقف شده ممکن است به اجرا ادامه دهد، بدون اینکه حتی متوجه شود که تا زمانی که ساعت خود را در زمانی بعداً بررسی می‌کند، در خواب بوده است.
    </p>
<h4>Response time guarantees</h4>
<p>
        در بسیاری از زبان‌های برنامه‌نویسی و <em>operating systems</em> ها، <em>threads</em> و <em>processes</em> ممکن است برای یک مقدار نامحدود زمان مکث کنند، همانطور که مورد بحث قرار گرفت. اگر شما به اندازه کافی سخت تلاش کنید، می‌توان این دلایل مکث را حذف کرد.
    </p>
<p>
        برخی از نرم‌افزارها در محیط‌هایی اجرا می‌شوند که در آن عدم پاسخگویی در یک زمان مشخص می‌تواند آسیب جدی ایجاد کند: کامپیوترهایی که هواپیما، موشک، روبات‌ها، خودروها و سایر اشیاء فیزیکی را کنترل می‌کنند، باید به ورودی‌های حسگرهای خود به سرعت و به طور قابل پیش‌بینی پاسخ دهند. در این سیستم‌ها، یک مهلت مشخص وجود دارد که نرم‌افزار باید در آن پاسخ دهد. اگر مهلت را رعایت نکند، این ممکن است باعث failure کل system شود.
    </p>
<p>
        اینها system های <em>hard real-time</em> نامیده می‌شوند.
    </p>
<h4>Is real-time really real?</h4>
<p>
        در embedded systems، <em>real-time</em> به این معنی است که یک system با دقت طراحی و آزمایش شده است تا <em>timing guarantees</em> مشخص شده را در همه شرایط برآورده کند. این معنی در تضاد با استفاده مبهم‌تر از اصطلاح <em>real-time</em> در وب است، که در آن سرورها داده‌ها را به <em>clients</em> و stream processing بدون محدودیت‌های زمان پاسخ سخت، ارسال می‌کنند (به فصل 11 مراجعه کنید).
    </p>
<p>
        به عنوان مثال، اگر حسگرهای onboard ماشین شما تشخیص دهند که شما در حال حاضر یک تصادف را تجربه می‌کنید، شما نمی‌خواهید که آزادسازی <em>airbag</em> به دلیل یک مکث GC نامناسب در system آزادسازی <em>airbag</em>، به تأخیر بیفتد.
    </p>
<p>
        ارائه <em>real-time guarantees</em> در یک system نیازمند پشتیبانی از تمام سطوح <em>software stack</em> است: یک <em>real-time operating system (RTOS)</em> که به <em>processes</em> اجازه می‌دهد تا با تخصیص تضمین شده زمان CPU در فواصل زمانی مشخص زمان‌بندی شوند، مورد نیاز است؛ library
        <br/>
        298
        <br/>
        |
        <br/>
        Chapter 8: The Trouble with Distributed Systems
    </p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 320" src="page_0320/image_1.png"/></div>
</div>
                <div class="page-number">صفحه 0320</div>
            </div>
        </div>
        <!-- Page 0321 -->
        <div class="chapter" id="page-0321">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
<em>functions</em> ها باید زمان‌های اجرای <em>worst-case</em> خود را مستند کنند. <em>dynamic memory allocation</em> ممکن است محدود یا به طور کامل ممنوع شود (<em>real-time garbage collectors</em> وجود دارند، اما application همچنان باید اطمینان حاصل کند که به GC کار زیادی نمی‌دهد)؛ و مقدار زیادی آزمایش و اندازه‌گیری باید انجام شود تا اطمینان حاصل شود که <em>guarantees</em> برآورده می‌شوند.
    </p>
<p>
        همه اینها نیازمند مقدار زیادی کار اضافی است و دامنه زبان‌های برنامه‌نویسی، کتابخانه‌ها و ابزارهایی را که می‌توان از آنها استفاده کرد، به شدت محدود می‌کند (از آنجایی که اکثر زبان‌ها و ابزارها، <em>real-time guarantees</em> را ارائه نمی‌دهند). به همین دلیل، توسعه سیستم‌های <em>real-time</em> بسیار گران است، و آنها معمولاً در دستگاه‌های <em>embedded</em> ایمنی-بحرانی استفاده می‌شوند. علاوه بر این، "<em>real-time</em>" با "<em>high-performance</em>" یکسان نیست—در واقع، سیستم‌های <em>real-time</em> ممکن است <em>throughput</em> کمتری داشته باشند، زیرا آنها باید پاسخ‌های به‌موقع را بالاتر از هر چیز دیگری اولویت‌بندی کنند (همچنین به "Latency and Resource Uti‐lization" در صفحه 286 مراجعه کنید).
    </p>
<p>
        برای اکثر سیستم‌های پردازش داده‌های سمت server، <em>real-time guarantees</em> به سادگی اقتصادی یا مناسب نیستند. در نتیجه، این سیستم‌ها باید از توقف‌ها و <em>clock instability</em> که از کار در یک محیط غیر <em>real-time</em> ناشی می‌شود، رنج ببرند.
    </p>
<h4>Limiting the impact of garbage collection</h4>
<p>
        اثرات منفی توقف‌های <em>process</em> را می‌توان بدون توسل به <em>expensive real-time scheduling guarantees</em> کاهش داد. <em>Language runtimes</em> ها مقداری انعطاف‌پذیری در مورد زمان‌بندی <em>garbage collections</em> دارند، زیرا آنها می‌توانند میزان تخصیص object و حافظه آزاد باقی‌مانده را در طول زمان ردیابی کنند.
    </p>
<p>
        یک ایده در حال ظهور این است که توقف‌های GC را مانند <em>brief planned outages of a node</em> در نظر بگیریم، و به سایر nodes اجازه دهیم تا درخواست‌ها را از clients در حالی که یک node در حال جمع‌آوری <em>garbage</em> خود است، مدیریت کنند.
        <br/>
        اگر <em>runtime</em> بتواند به application هشدار دهد که یک node به زودی نیاز به یک توقف GC دارد، application می‌تواند ارسال درخواست‌های جدید به آن node را متوقف کند، منتظر بماند تا پردازش درخواست‌های معوق را تمام کند، و سپس GC را در حالی که هیچ درخواستی در حال انجام نیست، انجام دهد.
    </p>
<p>
        این ترفند، توقف‌های GC را از <em>clients</em> پنهان می‌کند و <em>high percentiles</em> از زمان پاسخگویی را کاهش می‌دهد [70, 71]. برخی از سیستم‌های معاملاتی مالی حساس به <em>latency</em> [72] از این رویکرد استفاده می‌کنند.
    </p>
<p>
        یک variant از این ایده استفاده از <em>garbage collector</em> فقط برای objects کوتاه مدت است (که جمع‌آوری آنها سریع است) و <em>processes</em> را به صورت دوره‌ای راه‌اندازی مجدد می‌کند، قبل از اینکه آنها به اندازه کافی object های <em>long-lived</em> را جمع‌آوری کنند تا نیاز به یک GC کامل از objects های <em>long-lived</em> داشته باشند [65, 73]. یک node را می‌توان در یک زمان راه‌اندازی مجدد کرد، و ترافیک را می‌توان از node قبل از <em>planned restart</em>، مانند یک <em>rolling upgrade</em> (به فصل 4 مراجعه کنید)، دور کرد.
    </p>
<p>
        این اقدامات نمی‌توانند به‌طور کامل از توقف‌های <em>garbage collection</em> جلوگیری کنند، اما می‌توانند به طور مفیدی تأثیر آنها را بر application کاهش دهند.
        <br/>
        Unreliable Clocks
        <br/>
        |
        <br/>
        299
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0321</div>
            </div>
        </div>
        <!-- Page 0322 -->
        <div class="chapter" id="page-0322">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<h4>Knowledge, Truth, and Lies</h4>
<p>
        تا کنون در این فصل ما راه‌هایی را بررسی کردیم که در آنها <em>distributed systems</em> ها با برنامه‌هایی که روی یک کامپیوتر واحد اجرا می‌شوند، متفاوت هستند: هیچ حافظه مشترکی وجود ندارد، فقط ارسال پیام از طریق یک شبکه غیرقابل اعتماد با تأخیرهای متغیر وجود دارد، و سیستم‌ها ممکن است از <em>partial failures</em>، ساعت‌های غیرقابل اعتماد، و توقف‌های پردازش رنج ببرند.
    </p>
<p>
        اگر شما به <em>distributed systems</em> عادت نداشته باشید، پیامدهای این مسائل به شدت گیج‌کننده هستند. یک node در شبکه نمی‌تواند چیزی را با اطمینان بداند—تنها می‌تواند بر اساس پیام‌هایی که از طریق شبکه دریافت می‌کند (یا دریافت نمی‌کند) حدس بزند. یک node فقط می‌تواند دریابد که یک node دیگر در چه حالتی است (چه داده‌هایی را ذخیره کرده است، آیا به درستی کار می‌کند، و غیره) با تبادل پیام با آن. اگر یک node از راه دور پاسخ ندهد، هیچ راهی برای دانستن اینکه در چه حالتی است وجود ندارد، زیرا مشکلات در شبکه را نمی‌توان به طور قابل اعتمادی از مشکلات در یک node تشخیص داد.
    </p>
<p>
        بحث‌ها در مورد این system ها به مرزهای فلسفی می‌رسند: چه چیزی را در system خود درست یا غلط می‌دانیم؟ اگر مکانیسم‌های ادراک و اندازه‌گیری غیرقابل اعتماد باشند، چقدر می‌توانیم از آن دانش مطمئن باشیم؟ آیا سیستم‌های نرم‌افزاری باید از قوانینی که ما از دنیای فیزیکی انتظار داریم، مانند علت و معلول، اطاعت کنند؟
    </p>
<p>
        خوشبختانه، ما نیازی به رفتن به معنای زندگی نداریم. در یک <em>distributed system</em>، ما می‌توانیم فرضیاتی را که در مورد رفتار (<em>the system model</em>) در نظر داریم، بیان کنیم و system واقعی را به گونه‌ای طراحی کنیم که این فرضیات را برآورده کند. می‌توان ثابت کرد که الگوریتم‌ها در یک <em>system model</em> خاص به درستی عمل می‌کنند.
    </p>
<p>
        این بدان معناست که رفتار قابل اعتماد قابل دستیابی است، حتی اگر <em>underlying system model</em>، <em>guarantees</em> های بسیار کمی را ارائه دهد.
    </p>
<p>
        با این حال، اگرچه ممکن است نرم‌افزار را در یک مدل system غیرقابل اعتماد به خوبی رفتار کنید، انجام این کار ساده نیست. در ادامه این فصل، ما به بررسی بیشتر مفاهیم دانش و حقیقت در <em>distributed systems</em> خواهیم پرداخت، که به ما کمک می‌کند در مورد انواع فرضیاتی که می‌توانیم انجام دهیم و <em>guarantees</em> هایی که ممکن است بخواهیم ارائه دهیم، فکر کنیم. در فصل 9 ما به بررسی برخی از نمونه‌های <em>distributed systems</em>، الگوریتم‌هایی می‌پردازیم که <em>guarantees</em> های خاص را تحت فرضیات خاص ارائه می‌دهند.
    </p>
<h4>The Truth Is Defined by the Majority</h4>
<p>
        تصور کنید یک شبکه با یک <em>asymmetric fault</em>: یک node قادر است تمام پیام‌های ارسال شده به آن را دریافت کند، اما هر پیام خروجی از آن node <em>dropped</em> یا به تأخیر می‌افتد [19].
        <br/>
        حتی اگر آن node کاملاً خوب کار کند، و درخواست‌ها را از سایر nodes دریافت کند، سایر nodes نمی‌توانند پاسخ‌های آن را بشنوند. پس از مدتی <em>timeout</em>، سایر nodes ها آن را <em>dead</em> اعلام می‌کنند، زیرا آنها از node چیزی نشنیده‌اند. وضعیت مانند یک کابوس باز می‌شود: node نیمه قطع شده به گورستان کشیده می‌شود، با لگد زدن و فریاد زدن "من نمرده‌ام!"—اما از آنجایی که هیچ‌کس نمی‌تواند فریادهایش را بشنود، تشییع‌جنازه با عزم راسخ ادامه می‌یابد.
        <br/>
        300
        <br/>
        |
        <br/>
        Chapter 8: The Trouble with Distributed Systems
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0322</div>
            </div>
        </div>
        <!-- Page 0323 -->
        <div class="chapter" id="page-0323">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        در یک سناریو کمی وحشتناک‌تر، node نیمه قطع شده ممکن است متوجه شود که پیام‌هایی که ارسال می‌کند، توسط سایر nodes ها تأیید نمی‌شوند، و بنابراین متوجه می‌شود که باید یک <em>fault</em> در شبکه وجود داشته باشد. با این وجود، node به اشتباه توسط سایر nodes ها <em>dead</em> اعلام می‌شود، و node نیمه قطع شده نمی‌تواند در مورد آن کاری انجام دهد.
    </p>
<p>
        به عنوان یک سناریو سوم، یک node را تصور کنید که یک توقف طولانی <em>stop-the-world garbage collection</em> را تجربه می‌کند. تمام <em>threads</em> های node توسط GC <em>preempted</em> می‌شوند و برای یک دقیقه متوقف می‌شوند، و در نتیجه، هیچ درخواستی پردازش نمی‌شود و هیچ پاسخی ارسال نمی‌شود. سایر nodes ها منتظر می‌مانند، دوباره تلاش می‌کنند، بی‌صبر می‌شوند، و در نهایت node را <em>dead</em> اعلام می‌کنند و آن را روی آمبولانس قرار می‌دهند. سرانجام، GC به پایان می‌رسد و <em>threads</em> های node به گونه‌ای ادامه می‌دهند که گویی هیچ اتفاقی نیفتاده است. سایر nodes ها شگفت‌زده می‌شوند زیرا node که قرار بود <em>dead</em> باشد ناگهان سر خود را از تابوت بلند می‌کند، کاملاً سالم، و شروع به گپ زدن شاد با تماشاگران می‌کند. در ابتدا، node GCing حتی متوجه نمی‌شود که یک دقیقه کامل گذشته است و آن را <em>dead</em> اعلام کرده‌اند—از دیدگاه آن، تقریباً هیچ زمانی از زمانی که آخرین بار با سایر nodes صحبت می‌کرد، نگذشته است.
    </p>
<p>
        درس اخلاقی این داستان‌ها این است که یک node لزوماً نمی‌تواند به قضاوت خود از یک موقعیت اعتماد کند. یک <em>distributed system</em> نمی‌تواند منحصراً به یک node واحد متکی باشد، زیرا یک node ممکن است در هر زمانی شکست بخورد، که به طور بالقوه system را متوقف و ناتوان از بازیابی کند.
        <br/>
        در عوض، بسیاری از الگوریتم‌های <em>distributed</em> به یک <em>quorum</em> متکی هستند، یعنی، رأی‌گیری در میان nodes (به "Quorums for reading and writing" در صفحه 179 مراجعه کنید): تصمیم‌گیری‌ها به حداقل تعدادی از آرا از چندین node نیاز دارند تا وابستگی به هر node خاصی را کاهش دهند.
    </p>
<p>
        این شامل تصمیماتی در مورد اعلام <em>dead</em> شدن nodes است. اگر یک <em>quorum</em> از nodes، node دیگری را <em>dead</em> اعلام کند، پس باید <em>dead</em> در نظر گرفته شود، حتی اگر آن node هنوز هم خیلی احساس زنده بودن کند. node فردی باید از تصمیم <em>quorum</em> پیروی کند و کنار بکشد.
    </p>
<p>
        رایج‌ترین، <em>quorum</em>، یک اکثریت مطلق از بیش از نیمی از nodes است (اگرچه انواع دیگر quorums امکان‌پذیر است). یک <em>majority quorum</em> به system اجازه می‌دهد تا در صورت شکست nodes های فردی به کار خود ادامه دهد (با سه node، یک <em>failure</em> را می‌توان تحمل کرد. با پنج node، دو <em>failure</em> را می‌توان تحمل کرد). با این حال، هنوز هم ایمن است، زیرا فقط یک اکثریت در system می‌تواند وجود داشته باشد—دو اکثریت با تصمیمات متناقض نمی‌توانند همزمان وجود داشته باشند. ما استفاده از <em>quorums</em> را با جزئیات بیشتری هنگام رسیدن به الگوریتم‌های <em>consensus</em> در فصل 9 مورد بحث قرار خواهیم داد.
    </p>
<h4>The leader and the lock</h4>
<p>
        اغلب، یک system نیاز دارد که فقط یک مورد از چیزی وجود داشته باشد. به عنوان مثال:
    </p>
<ul>
<li>
            فقط به یک node اجازه داده می‌شود که leader برای یک partition database باشد، تا از <em>split brain</em> جلوگیری شود (به "Handling Node Outages" در صفحه 156 مراجعه کنید).
        </li>
<li>
            فقط به یک transaction یا client اجازه داده می‌شود که <em>lock</em> را برای یک <em>resource</em> یا object خاص نگه دارد، تا از نوشتن همزمان به آن و خراب کردن آن جلوگیری شود.
            <br/>
            Knowledge, Truth, and Lies
            <br/>
            |
            <br/>
            301
        </li>
</ul>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0323</div>
            </div>
        </div>
        <!-- Page 0324 -->
        <div class="chapter" id="page-0324">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<ul>
<li>
            فقط به یک user اجازه داده می‌شود که یک username خاص را ثبت کند، زیرا یک username باید یک user را به طور <em>unique</em> شناسایی کند.
        </li>
</ul>
<p>
        پیاده‌سازی این در یک <em>distributed system</em> نیازمند مراقبت است: حتی اگر یک node معتقد باشد که "انتخابی" است (leader از partition، دارنده <em>lock</em>، <em>request handler</em> از user که با موفقیت username را گرفته است)، این لزوماً به این معنا نیست که یک <em>quorum</em> از nodes موافق هستند! یک node ممکن است قبلاً leader بوده باشد، اما اگر nodes های دیگر در این میان آن را <em>dead</em> اعلام کردند (به عنوان مثال، به دلیل <em>network interruption</em> یا <em>GC pause</em>)، ممکن است عزل شده باشد و leader دیگری قبلاً انتخاب شده باشد.
    </p>
<p>
        اگر یک node به عنوان <em>chosen one</em> ادامه دهد، حتی اگر اکثریت nodes ها آن را <em>dead</em> اعلام کرده باشند، می‌تواند مشکلاتی را در یک system که با دقت طراحی نشده است، ایجاد کند. چنین node می‌تواند پیام‌هایی را به سایر nodes ها در ظرفیت خود تعیین شده ارسال کند، و اگر nodes های دیگر به آن اعتقاد داشته باشند، system در کل ممکن است کاری نادرست انجام دهد.
    </p>
<p>
        به عنوان مثال، شکل 8-4 یک باگ <em>data corruption</em> را به دلیل پیاده‌سازی نادرست از <em>locking</em> نشان می‌دهد. (باگ نظری نیست: HBase قبلاً این مشکل را داشته است [74, 75].) فرض کنید شما می‌خواهید اطمینان حاصل کنید که یک فایل در یک <em>storage service</em> فقط می‌تواند در یک زمان توسط یک client دسترسی پیدا کند، زیرا اگر چندین clients سعی کنند به آن بنویسند، فایل خراب می‌شود. شما سعی می‌کنید این را با نیاز به یک client برای دریافت یک <em>lease</em> از یک <em>lock service</em> قبل از دسترسی به فایل، پیاده‌سازی کنید.
    </p>
<figure>
<img alt="Figure 8-4. Incorrect implementation of a distributed lock: client 1 believes that it still has a valid lease, even though it has expired, and thus corrupts a file in storage." src="figure8-4.png"/>
<figcaption>Figure 8-4. Incorrect implementation of a distributed lock: client 1 believes that it still has a valid lease, even though it has expired, and thus corrupts a file in storage.</figcaption>
</figure>
<p>
        مشکل نمونه‌ای از آنچه ما در "Process Pauses" در صفحه 295 مورد بحث قرار دادیم: اگر client که <em>lease</em> را نگه می‌دارد، برای مدت طولانی مکث کند، <em>lease</em> آن منقضی می‌شود. client دیگری می‌تواند یک <em>lease</em> برای همان فایل دریافت کند و شروع به نوشتن در فایل کند. هنگامی که client متوقف شده بازمی‌گردد، (به اشتباه) معتقد است که هنوز <em>lease</em> معتبری دارد و به نوشتن در فایل ادامه می‌دهد. در نتیجه، <em>writes</em> های clients با هم برخورد می‌کنند و فایل را خراب می‌کنند.
        <br/>
        302
        <br/>
        |
        <br/>
        Chapter 8: The Trouble with Distributed Systems
    </p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 324" src="page_0324/image_1.png"/></div>
</div>
                <div class="page-number">صفحه 0324</div>
            </div>
        </div>
        <!-- Page 0325 -->
        <div class="chapter" id="page-0325">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<h4>Fencing tokens</h4>
<p>
        هنگام استفاده از یک <em>lock</em> یا <em>lease</em> برای محافظت از دسترسی به برخی از <em>resource</em> ها، مانند <em>file storage</em> در شکل 8-4، ما باید اطمینان حاصل کنیم که یک node که تحت یک باور غلط از اینکه "انتخابی" است، نمی‌تواند بقیه system را مختل کند. یک تکنیک نسبتاً ساده که این هدف را محقق می‌کند، <em>fencing</em> نامیده می‌شود، و در شکل 8-5 نشان داده شده است.
    </p>
<figure>
<img alt="Figure 8-5. Making access to storage safe by allowing writes only in the order of increasing fencing tokens." src="figure8-5.png"/>
<figcaption>Figure 8-5. Making access to storage safe by allowing writes only in the order of increasing fencing tokens.</figcaption>
</figure>
<p>
        بیایید فرض کنیم که هر بار سرور <em>lock</em> یک <em>lock</em> یا <em>lease</em> را اعطا می‌کند، یک <em>fencing token</em> نیز برمی‌گرداند، که عددی است که هر بار که یک <em>lock</em> اعطا می‌شود، افزایش می‌یابد (به عنوان مثال، توسط <em>lock service</em> افزایش می‌یابد). سپس ما می‌توانیم نیاز داشته باشیم که هر بار که یک client یک درخواست <em>write</em> را به <em>storage service</em> ارسال می‌کند، باید <em>fencing token</em> فعلی خود را شامل شود.
    </p>
<p>
        در شکل 8-5، client 1 <em>lease</em> را با یک <em>token</em> از 33 به دست می‌آورد، اما سپس به یک مکث طولانی می‌رود و <em>lease</em> منقضی می‌شود. Client 2، <em>lease</em> را با یک <em>token</em> از 34 (عدد همیشه افزایش می‌یابد) به دست می‌آورد و سپس درخواست <em>write</em> خود را به <em>storage service</em> ارسال می‌کند، که شامل <em>token</em> 34 است. بعداً، client 1 دوباره به زندگی بازمی‌گردد و <em>write</em> خود را به <em>storage service</em> ارسال می‌کند، که شامل مقدار <em>token</em> 33 است. با این حال، <em>storage server</em> به خاطر می‌آورد که قبلاً یک <em>write</em> را با یک شماره <em>token</em> بالاتر (34) پردازش کرده است، و بنابراین درخواست با <em>token</em> 33 را رد می‌کند.
    </p>
<p>
        اگر ZooKeeper به عنوان <em>lock service</em> استفاده شود، <em>transaction ID zxid</em> یا <em>the node version cversion</em> را می‌توان به عنوان <em>fencing token</em> استفاده کرد. از آنجایی که آنها تضمین می‌شوند که به طور <em>monotonically increasing</em> باشند، آنها دارای خواص مورد نیاز هستند [74].
    </p>
<p>
        توجه داشته باشید که این مکانیسم، نیاز دارد که خود <em>resource</em> یک نقش فعال در بررسی <em>tokens</em> داشته باشد با رد هر <em>writes</em> با یک <em>token</em> قدیمی‌تر از موردی که قبلاً پردازش شده است—اتکا به clients برای بررسی وضعیت <em>lock</em> خودشان کافی نیست.
    </p>
<p>
        برای <em>resources</em> هایی که صریحاً از <em>fencing tokens</em> پشتیبانی نمی‌کنند، شما هنوز هم ممکن است بتوانید از محدودیت‌ها استفاده کنید (به عنوان مثال، در مورد یک <em>file storage service</em> می‌توانید <em>fencing token</em> را در نام فایل قرار دهید). با این حال، برای جلوگیری از پردازش درخواست‌ها در خارج از حفاظت از <em>lock</em>، برخی از انواع بررسی ضروری است.
        <br/>
        Knowledge, Truth, and Lies
        <br/>
        |
        <br/>
        303
    </p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 325" src="page_0325/image_1.png"/></div>
</div>
                <div class="page-number">صفحه 0325</div>
            </div>
        </div>
        <!-- Page 0326 -->
        <div class="chapter" id="page-0326">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        بررسی یک <em>token</em> در سمت server، ممکن است یک <em>downside</em> به نظر برسد، اما به طور قطع یک چیز خوب است: برای یک service ناخردمندانه است که فرض کند که clients آن همیشه رفتار خوبی خواهند داشت، زیرا clients اغلب توسط افرادی اجرا می‌شوند که اولویت‌های آنها بسیار متفاوت از اولویت‌های افرادی است که service را اجرا می‌کنند [76]. بنابراین، این یک ایده خوب برای هر service است که خود را از clients هایی که به طور تصادفی سوء استفاده می‌کنند، محافظت کند.
    </p>
<h4>Byzantine Faults</h4>
<p>
<em>Fencing tokens</em> می‌توانند یک node را که به طور تصادفی در <em>error</em> عمل می‌کند تشخیص داده و مسدود کنند (به عنوان مثال، زیرا هنوز متوجه نشده است که <em>lease</em> آن منقضی شده است). با این حال، اگر node عمداً می‌خواست <em>guarantees</em> system را خراب کند، می‌تواند این کار را به راحتی با ارسال پیام‌هایی با یک <em>fake fencing token</em> انجام دهد.
    </p>
<p>
        در این کتاب ما فرض می‌کنیم که nodes غیرقابل اعتماد اما صادق هستند: آنها ممکن است کند باشند یا هرگز پاسخ ندهند (به دلیل یک <em>fault</em>)، و وضعیت آنها ممکن است منسوخ شده باشد (به دلیل یک <em>GC pause</em> یا تأخیرهای شبکه)، اما ما فرض می‌کنیم که اگر یک node پاسخ می‌دهد، "حقیقت" را می‌گوید: به بهترین دانش خود، طبق قوانین پروتکل عمل می‌کند.
    </p>
<p>
        مشکلات <em>distributed systems</em> بسیار سخت‌تر می‌شوند اگر خطر این وجود داشته باشد که nodes ها ممکن است "دروغ" بگویند (ارسال پاسخ‌های دلخواه معیوب یا خراب شده)—به عنوان مثال، اگر یک node ادعا کند که یک پیام خاص را دریافت کرده است در حالی که در واقع آن را دریافت نکرده است. چنین رفتاری به عنوان یک <em>Byzantine fault</em> شناخته می‌شود، و مشکل رسیدن به اجماع در این محیط بی‌اعتماد، به عنوان <em>the Byzantine Generals Problem</em> شناخته می‌شود [77].
    </p>
<h4>The Byzantine Generals Problem</h4>
<p>
<em>The Byzantine Generals Problem</em> یک تعمیم از به اصطلاح <em>Two Generals Problem</em> [78] است، که موقعیتی را تصور می‌کند که در آن دو ژنرال ارتش نیاز به توافق در مورد یک طرح نبرد دارند. از آنجایی که آنها در دو مکان مختلف اردو زده‌اند، آنها فقط می‌توانند با messenger ارتباط برقرار کنند، و <em>messengers</em> ها گاهی اوقات تأخیر یا از دست می‌روند (مانند <em>packets</em> در یک شبکه). ما این مشکل اجماع را در فصل 9 مورد بحث قرار خواهیم داد.
    </p>
<p>
        در نسخه <em>Byzantine</em> این مشکل، n ژنرال وجود دارد که باید توافق کنند، و تلاش آنها با این واقعیت مختل می‌شود که برخی از خائنان در میان آنها وجود دارند.
        <br/>
        اکثر ژنرال‌ها وفادار هستند، و بنابراین پیام‌های صادقانه را ارسال می‌کنند، اما خائنان ممکن است سعی کنند با ارسال پیام‌های جعلی یا نادرست، دیگران را فریب دهند و گیج کنند (در حالی که سعی می‌کنند ناشناس بمانند). از قبل مشخص نیست که خائنان چه کسانی هستند.
    </p>
<p>
        Byzantium یک شهر باستانی یونانی بود که بعداً به قسطنطنیه تبدیل شد، در مکانی که اکنون استانبول در ترکیه است. هیچ مدرک تاریخی وجود ندارد که نشان دهد ژنرال‌های Byzantium نسبت به دسیسه و توطئه نسبت به سایرین مستعدتر بوده‌اند. در عوض، این نام از Byzantium در مفهوم بیش از حد پیچیده، بوروکراتیک، فریبنده گرفته شده است، که مدت‌ها قبل از کامپیوترها در سیاست استفاده می‌شد [79]. Lamport می‌خواست ملیتی را انتخاب کند که هیچ یک از خوانندگان را آزرده‌خاطر نکند، و به او توصیه شد که نامیدن آن به عنوان The Albanian Generals Problem ایده چندان خوبی نیست [80].
        <br/>
        304
        <br/>
        |
        <br/>
        Chapter 8: The Trouble with Distributed Systems
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0326</div>
            </div>
        </div>
        <!-- Page 0327 -->
        <div class="chapter" id="page-0327">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        یک system، <em>Byzantine fault-tolerant</em> است اگر حتی اگر برخی از nodes ها عملکرد درستی نداشته باشند و از پروتکل پیروی نکنند، یا اگر مهاجمان مخرب در شبکه دخالت کنند، به درستی به کار خود ادامه دهد. این نگرانی در شرایط خاصی مرتبط است. به عنوان مثال:
    </p>
<ul>
<li>
            در محیط‌های هوافضا، داده‌ها در حافظه کامپیوتر یا <em>CPU register</em> می‌تواند توسط تابش خراب شود، که منجر به پاسخ دادن آن به سایر nodes به روش‌های غیرقابل پیش‌بینی می‌شود. از آنجایی که <em>system failure</em> بسیار گران تمام می‌شود (به عنوان مثال، سقوط یک هواپیما و کشتن همه سرنشینان، یا برخورد یک موشک با <em>the International Space Station</em>)، سیستم‌های کنترل پرواز باید <em>Byzantine faults</em> را تحمل کنند [81, 82].
        </li>
<li>
            در یک system با سازمان‌های متعدد شرکت‌کننده، برخی از شرکت‌کنندگان ممکن است سعی کنند دیگران را فریب دهند یا کلاهبرداری کنند. در چنین شرایطی، امن نیست که یک node به سادگی به پیام‌های node دیگری اعتماد کند، زیرا ممکن است با نیت بد ارسال شوند. به عنوان مثال، شبکه‌های <em>peer-to-peer</em> مانند بیت‌کوین و سایر <em>blockchains</em> را می‌توان راهی برای رساندن طرف‌های متقابلاً بی‌اعتماد به توافق در مورد وقوع یک transaction یا عدم وقوع آن، بدون اتکا به یک مرجع مرکزی، در نظر گرفت [83].
        </li>
</ul>
<p>
        با این حال، در انواع systems که ما در این کتاب مورد بحث قرار می‌دهیم، ما معمولاً می‌توانیم با خیال راحت فرض کنیم که هیچ <em>Byzantine faults</em> وجود ندارد. در <em>datacenter</em> شما، همه nodes تحت کنترل سازمان شما هستند (بنابراین می‌توان امیدوار بود که به آنها اعتماد شود) و سطوح تابش به اندازه‌ای کم است که <em>memory corruption</em> یک مشکل بزرگ نیست. پروتکل‌هایی برای ایجاد system های <em>Byzantine fault-tolerant</em>، بسیار پیچیده هستند [84]، و <em>fault-tolerant embedded systems</em> به پشتیبانی از سطح سخت‌افزار متکی هستند [81]. در اکثر سیستم‌های داده سمت server، هزینه استقرار راه‌حل‌های <em>Byzantine fault-tolerant</em> آنها را غیر عملی می‌کند.
    </p>
<p>
        Applications های وب باید رفتار دلخواه و مخرب clients هایی را که تحت کنترل end-user هستند، مانند <em>web browsers</em>، انتظار داشته باشند. به همین دلیل است که <em>input validation, sani‐tization</em>، و <em>output escaping</em> بسیار مهم هستند: به عنوان مثال، برای جلوگیری از <em>SQL injection</em> و <em>cross-site scripting</em>. با این حال، ما معمولاً از پروتکل‌های <em>Byzantine fault-tolerant</em> در اینجا استفاده نمی‌کنیم، بلکه به سادگی سرور را به عنوان مرجع در تصمیم‌گیری در مورد رفتار client که مجاز است یا نیست، قرار می‌دهیم. در شبکه‌های <em>peer-to-peer</em>، که چنین مرجع مرکزی وجود ندارد، <em>Byzantine fault tolerance</em> مرتبط‌تر است.
    </p>
<p>
        یک باگ در نرم‌افزار را می‌توان به عنوان یک <em>Byzantine fault</em> در نظر گرفت، اما اگر شما همان نرم‌افزار را در تمام nodes ها مستقر کنید، سپس یک الگوریتم <em>Byzantine fault-tolerant</em> نمی‌تواند شما را نجات دهد. اکثر الگوریتم‌های <em>Byzantine fault-tolerant</em> نیازمند یک <em>supermajority</em> از بیش از دو سوم nodes ها هستند تا به درستی کار کنند (یعنی، اگر شما چهار node داشته باشید، حداکثر یک مورد ممکن است خراب شود). برای استفاده از این رویکرد در برابر باگ‌ها، شما باید چهار پیاده‌سازی مستقل از نرم‌افزار یکسان داشته باشید و امیدوار باشید که یک باگ فقط در یکی از چهار پیاده‌سازی ظاهر شود.
        <br/>
        Knowledge, Truth, and Lies
        <br/>
        |
        <br/>
        305
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0327</div>
            </div>
        </div>
        <!-- Page 0328 -->
        <div class="chapter" id="page-0328">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        به طور مشابه، اگر یک پروتکل بتواند ما را از آسیب‌پذیری‌ها، <em>security compromises</em>، و حملات مخرب محافظت کند، جذاب خواهد بود. متاسفانه، این نیز واقع‌بینانه نیست: در اکثر systems ها، اگر یک <em>attacker</em> بتواند یک node را به خطر بیندازد، احتمالاً می‌تواند همه آنها را به خطر بیندازد، زیرا احتمالاً آنها در حال اجرای نرم‌افزار یکسان هستند. بنابراین، مکانیسم‌های سنتی (<em>authentication, access control, encryption, firewalls</em>، و غیره) همچنان محافظت اصلی در برابر <em>attackers</em> هستند.
    </p>
<h4>Weak forms of lying</h4>
<p>
        اگرچه ما فرض می‌کنیم که nodes ها به طور کلی صادق هستند، اما ممکن است اضافه کردن مکانیسم‌هایی به نرم‌افزار که در برابر <em>weak forms</em> از "دروغ گفتن" محافظت می‌کنند—به عنوان مثال، پیام‌های نامعتبر به دلیل مشکلات سخت‌افزاری، باگ‌های نرم‌افزاری، و <em>misconfiguration</em>—ارزش داشته باشد. این مکانیسم‌های محافظت، <em>full-blown Byzantine fault tolerance</em> نیستند، زیرا در برابر یک <em>determined adversary</em> مقاومت نمی‌کنند، اما با این وجود، گام‌های ساده و عمل‌گرایانه به سمت قابلیت اطمینان بهتر هستند. به عنوان مثال:
    </p>
<ul>
<li>
<em>Network packets</em> گاهی اوقات به دلیل مشکلات سخت‌افزاری یا باگ‌ها در <em>operating systems, drivers, routers</em> و غیره خراب می‌شوند. معمولاً، <em>corrupted packets</em> توسط <em>checksums</em> های ساخته شده در TCP و UDP گرفته می‌شوند، اما گاهی اوقات از تشخیص اجتناب می‌کنند [85, 86, 87]. اقدامات ساده معمولاً محافظت کافی در برابر چنین <em>corruption</em> ای هستند، مانند <em>checksums</em> در <em>application-level protocol</em>.
        </li>
<li>
            یک application که به صورت عمومی قابل دسترسی است، باید هر ورودی از users را با دقت <em>sanitize</em> کند، به عنوان مثال بررسی اینکه آیا یک value در یک محدوده معقول قرار دارد و محدود کردن اندازه <em>strings</em> برای جلوگیری از <em>denial of service</em> از طریق تخصیص حافظه بزرگ. یک service داخلی در پشت یک <em>firewall</em> ممکن است بتواند با بررسی‌های کمتری در مورد ورودی‌ها (به عنوان مثال، در <em>protocol parsing</em> [85]) کنار بیاید، اما برخی از <em>sanity-checking</em> های اساسی از <em>values</em> (به عنوان مثال، در <em>protocol parsing</em> [85]) یک ایده خوب است.
        </li>
<li>
<em>NTP clients</em> را می‌توان با چندین آدرس سرور پیکربندی کرد. هنگام همگام‌سازی، client با همه آنها تماس می‌گیرد، خطاهای آنها را تخمین می‌زند، و بررسی می‌کند که آیا اکثریت سرورها روی یک <em>time range</em> توافق دارند. تا زمانی که بیشتر سرورها خوب هستند، یک سرور NTP <em>misconfigured</em> که زمان نادرستی را گزارش می‌کند، به عنوان یک <em>outlier</em> تشخیص داده می‌شود و از همگام‌سازی مستثنی می‌شود [37]. استفاده از چندین سرور، NTP را بیشتر <em>robust</em> می‌کند نسبت به زمانی که فقط از یک سرور واحد استفاده می‌کند.
        </li>
</ul>
<p>
        Many algorithms have been designed to solve distributed systems problems—for
        example, we will examine solutions for the consensus problem in Chapter 9. In order
        to be useful, these algorithms need to tolerate the various faults of distributed systems
        that we discussed in this chapter.
        <br/>
        Clock readings have a confidence interval
        <br/>
        You may be able to read a machine’s time-of-day clock with microsecond or even
        nanosecond resolution. But even if you can get such a fine-grained measurement,
        that doesn’t mean the value is actually accurate to such precision. In fact, it most
        likely is not—as mentioned previously, the drift in an imprecise quartz clock can
        easily be several milliseconds, even if you synchronize with an NTP server on the
        local network every minute. With an NTP server on the public internet, the best pos‐
        sible accuracy is probably to the tens of milliseconds, and the error may easily spike
        to over 100 ms when there is network congestion [57].
        Thus, it doesn’t make sense to think of a clock reading as a point in time—it is more
        like a range of times, within a confidence interval: for example, a system may be 95%
        confident that the time now is between 10.3 and 10.5 seconds past the minute, but it
        Unreliable Clocks
        |
        293
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0328</div>
            </div>
        </div>
        <!-- Page 0329 -->
        <div class="chapter" id="page-0329">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        باید در system به نوعی <em>formalize</em> کنیم، در این صورت انواع <em>faults</em> را که انتظار داریم در یک system رخ دهند، پیش‌بینی می‌کنیم. ما این کار را با تعریف a <em>system model</em> انجام می‌دهیم، که یک <em>abstraction</em> است که توضیح می‌دهد که یک الگوریتم چه چیزهایی را می‌تواند فرض کند.
    </p>
<p>
        با توجه به فرضیات زمان‌بندی، سه <em>system models</em> به‌طور معمول مورد استفاده قرار می‌گیرند:
    </p>
<ul>
<li>
            Synchronous model
            <br/>
<em>The synchronous model</em>، تأخیر شبکه <em>bounded</em>، توقف <em>process pauses</em> <em>bounded</em>، و <em>bounded clock error</em> را فرض می‌کند. این به معنای ساعت‌های دقیقاً همگام‌سازی شده یا تأخیر شبکه صفر نیست. فقط به این معنی است که شما می‌دانید که تأخیر شبکه، توقف‌ها، و <em>clock drift</em> هرگز از یک <em>upper bound</em> ثابت تجاوز نخواهد کرد [88]. <em>The synchronous model</em>، یک مدل واقع‌بینانه از اکثر systems های کاربردی نیست، زیرا (همانطور که در این فصل مورد بحث قرار گرفت) تأخیرها و توقف‌های نامحدود رخ می‌دهند.
        </li>
<li>
            Partially synchronous model
            <br/>
            Partial synchrony به این معنی است که یک system، در بیشتر مواقع، مانند یک <em>synchronous system</em> رفتار می‌کند، اما گاهی اوقات از حدود تأخیر شبکه، توقف <em>process pauses</em>، و <em>clock drift</em> فراتر می‌رود [88]. این یک مدل واقع‌بینانه از بسیاری از systems ها است: در بیشتر مواقع، شبکه‌ها و <em>processes</em> ها به خوبی رفتار می‌کنند—در غیر این صورت ما هرگز نمی‌توانستیم هیچ کاری انجام دهیم—اما ما باید با این واقعیت حساب کنیم که هر فرضیات زمان‌بندی ممکن است گه‌گاه شکسته شود. هنگامی که این اتفاق می‌افتد، تأخیر شبکه، توقف‌ها، و خطای ساعت ممکن است به طور دلخواه زیاد شوند.
        </li>
<li>
            Asynchronous model
            <br/>
            در این مدل، یک الگوریتم مجاز به انجام هیچ فرضیات زمان‌بندی نیست—در واقع، حتی یک ساعت ندارد (بنابراین نمی‌تواند از <em>timeouts</em> استفاده کند). برخی از الگوریتم‌ها را می‌توان برای مدل <em>asynchronous</em> طراحی کرد، اما بسیار محدودکننده است.
        </li>
</ul>
<p>
        علاوه بر این، در کنار مسائل زمان‌بندی، ما باید <em>node failures</em> را در نظر بگیریم. سه <em>system models</em> رایج برای nodes عبارتند از:
    </p>
<ul>
<li>
            Crash-stop faults
            <br/>
            در <em>the crash-stop model</em>، یک الگوریتم ممکن است فرض کند که یک node فقط می‌تواند به یک روش <em>fail</em> شود، یعنی با <em>crashing</em>. این بدان معناست که node ممکن است ناگهان در هر لحظه پاسخ دادن را متوقف کند، و پس از آن، آن node برای همیشه از بین می‌رود—هرگز برنمی‌گردد.
        </li>
<li>
            Crash-recovery faults
            <br/>
            ما فرض می‌کنیم که nodes ممکن است در هر لحظه <em>crash</em> کنند، و شاید پس از مدتی نامعلوم دوباره پاسخ دهند. در <em>the crash-recovery model</em>، فرض می‌شود که nodes، <em>stable storage</em> (یعنی، ذخیره‌سازی دیسک غیرفرار) دارند که در سراسر <em>crashes</em> حفظ می‌شود، در حالی که فرض می‌شود که <em>in-memory state</em> از بین رفته است.
        </li>
<li>
            Byzantine (arbitrary) faults
            <br/>
            Nodes ها ممکن است مطلقاً هر کاری انجام دهند، از جمله تلاش برای فریب و گمراه کردن سایر nodes ها، همانطور که در بخش آخر توضیح داده شد.
            <br/>
            Knowledge, Truth, and Lies
            <br/>
            |
            <br/>
            307
        </li>
</ul>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0329</div>
            </div>
        </div>
        <!-- Page 0330 -->
        <div class="chapter" id="page-0330">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        برای مدل‌سازی سیستم‌های واقعی، <em>the partially synchronous model</em> با <em>crash-recovery faults</em>، عموماً مفیدترین مدل است. اما الگوریتم‌های <em>distributed</em> چگونه با آن مدل مقابله می‌کنند؟
    </p>
<h4>Correctness of an algorithm</h4>
<p>
        برای تعریف اینکه یک الگوریتم correct چه معنایی دارد، ما می‌توانیم ویژگی‌های آن را توصیف کنیم.
        <br/>
        به عنوان مثال، خروجی یک الگوریتم مرتب‌سازی دارای این ویژگی است که برای هر دو عنصر مجزا از list خروجی، عنصری که به سمت چپ‌تر است، از عنصری که به سمت راست‌تر است، کوچک‌تر است. این به سادگی یک راه رسمی برای تعریف این است که چه معنایی دارد که یک list مرتب شود.
    </p>
<p>
        به طور مشابه، ما می‌توانیم ویژگی‌هایی را که از یک الگوریتم <em>distributed</em> می‌خواهیم، بنویسیم تا تعریف کنیم که درست بودن آن به چه معناست. به عنوان مثال، اگر ما در حال تولید <em>fencing tokens</em> برای یک <em>lock</em> هستیم (به "Fencing tokens" در صفحه 303 مراجعه کنید)، ممکن است الگوریتم را ملزم کنیم که دارای ویژگی‌های زیر باشد:
    </p>
<ul>
<li>
            Uniqueness
            <br/>
            هیچ دو درخواست برای یک <em>fencing token</em> مقدار یکسانی را برنمی‌گردانند.
        </li>
<li>
            Monotonic sequence
            <br/>
            اگر درخواست x توکن tx را برگرداند، و درخواست y توکن ty را برگرداند، و x قبل از شروع y تکمیل شد، در این صورت tx &lt; ty.
        </li>
<li>
            Availability
            <br/>
            یک node که یک <em>fencing token</em> درخواست می‌کند و <em>crashed</em> نمی‌شود، در نهایت پاسخی دریافت می‌کند.
        </li>
</ul>
<p>
        یک الگوریتم در برخی از <em>system model</em> ها correct است اگر همیشه ویژگی‌های خود را در تمام موقعیت‌هایی که ما فرض می‌کنیم ممکن است در آن <em>system model</em> رخ دهد، برآورده کند. اما این چگونه منطقی است؟ اگر همه nodes <em>crash</em> کنند، یا تمام تأخیرهای شبکه ناگهان بی‌نهایت طولانی شوند، در این صورت هیچ الگوریتمی قادر به انجام کاری نخواهد بود.
    </p>
<h4>Safety and liveness</h4>
<p>
        برای روشن شدن وضعیت، ارزش دارد که بین دو نوع مختلف از ویژگی‌ها تمایز قائل شویم: <em>safety</em> و <em>liveness properties</em>. در مثال ارائه شده، <em>uniqueness</em> و <em>monotonic sequence</em>، <em>safety properties</em> هستند، اما <em>availability</em> یک <em>liveness property</em> است.
    </p>
<p>
        چه چیزی دو نوع از ویژگی‌ها را متمایز می‌کند؟ یک نشانه این است که <em>liveness properties</em> اغلب کلمه "eventually" را در تعریف خود گنجانده‌اند. (و بله، شما حدس زدید—<em>eventual consistency</em> یک <em>liveness property</em> است [89].)
    </p>
<p>
<em>Safety</em> اغلب به طور غیررسمی به عنوان <em>nothing bad happens</em> تعریف می‌شود، و <em>liveness</em> به عنوان <em>something good eventually happens</em>. با این حال، بهتر است که بیش از حد به این تعاریف غیررسمی اعتماد نکنید، زیرا معنای خوب و بد ذهنی است. تعاریف واقعی <em>safety</em> و <em>liveness</em> دقیق و ریاضیاتی هستند [90]:
        <br/>
        308
        <br/>
        |
        <br/>
        Chapter 8: The Trouble with Distributed Systems
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0330</div>
            </div>
        </div>
        <!-- Page 0331 -->
        <div class="chapter" id="page-0331">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<ul>
<li>
            اگر a <em>safety property</em> نقض شود، ما می‌توانیم به یک نقطه زمانی خاص که در آن شکسته شد، اشاره کنیم (به عنوان مثال، اگر <em>the uniqueness property</em> نقض شد، ما می‌توانیم operation خاصی را که در آن یک <em>duplicate fencing token</em> بازگردانده شد، شناسایی کنیم).
            <br/>
            پس از اینکه یک <em>safety property</em> نقض شد، این تخلف را نمی‌توان لغو کرد—آسیب قبلاً وارد شده است.
        </li>
<li>
            A <em>liveness property</em> به روش دیگری عمل می‌کند: ممکن است در برخی از نقاط زمانی حفظ نشود (به عنوان مثال، یک node ممکن است یک درخواست ارسال کرده باشد اما هنوز پاسخی دریافت نکرده باشد)، اما همیشه این امید وجود دارد که ممکن است در آینده برآورده شود (یعنی با دریافت یک پاسخ).
        </li>
</ul>
<p>
        یک مزیت از تمایز بین <em>safety</em> و <em>liveness properties</em> این است که به ما در برخورد با <em>system models</em> های دشوار کمک می‌کند. برای الگوریتم‌های <em>distributed</em>، معمول است که <em>safety properties</em> همیشه برقرار باشند، در تمام موقعیت‌های ممکن از یک <em>system model</em> [88]. یعنی، حتی اگر همه nodes <em>crash</em> کنند، یا کل شبکه شکست بخورد، الگوریتم باید اطمینان حاصل کند که یک نتیجه نادرست را برنمی‌گرداند (یعنی، <em>safety properties</em> همچنان برآورده می‌شوند).
    </p>
<p>
        با این حال، با <em>liveness properties</em>، ما مجاز به ایجاد caveats هستیم: به عنوان مثال، ما می‌توانیم بگوییم که یک درخواست فقط در صورتی نیاز به دریافت پاسخ دارد که اکثریت nodes ها <em>crashed</em> نشده باشند، و فقط در صورتی که شبکه در نهایت از یک <em>outage</em> بازیابی شود. تعریف <em>the partially synchronous model</em> نیازمند است که در نهایت system به یک حالت <em>synchronous</em> بازگردد—یعنی، هر دوره از <em>network interruption</em> فقط برای یک مدت زمان محدود دوام دارد و سپس تعمیر می‌شود.
    </p>
<h4>Mapping system models to the real world</h4>
<p>
<em>Safety</em> و <em>liveness properties</em> و <em>system models</em> برای استدلال در مورد correctness یک الگوریتم <em>distributed</em> بسیار مفید هستند. با این حال، هنگام پیاده‌سازی یک الگوریتم در عمل، واقعیت‌های درهم و برهم دوباره شما را گاز می‌گیرند، و مشخص می‌شود که <em>system model</em> یک <em>simplified abstraction of reality</em> است.
    </p>
<p>
        به عنوان مثال، الگوریتم‌ها در <em>the crash-recovery model</em> عموماً فرض می‌کنند که داده‌ها در ذخیره‌سازی stable، از <em>crashes</em> ها جان سالم به در می‌برند. با این حال، اگر داده‌ها روی دیسک خراب شوند، یا داده‌ها به دلیل <em>hardware error</em> یا <em>misconfiguration</em> پاک شوند، چه اتفاقی می‌افتد [91]؟ اگر یک server دارای باگ <em>firmware</em> است و در زمان <em>reboot</em>، هارد درایوهای خود را شناسایی نمی‌کند، حتی اگر درایوها به درستی به server متصل شده باشند، چه اتفاقی می‌افتد [92]؟
    </p>
<p>
<em>Quorum algorithms</em> (به "Quorums for reading and writing" در صفحه 179 مراجعه کنید) متکی به یک node هستند که داده‌هایی را که ادعا می‌کند ذخیره کرده است، به خاطر می‌آورد. اگر یک node ممکن است از <em>amnesia</em> رنج ببرد و داده‌های ذخیره شده قبلی را فراموش کند، این شرط <em>quorum</em> را می‌شکند، و بنابراین correctness الگوریتم را می‌شکند. شاید یک <em>system model</em> جدید مورد نیاز است، که در آن ما فرض می‌کنیم که ذخیره‌سازی <em>stable</em> عمدتاً از <em>crashes</em> ها جان سالم به در می‌برد، اما ممکن است گاهی اوقات از دست برود. اما استدلال در مورد آن مدل، سخت‌تر می‌شود.
        <br/>
        Knowledge, Truth, and Lies
        <br/>
        |
        <br/>
        309
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0331</div>
            </div>
        </div>
        <!-- Page 0332 -->
        <div class="chapter" id="page-0332">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
<em>A theoretical description of an algorithm</em> می‌تواند اعلام کند که موارد خاصی به سادگی فرض می‌شود که اتفاق نمی‌افتند—و در <em>non-Byzantine systems</em>، ما باید برخی از فرضیات را در مورد <em>faults</em> هایی که می‌توانند و نمی‌توانند رخ دهند، ایجاد کنیم. با این حال، یک پیاده‌سازی واقعی ممکن است همچنان نیاز داشته باشد که کدی را برای رسیدگی به موردی که در آن چیزی که فرض می‌شد غیرممکن است، رخ می‌دهد، شامل شود، حتی اگر آن مدیریت به <em>printf("Sucks to be you")</em> و <em>exit(666)</em> منتهی شود—یعنی، اجازه دادن به یک <em>human operator</em> برای پاک کردن مشکل [93].
    </p>
<p>
        (این احتمالاً تفاوت بین علوم کامپیوتر و <em>software engineering</em> است.)
    </p>
<p>
        این بدان معنا نیست که <em>theoretical, abstract system models</em> بی‌ارزش هستند—برعکس این است. آنها برای تقطیر پیچیدگی سیستم‌های واقعی به مجموعه‌ای از <em>faults</em> ها، که ما می‌توانیم در مورد آنها استدلال کنیم، بسیار مفید هستند، به‌طوری‌که می‌توانیم مشکل را درک کنیم و سعی کنیم آن را به‌طور سیستماتیک حل کنیم. ما می‌توانیم <em>algorithms</em> را با نشان دادن اینکه ویژگی‌های آنها همیشه در برخی از <em>system model</em> ها حفظ می‌شوند، correct کنیم.
    </p>
<p>
        اثبات <em>correct</em> بودن یک الگوریتم به این معنی نیست که پیاده‌سازی آن در یک system واقعی لزوماً همیشه به درستی رفتار می‌کند. اما این یک گام اول بسیار خوب است، زیرا تحلیل نظری می‌تواند مشکلاتی را در یک الگوریتم کشف کند که ممکن است برای مدت طولانی در یک system واقعی پنهان بماند، و فقط زمانی شما را <em>bite</em> کند که فرضیات شما (به عنوان مثال، در مورد زمان‌بندی) به دلیل شرایط غیرعادی شکست خورده باشد. <em>Theoretical analysis</em> و آزمایش تجربی به یک اندازه مهم هستند.
    </p>
<h4>Summary</h4>
<p>
        در این فصل ما در مورد طیف گسترده‌ای از مشکلاتی که می‌تواند در <em>distributed systems</em> رخ دهد، بحث کردیم، از جمله:
    </p>
<ul>
<li>
            هر زمان که شما سعی می‌کنید یک <em>packet</em> را از طریق شبکه ارسال کنید، ممکن است از دست برود یا به طور دلخواه به تأخیر بیفتد. به همین ترتیب، پاسخ ممکن است از دست برود یا به تأخیر بیفتد، بنابراین اگر شما پاسخی دریافت نمی‌کنید، هیچ ایده‌ای ندارید که آیا پیام ارسال شده است یا خیر.
        </li>
<li>
            ساعت یک node ممکن است به طور قابل توجهی با سایر nodes همگام‌سازی شده باشد (علیرغم تلاش‌های شما برای تنظیم NTP)، ممکن است ناگهان به جلو یا عقب در زمان بپرد، و تکیه بر آن خطرناک است زیرا شما به احتمال زیاد اندازه‌گیری خوبی از <em>error interval</em> ساعت خود ندارید.
        </li>
<li>
            یک process ممکن است برای یک مدت زمان قابل توجهی در هر نقطه‌ای در اجرای خود متوقف شود (شاید به دلیل یک <em>stop-the-world garbage collector</em>)، توسط سایر nodes ها <em>dead</em> اعلام شود، و سپس دوباره بدون اینکه متوجه شود متوقف شده است، به زندگی بازگردد.
        </li>
</ul>
<p>
        این واقعیت که چنین <em>partial failures</em> می‌تواند رخ دهد، ویژگی تعیین‌کننده <em>distributed systems</em> است. هر زمان که نرم‌افزار سعی می‌کند کاری را که شامل nodes های دیگر است انجام دهد، این احتمال وجود دارد که گاهی اوقات شکست بخورد، یا به طور تصادفی کند شود، یا اصلاً پاسخ ندهد (و در نهایت <em>timeout</em>). در <em>distributed systems</em>، ما سعی می‌کنیم system های <em>tolerant</em> بسازیم
        <br/>
        310
        <br/>
        |
        <br/>
        Chapter 8: The Trouble with Distributed Systems
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0332</div>
            </div>
        </div>
        <!-- Page 0333 -->
        <div class="chapter" id="page-0333">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
<em>ance of partial failures</em> into software، به‌طوری‌که system در کل ممکن است به عملکرد خود ادامه دهد، حتی زمانی که برخی از بخش‌های تشکیل‌دهنده آن خراب هستند.
    </p>
<p>
        برای تحمل <em>faults</em>، اولین گام، تشخیص آنها است، اما حتی این هم دشوار است. اکثر systems ها یک مکانیسم دقیق برای تشخیص اینکه آیا یک node شکست خورده است یا خیر ندارند، بنابراین اکثر الگوریتم‌های <em>distributed</em> به <em>timeouts</em> متکی هستند تا تعیین کنند که آیا یک node از راه دور هنوز در دسترس است یا خیر. با این حال، <em>timeouts</em> نمی‌توانند بین <em>network</em> و <em>node failures</em> تمایز قائل شوند، و تأخیر شبکه متغیر گاهی اوقات باعث می‌شود که یک node به اشتباه مشکوک به <em>crashing</em> شود. علاوه بر این، گاهی اوقات یک node می‌تواند در یک حالت <em>degraded</em> قرار داشته باشد: به عنوان مثال، یک <em>Gigabit network interface</em> می‌تواند ناگهان به <em>throughput</em> 1 کیلوبیت بر ثانیه به دلیل یک باگ <em>driver</em> <em>drop</em> شود [94]. رسیدگی به چنین node ای که <em>“limping”</em> است اما <em>dead</em> نیست، دشوارتر از یک node که به طور منظم <em>failed</em> است، می‌باشد.
    </p>
<p>
        هنگامی که یک <em>fault</em> تشخیص داده شد، ایجاد یک system که آن را تحمل کند نیز آسان نیست: هیچ متغیر global، حافظه مشترک، دانش مشترک یا هر نوع دیگری از <em>shared state</em> بین machine ها وجود ندارد. nodes ها حتی نمی‌توانند بر سر زمان به توافق برسند، چه برسد به هر چیز عمیق‌تری. تنها راهی که اطلاعات می‌تواند از یک node به node دیگر جریان یابد، ارسال آن از طریق شبکه غیرقابل اعتماد است. تصمیمات اصلی را نمی‌توان با خیال راحت توسط یک node واحد اتخاذ کرد، بنابراین ما به پروتکل‌هایی نیاز داریم که کمک سایر nodes ها را جذب کنند و سعی کنند یک <em>quorum</em> را به توافق برسانند.
    </p>
<p>
        اگر شما به نوشتن نرم‌افزار در کمال ریاضیاتی ایده‌آل یک کامپیوتر واحد عادت کرده‌اید، که در آن یک operation یکسان همیشه به طور قطعی نتیجه یکسانی را برمی‌گرداند، پس حرکت به سمت واقعیت فیزیکی درهم و برهم <em>distributed systems</em> می‌تواند کمی شوکه‌کننده باشد. برعکس، مهندسان <em>distributed systems</em> اغلب یک مشکل را بی‌اهمیت می‌دانند اگر بتوان آن را روی یک کامپیوتر واحد حل کرد [5]، و در واقع یک کامپیوتر واحد امروزه می‌تواند کارهای زیادی انجام دهد [95]. اگر می‌توانید از باز کردن جعبه پاندورا اجتناب کنید و به سادگی چیزها را روی یک machine نگه دارید، به‌طور کلی ارزش انجام این کار را دارد.
    </p>
<p>
        با این حال، همانطور که در مقدمه قسمت II مورد بحث قرار گرفت، مقیاس‌پذیری تنها دلیل برای تمایل به استفاده از یک <em>distributed system</em> نیست. <em>Fault tolerance</em> و <em>low latency</em> (با قرار دادن داده‌ها از نظر جغرافیایی نزدیک به users) اهداف به همان اندازه مهمی هستند، و آن چیزها را نمی‌توان با یک node واحد به دست آورد.
    </p>
<p>
        در این فصل، ما همچنین به برخی از <em>tangents</em> ها رفتیم تا بررسی کنیم که آیا غیرقابل اعتماد بودن شبکه‌ها، ساعت‌ها، و <em>processes</em> یک قانون اجتناب‌ناپذیر طبیعت است یا خیر. ما دیدیم که اینطور نیست: ارائه <em>hard real-time response guarantees</em> و تأخیرهای <em>bounded</em> در شبکه‌ها امکان‌پذیر است، اما انجام این کار بسیار گران است و منجر به استفاده کمتر از منابع سخت‌افزاری می‌شود. اکثر سیستم‌های غیر <em>safety-critical</em>، ارزان و غیرقابل اعتماد را بر گران و قابل اعتماد ترجیح می‌دهند.
    </p>
<p>
        ما همچنین به <em>supercomputers</em> ها اشاره کردیم، که اجزای قابل اعتماد را فرض می‌کنند و بنابراین باید به طور کامل وقتی یک component <em>fail</em> می‌شود، متوقف و راه‌اندازی مجدد شوند. در مقابل، <em>distributed systems</em> می‌توانند برای همیشه بدون وقفه در سطح service اجرا شوند، زیرا تمام <em>faults</em> و maintenance را می‌توان در سطح node مدیریت کرد—حداقل در
        <br/>
        309
        <br/>
        |
        <br/>
        Chapter 8: The Trouble with Distributed Systems
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0333</div>
            </div>
        </div>
        <!-- Page 0334 -->
        <div class="chapter" id="page-0334">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        theory. (در عمل، اگر یک تغییر پیکربندی بد به تمام nodes ها اعمال شود، آن همچنان یک <em>distributed system</em> را از بین می‌برد.)
    </p>
<p>
        این فصل همه در مورد مشکلات بوده است، و یک دیدگاه تیره را به ما ارائه کرده است. در فصل بعد ما به سمت راه‌حل‌ها حرکت خواهیم کرد، و در مورد برخی از الگوریتم‌هایی بحث خواهیم کرد که برای مقابله با تمام مشکلات در <em>distributed systems</em> طراحی شده‌اند.
    </p>
<h3>References</h3>
<ol>
<li>
            [1] Mark Cavage: “There’s Just No Getting Around It: You’re Building a Distributed
            System,” ACM Queue, volume 11, number 4, pages 80-89, April 2013. doi:
            10.1145/2466486.2482856
        </li>
<li>
            [2] Jay Kreps: “Getting Real About Distributed System Reliability,” blog.empathy‐
            box.com, March 19, 2012.
        </li>
<li>
            [3] Sydney Padua: The Thrilling Adventures of Lovelace and Babbage: The (Mostly)
            True Story of the First Computer. Particular Books, April 2015. ISBN:
            978-0-141-98151-2
        </li>
<li>
            [4] Coda Hale: “You Can’t Sacrifice Partition Tolerance,” codahale.com, October 7,
            2010.
        </li>
<li>
            [5] Jeff Hodges: “Notes on Distributed Systems for Young Bloods,” somethingsimi‐
            lar.com, January 14, 2013.
        </li>
<li>
            [6] Antonio Regalado: “Who Coined ‘Cloud Computing’?,” technologyreview.com,
            October 31, 2011.
        </li>
<li>
            [7] Luiz André Barroso, Jimmy Clidaras, and Urs Hölzle: “The Datacenter as a Com‐
            puter: An Introduction to the Design of Warehouse-Scale Machines, Second Edi‐
            tion,” Synthesis Lectures on Computer Architecture, volume 8, number 3, Morgan &amp;
            Claypool Publishers, July 2013. doi:10.2200/S00516ED2V01Y201306CAC024, ISBN:
            978-1-627-05010-4
        </li>
<li>
            [8] David Fiala, Frank Mueller, Christian Engelmann, et al.: “Detection and Correc‐
            tion of Silent Data Corruption for Large-Scale High-Performance Computing,” at
            International Conference for High Performance Computing, Networking, Storage and
            Analysis (SC12), November 2012.
        </li>
<li>
            [9] Arjun Singh, Joon Ong, Amit Agarwal, et al.: “Jupiter Rising: A Decade of Clos
            Topologies and Centralized Control in Google’s Datacenter Network,” at Annual
            Conference of the ACM Special Interest Group on Data Communication (SIGCOMM),
            August 2015. doi:10.1145/2785956.2787508
        </li>
<li>
            [10] Glenn K. Lockwood: “Hadoop’s Uncomfortable Fit in HPC,” glennklock‐
            wood.blogspot.co.uk, May 16, 2014.
        </li>
</ol>
<p>
        312
        <br/>
        |
        <br/>
        Chapter 8: The Trouble with Distributed Systems
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0334</div>
            </div>
        </div>
        <!-- Page 0335 -->
        <div class="chapter" id="page-0335">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<ol>
<li>
            [11] John von Neumann: “Probabilistic Logics and the Synthesis of Reliable Organ‐
            isms from Unreliable Components,” in Automata Studies (AM-34), edited by Claude
            E. Shannon and John McCarthy, Princeton University Press, 1956. ISBN:
            978-0-691-07916-5
        </li>
<li>
            [12] Richard W. Hamming: The Art of Doing Science and Engineering. Taylor &amp; Fran‐
            cis, 1997. ISBN: 978-9-056-99500-3
        </li>
<li>
            [13] Claude E. Shannon: “A Mathematical Theory of Communication,” The Bell Sys‐
            tem Technical Journal, volume 27, number 3, pages 379–423 and 623–656, July 1948.
        </li>
<li>
            [14] Peter Bailis and Kyle Kingsbury: “The Network Is Reliable,” ACM Queue, vol‐
            ume 12, number 7, pages 48-55, July 2014. doi:10.1145/2639988.2639988
        </li>
<li>
            [15] Joshua B. Leners, Trinabh Gupta, Marcos K. Aguilera, and Michael Walfish:
            “Taming Uncertainty in Distributed Systems with Help from the Network,” at 10th
            European Conference on Computer Systems (EuroSys), April 2015. doi:
            10.1145/2741948.2741976
        </li>
<li>
            [16] Phillipa Gill, Navendu Jain, and Nachiappan Nagappan: “Understanding Net‐
            work Failures in Data Centers: Measurement, Analysis, and Implications,” at ACM
            SIGCOMM Conference, August 2011. doi:10.1145/2018436.2018477
        </li>
<li>
            [17] Mark Imbriaco: “Downtime Last Saturday,” github.com, December 26, 2012.
        </li>
<li>
            [18] Will Oremus: “The Global Internet Is Being Attacked by Sharks, Google Con‐
            firms,” slate.com, August 15, 2014.
        </li>
<li>
            [19] Marc A. Donges: “Re: bnx2 cards Intermittantly Going Offline,” Message to
            Linux netdev mailing list, spinics.net, September 13, 2012.
        </li>
<li>
            [20] Kyle Kingsbury: “Call Me Maybe: Elasticsearch,” aphyr.com, June 15, 2014.
        </li>
<li>
            [21] Salvatore Sanfilippo: “A Few Arguments About Redis Sentinel Properties and
            Fail Scenarios,” antirez.com, October 21, 2014.
        </li>
<li>
            [22] Bert Hubert: “The Ultimate SO_LINGER Page, or: Why Is My TCP Not Relia‐
            ble,” blog.netherlabs.nl, January 18, 2009.
        </li>
<li>
            [23] Nicolas Liochon: “CAP: If All You Have Is a Timeout, Everything Looks Like a
            Partition,” blog.thislongrun.com, May 25, 2015.
        </li>
<li>
            [24] Jerome H. Saltzer, David P. Reed, and David D. Clark: “End-To-End Arguments
            in System Design,” ACM Transactions on Computer Systems, volume 2, number 4,
            pages 277–288, November 1984. doi:10.1145/357401.357402
        </li>
<li>
            [25] Matthew P. Grosvenor, Malte Schwarzkopf, Ionel Gog, et al.: “Queues Don’t
            Matter When You Can JUMP Them!,” at 12th USENIX Symposium on Networked
            Systems Design and Implementation (NSDI), May 2015.
        </li>
</ol>
<p>
        Summary
        <br/>
        |
        <br/>
        313
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0335</div>
            </div>
        </div>
        <!-- Page 0336 -->
        <div class="chapter" id="page-0336">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<ol>
<li>
            [26] Guohui Wang and T. S. Eugene Ng: “The Impact of Virtualization on Network
            Performance of Amazon EC2 Data Center,” at 29th IEEE International Conference on
            Computer Communications (INFOCOM), March 2010. doi:10.1109/INFCOM.
            2010.5461931
        </li>
<li>
            [27] Van Jacobson: “Congestion Avoidance and Control,” at ACM Symposium on
            Communications Architectures and Protocols (SIGCOMM), August 1988. doi:
            10.1145/52324.52356
        </li>
<li>
            [28] Brandon Philips: “etcd: Distributed Locking and Service Discovery,” at Strange
            Loop, September 2014.
        </li>
<li>
            [29] Steve Newman: “A Systematic Look at EC2 I/O,” blog.scalyr.com, October 16,
            2012.
        </li>
<li>
            [30] Naohiro Hayashibara, Xavier Défago, Rami Yared, and Takuya Katayama: “The
            ϕ Accrual Failure Detector,” Japan Advanced Institute of Science and Technology,
            School of Information Science, Technical Report IS-RR-2004-010, May 2004.
        </li>
<li>
            [31] Jeffrey Wang: “Phi Accrual Failure Detector,” ternarysearch.blogspot.co.uk,
            August 11, 2013.
        </li>
<li>
            [32] Srinivasan Keshav: An Engineering Approach to Computer Networking: ATM
            Networks, the Internet, and the Telephone Network. Addison-Wesley Professional,
            May 1997. ISBN: 978-0-201-63442-6
        </li>
<li>
            [33] Cisco, “Integrated Services Digital Network,” docwiki.cisco.com.
        </li>
<li>
            [34] Othmar Kyas: ATM Networks. International Thomson Publishing, 1995. ISBN:
            978-1-850-32128-6
        </li>
<li>
            [35] “InfiniBand FAQ,” Mellanox Technologies, December 22, 2014.
        </li>
<li>
            [36] Jose Renato Santos, Yoshio Turner, and G. (John) Janakiraman: “End-to-End
            Congestion Control for InfiniBand,” at 22nd Annual Joint Conference of the IEEE
            Computer and Communications Societies (INFOCOM), April 2003. Also published by
            HP Laboratories Palo Alto, Tech Report HPL-2002-359. doi:10.1109/INFCOM.
            2003.1208949
        </li>
<li>
            [37] Ulrich Windl, David Dalton, Marc Martinec, and Dale R. Worley: “The NTP
            FAQ and HOWTO,” ntp.org, November 2006.
        </li>
<li>
            [38] John Graham-Cumming: “How and why the leap second affected Cloudflare
            DNS,” blog.cloudflare.com, January 1, 2017.
        </li>
<li>
            [39] David Holmes: “Inside the Hotspot VM: Clocks, Timers and Scheduling Events
            – Part I – Windows,” blogs.oracle.com, October 2, 2006.
        </li>
<li>
            [40] Steve Loughran: “Time on Multi-Core, Multi-Socket Servers,” stevelough‐
            ran.blogspot.co.uk, September 17, 2015.
        </li>
</ol>
<p>
        314
        <br/>
        |
        <br/>
        Chapter 8: The Trouble with Distributed Systems
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0336</div>
            </div>
        </div>
        <!-- Page 0337 -->
        <div class="chapter" id="page-0337">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<ol>
<li>
            [41] James C. Corbett, Jeffrey Dean, Michael Epstein, et al.: “Spanner: Google’s
            Globally-Distributed Database,” at 10th USENIX Symposium on Operating System
            Design and Implementation (OSDI), October 2012.
        </li>
<li>
            [42] M. Caporaloni and R. Ambrosini: “How Closely Can a Personal Computer
            Clock Track the UTC Timescale Via the Internet?,” European Journal of Physics, vol‐
            ume 23, number 4, pages L17–L21, June 2012. doi:10.1088/0143-0807/23/4/103
        </li>
<li>
            [43] Nelson Minar: “A Survey of the NTP Network,” alumni.media.mit.edu, Decem‐
            ber 1999.
        </li>
<li>
            [44] Viliam Holub: “Synchronizing Clocks in a Cassandra Cluster Pt. 1 – The Prob‐
            lem,” blog.logentries.com, March 14, 2014.
        </li>
<li>
            [45] Poul-Henning Kamp: “The One-Second War (What Time Will You Die?),”
            ACM 
            Queue, 
            volume 
            9, 
            number 
            4, 
            pages 
            44–48, 
            April 
            2011. 
            doi:
            10.1145/1966989.1967009
        </li>
<li>
            [46] Nelson Minar: “Leap Second Crashes Half the Internet,” somebits.com, July 3,
            2012.
        </li>
<li>
            [47] Christopher Pascoe: “Time, Technology and Leaping Seconds,” googleblog.blog‐
            spot.co.uk, September 15, 2011.
        </li>
<li>
            [48] Mingxue Zhao and Jeff Barr: “Look Before You Leap – The Coming Leap Second
            and AWS,” aws.amazon.com, May 18, 2015.
        </li>
<li>
            [49] Darryl Veitch and Kanthaiah Vijayalayan: “Network Timing and the 2015 Leap
            Second,” at 17th International Conference on Passive and Active Measurement
            (PAM), April 2016. doi:10.1007/978-3-319-30505-9_29
        </li>
<li>
            [50] “Timekeeping in VMware Virtual Machines,” Information Guide, VMware, Inc.,
            December 2011.
        </li>
<li>
            [51] “MiFID II / MiFIR: Regulatory Technical and Implementing Standards – Annex
            I (Draft),” European Securities and Markets Authority, Report ESMA/2015/1464,
            September 2015.
        </li>
<li>
            [52] Luke Bigum: “Solving MiFID II Clock Synchronisation With Minimum Spend
            (Part 1),” lmax.com, November 27, 2015.
        </li>
<li>
            [53] Kyle Kingsbury: “Call Me Maybe: Cassandra,” aphyr.com, September 24, 2013.
        </li>
<li>
            [54] John Daily: “Clocks Are Bad, or, Welcome to the Wonderful World of Dis‐
            tributed Systems,” basho.com, November 12, 2013.
        </li>
<li>
            [55] Kyle Kingsbury: “The Trouble with Timestamps,” aphyr.com, October 12, 2013.
        </li>
</ol>
<p>
        Summary
        <br/>
        |
        <br/>
        315
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0337</div>
            </div>
        </div>
        <!-- Page 0338 -->
        <div class="chapter" id="page-0338">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<ol>
<li>
            [56] Leslie Lamport: “Time, Clocks, and the Ordering of Events in a Distributed Sys‐
            tem,” Communications of the ACM, volume 21, number 7, pages 558–565, July 1978.
            doi:10.1145/359545.359563
        </li>
<li>
            [57] Sandeep Kulkarni, Murat Demirbas, Deepak Madeppa, et al.: “Logical Physical
            Clocks and Consistent Snapshots in Globally Distributed Databases,” State University
            of New York at Buffalo, Computer Science and Engineering Technical Report
            2014-04, May 2014.
        </li>
<li>
            [58] Justin Sheehy: “There Is No Now: Problems With Simultaneity in Distributed
            Systems,” ACM Queue, volume 13, number 3, pages 36–41, March 2015. doi:
            10.1145/2733108
        </li>
<li>
            [59] Murat Demirbas: “Spanner: Google’s Globally-Distributed Database,” muratbuf‐
            falo.blogspot.co.uk, July 4, 2013.
        </li>
<li>
            [60] Dahlia Malkhi and Jean-Philippe Martin: “Spanner’s Concurrency Control,”
            ACM SIGACT News, volume 44, number 3, pages 73–77, September 2013. doi:
            10.1145/2527748.2527767
        </li>
<li>
            [61] Manuel Bravo, Nuno Diegues, Jingna Zeng, et al.: “On the Use of Clocks to
            Enforce Consistency in the Cloud,” IEEE Data Engineering Bulletin, volume 38, num‐
            ber 1, pages 18–31, March 2015.
        </li>
<li>
            [62] Spencer Kimball: “Living Without Atomic Clocks,” cockroachlabs.com, February
            17, 2016.
        </li>
<li>
            [63] Cary G. Gray and David R. Cheriton: “Leases: An Efficient Fault-Tolerant Mech‐
            anism for Distributed File Cache Consistency,” at 12th ACM Symposium on Operat‐
            ing Systems Principles (SOSP), December 1989. doi:10.1145/74850.74870
        </li>
<li>
            [64] Todd Lipcon: “Avoiding Full GCs in Apache HBase with MemStore-Local Allo‐
            cation Buffers: Part 1,” blog.cloudera.com, February 24, 2011.
        </li>
<li>
            [65] Martin Thompson: “Java Garbage Collection Distilled,” mechanical-
            sympathy.blogspot.co.uk, July 16, 2013.
        </li>
<li>
            [66] Alexey Ragozin: “How to Tame Java GC Pauses? Surviving 16GiB Heap and
            Greater,” java.dzone.com, June 28, 2011.
        </li>
<li>
            [67] Christopher Clark, Keir Fraser, Steven Hand, et al.: “Live Migration of Virtual
            Machines,” at 2nd USENIX Symposium on Symposium on Networked Systems Design
            &amp; Implementation (NSDI), May 2005.
        </li>
<li>
            [68] Mike Shaver: “fsyncers and Curveballs,” shaver.off.net, May 25, 2008.
        </li>
<li>
            [69] Zhenyun Zhuang and Cuong Tran: “Eliminating Large JVM GC Pauses Caused
            by Background IO Traffic,” engineering.linkedin.com, February 10, 2016.
        </li>
</ol>
<p>
        316
        <br/>
        |
        <br/>
        Chapter 8: The Trouble with Distributed Systems
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0338</div>
            </div>
        </div>
        <!-- Page 0339 -->
        <div class="chapter" id="page-0339">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<ol>
<li>
            [70] David Terei and Amit Levy: “Blade: A Data Center Garbage Collector,” arXiv:
            1504.02578, April 13, 2015.
        </li>
<li>
            [71] Martin Maas, Tim Harris, Krste Asanović, and John Kubiatowicz: “Trash Day:
            Coordinating Garbage Collection in Distributed Systems,” at 15th USENIX Workshop
            on Hot Topics in Operating Systems (HotOS), May 2015.
        </li>
<li>
            [72] “Predictable Low Latency,” Cinnober Financial Technology AB, cinnober.com,
            November 24, 2013.
        </li>
<li>
            [73] Martin Fowler: “The LMAX Architecture,” martinfowler.com, July 12, 2011.
        </li>
<li>
            [74] Flavio P. Junqueira and Benjamin Reed: ZooKeeper: Distributed Process Coordi‐
            nation. O’Reilly Media, 2013. ISBN: 978-1-449-36130-3
        </li>
<li>
            [75] Enis Söztutar: “HBase and HDFS: Understanding Filesystem Usage in HBase,” at
            HBaseCon, June 2013.
        </li>
<li>
            [76] Caitie McCaffrey: “Clients Are Jerks: AKA How Halo 4 DoSed the Services at
            Launch &amp; How We Survived,” caitiem.com, June 23, 2015.
        </li>
<li>
            [77] Leslie Lamport, Robert Shostak, and Marshall Pease: “The Byzantine Generals
            Problem,” ACM Transactions on Programming Languages and Systems (TOPLAS),
            volume 4, number 3, pages 382–401, July 1982. doi:10.1145/357172.357176
        </li>
<li>
            [78] Jim N. Gray: “Notes on Data Base Operating Systems,” in Operating Systems: An
            Advanced Course, Lecture Notes in Computer Science, volume 60, edited by R. Bayer,
            R. M. Graham, and G. Seegmüller, pages 393–481, Springer-Verlag, 1978. ISBN:
            978-3-540-08755-7
        </li>
<li>
            [79] Brian Palmer: “How Complicated Was the Byzantine Empire?,” slate.com, Octo‐
            ber 20, 2011.
        </li>
<li>
            [80] Leslie Lamport: “My Writings,” research.microsoft.com, December 16, 2014. This
            page can be found by searching the web for the 23-character string obtained by
            removing the hyphens from the string allla-mport-spubso-ntheweb.
        </li>
<li>
            [81] John Rushby: “Bus Architectures for Safety-Critical Embedded Systems,” at 1st
            International Workshop on Embedded Software (EMSOFT), October 2001.
        </li>
<li>
            [82] Jake Edge: “ELC: SpaceX Lessons Learned,” lwn.net, March 6, 2013.
        </li>
<li>
            [83] Andrew Miller and Joseph J. LaViola, Jr.: “Anonymous Byzantine Consensus
            from Moderately-Hard Puzzles: A Model for Bitcoin,” University of Central Florida,
            Technical Report CS-TR-14-01, April 2014.
        </li>
<li>
            [84] James Mickens: “The Saddest Moment,” USENIX ;login: logout, May 2013.
        </li>
<li>
            [85] Evan Gilman: “The Discovery of Apache ZooKeeper’s Poison Packet,” pagerd‐
            uty.com, May 7, 2015.
        </li>
</ol>
<p>
        Summary
        <br/>
        |
        <br/>
        317
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0339</div>
            </div>
        </div>
        <!-- Page 0340 -->
        <div class="chapter" id="page-0340">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<ol>
<li>
            [86] Jonathan Stone and Craig Partridge: “When the CRC and TCP Checksum Disa‐
            gree,” at ACM Conference on Applications, Technologies, Architectures, and Protocols
            for 
            Computer 
            Communication 
            (SIGCOMM), 
            August 
            2000. 
            doi:
            10.1145/347059.347561
        </li>
<li>
            [87] Evan Jones: “How Both TCP and Ethernet Checksums Fail,” evanjones.ca, Octo‐
            ber 5, 2015.
        </li>
<li>
            [88] Cynthia Dwork, Nancy Lynch, and Larry Stockmeyer: “Consensus in the Pres‐
            ence of Partial Synchrony,” Journal of the ACM, volume 35, number 2, pages 288–
            323, April 1988. doi:10.1145/42282.42283
        </li>
<li>
            [89] Peter Bailis and Ali Ghodsi: “Eventual Consistency Today: Limitations, Exten‐
            sions, and Beyond,” ACM Queue, volume 11, number 3, pages 55-63, March 2013.
            doi:10.1145/2460276.2462076
        </li>
<li>
            [90] Bowen Alpern and Fred B. Schneider: “Defining Liveness,” Information Process‐
            ing Letters, volume 21, number 4, pages 181–185, October 1985. doi:
            10.1016/0020-0190(85)90056-0
        </li>
<li>
            [91] Flavio P. Junqueira: “Dude, Where’s My Metadata?,” fpj.me, May 28, 2015.
        </li>
<li>
            [92] Scott Sanders: “January 28th Incident Report,” github.com, February 3, 2016.
        </li>
<li>
            [93] Jay Kreps: “A Few Notes on Kafka and Jepsen,” blog.empathybox.com, Septem‐
            ber 25, 2013.
        </li>
<li>
            [94] Thanh Do, Mingzhe Hao, Tanakorn Leesatapornwongsa, et al.: “Limplock:
            Understanding the Impact of Limpware on Scale-out Cloud Systems,” at 4th ACM
            Symposium 
            on 
            Cloud 
            Computing 
            (SoCC), 
            October 
            2013. 
            doi:
            10.1145/2523616.2523627
        </li>
<li>
            [95] Frank McSherry, Michael Isard, and Derek G. Murray: “Scalability! But at What
            COST?,” at 15th USENIX Workshop on Hot Topics in Operating Systems (HotOS),
            May 2015.
        </li>
</ol>
<p>
        318
        <br/>
        |
        <br/>
        Chapter 8: The Trouble with Distributed Systems
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0340</div>
            </div>
        </div>
        <!-- Page 0343 -->
        <div class="chapter" id="page-0343">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<h3>CHAPTER 9</h3>
<h4>Consistency and Consensus</h4>
<p>
        Is it better to be alive and wrong or right and dead?
        <br/>
        —Jay Kreps, A Few Notes on Kafka and Jepsen (2013)
    </p>
<p>
        همانطور که در فصل 8 مورد بحث قرار گرفت، موارد زیادی می‌توانند در <em>distributed systems</em> اشتباه پیش بروند. ساده‌ترین راه برای رسیدگی به چنین <em>faults</em>، این است که اجازه دهیم کل <em>service</em> شکست بخورد، و به user یک پیام <em>error</em> نشان دهیم. اگر آن راه‌حل غیرقابل قبول باشد، ما باید راه‌هایی را برای تحمل <em>faults</em> پیدا کنیم—یعنی، حفظ عملکرد صحیح service، حتی اگر برخی از اجزای داخلی آن <em>faulty</em> باشند.
    </p>
<p>
        در این فصل، ما در مورد برخی از نمونه‌های الگوریتم‌ها و پروتکل‌ها برای ساختن <em>fault-tolerant distributed systems</em> صحبت خواهیم کرد. ما فرض خواهیم کرد که تمام مشکلات فصل 8 می‌توانند رخ دهند: <em>packets</em> می‌توانند از بین بروند، reordered شوند، تکراری شوند، یا به طور دلخواه در شبکه به تأخیر بیفتند. ساعت‌ها در بهترین حالت تقریبی هستند. و nodes ها می‌توانند متوقف شوند (به عنوان مثال، به دلیل <em>garbage collection</em>) یا در هر زمانی <em>crash</em> کنند.
    </p>
<p>
        بهترین راه برای ساختن <em>fault-tolerant systems</em>، یافتن برخی از <em>general-purpose abstractions</em> ها با <em>useful guarantees</em> ها، پیاده‌سازی آنها یک‌بار است، و سپس به application ها اجازه دهیم که به آن <em>guarantees</em> تکیه کنند. این همان رویکردی است که ما در فصل 7 با <strong>Transactions</strong> استفاده کردیم: با استفاده از یک <strong>Transaction</strong>، application می‌تواند وانمود کند که هیچ <em>crashes</em> (atomicity) وجود ندارد، که هیچ‌کس دیگری به طور همزمان به database دسترسی ندارد (<em>isola‐tion</em>)، و اینکه دستگاه‌های ذخیره‌سازی کاملاً قابل اعتماد هستند (<em>durability</em>). حتی اگر <em>crashes, race conditions</em>، و <em>disk failures</em> رخ دهند، <em>transaction abstraction</em>، این مشکلات را پنهان می‌کند تا application نیازی به نگرانی در مورد آنها نداشته باشد.
    </p>
<p>
        ما اکنون در امتداد همان مسیر ادامه خواهیم داد، و به دنبال <em>abstractions</em> هایی هستیم که می‌توانند به یک application اجازه دهند تا برخی از مشکلات موجود در <em>distributed systems</em> را نادیده بگیرد. به عنوان مثال، یکی از مهم‌ترین <em>abstractions</em> ها برای <em>distributed systems</em>، <em>consensus</em> است: یعنی، وادار کردن تمام nodes ها برای توافق بر سر چیزی. همانطور که در این فصل خواهیم دید، به طور قابل اعتماد
        <br/>
        321
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0343</div>
            </div>
        </div>
        <!-- Page 0344 -->
        <div class="chapter" id="page-0344">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
<em>reaching consensus</em>، علیرغم <em>network faults</em> و <em>process failures</em>، یک مشکل به طرز شگفت‌آوری دشوار است.
    </p>
<p>
        هنگامی که شما یک پیاده‌سازی از <em>consensus</em> دارید، applications ها می‌توانند از آن برای اهداف مختلف استفاده کنند. به عنوان مثال، فرض کنید شما یک database با <em>single-leader replication</em> دارید. اگر leader از بین برود و شما نیاز به <em>fail over</em> به یک node دیگر داشته باشید، nodes های database باقی‌مانده می‌توانند از <em>consensus</em> برای انتخاب یک leader جدید استفاده کنند. همانطور که در "Handling Node Outages" در صفحه 156 مورد بحث قرار گرفت، مهم است که فقط یک leader وجود داشته باشد، و اینکه تمام nodes ها بر سر اینکه leader کیست، توافق داشته باشند. اگر دو node هر دو معتقد باشند که آنها leader هستند، این وضعیت <em>split brain</em> نامیده می‌شود، و اغلب منجر به <em>data loss</em> می‌شود. پیاده‌سازی‌های correct از <em>consensus</em> به جلوگیری از چنین مشکلاتی کمک می‌کنند.
    </p>
<p>
        در ادامه این فصل، در "Distributed Transactions and Consensus" در صفحه 352، ما به الگوریتم‌هایی برای حل <em>consensus</em> و مشکلات مرتبط با آن نگاه خواهیم کرد. اما ابتدا ما نیاز داریم که دامنه <em>guarantees</em> و <em>abstractions</em> را که می‌توان در یک <em>distributed system</em> ارائه کرد، بررسی کنیم.
    </p>
<p>
        ما باید scope آنچه را که می‌توان و نمی‌توان انجام داد، درک کنیم: در برخی از <em>situa‐tions</em>، این امکان وجود دارد که system <em>faults</em> را تحمل کند و به کار خود ادامه دهد. در سایر <em>situa‐tions</em>، این امکان‌پذیر نیست. محدودیت‌های آنچه که ممکن است و ممکن نیست، هم در <em>theoretical proofs</em> و هم در پیاده‌سازی‌های عملی، به تفصیل بررسی شده‌اند. ما در این فصل یک مرور کلی از آن محدودیت‌های اساسی خواهیم داشت.
    </p>
<p>
        محققان در زمینه <em>distributed systems</em> دهه‌هاست که این موضوعات را مطالعه می‌کنند، بنابراین مطالب زیادی وجود دارد—ما فقط می‌توانیم سطح را خراش دهیم. در این کتاب ما فضای کافی برای پرداختن به جزئیات مدل‌ها و اثبات‌های رسمی نداریم، بنابراین ما به شهودهای غیررسمی می‌چسبیم. ارجاعات ادبیات، عمق زیادی را در صورت تمایل شما ارائه می‌دهند.
    </p>
<h4>Consistency Guarantees</h4>
<p>
        در "Problems with Replication Lag" در صفحه 161 ما به برخی از مسائل زمان‌بندی که در یک replicated database رخ می‌دهد، نگاه کردیم. اگر شما به دو node database در همان لحظه نگاه کنید، احتمالاً داده‌های متفاوتی را در دو node خواهید دید، زیرا درخواست‌های <em>write</em> در زمان‌های مختلف به nodes های مختلف می‌رسند. این <em>inconsistencies</em> ها بدون توجه به اینکه database از چه متدی از <em>replication</em> استفاده می‌کند (<em>single-leader, multi-leader, or leaderless replication</em>) رخ می‌دهند.
    </p>
<p>
        اکثر databases های replicated حداقل <em>eventual consistency</em> را ارائه می‌دهند، که به این معنی است که اگر شما نوشتن به database را متوقف کنید و برای مدتی نامشخص منتظر بمانید، در نهایت تمام درخواست‌های <em>read</em> مقدار یکسانی را برمی‌گردانند [1]. به عبارت دیگر، <em>inconsistency</em> موقتی است، و در نهایت خود به خود حل می‌شود (با فرض اینکه هر گونه <em>faults</em> در شبکه نیز در نهایت تعمیر شوند). یک نام بهتر برای <em>eventual consistency</em> ممکن است <em>convergence</em> باشد، زیرا ما انتظار داریم که تمام <em>replicas</em> در نهایت به یک value یکسان همگرا شوند [2].
        <br/>
        322
        <br/>
        |
        <br/>
        Chapter 9: Consistency and Consensus
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0344</div>
            </div>
        </div>
        <!-- Page 0345 -->
        <div class="chapter" id="page-0345">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        با این حال، این یک <em>guarantee</em> بسیار ضعیف است—این در مورد زمان همگرایی <em>repli‐cas</em> چیزی نمی‌گوید. تا زمان <em>convergence</em>، <em>reads</em> می‌توانند هر چیزی یا هیچ‌چیز را برگردانند [1]. به عنوان مثال، اگر شما یک value را <em>write</em> کنید و سپس فوراً آن را دوباره بخوانید، هیچ تضمینی وجود ندارد که value را که تازه <em>wrote</em> کرده‌اید، ببینید، زیرا <em>read</em> ممکن است به یک <em>replica</em> متفاوت هدایت شود (به "Reading Your Own Writes" در صفحه 162 مراجعه کنید).
    </p>
<p>
<em>Eventual consistency</em> برای توسعه‌دهندگان application دشوار است زیرا با رفتار <em>variables</em> ها در یک برنامه <em>single-threaded</em> عادی بسیار متفاوت است. اگر شما یک value را به یک متغیر اختصاص دهید و سپس بلافاصله بعد از آن آن را بخوانید، انتظار ندارید که value قدیمی را دوباره بخوانید، یا اینکه <em>read</em> با شکست مواجه شود. یک database ظاهراً شبیه یک متغیر است که شما می‌توانید آن را بخوانید و به آن <em>write</em> کنید، اما در واقع معناشناسی بسیار پیچیده‌تری دارد [3].
    </p>
<p>
        هنگام کار با یک database که فقط <em>weak guarantees</em> ارائه می‌دهد، شما باید دائماً از محدودیت‌های آن آگاه باشید و به طور تصادفی بیش از حد فرض نکنید. باگ‌ها اغلب ظریف هستند و یافتن آنها با آزمایش دشوار است، زیرا application ممکن است در بیشتر مواقع خوب کار کند. <em>Edge cases</em> از <em>eventual consistency</em> فقط زمانی آشکار می‌شوند که یک <em>fault</em> در system (به عنوان مثال، یک <em>network interruption</em>) یا <em>high concurrency</em> وجود داشته باشد.
    </p>
<p>
        در این فصل ما مدل‌های <em>stronger consistency</em> را که system های داده ممکن است انتخاب کنند تا ارائه دهند، بررسی خواهیم کرد. آنها رایگان نمی‌آیند: system هایی با <em>stronger guarantees</em> ممکن است performance بدتری داشته باشند یا کمتر <em>fault-tolerant</em> از system هایی با <em>weaker guaran‐tees</em> باشند. با این وجود، <em>stronger guarantees</em> می‌توانند جذاب باشند زیرا استفاده صحیح از آنها آسان‌تر است. هنگامی که شما چند مدل <em>consistency</em> مختلف را دیدید، در موقعیت بهتری قرار خواهید گرفت تا تصمیم بگیرید که کدام یک بهترین نیازهای شما را برآورده می‌کند.
    </p>
<p>
        برخی شباهت‌ها بین مدل‌های <em>distributed consistency</em> و سلسله مراتب <em>transaction isolation levels</em> وجود دارد که ما قبلاً مورد بحث قرار دادیم [4, 5] (به "Weak Isolation Lev‐els" در صفحه 233 مراجعه کنید). اما در حالی که همپوشانی وجود دارد، آنها بیشتر نگرانی‌های مستقل هستند: <em>transaction isolation</em> در درجه اول در مورد جلوگیری از <em>race conditions</em> به دلیل <em>concurrently executing transactions</em> است، در حالی که <em>distributed consistency</em> بیشتر در مورد هماهنگی وضعیت <em>replicas</em> در مواجهه با تأخیرها و <em>faults</em> است.
    </p>
<p>
        این فصل طیف وسیعی از موضوعات را پوشش می‌دهد، اما همانطور که خواهیم دید، این حوزه‌ها در واقع عمیقاً به هم مرتبط هستند:
    </p>
<ul>
<li>
            ما با نگاهی به یکی از قوی‌ترین مدل‌های <em>consistency</em> که در حال حاضر استفاده می‌شود، linearizability، شروع خواهیم کرد و مزایا و معایب آن را بررسی خواهیم کرد.
        </li>
<li>
            سپس ما مسئله مرتب‌سازی رویدادها در یک <em>distributed system</em> را بررسی خواهیم کرد ("Ordering Guarantees" در صفحه 339)، به ویژه در مورد <em>causality</em> و <em>total ordering</em>.
        </li>
<li>
            در بخش سوم ("Distributed Transactions and Consensus" در صفحه 352) ما بررسی خواهیم کرد که چگونه یک <em>distributed transaction</em> را به صورت <em>atomically commit</em> کنیم، که در نهایت ما را به سمت راه‌حل‌هایی برای مشکل <em>consensus</em> هدایت می‌کند.
            <br/>
            Consistency Guarantees
            <br/>
            |
            <br/>
            323
        </li>
</ul>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0345</div>
            </div>
        </div>
        <!-- Page 0346 -->
        <div class="chapter" id="page-0346">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<h4>Linearizability</h4>
<p>
        در یک database <em>eventually consistent</em>، اگر شما از دو <em>replicas</em> مختلف یک سوال یکسان را در یک زمان یکسان بپرسید، ممکن است دو پاسخ متفاوت دریافت کنید. این گیج‌کننده است. آیا خیلی ساده‌تر نبود اگر database می‌توانست این توهم را ایجاد کند که فقط یک <em>replica</em> وجود دارد (یعنی، فقط یک کپی از داده‌ها)؟ سپس هر client دیدگاه یکسانی از داده‌ها را خواهد داشت، و شما نیازی به نگرانی در مورد <em>replication lag</em> نخواهید داشت.
    </p>
<p>
        این ایده پشت <em>linearizability</em> [6] است (همچنین به عنوان <em>atomic consistency</em> [7]، <em>strong consistency, immediate consistency</em>، یا <em>external consistency</em> [8] شناخته می‌شود). تعریف دقیق <em>linearizability</em>، کاملاً ظریف است، و ما آن را در بقیه این بخش بررسی خواهیم کرد. اما ایده اساسی این است که یک system را طوری جلوه دهیم که گویی فقط یک کپی از داده‌ها وجود دارد، و تمام عملیات روی آن <em>atomic</em> هستند. با این <em>guarantee</em>، حتی اگر در واقعیت چندین <em>replica</em> وجود داشته باشد، application نیازی به نگرانی در مورد آنها ندارد.
    </p>
<p>
        در یک system <em>linearizable</em>، به محض اینکه یک client، یک <em>write</em> را با موفقیت تکمیل کرد، تمام clients ها که از database می‌خوانند، باید قادر به دیدن value که تازه نوشته شده است، باشند. حفظ توهم یک کپی واحد از داده‌ها به معنای تضمین این است که value خوانده شده، جدیدترین و به‌روزترین value است، و از یک cache یا <em>replica stale</em> نمی‌آید. به عبارت دیگر، <em>linearizability</em> یک <em>recency guarantee</em> است. برای روشن شدن این ایده، بیایید به یک مثال از یک system که <em>linearizable</em> نیست، نگاهی بیندازیم.
    </p>
<figure>
<img alt="Figure 9-1. This system is not linearizable, causing football fans to be confused." src="figure9-1.png"/>
<figcaption>Figure 9-1. This system is not linearizable, causing football fans to be confused.</figcaption>
</figure>
<p>
        این system <em>linearizable</em> نیست، و باعث می‌شود طرفداران فوتبال گیج شوند.
        <br/>
        324
        <br/>
        |
        <br/>
        Chapter 9: Consistency and Consensus
    </p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 346" src="page_0346/image_1.png"/></div>
</div>
                <div class="page-number">صفحه 0346</div>
            </div>
        </div>
        <!-- Page 0347 -->
        <div class="chapter" id="page-0347">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        شکل 9-1 مثالی از یک وب‌سایت ورزشی <em>nonlinearizable</em> را نشان می‌دهد [9]. آلیس و باب در یک اتاق نشسته‌اند، و هر دو در حال بررسی تلفن‌های خود هستند تا نتیجه فینال جام جهانی 2014 فیفا را ببینند. درست پس از اعلام نتیجه نهایی، آلیس صفحه را رفرش می‌کند، اعلام برنده را می‌بیند، و با هیجان در مورد آن به باب می‌گوید. باب با بی‌اعتمادی روی تلفن خود دکمه reload را می‌زند، اما درخواست او به یک <em>database replica</em> می‌رود که در حال <em>lagging</em> است، و بنابراین تلفن او نشان می‌دهد که بازی هنوز در حال انجام است.
    </p>
<p>
        اگر آلیس و باب همزمان دکمه <em>reload</em> را زده بودند، اگر نتایج query متفاوتی را دریافت می‌کردند، کمتر تعجب‌آور بود، زیرا آنها نمی‌دانستند که دقیقاً درخواست‌های مربوطه آنها توسط سرور در چه زمانی پردازش شده است. با این حال، باب می‌داند که او پس از شنیدن فریاد آلیس در مورد نتیجه نهایی، دکمه <em>reload</em> (<em>initiated</em> query خود را) را فشار داد، و بنابراین او انتظار دارد که نتیجه <em>query</em> او حداقل به اندازه آلیس اخیر باشد. این واقعیت که <em>query</em> او یک نتیجه <em>stale</em> را برگرداند، یک تخلف از <em>linearizability</em> است.
    </p>
<h4>What Makes a System Linearizable?</h4>
<p>
        ایده اصلی پشت <em>linearizability</em> ساده است: ایجاد یک system که گویی فقط یک کپی از داده‌ها وجود دارد. با این حال، تعریف دقیقاً اینکه این به چه معناست، در واقع نیاز به مراقبت دارد. برای درک بهتر <em>linearizability</em>، بیایید به چند مثال دیگر نگاهی بیندازیم.
    </p>
<p>
        شکل 9-2 سه client را نشان می‌دهد که همزمان در حال خواندن و نوشتن کلید x در یک database <em>linearizable</em> هستند. در <em>distributed systems literature</em>، x یک <em>register</em> نامیده می‌شود—در عمل، می‌تواند یک کلید در یک <em>key-value store</em>، یک <em>row</em> در یک <em>relational database</em>، یا یک document در یک <em>document database</em>، به عنوان مثال، باشد.
    </p>
<figure>
<img alt="Figure 9-2. If a read request is concurrent with a write request, it may return either the old or the new value." src="figure9-2.png"/>
<figcaption>Figure 9-2. If a read request is concurrent with a write request, it may return either the old or the new value.</figcaption>
</figure>
<p>
        برای سادگی، شکل 9-2 فقط درخواست‌ها را از دیدگاه clients نشان می‌دهد، نه <em>internals</em> از database. هر نوار یک درخواست است که توسط یک client ایجاد شده است، که در آن شروع یک نوار، زمانی است که درخواست ارسال شده است، و انتهای یک نوار زمانی است که پاسخ توسط client دریافت شده است. به دلیل تأخیرهای شبکه متغیر، یک client نمی‌داند
        <br/>
        Linearizability
        <br/>
        |
        <br/>
        325
    </p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 347" src="page_0347/image_1.png"/></div>
</div>
                <div class="page-number">صفحه 0347</div>
            </div>
        </div>
        <!-- Page 0348 -->
        <div class="chapter" id="page-0348">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        i. یک جزئیات ظریف از این نمودار این است که وجود یک ساعت global را فرض می‌کند، که توسط محور افقی نشان داده شده است. حتی اگر سیستم‌های واقعی ساعت‌های دقیقی نداشته باشند (به "Unreliable Clocks" در صفحه 287 مراجعه کنید)، این فرض اشکالی ندارد: برای اهداف تجزیه و تحلیل یک <em>distributed algorithm</em>، ما ممکن است تظاهر کنیم که یک ساعت <em>accurate global</em> وجود دارد، تا زمانی که الگوریتم به آن دسترسی نداشته باشد [47]. در عوض، الگوریتم فقط می‌تواند یک تقریب درهم و برهم از زمان واقعی را ببیند، که توسط یک <em>quartz oscillator</em> و NTP تولید می‌شود.
    </p>
<p>
        ii. A <em>register</em> که در آن <em>reads</em> ممکن است در صورت همزمان بودن با یک <em>write</em>،value قدیمی یا جدید را برگرداند، به عنوان a <em>regular register</em> [7, 25] شناخته می‌شود.
    </p>
<p>
        دقیقاً در چه زمانی database درخواست آن را پردازش کرد—فقط می‌داند که باید در زمانی بین ارسال درخواست client و دریافت پاسخ اتفاق افتاده باشد.
    </p>
<p>
        در این مثال، <em>register</em> دارای دو نوع operation است:
    </p>
<ul>
<li>
            read(x) ⇒ v به این معنی است که client درخواست خواندن value از <em>register</em> x را داد، و database value v را برگرداند.
        </li>
<li>
            write(x, v) ⇒ r به این معنی است که client درخواست کرد که <em>register</em> x را روی value v تنظیم کند، و database پاسخ r را برگرداند (که می‌تواند ok یا <em>error</em> باشد).
        </li>
</ul>
<p>
        در شکل 9-2، value از x در ابتدا 0 است، و client C یک درخواست <em>write</em> را برای تنظیم آن روی 1 انجام می‌دهد. در حالی که این اتفاق در حال رخ دادن است، clients های A و B به طور مکرر در حال <em>polling</em> database برای خواندن آخرین value هستند. پاسخ‌های ممکن که A و B ممکن است برای درخواست‌های <em>read</em> خود دریافت کنند، چیست؟
    </p>
<ul>
<li>
            اولین operation <em>read</em> توسط client A قبل از شروع <em>write</em> تکمیل می‌شود، بنابراین قطعاً باید value قدیمی 0 را برگرداند.
        </li>
<li>
            آخرین <em>read</em> توسط client A پس از تکمیل <em>write</em> شروع شد، بنابراین باید قطعاً value جدید 1 را برگرداند اگر database <em>linearizable</em> باشد: ما می‌دانیم که <em>write</em> باید در زمانی بین شروع و پایان operation <em>write</em>، پردازش شده باشد، و <em>read</em> باید در زمانی بین شروع و پایان operation <em>read</em> پردازش شده باشد. اگر <em>read</em> بعد از پایان <em>write</em> شروع شد، در این صورت <em>read</em> باید بعد از <em>write</em> پردازش شده باشد، و بنابراین باید value جدیدی را که نوشته شده است، ببیند.
        </li>
<li>
            هر operation <em>read</em> که با operation <em>write</em> در زمان همپوشانی دارد، ممکن است 0 یا 1 را برگرداند، زیرا ما نمی‌دانیم که آیا <em>write</em> در زمان پردازش operation <em>read</em>، تأثیر داشته است یا خیر. این operations ها با <em>write</em> همزمان هستند.
        </li>
</ul>
<p>
        با این حال، این هنوز برای توصیف کامل <em>linearizability</em> کافی نیست: اگر <em>reads</em> که با یک <em>write</em> همزمان هستند، می‌توانند value قدیمی یا جدید را برگردانند، پس خوانندگان می‌توانند ببینند که یک value چندین بار بین value قدیمی و جدید در حالی که یک <em>write</em> در حال انجام است، بین آن دو نوسان می‌کند. این چیزی نیست که ما از یک system که یک "single copy of the data" را شبیه‌سازی می‌کند، انتظار داریم.ii
        <br/>
        326
        <br/>
        |
        <br/>
        Chapter 9: Consistency and Consensus
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0348</div>
            </div>
        </div>
        <!-- Page 0349 -->
        <div class="chapter" id="page-0349">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        برای <em>linearizable</em> کردن system، ما نیاز داریم که یک <em>constraint</em> دیگر را اضافه کنیم، که در شکل 9-3 نشان داده شده است.
    </p>
<figure>
<img alt="Figure 9-3. After any one read has returned the new value, all following reads (on the same or other clients) must also return the new value." src="figure9-3.png"/>
<figcaption>Figure 9-3. After any one read has returned the new value, all following reads (on the same or other clients) must also return the new value.</figcaption>
</figure>
<p>
        در یک system <em>linearizable</em> ما تصور می‌کنیم که باید نقطه‌ای در زمان (بین شروع و پایان operation <em>write</em>) وجود داشته باشد که در آن value از x به صورت <em>atomically</em> از 0 به 1 <em>flips</em> شود. بنابراین، اگر <em>read</em> یک client value جدید 1 را برگرداند، تمام <em>reads</em> های بعدی باید value جدید را نیز برگردانند، حتی اگر operation <em>write</em> هنوز تکمیل نشده باشد.
    </p>
<p>
        این وابستگی زمان‌بندی با یک فلش در شکل 9-3 نشان داده شده است. Client A اولین کسی است که value جدید 1 را می‌خواند. درست بعد از اینکه <em>read</em> A برمی‌گردد، B یک <em>read</em> جدید را شروع می‌کند. از آنجایی که <em>read</em> B دقیقاً بعد از <em>read</em> A رخ می‌دهد، باید 1 را نیز برگرداند، حتی اگر <em>write</em> توسط C همچنان در حال انجام باشد. (این همان وضعیت آلیس و باب در شکل 9-1 است: بعد از اینکه آلیس value جدید را خواند، باب نیز انتظار دارد که value جدید را بخواند.)
    </p>
<p>
        ما می‌توانیم این نمودار زمان‌بندی را بیشتر اصلاح کنیم تا هر operation به صورت <em>atomically</em> در یک نقطه زمانی، تأثیر بگذارد. یک مثال پیچیده‌تر در شکل 9-4 نشان داده شده است [10].
    </p>
<p>
        در شکل 9-4 ما یک نوع سوم از operation را علاوه بر <em>read</em> و <em>write</em> اضافه می‌کنیم:
    </p>
<ul>
<li>
            cas(x, vold, vnew) ⇒ r به این معنی است که client یک operation <em>atomic compare-and-set</em> را درخواست کرد (به "Compare-and-set" در صفحه 245 مراجعه کنید). اگر value فعلی از <em>register</em> x با vold برابر باشد، باید به صورت <em>atomically</em> به vnew تنظیم شود. اگر x ≠ vold باشد، سپس operation باید <em>register</em> را بدون تغییر بگذارد و یک <em>error</em> را برگرداند. r پاسخ database است (ok یا <em>error</em>).
        </li>
</ul>
<p>
        هر operation در شکل 9-4 با یک خط عمودی (در داخل نوار برای هر operation) در زمانی که ما فکر می‌کنیم operation اجرا شده است، علامت‌گذاری شده است. آن نشانگرها به ترتیب متوالی متصل می‌شوند، و نتیجه باید یک sequence معتبر از <em>reads</em> و <em>writes</em> برای یک <em>register</em> باشد (هر <em>read</em> باید value تنظیم شده توسط جدیدترین <em>write</em> را برگرداند).
    </p>
<p>
        requirement از <em>linearizability</em> این است که خطوطی که نشانگرهای operation را به هم متصل می‌کنند، همیشه در زمان به سمت جلو حرکت می‌کنند (از چپ به راست)، هرگز به عقب. این requirement
        <br/>
        Linearizability
        <br/>
        |
        <br/>
        327
    </p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 349" src="page_0349/image_1.png"/></div>
</div>
                <div class="page-number">صفحه 0349</div>
            </div>
        </div>
        <!-- Page 0350 -->
        <div class="chapter" id="page-0350">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
<em>ensures the recency guarantee</em> که ما قبلاً در مورد آن بحث کردیم: هنگامی که یک value جدید <em>written</em> یا خوانده شده است، تمام <em>reads</em> های بعدی value ای را که نوشته شده است می‌بینند، تا زمانی که دوباره بازنویسی شود.
    </p>
<figure>
<img alt="Figure 9-4. Visualizing the points in time at which the reads and writes appear to have taken effect. The final read by B is not linearizable." src="figure9-4.png"/>
<figcaption>Figure 9-4. Visualizing the points in time at which the reads and writes appear to have taken effect. The final read by B is not linearizable.</figcaption>
</figure>
<p>
        چندین جزئیات جالب وجود دارد که باید در شکل 9-4 به آنها اشاره کنیم:
    </p>
<ul>
<li>
            اول، client B یک درخواست برای خواندن x ارسال کرد، سپس client D یک درخواست برای تنظیم x روی 0 ارسال کرد، و سپس client A یک درخواست برای تنظیم x روی 1 ارسال کرد. با این وجود، value بازگردانده شده به <em>read</em> از B، 1 است (value نوشته شده توسط A). این اشکالی ندارد: به این معنی است که database ابتدا <em>write</em> D را پردازش کرد، سپس <em>write</em> A را، و در نهایت <em>read</em> B را. اگرچه این ترتیبی نیست که درخواست‌ها ارسال شده‌اند، اما یک ترتیب قابل قبول است، زیرا سه درخواست همزمان هستند. شاید درخواست <em>read</em> B کمی در شبکه تأخیر داشته باشد، بنابراین فقط پس از دو <em>writes</em> به database رسید.
        </li>
<li>
<em>read</em> از client B، 1 را قبل از اینکه client A پاسخ خود را از database دریافت کند، برگرداند، که نشان می‌دهد که <em>write</em> از value 1 موفقیت‌آمیز بود. این نیز اشکالی ندارد: به این معنی نیست که value قبل از نوشته شدن خوانده شده است، فقط به این معنی است که پاسخ ok از database به client A، کمی در شبکه تأخیر داشته است.
        </li>
<li>
            این مدل هیچ <em>transaction isolation</em> را فرض نمی‌کند: یک client دیگر ممکن است در هر زمانی یک value را تغییر دهد. به عنوان مثال، C ابتدا 1 را می‌خواند و سپس 2 را می‌خواند، زیرا value بین دو <em>reads</em> توسط B تغییر یافته است. یک operation <em>atomic compare-and-set (cas)</em> می‌تواند برای بررسی اینکه آیا value به طور همزمان توسط client دیگری تغییر نکرده است استفاده شود: درخواست‌های cas از B و C موفق می‌شوند، اما درخواست <em>cas</em> از D شکست می‌خورد (تا زمانی که database آن را پردازش کند، value از x دیگر 0 نیست).
        </li>
<li>
            آخرین <em>read</em> توسط client B (در یک نوار <em>shaded</em>) <em>linearizable</em> نیست. Operation با <em>cas write</em> از C همزمان است، که x را از 2 به 4 به‌روزرسانی می‌کند. در غیاب
            <br/>
            328
            <br/>
            |
            <br/>
            Chapter 9: Consistency and Consensus
        </li>
</ul>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 350" src="page_0350/image_1.png"/></div>
</div>
                <div class="page-number">صفحه 0350</div>
            </div>
        </div>
        <!-- Page 0351 -->
        <div class="chapter" id="page-0351">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        در <em>other requests</em>، برای <em>read</em> B، مشکلی نداشت که 2 را برگرداند. با این حال، client A قبلاً value جدید 4 را قبل از شروع <em>read</em> B خوانده است، بنابراین B مجاز نیست که یک value قدیمی‌تر از A را بخواند. دوباره، این همان وضعیت آلیس و باب در شکل 9-1 است.
    </p>
<p>
        این شهود پشت <em>linearizability</em> است. تعریف رسمی [6] آن را دقیق‌تر توضیح می‌دهد. امکان‌پذیر است (اگرچه از نظر محاسباتی پرهزینه است) که آزمایش کنیم آیا رفتار system <em>linearizable</em> است یا خیر، با ثبت زمان‌بندی تمام درخواست‌ها و پاسخ‌ها، و بررسی اینکه آیا می‌توان آنها را به یک <em>sequential order</em> معتبر مرتب کرد [11].
    </p>
<h4>Linearizability Versus Serializability</h4>
<p>
<em>Linearizability</em> به راحتی با <em>serializability</em> اشتباه گرفته می‌شود (به "Serializability" در صفحه 251 مراجعه کنید)، زیرا به نظر می‌رسد هر دو کلمه به معنای چیزی شبیه به "می‌توانند به ترتیب متوالی مرتب شوند" هستند.
        <br/>
        با این حال، آنها دو <em>guarantees</em> کاملاً متفاوت هستند، و تمایز بین آنها مهم است:
    </p>
<ul>
<li>
            Serializability
            <br/>
<em>Serializability</em> یک <em>isolation property</em> از <strong>Transactions</strong> است، که در آن هر <strong>Transaction</strong> ممکن است چندین object (rows, documents, records) را بخواند و به آنها <em>write</em> کند—به "Single-Object and Multi-Object Operations" در صفحه 228 مراجعه کنید. این تضمین می‌کند که <strong>Transactions</strong> ها به همان صورت عمل می‌کنند که گویی در برخی از <em>serial order</em> اجرا شده‌اند (هر <strong>Transaction</strong> قبل از شروع <strong>Transaction</strong> بعدی به پایان می‌رسد). این خوب است که آن <em>serial order</em> با ترتیبی که <strong>Transactions</strong> واقعاً اجرا شده‌اند متفاوت باشد [12].
        </li>
<li>
            Linearizability
            <br/>
<em>Linearizability</em> یک <em>recency guarantee</em> در <em>reads</em> و <em>writes</em> از یک <em>register</em> (یک object فردی) است. عملیات را با هم در <strong>Transactions</strong> گروه‌بندی نمی‌کند، بنابراین از مشکلاتی مانند <em>write skew</em> (به "Write Skew and Phantoms" در صفحه 246 مراجعه کنید) جلوگیری نمی‌کند، مگر اینکه شما اقدامات اضافی مانند <em>materializing conflicts</em> را انجام دهید (به "Materializing conflicts" در صفحه 251 مراجعه کنید).
        </li>
</ul>
<p>
        یک database ممکن است هم <em>serializability</em> و هم <em>linearizability</em> را ارائه دهد، و این ترکیب، <em>strict serializability</em> یا <em>strong one-copy serializability (strong-1SR)</em> [4, 13] نامیده می‌شود.
    </p>
<p>
        پیاده‌سازی‌های <em>serializability</em> مبتنی بر <em>two-phase locking</em> (به "Two-Phase Lock‐ing (2PL)" در صفحه 257 مراجعه کنید) یا اجرای سریال واقعی (به "Actual Serial Execution" در صفحه 252 مراجعه کنید) معمولاً <em>linearizable</em> هستند.
    </p>
<p>
        با این حال، <em>serializable snapshot isolation (SSI)</em> (به "Serializable Snapshot Isolation (SSI)" در صفحه 261 مراجعه کنید) <em>linearizable</em> نیست: طبق طراحی، این <em>reads</em> را از یک <em>consistent snapshot</em> انجام می‌دهد، تا از <em>lock contention</em> بین خوانندگان و <em>writers</em> جلوگیری کند. کل نکته یک <em>consistent snapshot</em> این است که شامل <em>writes</em> هایی که اخیرتر از <em>snapshot</em> هستند نمی‌شود، و بنابراین <em>reads</em> از <em>snapshot</em> ها <em>linearizable</em> نیستند.
        <br/>
        Linearizability
        <br/>
        |
        <br/>
        329
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0351</div>
            </div>
        </div>
        <!-- Page 0352 -->
        <div class="chapter" id="page-0352">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        iii. به طور دقیق، ZooKeeper و etcd <em>linearizable writes</em> را ارائه می‌دهند، اما <em>reads</em> ها ممکن است <em>stale</em> باشند، زیرا به طور پیش‌فرض می‌توانند توسط هر یک از <em>replicas</em> ها ارائه شوند. شما به‌طور اختیاری می‌توانید یک <em>linearizable read</em> را درخواست کنید: etcd این را یک <em>quorum read</em> [16] می‌نامد، و در ZooKeeper شما نیاز دارید که قبل از <em>read</em>، <em>sync()</em> را فراخوانی کنید [15]؛ به "Implementing linearizable storage using total order broadcast" در صفحه 350 مراجعه کنید.
    </p>
<h4>Relying on Linearizability</h4>
<p>
        در چه شرایطی <em>linearizability</em> مفید است؟ مشاهده نتیجه نهایی یک مسابقه ورزشی شاید یک مثال بی‌اهمیت باشد: بعید است که یک نتیجه که چند ثانیه قدیمی شده است، در این شرایط باعث آسیب واقعی شود. با این حال، در چند مورد، <em>linearizability</em> یک requirement مهم برای عملکرد صحیح system است.
    </p>
<ul>
<li>
            Locking and leader election
            <br/>
            یک system که از <em>single-leader replication</em> استفاده می‌کند، نیاز دارد اطمینان حاصل کند که واقعاً فقط یک leader وجود دارد، نه چندین (<em>split brain</em>). یک راه برای انتخاب یک leader استفاده از یک <em>lock</em> است: هر node که راه‌اندازی می‌شود، سعی می‌کند <em>lock</em> را به دست آورد، و node ای که موفق می‌شود، leader می‌شود [14]. مهم نیست که این <em>lock</em> چگونه پیاده‌سازی می‌شود، باید <em>linearizable</em> باشد: تمام nodes ها باید موافقت کنند که چه node ای صاحب <em>lock</em> است. در غیر این صورت، بی‌فایده است.
        </li>
<li>
            Coordination services مانند Apache ZooKeeper [15] و etcd [16] اغلب برای پیاده‌سازی <em>distributed locks</em> و <em>leader election</em> استفاده می‌شوند. آنها از الگوریتم‌های <em>consensus</em> برای پیاده‌سازی operations <em>linearizable</em> به روشی <em>fault-tolerant</em> استفاده می‌کنند (ما در مورد چنین الگوریتم‌هایی در ادامه این فصل، در "Fault-Tolerant Consensus" در صفحه 364 بحث می‌کنیم).iii هنوز هم جزئیات ظریف زیادی برای پیاده‌سازی صحیح <em>locks</em> و <em>leader election</em> وجود دارد (به عنوان مثال، مسئله <em>fencing</em> در "The leader and the lock" در صفحه 301 مراجعه کنید)، و کتابخانه‌هایی مانند Apache Curator [17] با ارائه دستورالعمل‌های سطح بالاتر در بالای ZooKeeper کمک می‌کنند.
        </li>
</ul>
<p>
        با این حال، یک <em>linearizable storage service</em>، پایه اساسی برای این <em>coordination tasks</em> است.
    </p>
<p>
<em>Distributed locking</em> در برخی از databases های <em>distributed</em>، مانند Oracle Real Application Clusters (RAC) [18]، در سطح بسیار granularتر نیز استفاده می‌شود. RAC از یک <em>lock per disk page</em>، با چندین node که دسترسی به system ذخیره‌سازی دیسک یکسان را به اشتراک می‌گذارند، استفاده می‌کند. از آنجایی که این <em>linearizable locks</em> در مسیر بحرانی اجرای <strong>Transaction</strong> هستند، <em>RAC deployments</em> معمولاً یک شبکه <em>cluster interconnect</em> اختصاصی برای ارتباط بین nodes های database دارند.
    </p>
<li>
        Constraints and uniqueness guarantees
        <br/>
<em>Uniqueness constraints</em> در databases ها رایج هستند: به عنوان مثال، یک username یا آدرس ایمیل باید به طور <em>unique</em> یک user را شناسایی کند، و در یک <em>file storage service</em>، نمی‌تواند دو فایل با مسیر و نام فایل یکسان وجود داشته باشد. اگر شما می‌خواهید این <em>constraint</em> را در حین <em>written</em> شدن داده‌ها اجرا کنید (به طوری که اگر دو نفر همزمان سعی کنند یک user یا یک فایل را با همان نام ایجاد کنند، یکی از آنها یک <em>error</em> را برمی‌گرداند)، شما نیاز به <em>linearizability</em> دارید.
    </li>
<p>
        330
        <br/>
        |
        <br/>
        Chapter 9: Consistency and Consensus
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0352</div>
            </div>
        </div>
        <!-- Page 0353 -->
        <div class="chapter" id="page-0353">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        این وضعیت در واقع شبیه به یک <em>lock</em> است: هنگامی که یک user در service شما ثبت‌نام می‌کند، شما می‌توانید تصور کنید که آنها یک "<em>lock</em>" بر روی username انتخاب‌شده خود به دست می‌آورند. این عملیات نیز بسیار شبیه به یک <em>atomic compare-and-set</em> است، که username را به ID از user که آن را claim کرده است، تنظیم می‌کند، به شرطی که username قبلاً گرفته نشده باشد.
    </p>
<p>
        مشکلات مشابهی در صورتی ایجاد می‌شود که شما می‌خواهید اطمینان حاصل کنید که موجودی حساب بانکی هرگز منفی نمی‌شود، یا اینکه شما بیشتر از آنچه در انبار دارید، کالا نفروشید، یا اینکه دو نفر به طور همزمان صندلی یکسانی را در یک پرواز یا تئاتر رزرو نکنند.
    </p>
<p>
        این <em>constraints</em> ها همگی مستلزم این هستند که یک <em>single up-to-date value</em> وجود داشته باشد (موجودی حساب، سطح سهام، اشغال صندلی) که تمام nodes ها بر سر آن توافق داشته باشند.
    </p>
<p>
        در applications های واقعی، گاهی اوقات قابل قبول است که با چنین <em>constraints</em> هایی به طور سست رفتار کنیم (به عنوان مثال، اگر یک پرواز <em>overbooked</em> باشد، شما می‌توانید مشتریان را به یک پرواز متفاوت منتقل کنید و برای ناراحتی آنها به آنها غرامت دهید). در این موارد، <em>linearizability</em> ممکن است مورد نیاز نباشد، و ما در مورد چنین <em>constraints</em> هایی که به طور سست تفسیر شده‌اند، در "Timeliness and Integrity" در صفحه 524 بحث خواهیم کرد.
    </p>
<p>
        با این حال، یک <em>hard uniqueness constraint</em>، مانند موردی که معمولاً در relational databases ها پیدا می‌کنید، به <em>linearizability</em> نیاز دارد. انواع دیگر <em>constraints</em>، مانند <em>foreign key</em> یا <em>attribute constraints</em>، را می‌توان بدون نیاز به <em>linearizability</em> پیاده‌سازی کرد [19].
    </p>
<h4>Cross-channel timing dependencies</h4>
<p>
        به یک جزئیات در شکل 9-1 توجه کنید: اگر آلیس نتیجه را اعلام نکرده بود، باب نمی‌دانست که نتیجه query او <em>stale</em> است. او فقط چند ثانیه بعد دوباره صفحه را رفرش می‌کرد، و در نهایت نتیجه نهایی را می‌دید. تخلف از linearizability فقط به این دلیل مشاهده شد که یک کانال ارتباطی اضافی در system وجود داشت (صدای آلیس به گوش باب).
    </p>
<p>
        وضعیت‌های مشابهی می‌تواند در system های کامپیوتری ایجاد شود. به عنوان مثال، فرض کنید شما یک وب‌سایت دارید که در آن users می‌توانند یک عکس را <em>upload</em> کنند، و یک فرآیند پس‌زمینه، اندازه‌های عکس‌ها را برای دانلود سریع‌تر (<em>thumbnails</em>) تغییر می‌دهد. معماری و <em>dataflow</em> از این system در شکل 9-5 نشان داده شده است.
    </p>
<p>
<em>The image resizer</em> نیاز دارد که صریحاً دستورالعمل اجرای یک <em>resizing job</em> را دریافت کند، و این دستورالعمل از وب سرور از طریق یک صف پیام (به فصل 11 مراجعه کنید) به <em>resizer</em> ارسال می‌شود. وب سرور کل عکس را در صف قرار نمی‌دهد، زیرا اکثر <em>message brokers</em> برای پیام‌های کوچک طراحی شده‌اند، و یک عکس ممکن است چندین مگابایت حجم داشته باشد. در عوض، عکس ابتدا در یک <em>file storage service</em> نوشته می‌شود، و هنگامی که <em>write</em> تکمیل شد، دستورالعمل به <em>resizer</em> در صف قرار می‌گیرد.
        <br/>
        Linearizability
        <br/>
        |
        <br/>
        331
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0353</div>
            </div>
        </div>
        <!-- Page 0354 -->
        <div class="chapter" id="page-0354">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<figure>
<img alt="Figure 9-5. The web server and image resizer communicate both through file storage and a message queue, opening the potential for race conditions." src="figure9-5.png"/>
<figcaption>Figure 9-5. The web server and image resizer communicate both through file storage and a message queue, opening the potential for race conditions.</figcaption>
</figure>
<p>
        شکل 9-5، web server و <em>image resizer</em> هم از طریق <em>file storage</em> و هم یک صف پیام با هم ارتباط برقرار می‌کنند، که پتانسیل <em>race conditions</em> را ایجاد می‌کند.
    </p>
<p>
        اگر <em>file storage service</em> <em>linearizable</em> باشد، پس این system باید خوب کار کند. اگر <em>linearizable</em> نباشد، خطر یک <em>race condition</em> وجود دارد: صف پیام (مراحل 3 و 4 در شکل 9-5) ممکن است سریع‌تر از <em>internal replication</em> در داخل <em>storage service</em> باشد. در این حالت، وقتی resizer، image را واکشی می‌کند (مرحله 5)، ممکن است یک نسخه قدیمی از image، یا اصلاً هیچ چیزی را نبیند. اگر یک نسخه قدیمی از image را پردازش کند، <em>full-size</em> و <em>resized images</em> در <em>file storage</em> به‌طور دائمی ناسازگار می‌شوند.
    </p>
<p>
        این مشکل به این دلیل ایجاد می‌شود که دو کانال ارتباطی مختلف بین وب سرور و <em>resizer</em> وجود دارد: <em>file storage</em> و صف پیام.
        <br/>
        بدون <em>recency guarantee</em> از <em>linearizability</em>، <em>race conditions</em> بین این دو کانال ممکن است. این وضعیت شبیه به شکل 9-1 است، جایی که همچنین یک <em>race condition</em> بین دو کانال ارتباطی وجود داشت: <em>the database replication</em> و <em>the real-life audio channel</em> بین دهان آلیس و گوش‌های باب.
    </p>
<p>
<em>Linearizability</em> تنها راه برای اجتناب از این <em>race condition</em> نیست، اما ساده‌ترین راه برای درک آن است. اگر شما کانال ارتباطی اضافی را کنترل می‌کنید (مانند مورد صف پیام، اما نه در مورد آلیس و باب)، شما می‌توانید از رویکردهای جایگزینی مشابه آنچه که در "Reading Your Own Writes" در صفحه 162 مورد بحث قرار دادیم، با هزینه پیچیدگی اضافی استفاده کنید.
    </p>
<h4>Implementing Linearizable Systems</h4>
<p>
        اکنون که ما به چند نمونه نگاهی انداختیم که در آنها <em>linearizability</em> مفید است، بیایید در مورد چگونگی پیاده‌سازی یک system که <em>linearizable semantics</em> را ارائه می‌دهد، فکر کنیم.
    </p>
<p>
        از آنجایی که <em>linearizability</em> اساساً به معنای "به‌گونه‌ای رفتار کنید که گویی فقط یک کپی از داده‌ها وجود دارد، و تمام عملیات روی آن <em>atomic</em> هستند"، ساده‌ترین پاسخ این است که واقعاً فقط از یک کپی از داده‌ها استفاده کنید. با این حال، آن رویکرد قادر به تحمل <em>faults</em> نخواهد بود: اگر node که آن یک کپی را نگه می‌دارد شکست بخورد، داده‌ها از دست می‌روند، یا حداقل تا زمانی که node دوباره راه‌اندازی شود، غیرقابل دسترسی خواهند بود.
        <br/>
        332
        <br/>
        |
        <br/>
        Chapter 9: Consistency and Consensus
    </p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 354" src="page_0354/image_1.png"/></div>
</div>
                <div class="page-number">صفحه 0354</div>
            </div>
        </div>
        <!-- Page 0355 -->
        <div class="chapter" id="page-0355">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<h3>iv. Partitioning (sharding) a single-leader database</h3>
<p>
        تقسیم بندی (sharding) یک پایگاه داده تک رهبر، به طوری که یک رهبر جداگانه برای هر partition وجود داشته باشد، بر linearizability تأثیری نمی گذارد، زیرا این فقط یک تضمین تک شی است. تراکنش‌های Cross-partition یک موضوع متفاوت است (به "Distributed Transactions and Consensus" در صفحه 352 مراجعه کنید).
    </p>
<p>
        متداول‌ترین رویکرد برای fault-tolerant کردن یک سیستم، استفاده از replication است.
    </p>
<p>
        بیایید روش‌های replication را از فصل 5 بازبینی کنیم و مقایسه کنیم که آیا می‌توان آن‌ها را linearizable کرد:
    </p>
<h4>Single-leader replication (potentially linearizable)</h4>
<p>
        در یک سیستم با single-leader replication (به "Leaders and Followers" در صفحه 152 مراجعه کنید)، رهبر دارای کپی اولیه داده است که برای نوشتن استفاده می‌شود، و فالوئرها کپی‌های پشتیبان داده‌ها را در nodeهای دیگر نگهداری می‌کنند. اگر از رهبر یا از فالوئرهای به‌روزرسانی‌شده به صورت synchronous، خواندن انجام دهید، پتانسیل linearizable بودن را دارند.iv با این حال، هر پایگاه داده single-leader در واقع linearizable نیست، چه از نظر طراحی (به عنوان مثال، به این دلیل که از snapshot isolation استفاده می‌کند) یا به دلیل باگ‌های concurrency [10].
    </p>
<p>
        استفاده از رهبر برای خواندن، به این فرض متکی است که شما مطمئناً می‌دانید رهبر کیست. همانطور که در "The Truth Is Defined by the Majority" در صفحه 300 بحث شد، کاملاً ممکن است یک node فکر کند که رهبر است، در حالی که در واقع اینطور نیست - و اگر رهبر دچار توهم به سرویس دهی به درخواست‌ها ادامه دهد، احتمالاً linearizability را نقض می‌کند [20]. با asynchronous replication، failover ممکن است حتی نوشته‌های committed را از دست بدهد (به "Handling Node Outages" در صفحه 156 مراجعه کنید)، که هم durability و هم linearizability را نقض می‌کند.
    </p>
<h4>Consensus algorithms (linearizable)</h4>
<p>
        برخی از consensus algorithms، که بعداً در این فصل در مورد آنها بحث خواهیم کرد، شباهتی به single-leader replication دارند. با این حال، consensus protocols شامل اقداماتی برای جلوگیری از split brain و stale replicas هستند. با تشکر از این جزئیات، consensus algorithms می‌توانند linearizable storage را با خیال راحت پیاده‌سازی کنند. به عنوان مثال، این نحوه عملکرد ZooKeeper [21] و etcd [22] است.
    </p>
<h4>Multi-leader replication (not linearizable)</h4>
<p>
        سیستم‌های با multi-leader replication عموماً linearizable نیستند، زیرا همزمان نوشته‌ها را در چندین node پردازش می‌کنند و به صورت asynchronous آن‌ها را به سایر nodeها replicate می‌کنند. به همین دلیل، آن‌ها می‌توانند نوشته‌های conflicting تولید کنند که نیاز به resolution دارند (به "Handling Write Conflicts" در صفحه 171 مراجعه کنید). چنین conflictsهایی یک artifact از فقدان یک کپی واحد از داده‌ها هستند.
    </p>
<h4>Leaderless replication (probably not linearizable)</h4>
<p>
        برای سیستم‌هایی با leaderless replication (سبک Dynamo؛ به "Leaderless Replication" در صفحه 177 مراجعه کنید)، مردم گاهی ادعا می‌کنند که می‌توانید "strong consistency" را با الزامات quorum reads و writes (w + r &gt; n) به دست آورید. بسته به دقیق
    </p>
<p>
        Linearizability
        |
        333
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0355</div>
            </div>
        </div>
        <!-- Page 0356 -->
        <div class="chapter" id="page-0356">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        configuration of the quorums، و بسته به نحوه تعریف strong consistency، این کاملاً درست نیست.
    </p>
<p>
        روش‌های "Last write wins" conflict resolution مبتنی بر ساعت‌های زمان روز (به عنوان مثال، در Cassandra؛ به "Relying on Synchronized Clocks" در صفحه 291 مراجعه کنید) تقریباً مطمئناً nonlinearizable هستند، زیرا نمی‌توان تضمین کرد که timestampهای ساعت با ترتیب رویداد واقعی به دلیل clock skew سازگار باشند. Sloppy quorums ("Sloppy Quorums and Hinted Handoff" در صفحه 183) نیز هر فرصتی برای linearizability را از بین می‌برند. حتی با strict quorums، رفتار nonlinearizable امکان‌پذیر است، همانطور که در بخش بعدی نشان داده شده است.
    </p>
<h4>Linearizability and quorums</h4>
<p>
        از نظر شهودی، به نظر می‌رسد که strict quorum reads و writes باید در یک مدل Dynamo-style linearizable باشند. با این حال، زمانی که ما تأخیرهای متغیر شبکه را داریم، race conditions امکان‌پذیر است، همانطور که در شکل 9-6 نشان داده شده است.
    </p>
<figure>
<img alt="شکل 9-6" src="figure9-6.png" style="max-width: 100%;"/>
<figcaption>
            شکل 9-6. یک اجرای nonlinearizable، با وجود استفاده از یک strict quorum.
        </figcaption>
</figure>
<p>
        در شکل 9-6، مقدار اولیه x برابر 0 است، و یک writer client در حال به‌روزرسانی x به 1 با ارسال write به هر سه replica (n = 3, w = 3) است. همزمان، client A از یک quorum از دو node (r = 2) می‌خواند و مقدار جدید 1 را در یکی از nodeها می‌بیند. همچنین همزمان با write، client B از یک quorum متفاوت از دو node می‌خواند و مقدار قدیمی 0 را از هر دو دریافت می‌کند.
    </p>
<p>
        شرط quorum برآورده شده است (w + r &gt; n)، اما این اجرا با این وجود linearizable نیست: درخواست B پس از تکمیل درخواست A شروع می‌شود، اما B مقدار قدیمی را برمی‌گرداند.
    </p>
<p>
        334 | Chapter 9: Consistency and Consensus
    </p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 356" src="page_0356/image_1.png"/></div>
</div>
                <div class="page-number">صفحه 0356</div>
            </div>
        </div>
        <!-- Page 0357 -->
        <div class="chapter" id="page-0357">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        در حالی که A مقدار جدید را برمی‌گرداند. (این بار دیگر وضعیت آلیس و باب از شکل 9-1 است.)
    </p>
<p>
        جالب اینجاست که ممکن است quorums سبک Dynamo را با هزینه کاهش performance linearizable کرد: یک reader باید read repair را به صورت synchronous انجام دهد (به "Read repair and anti-entropy" در صفحه 178 مراجعه کنید)، قبل از بازگرداندن نتایج به application [23]، و یک writer باید آخرین وضعیت یک quorum از nodes را قبل از ارسال writes خود بخواند [24, 25]. با این حال، Riak به دلیل performance penalty، read repair همزمان را انجام نمی‌دهد [26]. Cassandra منتظر تکمیل read repair در quorum reads [27] می‌شود، اما اگر چندین write همزمان به همان کلید وجود داشته باشد، linearizability را از دست می‌دهد، به دلیل استفاده از last-write-wins conflict resolution.
    </p>
<p>
        علاوه بر این، تنها عملیات linearizable read و write را می‌توان به این روش پیاده‌سازی کرد. یک عملیات linearizable compare-and-set نمی‌تواند، زیرا به یک consensus algorithm نیاز دارد [28].
    </p>
<p>
        به طور خلاصه، امن‌ترین حالت این است که فرض کنیم یک سیستم leaderless با replication سبک Dynamo، linearizability را ارائه نمی‌دهد.
    </p>
<h4>The Cost of Linearizability</h4>
<p>
        از آنجایی که برخی از روش‌های replication می‌توانند linearizability را ارائه دهند و برخی دیگر نمی‌توانند، بررسی جوانب مثبت و منفی linearizability با جزئیات بیشتر جالب است.
    </p>
<p>
        ما قبلاً در مورد برخی موارد استفاده برای روش‌های مختلف replication در فصل 5 بحث کردیم. به عنوان مثال، دیدیم که multi-leader replication اغلب یک انتخاب خوب برای multi-datacenter replication است (به "Multi-datacenter operation" در صفحه 168 مراجعه کنید). نمونه‌ای از این استقرار در شکل 9-7 نشان داده شده است.
    </p>
<figure>
<img alt="شکل 9-7" src="figure9-7.png" style="max-width: 100%;"/>
<figcaption>
            شکل 9-7. یک network interruption که انتخاب بین linearizability و availability را تحمیل می‌کند.
        </figcaption>
</figure>
<p>
        Linearizability | 335
    </p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 357" src="page_0357/image_1.png"/></div>
</div>
                <div class="page-number">صفحه 0357</div>
            </div>
        </div>
        <!-- Page 0358 -->
        <div class="chapter" id="page-0358">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<h4>v. These two choices</h4>
<p>
        این دو انتخاب گاهی اوقات به ترتیب CP (consistent but not available under network partitions) و AP (available but not consistent under network partitions) نامیده می‌شوند. با این حال، این طرح طبقه‌بندی دارای چندین نقص [9] است، بنابراین بهتر است از آن اجتناب شود.
    </p>
<p>
        در نظر بگیرید چه اتفاقی می‌افتد اگر یک network interruption بین دو datacenter وجود داشته باشد. بیایید فرض کنیم که شبکه در داخل هر datacenter در حال کار است و clients می‌توانند به datacenters دسترسی داشته باشند، اما datacenters نمی‌توانند به یکدیگر متصل شوند.
    </p>
<p>
        با یک multi-leader database، هر datacenter می‌تواند به طور معمول به کار خود ادامه دهد: از آنجایی که writes از یک datacenter به صورت asynchronous به دیگری replicate می‌شوند، writes به سادگی در صف قرار می‌گیرند و زمانی که اتصال شبکه بازیابی شد، تبادل می‌شوند.
    </p>
<p>
        از سوی دیگر، اگر single-leader replication استفاده شود، leader باید در یکی از datacenters باشد. هر گونه write و هر گونه linearizable read باید به leader ارسال شود - بنابراین، برای هر client متصل به یک follower datacenter، آن read و write requests باید به صورت synchronous از طریق شبکه به leader datacenter ارسال شوند.
    </p>
<p>
        اگر شبکه بین datacenters در یک setup single-leader دچار اختلال شود، clients متصل به follower datacenters نمی‌توانند با leader تماس بگیرند، بنابراین آن‌ها نمی‌توانند هیچ writeای را به database انجام دهند، و نه هیچ linearizable readای را. آن‌ها هنوز هم می‌توانند از follower بخوانند، اما ممکن است stale (nonlinearizable) باشند. اگر application به linearizable reads و writes نیاز داشته باشد، network interruption باعث می‌شود application در datacenters که نمی‌توانند با leader تماس بگیرند، غیرقابل دسترس شود.
    </p>
<p>
        اگر clients بتوانند مستقیماً به leader datacenter متصل شوند، این یک مشکل نیست، زیرا application در آنجا به طور معمول به کار خود ادامه می‌دهد. اما clients که فقط می‌توانند به یک follower datacenter دسترسی داشته باشند، تا زمانی که پیوند شبکه تعمیر شود، outage را تجربه خواهند کرد.
    </p>
<h4>The CAP theorem</h4>
<p>
        این مسئله فقط نتیجه single-leader و multi-leader replication نیست: هر linearizable database این مشکل را دارد، مهم نیست که چگونه پیاده‌سازی شده است. این مسئله همچنین مختص استقرار multi-datacenter نیست، بلکه می‌تواند در هر شبکه غیرقابل اعتمادی، حتی در یک datacenter نیز رخ دهد. trade-off به شرح زیر است:v
    </p>
<ul>
<li>
            اگر application شما به linearizability نیاز دارد، و برخی از replicas به دلیل یک مشکل شبکه از سایر replicas جدا شده‌اند، پس برخی از replicas نمی‌توانند requests را در حالی که قطع هستند، پردازش کنند: آن‌ها باید یا منتظر بمانند تا مشکل شبکه برطرف شود، یا یک error برگردانند (در هر صورت، آن‌ها غیرقابل دسترس می‌شوند).
        </li>
<li>
            اگر application شما به linearizability نیاز ندارد، پس می‌تواند به گونه‌ای نوشته شود که هر replica بتواند requests را به طور مستقل پردازش کند، حتی اگر از سایر replicas جدا شده باشد (به عنوان مثال، multi-leader). در این حالت، application می‌تواند در مواجهه با یک مشکل شبکه در دسترس باقی بماند، اما رفتار آن linearizable نیست.
        </li>
</ul>
<p>
        336 | Chapter 9: Consistency and Consensus
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0358</div>
            </div>
        </div>
        <!-- Page 0359 -->
        <div class="chapter" id="page-0359">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<h4>vi. As discussed in “Network Faults in Practice”</h4>
<p>
        همانطور که در "Network Faults in Practice" در صفحه 279 بحث شد، این کتاب از partitioning برای اشاره به شکستن عمدی یک dataset بزرگ به datasetهای کوچکتر (sharding؛ به فصل 6 مراجعه کنید) استفاده می‌کند. در مقابل، network partition یک نوع خاص از network fault است، که ما معمولاً جدا از انواع دیگر faults در نظر نمی‌گیریم. با این حال، از آنجایی که این P در CAP است، ما نمی‌توانیم از سردرگمی در این مورد اجتناب کنیم.
    </p>
<p>
        بنابراین، applications که نیازی به linearizability ندارند، می‌توانند تحمل بیشتری نسبت به مشکلات شبکه داشته باشند. این بینش به طور گسترده‌ای به عنوان the CAP theorem [29, 30, 31, 32] شناخته می‌شود، که توسط Eric Brewer در سال 2000 نامگذاری شد، اگرچه trade-off از دهه 1970 برای طراحان distributed databases شناخته شده بود [33, 34, 35, 36].
    </p>
<p>
        CAP در اصل به عنوان یک rule of thumb پیشنهاد شد، بدون تعاریف دقیق، با هدف شروع بحثی در مورد trade-offs در databases. در آن زمان، بسیاری از distributed databases بر ارائه linearizable semantics در یک cluster از ماشین‌ها با shared storage متمرکز بودند [18]، و CAP مهندسان database را تشویق کرد تا فضای طراحی گسترده‌تری از سیستم‌های distributed shared-nothing را بررسی کنند، که برای پیاده‌سازی large-scale web services مناسب‌تر بودند [37]. CAP شایسته این تغییر فرهنگی است - شاهد انفجار فناوری‌های جدید database از اواسط دهه 2000 (معروف به NoSQL) باشید.
    </p>
<h4>The Unhelpful CAP Theorem</h4>
<p>
        CAP گاهی اوقات به عنوان Consistency, Availability, Partition tolerance ارائه می‌شود: pick 2 out of 3. متأسفانه، قرار دادن آن به این شکل گمراه‌کننده است [32] زیرا network partitions یک نوع fault هستند، بنابراین آن‌ها چیزی نیستند که شما در مورد آن انتخاب داشته باشید: آن‌ها اتفاق خواهند افتاد، چه شما بخواهید چه نخواهید [38].
    </p>
<p>
        در زمان‌هایی که شبکه به درستی کار می‌کند، یک سیستم می‌تواند هم consistency (linearizability) و هم total availability را ارائه دهد. هنگامی که یک network fault رخ می‌دهد، شما باید بین linearizability یا total availability انتخاب کنید. بنابراین، یک راه بهتر برای phrasing CAP این است که یا Consistent یا Available when Partitioned [39]. یک شبکه قابل اعتمادتر نیاز به این دارد که این انتخاب را کمتر انجام دهد، اما در مقطعی این انتخاب اجتناب ناپذیر است.
    </p>
<p>
        در بحث‌های CAP چندین تعریف متناقض از اصطلاح availability وجود دارد، و formalization به عنوان یک theorem [30] با معنی معمول آن مطابقت ندارد [40]. بسیاری از سیستم‌های به اصطلاح "highly available" (fault-tolerant) در واقع تعریف idiosyncratic CAP از availability را برآورده نمی‌کنند. در مجموع، سوء تفاهم و سردرگمی زیادی در مورد CAP وجود دارد، و به ما کمک نمی‌کند سیستم‌ها را بهتر درک کنیم، بنابراین CAP بهتر است اجتناب شود.
    </p>
<p>
        The CAP theorem as formally defined [30] is of very narrow scope: it only considers one consistency model (namely linearizability) and one kind of fault (network parti-vi tions, or nodes that are alive but disconnected from each other). It doesn’t say any-
    </p>
<p>
        Linearizability | 337
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0359</div>
            </div>
        </div>
        <!-- Page 0360 -->
        <div class="chapter" id="page-0360">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        thing در مورد network delays، dead nodes، یا other trade-offs. بنابراین، اگرچه CAP از نظر تاریخی تأثیرگذار بوده است، اما ارزش عملی کمی برای طراحی سیستم‌ها دارد [9, 40].
    </p>
<p>
        نتایج غیرممکن جالب‌تری در سیستم‌های distributed وجود دارد [41]، و CAP اکنون با نتایج دقیق‌تری جایگزین شده است [2, 42]، بنابراین امروزه بیشتر مورد توجه تاریخی است.
    </p>
<h4>Linearizability and network delays</h4>
<p>
        اگرچه linearizability یک تضمین مفید است، اما در عمل سیستم‌های کمی واقعاً linearizable هستند. به عنوان مثال، حتی RAM در یک CPU multi-core مدرن linearizable نیست [43]: اگر یک thread که روی یک CPU core اجرا می‌شود به یک آدرس حافظه write کند، و یک thread روی CPU core دیگری اندکی پس از آن همان آدرس را بخواند، تضمین نمی‌شود که مقدار نوشته شده توسط اولین thread را بخواند (مگر اینکه از یک memory barrier یا fence [44] استفاده شود).
    </p>
<p>
        دلیل این رفتار این است که هر CPU core cache و store buffer حافظه خود را دارد. دسترسی به حافظه به طور پیش‌فرض ابتدا به cache می‌رود و هر گونه تغییری به صورت asynchronous به main memory نوشته می‌شود. از آنجایی که دسترسی به داده‌ها در cache بسیار سریعتر از رفتن به main memory است [45]، این ویژگی برای performance خوب در CPUهای مدرن ضروری است. با این حال، اکنون چندین کپی از داده‌ها وجود دارد (یکی در main memory، و شاید چندین مورد دیگر در cacheهای مختلف)، و این کپی‌ها به صورت asynchronous به‌روزرسانی می‌شوند، بنابراین linearizability از دست می‌رود.
    </p>
<p>
        چرا این trade-off را انجام دهیم؟ استفاده از the CAP theorem برای توجیه مدل consistency حافظه multi-core منطقی نیست: در یک کامپیوتر ما معمولاً ارتباط قابل اطمینان را فرض می‌کنیم، و ما انتظار نداریم که یک CPU core بتواند به طور معمول به کار خود ادامه دهد اگر از بقیه کامپیوتر قطع شده باشد. دلیل dropping linearizability performance است، نه fault tolerance.
    </p>
<p>
        همین امر در مورد بسیاری از distributed databases که انتخاب می‌کنند تا guarantees linearizable را ارائه ندهند، صدق می‌کند: آن‌ها این کار را در درجه اول برای افزایش performance انجام می‌دهند، نه چندان برای fault tolerance [46]. Linearizability کند است - و این همیشه صادق است، نه فقط در طول یک network fault.
    </p>
<p>
        آیا نمی‌توانیم یک پیاده‌سازی کارآمدتر از linearizable storage پیدا کنیم؟ به نظر می‌رسد پاسخ منفی است: Attiya و Welch [47] ثابت می‌کنند که اگر می‌خواهید linearizability، زمان پاسخگویی درخواست‌های read و write حداقل متناسب با عدم اطمینان از تاخیرها در شبکه است. در یک شبکه با تاخیرهای بسیار متغیر، مانند اکثر computer networks (به "Timeouts and Unbounded Delays" در صفحه 281 مراجعه کنید)، زمان پاسخگویی linearizable reads و writes به ناچار بالا خواهد بود. یک algorithm سریعتر برای linearizability وجود ندارد، اما weaker consistency models می‌توانند بسیار سریعتر باشند، بنابراین این trade-off برای سیستم‌های حساس به latency مهم است. در فصل 12 ما در مورد برخی از رویکردها برای اجتناب از linearizability بدون قربانی کردن correctness بحث خواهیم کرد.
    </p>
<p>
        338 | Chapter 9: Consistency and Consensus
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0360</div>
            </div>
        </div>
        <!-- Page 0361 -->
        <div class="chapter" id="page-0361">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<h3>Ordering Guarantees</h3>
<p>
        ما قبلاً گفتیم که یک linearizable register طوری رفتار می‌کند که گویی فقط یک کپی از داده وجود دارد، و هر عملیات به نظر می‌رسد در یک نقطه از زمان به صورت اتمی اعمال می‌شود. این تعریف مستلزم آن است که عملیات‌ها به ترتیب مشخصی اجرا شوند.
    </p>
<p>
        ما ترتیب را در شکل 9-4 با پیوستن به عملیات‌ها به ترتیبی که به نظر می‌رسد اجرا شده‌اند، نشان دادیم.
    </p>
<p>
        Ordering یک موضوع تکراری در این کتاب بوده است، که نشان می‌دهد ممکن است یک ایده اساسی مهم باشد. بیایید به طور خلاصه برخی از زمینه‌های دیگری را که در آن‌ها در مورد ordering بحث کرده‌ایم، مرور کنیم:
    </p>
<ul>
<li>
            در فصل 5 دیدیم که هدف اصلی leader در single-leader replication، تعیین ترتیب writes در replication log است - یعنی ترتیبی که فالوئرها آن writes را اعمال می‌کنند. اگر هیچ single leader وجود نداشته باشد، conflicts می‌تواند به دلیل عملیات concurrent رخ دهد (به "Handling Write Conflicts" در صفحه 171 مراجعه کنید).
        </li>
<li>
            Serializability، که در فصل 7 مورد بحث قرار دادیم، در مورد اطمینان از این است که transactions طوری رفتار می‌کنند که گویی به ترتیب متوالی اجرا شده‌اند. این می‌تواند با اجرای لفظی transactions به ترتیب سریال، یا با اجازه دادن به اجرای concurrent در حالی که از conflicts serialization جلوگیری می‌شود (با قفل کردن یا aborting) به دست آید.
        </li>
<li>
            استفاده از timestamps و clocks در سیستم‌های distributed که در فصل 8 مورد بحث قرار دادیم (به "Relying on Synchronized Clocks" در صفحه 291 مراجعه کنید) یک تلاش دیگر برای معرفی order به یک دنیای بی‌نظم است، به عنوان مثال برای تعیین اینکه کدام یک از دو write بعداً اتفاق افتاده است.
        </li>
</ul>
<p>
        مشخص می‌شود که ارتباطات عمیقی بین ordering، linearizability و consensus وجود دارد. اگرچه این مفهوم کمی بیشتر از بقیه این کتاب، نظری و انتزاعی است، اما برای روشن کردن درک ما از آنچه سیستم‌ها می‌توانند و نمی‌توانند انجام دهند، بسیار مفید است. ما این موضوع را در چند بخش بعدی بررسی خواهیم کرد.
    </p>
<h4>Ordering and Causality</h4>
<p>
        دلایل متعددی وجود دارد که چرا ordering همچنان مطرح می‌شود، و یکی از دلایل این است که به حفظ causality کمک می‌کند. ما قبلاً چندین مثال را در طول این کتاب دیده‌ایم که causality در آن‌ها مهم بوده است:
    </p>
<ul>
<li>
            در "Consistent Prefix Reads" در صفحه 165 (شکل 5-5) ما مثالی را دیدیم که در آن ناظر یک مکالمه ابتدا پاسخ به یک سوال و سپس سوالی که به آن پاسخ داده می‌شود را مشاهده کرد. این گیج کننده است زیرا intuition ما از cause and effect را نقض می‌کند: اگر به سؤالی پاسخ داده شود، پس مشخص است که سؤال باید ابتدا وجود داشته باشد، زیرا شخصی که پاسخ را می‌دهد باید سؤال را دیده باشد (با فرض اینکه آن‌ها روانی نیستند و نمی‌توانند آینده را ببینند). ما می‌گوییم که یک causal dependency بین سوال و پاسخ وجود دارد.
        </li>
</ul>
<p>
        Ordering Guarantees | 339
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0361</div>
            </div>
        </div>
        <!-- Page 0362 -->
        <div class="chapter" id="page-0362">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<ul>
<li>
            یک الگوی مشابه در شکل 5-9 ظاهر شد، جایی که ما به replication بین سه leader نگاه کردیم و متوجه شدیم که برخی از writes می‌توانند به دلیل network delays، دیگران را "overtake" کنند. از دیدگاه یکی از replicas به نظر می‌رسید که یک update برای یک row وجود دارد که وجود نداشته است. Causality در اینجا به این معنی است که یک row ابتدا باید ایجاد شود تا بتواند update شود.
        </li>
<li>
            در "Detecting Concurrent Writes" در صفحه 184 مشاهده کردیم که اگر شما دو عملیات A و B دارید، سه امکان وجود دارد: یا A قبل از B اتفاق افتاده است، یا B قبل از A اتفاق افتاده است، یا A و B concurrent هستند. این رابطه happened before، بیان دیگری از causality است: اگر A قبل از B اتفاق افتاده باشد، این بدان معناست که B ممکن است در مورد A بداند، یا بر اساس A ساخته شده باشد، یا به A وابسته باشد. اگر A و B concurrent باشند، هیچ پیوند causal بین آن‌ها وجود ندارد؛ به عبارت دیگر، ما مطمئن هستیم که هیچ یک از دیگری خبر نداشتند.
        </li>
<li>
            در context از snapshot isolation برای transactions ("Snapshot Isolation and Repeatable Read" در صفحه 237)، ما گفتیم که یک transaction از یک consistent snapshot می‌خواند. اما "consistent" در این context به چه معناست؟ این به معنای سازگاری با causality است: اگر snapshot شامل یک answer باشد، باید شامل question نیز باشد [48]. مشاهده کل database در یک نقطه زمانی واحد آن را با causality سازگار می‌کند: اثرات تمام عملیات‌هایی که به صورت causal قبل از آن نقطه زمانی اتفاق افتاده‌اند، قابل مشاهده هستند، اما هیچ عملیاتی که به صورت causal بعد از آن اتفاق افتاده است، قابل مشاهده نیست. Read skew (non-repeatable reads، همانطور که در شکل 7-6 نشان داده شده است) به معنای خواندن داده‌ها در حالتی است که causality را نقض می‌کند.
        </li>
<li>
            مثال‌های ما از write skew بین transactions (به "Write Skew and Phantoms" در صفحه 246 مراجعه کنید) نیز causal dependencies را نشان داد: در شکل 7-8، به آلیس اجازه داده شد که از call خارج شود زیرا transaction فکر می‌کرد که باب هنوز در call است، و بالعکس. در این مورد، عمل خارج شدن از call به observation از اینکه چه کسی در حال حاضر در call است، به صورت causal وابسته است. Serializable snapshot isolation (به "Serializable Snapshot Isolation (SSI)" در صفحه 261 مراجعه کنید) write skew را با ردیابی causal dependencies بین transactions شناسایی می‌کند.
        </li>
<li>
            در مثال آلیس و باب که فوتبال تماشا می‌کردند (شکل 9-1)، این واقعیت که باب پس از شنیدن exclamation آلیس، نتیجه‌ای stale از server دریافت کرد، یک causality violation است: exclamation آلیس به announcement از score به صورت causal وابسته است، بنابراین باب نیز باید بتواند score را پس از شنیدن آلیس ببیند. همان الگو دوباره در "Cross-channel timing dependencies" در صفحه 331 در guise از یک image resizing service ظاهر شد.
        </li>
</ul>
<p>
        Causality یک ordering را بر روی رویدادها تحمیل می‌کند: cause قبل از effect می‌آید؛ یک message قبل از دریافت آن message ارسال می‌شود؛ question قبل از answer می‌آید. و، مانند زندگی واقعی، یک چیز به چیز دیگر منجر می‌شود: یک node برخی از داده‌ها را می‌خواند و سپس در نتیجه چیزی می‌نویسد، node دیگری چیزی را که نوشته شده است می‌خواند و به نوبه خود چیز دیگری می‌نویسد و غیره. این زنجیره‌های causally dependent operations، causal order را در سیستم تعریف می‌کنند - یعنی چه چیزی قبل از چه چیزی اتفاق افتاده است.
    </p>
<p>
        340 | Chapter 9: Consistency and Consensus
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0362</div>
            </div>
        </div>
        <!-- Page 0363 -->
        <div class="chapter" id="page-0363">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        اگر یک سیستم از ordering تحمیل شده توسط causality پیروی کند، ما می‌گوییم که آن causally consistent است. به عنوان مثال، snapshot isolation, causal consistency را فراهم می‌کند: هنگامی که شما از database می‌خوانید، و مقداری از داده‌ها را می‌بینید، باید قادر باشید هر داده‌ای را که به صورت causal قبل از آن قرار دارد نیز ببینید (با فرض اینکه در این بین حذف نشده باشد).
    </p>
<h4>The causal order is not a total order</h4>
<p>
        یک total order به هر دو عنصر اجازه می‌دهد تا مقایسه شوند، بنابراین اگر شما دو عنصر دارید، همیشه می‌توانید بگویید کدام یک بزرگتر و کدام یک کوچکتر است. به عنوان مثال، natural numbers به طور کامل ordered هستند: اگر من به شما دو عدد بدهم، مثلاً 5 و 13، شما می‌توانید به من بگویید که 13 بزرگتر از 5 است.
    </p>
<p>
        با این حال، mathematical sets به طور کامل ordered نیستند: آیا {a, b} بزرگتر از {b, c} است؟ خوب، شما واقعاً نمی‌توانید آن‌ها را مقایسه کنید، زیرا هیچ‌کدام subset دیگری نیستند. ما می‌گوییم آن‌ها غیرقابل مقایسه هستند، و بنابراین mathematical sets به طور partial ordered هستند: در برخی موارد یک set بزرگتر از set دیگری است (اگر یک set شامل تمام عناصر set دیگری باشد)، اما در موارد دیگر آن‌ها غیرقابل مقایسه هستند.
    </p>
<p>
        تفاوت بین یک total order و یک partial order در مدل‌های consistency مختلف database منعکس می‌شود:
    </p>
<ul>
<li>
            Linearizability
            <p>
                در یک سیستم linearizable، ما یک total order از operations داریم: اگر سیستم طوری رفتار می‌کند که گویی فقط یک کپی از داده وجود دارد، و هر عملیات atomic است، این بدان معناست که برای هر دو عملیات ما همیشه می‌توانیم بگوییم کدام یک اول اتفاق افتاده است.
                این total ordering در شکل 9-4 به عنوان یک timeline نشان داده شده است.
            </p>
</li>
<li>
            Causality
            <p>
                ما گفتیم که دو عملیات concurrent هستند اگر هیچ کدام قبل از دیگری اتفاق نیفتاده باشد (به "The “happens-before” relationship and concurrency" در صفحه 186 مراجعه کنید). به عبارت دیگر، دو رویداد ordered هستند اگر به صورت causal با هم مرتبط باشند (یکی قبل از دیگری اتفاق افتاده است)، اما اگر concurrent باشند، غیرقابل مقایسه هستند. این بدان معناست که causality یک partial order را تعریف می‌کند، نه یک total order: برخی از operations نسبت به یکدیگر ordered هستند، اما برخی غیرقابل مقایسه هستند.
            </p>
</li>
</ul>
<p>
        بنابراین، طبق این تعریف، هیچ عملیات concurrent در یک linearizable datastore وجود ندارد: باید یک timeline واحد وجود داشته باشد که در آن همه عملیات به طور کامل ordered شده‌اند. ممکن است چندین request وجود داشته باشد که منتظر رسیدگی هستند، اما datastore تضمین می‌کند که هر request به صورت اتمی در یک نقطه از زمان، با عملکرد بر روی یک کپی از داده‌ها، در امتداد یک timeline واحد، بدون هیچ concurrency رسیدگی می‌شود.
    </p>
<p>
        Concurrency به این معنی است که timeline شاخه می‌شود و دوباره ادغام می‌شود - و در این صورت، عملیات‌ها در شاخه‌های مختلف غیرقابل مقایسه هستند (یعنی concurrent). ما این پدیده را در فصل 5 دیدیم: به عنوان مثال، شکل 5-14 یک total order خط مستقیم نیست، بلکه یک jumble از عملیات‌های مختلف است که به طور concurrent در حال انجام هستند. فلش‌ها در نمودار نشان‌دهنده causal dependencies هستند - partial ordering of operations.
    </p>
<p>
        Ordering Guarantees | 341
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0363</div>
            </div>
        </div>
        <!-- Page 0364 -->
        <div class="chapter" id="page-0364">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        اگر شما با distributed version control systems مانند Git آشنا هستید، تاریخچه‌های version آن‌ها بسیار شبیه به graph of causal dependencies است. اغلب یک commit پس از دیگری، در یک خط مستقیم اتفاق می‌افتد، اما گاهی اوقات شما branchها را دریافت می‌کنید (زمانی که چندین نفر به طور concurrent روی یک project کار می‌کنند)، و merges زمانی ایجاد می‌شوند که آن commits که به طور concurrent ایجاد شده‌اند، ترکیب می‌شوند.
    </p>
<h4>Linearizability is stronger than causal consistency</h4>
<p>
        بنابراین ارتباط بین causal order و linearizability چیست؟ پاسخ این است که linearizability، causality را implies می‌کند: هر سیستمی که linearizable باشد، causality را به درستی حفظ می‌کند [7]. به طور خاص، اگر چندین communication channel در یک سیستم وجود داشته باشد (مانند message queue و file storage service در شکل 9-5)، linearizability تضمین می‌کند که causality به طور خودکار حفظ می‌شود بدون اینکه سیستم مجبور باشد کار خاصی انجام دهد (مانند انتقال timestamps بین componentsهای مختلف).
    </p>
<p>
        این واقعیت که linearizability، causality را تضمین می‌کند، چیزی است که باعث می‌شود systems linearizable simple to understand و appealing شوند. با این حال، همانطور که در "The Cost of Linearizability" در صفحه 335 بحث شد، linearizable کردن یک سیستم می‌تواند به performance و availability آن آسیب برساند، به خصوص اگر سیستم network delays قابل توجهی داشته باشد (به عنوان مثال، اگر geographically distributed باشد). به همین دلیل، برخی از distributed data systems، linearizability را کنار گذاشته‌اند، که به آن‌ها اجازه می‌دهد performance بهتری داشته باشند اما می‌تواند کار کردن با آن‌ها را دشوار کند.
    </p>
<p>
        خبر خوب این است که یک middle ground امکان‌پذیر است. Linearizability تنها راه حفظ causality نیست - راه‌های دیگری نیز وجود دارد. یک سیستم می‌تواند causally consistent باشد بدون اینکه performance hit ناشی از linearizable کردن آن (به طور خاص، the CAP theorem اعمال نمی‌شود) را متحمل شود. در واقع، causal consistency قوی‌ترین consistency model ممکن است که به دلیل network delays کند نمی‌شود، و در مواجهه با network failures در دسترس باقی می‌ماند [2, 42].
    </p>
<p>
        در بسیاری از موارد، systems که به نظر می‌رسد به linearizability نیاز دارند، در واقع فقط به causal consistency نیاز دارند، که می‌تواند کارآمدتر پیاده‌سازی شود. بر اساس این observation، محققان در حال بررسی انواع جدیدی از databases هستند که causality را حفظ می‌کنند، با ویژگی‌های performance و availability که شبیه به systems eventually consistent هستند [49, 50, 51].
    </p>
<p>
        از آنجایی که این research بسیار recent است، هنوز بخش زیادی از آن وارد production systems نشده است، و هنوز چالش‌هایی برای غلبه بر آن‌ها وجود دارد [52, 53]. با این حال، یک direction امیدوارکننده برای future systems است.
    </p>
<h4>Capturing causal dependencies</h4>
<p>
        ما به تمام جزئیات nitty-gritty از چگونگی حفظ causal consistency توسط systems nonlinearizable در اینجا نمی‌پردازیم، اما فقط به طور خلاصه برخی از ideas اصلی را بررسی می‌کنیم.
    </p>
<p>
        342 | Chapter 9: Consistency and Consensus
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0364</div>
            </div>
        </div>
        <!-- Page 0365 -->
        <div class="chapter" id="page-0365">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        برای حفظ causality، شما باید بدانید کدام operation قبل از کدام operation دیگر اتفاق افتاده است. این یک partial order است: عملیات concurrent ممکن است به هر ترتیبی پردازش شوند، اما اگر یک operation قبل از دیگری اتفاق افتاده باشد، پس باید به همان ترتیب در هر replica پردازش شوند. بنابراین، هنگامی که یک replica یک operation را پردازش می‌کند، باید اطمینان حاصل کند که تمام عملیات causally preceding (تمام عملیات‌هایی که قبل از آن اتفاق افتاده‌اند) قبلاً پردازش شده‌اند؛ اگر برخی از operationهای قبلی وجود نداشته باشند، عملیات بعدی باید منتظر بماند تا operation قبلی پردازش شود.
    </p>
<p>
        به منظور تعیین causal dependencies، ما به روشی برای توصیف "knowledge" یک node در سیستم نیاز داریم. اگر یک node، مقدار X را زمانی که write Y را صادر کرد، قبلاً دیده بود، پس X و Y ممکن است causally related باشند. این analysis از انواع سوالاتی استفاده می‌کند که شما در یک criminal investigation از اتهامات تقلب انتظار دارید: آیا مدیر عامل در زمان اتخاذ تصمیم Y، در مورد X می‌دانست؟
    </p>
<p>
        تکنیک‌ها برای تعیین اینکه کدام operation قبل از کدام operation دیگر اتفاق افتاده است، شبیه به چیزی است که ما در "Detecting Concurrent Writes" در صفحه 184 بحث کردیم. آن بخش در مورد causality در یک leaderless datastore بحث کرد، جایی که ما نیاز داریم تا concurrent writes را به همان کلید شناسایی کنیم تا از lost updates جلوگیری کنیم. Causal consistency فراتر می‌رود: باید causal dependencies را در سراسر database، نه فقط برای یک کلید، ردیابی کند. Version vectors را می‌توان برای انجام این کار تعمیم داد [54].
    </p>
<p>
        به منظور تعیین causal ordering، database باید بداند که کدام version از داده توسط application خوانده شده است. به همین دلیل است که، در شکل 5-13، version number از operation قبلی در یک write به database بازگردانده می‌شود. یک ایده مشابه در conflict detection از SSI، همانطور که در "Serializable Snapshot Isolation (SSI)" در صفحه 261 بحث شد، ظاهر می‌شود: هنگامی که یک transaction می‌خواهد commit کند، database بررسی می‌کند که آیا version از داده که خوانده است هنوز به روز است یا خیر. برای این منظور، database پیگیری می‌کند که کدام داده توسط کدام transaction خوانده شده است.
    </p>
<h4>Sequence Number Ordering</h4>
<p>
        اگرچه causality یک مفهوم تئوری مهم است، اما در واقع پیگیری تمام causal dependencies می‌تواند غیر عملی شود. در بسیاری از applications، clients قبل از نوشتن چیزی، داده‌های زیادی را می‌خوانند، و سپس مشخص نیست که آیا write به تمام یا فقط برخی از آن readsهای قبلی به صورت causal وابسته است یا خیر. ردیابی صریح تمام داده‌هایی که خوانده شده‌اند، به معنای overhead زیادی خواهد بود.
    </p>
<p>
        با این حال، یک راه بهتر وجود دارد: ما می‌توانیم از sequence numbers یا timestamps برای order کردن events استفاده کنیم. یک timestamp نیازی نیست که از یک time-of-day clock (یا physical clock، که مشکلات زیادی دارند، همانطور که در "Unreliable Clocks" در صفحه 287 بحث شد) بیاید. در عوض، می‌تواند از یک logical clock، که یک algorithm برای تولید یک sequence از اعداد برای شناسایی operations است، بیاید، که معمولاً از counters استفاده می‌کند که برای هر operation افزایش می‌یابد.
    </p>
<p>
        Ordering Guarantees | 343
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0365</div>
            </div>
        </div>
        <!-- Page 0366 -->
        <div class="chapter" id="page-0366">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<h4>vii. A total order that is inconsistent with causality</h4>
<p>
        یک total order که با causality ناسازگار است، به راحتی ایجاد می‌شود، اما خیلی مفید نیست. به عنوان مثال، شما می‌توانید یک UUID تصادفی برای هر operation تولید کنید، و UUIDها را lexicographically مقایسه کنید تا total ordering از operations را تعریف کنید. این یک total order معتبر است، اما UUIDهای تصادفی به شما چیزی در مورد اینکه کدام operation واقعاً اول اتفاق افتاده است، یا اینکه آیا operations concurrent بوده‌اند یا نه، نمی‌گویند.
    </p>
<p>
        چنین sequence numbers یا timestamps فشرده هستند (فقط چند بایت اندازه دارند)، و آن‌ها یک total order ارائه می‌دهند: یعنی هر operation یک sequence number منحصر به فرد دارد، و شما همیشه می‌توانید دو sequence numbers را مقایسه کنید تا تعیین کنید کدام یک بزرگتر است (یعنی کدام operation بعداً اتفاق افتاده است).
    </p>
<p>
        به طور خاص، ما می‌توانیم sequence numbers را در یک total order ایجاد کنیم که با causality سازگار است:vii ما قول می‌دهیم که اگر operation A به صورت causal قبل از B اتفاق افتاده باشد، پس A قبل از B در total order رخ می‌دهد (A یک sequence number کمتر از B دارد). Operations concurrent ممکن است به طور دلخواه order شوند. چنین total order تمام اطلاعات causality را capture می‌کند، اما همچنین ordering بیشتری را نسبت به آنچه دقیقاً توسط causality مورد نیاز است، تحمیل می‌کند.
    </p>
<p>
        در یک database با single-leader replication (به "Leaders and Followers" در صفحه 152 مراجعه کنید)، replication log یک total order از write operations را تعریف می‌کند که با causality سازگار است. leader می‌تواند به سادگی یک counter را برای هر operation افزایش دهد، و در نتیجه یک sequence number monotonically increasing را به هر operation در replication log اختصاص دهد. اگر یک follower، writes را به ترتیبی که در replication log ظاهر می‌شوند اعمال کند، حالت follower همیشه causally consistent است (حتی اگر از leader عقب باشد).
    </p>
<h4>Noncausal sequence number generators</h4>
<p>
        اگر یک single leader وجود نداشته باشد (شاید به این دلیل که شما از یک multi-leader یا leaderless database استفاده می‌کنید، یا به این دلیل که database partitioned است)، مشخص نیست که چگونه sequence numbers را برای operations تولید کنید. روش‌های مختلفی در عمل استفاده می‌شود:
    </p>
<ul>
<li>
            هر node می‌تواند مجموعه sequence numbers خود را به طور independent تولید کند. به عنوان مثال، اگر شما دو node دارید، یک node می‌تواند فقط اعداد فرد و دیگری فقط اعداد زوج را تولید کند. به طور کلی، شما می‌توانید برخی از بیت‌ها را در نمایش باینری sequence number ذخیره کنید تا یک unique node identifier را شامل شود، و این تضمین می‌کند که دو node مختلف هرگز نمی‌توانند یک sequence number یکسان را تولید کنند.
        </li>
<li>
            شما می‌توانید یک timestamp از یک time-of-day clock (physical clock) را به هر operation متصل کنید [55]. چنین timestamps sequential نیستند، اما اگر آن‌ها resolution به اندازه کافی بالایی داشته باشند، ممکن است برای total order operations کافی باشند. این واقعیت در روش last write wins conflict resolution استفاده می‌شود (به "Timestamps for ordering events" در صفحه 291 مراجعه کنید).
        </li>
<li>
            شما می‌توانید بلوک‌هایی از sequence numbers را preallocate کنید. به عنوان مثال، node A ممکن است بلوک sequence numbers از 1 تا 1000 را ادعا کند، و node B ممکن است ادعا کند
    </li>
</ul></div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0366</div>
            </div>
        </div>
        <!-- Page 0367 -->
        <div class="chapter" id="page-0367">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<h4>viii. It is possible to make physical clock timestamps consistent with causality</h4>
<p>
        ممکن است که physical clock timestamps را با causality سازگار کرد: در "Synchronized clocks for global snapshots" در صفحه 294 ما در مورد Spanner گوگل بحث کردیم، که clock skew مورد انتظار را تخمین می‌زند و قبل از commit کردن یک write، interval عدم اطمینان را انتظار می‌کشد. این روش تضمین می‌کند که به یک transaction که به صورت causal later شده است، یک timestamp بزرگتر داده می‌شود. با این حال، بیشتر clocks نمی‌توانند metric عدم اطمینان مورد نیاز را ارائه دهند.
    </p>
<p>
        the block از 1001 تا 2000. سپس هر node می‌تواند به طور مستقل sequence numbers را از block خود اختصاص دهد، و زمانی که supply از sequence numbers شروع به کم شدن می‌کند، یک block جدید اختصاص دهد.
    </p>
<p>
        این سه گزینه همگی عملکرد بهتری دارند و مقیاس‌پذیرتر از push کردن تمام operations از طریق یک leader واحد که یک counter را افزایش می‌دهد، هستند. آن‌ها یک sequence number منحصر به فرد و تقریباً افزایشی را برای هر operation تولید می‌کنند. با این حال، همه آن‌ها یک مشکل دارند: sequence numbers که تولید می‌کنند با causality سازگار نیستند.
    </p>
<p>
        مشکلات causality رخ می‌دهد زیرا این sequence number generators به درستی ordering از operations در سراسر nodesهای مختلف را capture نمی‌کنند:
    </p>
<ul>
<li>
            هر node ممکن است تعداد متفاوتی از operations را در هر ثانیه پردازش کند. بنابراین، اگر یک node اعداد زوج و دیگری اعداد فرد را تولید کند، counter برای اعداد زوج ممکن است از counter برای اعداد فرد عقب بماند، یا بالعکس. اگر شما یک operation با شماره فرد و یک operation با شماره زوج دارید، شما نمی‌توانید با دقت بگویید کدام یک به صورت causal اول اتفاق افتاده است.
        </li>
<li>
            Timestamps از physical clocks، subject to clock skew هستند، که می‌تواند آن‌ها را با causality ناسازگار کند. به عنوان مثال، به شکل 8-3 مراجعه کنید، که سناریویی را نشان می‌دهد که در آن به یک operation که به صورت causal later اتفاق افتاده است، در واقع یک timestamp کمتری اختصاص داده شد.viii
        </li>
<li>
            در مورد block allocator، ممکن است به یک operation یک sequence number در محدوده 1001 تا 2000 داده شود، و به یک operation که به صورت causal later شده است، ممکن است یک عدد در محدوده 1 تا 1000 داده شود. در اینجا، دوباره، sequence number با causality ناسازگار است.
        </li>
</ul>
<h4>Lamport timestamps</h4>
<p>
        اگرچه سه sequence number generators که تازه توضیح داده شدند، با causality ناسازگار هستند، اما در واقع یک روش ساده برای تولید sequence numbers وجود دارد که با causality سازگار است. این روش، Lamport timestamp نامیده می‌شود، که در سال 1978 توسط Leslie Lamport [56] پیشنهاد شد، که اکنون یکی از مقالات پر استناد در زمینه سیستم‌های distributed است.
    </p>
<p>
        استفاده از Lamport timestamps در شکل 9-8 نشان داده شده است. هر node یک unique identifier دارد، و هر node یک counter از تعداد operations که پردازش کرده است، نگهداری می‌کند. سپس Lamport timestamp به سادگی یک جفت (counter, node ID) است. Two
    </p>
<p>
        Ordering Guarantees | 345
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0367</div>
            </div>
        </div>
        <!-- Page 0368 -->
        <div class="chapter" id="page-0368">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        nodes ممکن است گاهی اوقات مقدار counter یکسانی داشته باشند، اما با inclusion از node ID در timestamp، هر timestamp منحصر به فرد می‌شود.
    </p>
<figure>
<img alt="شکل 9-8" src="figure9-8.png" style="max-width: 100%;"/>
<figcaption>
            شکل 9-8. Lamport timestamps یک total ordering را که با causality سازگار است، فراهم می‌کنند.
        </figcaption>
</figure>
<p>
        یک Lamport timestamp هیچ ارتباطی با یک physical time-of-day clock ندارد، اما total ordering را فراهم می‌کند: اگر شما دو timestamps دارید، آن که دارای counter value بزرگتری است، timestamp بزرگتر است؛ اگر counter values یکسان باشند، آن که دارای node ID بزرگتری است، timestamp بزرگتر است.
    </p>
<p>
        تا کنون این description اساساً همانند counterهای even/odd که در بخش قبل توضیح داده شد، است. ایده کلیدی در مورد Lamport timestamps، که آن‌ها را با causality سازگار می‌کند، به شرح زیر است: هر node و هر client، maximum counter value که تا کنون دیده است را پیگیری می‌کند، و آن maximum را در هر request لحاظ می‌کند. هنگامی که یک node یک request یا response با یک maximum counter value بزرگتر از counter value خود دریافت می‌کند، فوراً counter خود را به آن maximum افزایش می‌دهد.
    </p>
<p>
        این در شکل 9-8 نشان داده شده است، جایی که client A یک counter value از 5 را از node 2 دریافت می‌کند، و سپس آن maximum از 5 را به node 1 ارسال می‌کند. در آن زمان، counter node 1 فقط 1 بود، اما بلافاصله به 5 منتقل شد، بنابراین operation بعدی یک counter value افزایشی از 6 داشت.
    </p>
<p>
        تا زمانی که maximum counter value همراه با هر operation منتقل شود، این scheme تضمین می‌کند که ordering از Lamport timestamps با causality سازگار است، زیرا هر causal dependency منجر به یک timestamp افزایش یافته می‌شود.
    </p>
<p>
        Lamport timestamps گاهی با version vectors اشتباه گرفته می‌شوند، که ما در "Detecting Concurrent Writes" در صفحه 184 دیدیم. اگرچه برخی شباهت‌ها وجود دارد، اما آن‌ها هدف متفاوتی دارند: version vectors می‌توانند تشخیص دهند که آیا دو operations concurrent هستند یا اینکه آیا یکی به صورت causal به دیگری وابسته است، در حالی که Lamport timestamps همیشه یک total ordering را اعمال می‌کنند. از total ordering از Lamport time-
    </p>
<p>
        346 | Chapter 9: Consistency and Consensus
    </p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 368" src="page_0368/image_1.png"/></div>
</div>
                <div class="page-number">صفحه 0368</div>
            </div>
        </div>
        <!-- Page 0369 -->
        <div class="chapter" id="page-0369">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        estamps، شما نمی‌توانید بگویید که آیا دو operations concurrent هستند یا اینکه آیا آن‌ها به صورت causal وابسته هستند. مزیت Lamport timestamps نسبت به version vectors این است که فشرده‌تر هستند.
    </p>
<h4>Timestamp ordering is not sufficient</h4>
<p>
        اگرچه Lamport timestamps یک total order از operations را تعریف می‌کنند که با causality سازگار است، اما آن‌ها برای حل بسیاری از مشکلات رایج در سیستم‌های distributed کاملاً کافی نیستند.
    </p>
<p>
        به عنوان مثال، یک سیستمی را در نظر بگیرید که نیاز دارد اطمینان حاصل کند که یک username به طور منحصر به فرد یک user account را شناسایی می‌کند. اگر دو user به طور concurrent سعی کنند یک account را با همان username ایجاد کنند، یکی از این دو باید موفق شود و دیگری باید شکست بخورد. (ما قبلاً در "The leader and the lock" در صفحه 301 به این مشکل اشاره کردیم.)
    </p>
<p>
        در نگاه اول، به نظر می‌رسد که یک total ordering از operations (به عنوان مثال، با استفاده از Lamport timestamps) باید برای حل این مشکل کافی باشد: اگر دو account با همان username ایجاد شوند، یکی را با timestamp کمتری به عنوان برنده انتخاب کنید (کسی که username را first گرفت)، و اجازه دهید آن که timestamp بزرگتری دارد، شکست بخورد.
        از آنجایی که timestamps به طور total ordered هستند، این مقایسه همیشه معتبر است.
    </p>
<p>
        این رویکرد برای تعیین برنده پس از fact کار می‌کند: هنگامی که شما تمام operations ایجاد username را در سیستم جمع‌آوری کردید، می‌توانید timestamps آن‌ها را مقایسه کنید. با این حال، هنگامی که یک node، requestی را از یک user برای ایجاد یک username دریافت کرده است، و نیاز دارد که همین الان تصمیم بگیرد که آیا request باید موفق شود یا شکست بخورد، کافی نیست. در آن لحظه، node نمی‌داند که آیا node دیگری به طور concurrent در حال ایجاد یک account با همان username است، و چه timestampی ممکن است آن node دیگر به operation اختصاص دهد.
    </p>
<p>
        به منظور اطمینان از اینکه هیچ node دیگری در حال ایجاد یک account با همان username و یک timestamp کمتر نیست، شما باید با هر node دیگری بررسی کنید تا ببینید چه کاری انجام می‌دهد [56]. اگر یکی از nodesهای دیگر به دلیل یک network problem شکست خورده یا قابل دسترسی نباشد، این سیستم متوقف خواهد شد.
        این نوع سیستم fault-tolerant که ما نیاز داریم، نیست.
    </p>
<p>
        مشکل در اینجا این است که total order از operations فقط پس از جمع‌آوری تمام operations ظاهر می‌شود. اگر یک node دیگر، برخی از operations را تولید کرده باشد، اما شما هنوز نمی‌دانید آن‌ها چه هستند، شما نمی‌توانید ordering نهایی از operations را ایجاد کنید: operations ناشناخته از node دیگر ممکن است نیاز داشته باشند که در موقعیت‌های مختلف در total order درج شوند.
    </p>
<p>
        در نتیجه: به منظور پیاده‌سازی چیزی مانند یک uniqueness constraint برای usernames، داشتن یک total ordering از operations کافی نیست - شما همچنین باید بدانید که آن order چه زمانی نهایی می‌شود. اگر شما یک operation برای ایجاد یک username دارید، و شما مطمئن هستید که هیچ node دیگری نمی‌تواند یک claim برای همان username را قبل از operation شما در total order درج کند، پس شما می‌توانید با خیال راحت declare کنید که operation موفقیت‌آمیز است.
    </p>
<p>
        Ordering Guarantees | 347
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0369</div>
            </div>
        </div>
        <!-- Page 0370 -->
        <div class="chapter" id="page-0370">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<h4>ix. The term atomic broadcast</h4>
<p>
        اصطلاح atomic broadcast سنتی است، اما بسیار گیج‌کننده است زیرا با سایر موارد استفاده از کلمه atomic ناسازگار است: هیچ ارتباطی با atomicity در ACID transactions ندارد و فقط به طور غیرمستقیم با atomic operations (به معنای multi-threaded programming) یا atomic registers (linearizable storage) مرتبط است. اصطلاح total order multicast یک مترادف دیگر است.
    </p>
<p>
        این ایده که بدانید چه زمانی total order شما نهایی شده است، در موضوع total order broadcast capture می‌شود.
    </p>
<h4>Total Order Broadcast</h4>
<p>
        اگر برنامه شما فقط روی یک CPU core اجرا شود، تعریف یک total ordering از operations آسان است: این به سادگی ترتیبی است که آن‌ها توسط CPU اجرا شده‌اند. با این حال، در یک سیستم distributed، اینکه همه nodes در مورد total ordering یکسانی از operations توافق کنند، دشوار است. در بخش قبل ما در مورد ordering توسط timestamps یا sequence numbers بحث کردیم، اما دریافتیم که به اندازه single-leader replication قدرتمند نیست (اگر شما از timestamp ordering برای پیاده‌سازی یک uniqueness constraint استفاده کنید، شما نمی‌توانید هیچ faultی را تحمل کنید).
    </p>
<p>
        همانطور که بحث شد، single-leader replication یک total order از operations را با انتخاب یک node به عنوان leader و sequencing تمام operations بر روی یک CPU core واحد در leader تعیین می‌کند. سپس چالش این است که چگونه سیستم را مقیاس‌پذیر کنیم اگر throughput بزرگتر از throughputی باشد که یک leader واحد می‌تواند handle کند، و همچنین چگونه failover را در صورت failure leader handle کنیم (به "Handling Node Outages" در صفحه 156 مراجعه کنید). در the distributed systems literature، این مشکل به عنوان total order broadcast یا atomic broadcast [25, 57, 58].ix شناخته می‌شود.
    </p>
<h5>Scope of ordering guarantee</h5>
<p>
        Partitioned databases با یک single leader per partition اغلب ordering را فقط per partition حفظ می‌کنند، که به این معنی است که آن‌ها نمی‌توانند consistency guarantees (به عنوان مثال، consistent snapshots، foreign key references) را در سراسر partitions ارائه دهند. Total ordering در سراسر تمام partitions امکان‌پذیر است، اما به هماهنگی اضافی نیاز دارد [59].
    </p>
<p>
        Total order broadcast معمولاً به عنوان یک protocol برای تبادل messages بین nodes توصیف می‌شود. به طور غیررسمی، مستلزم آن است که دو safety properties همیشه باید برآورده شوند:
    </p>
<ul>
<li>Reliable delivery
            <p>
                هیچ message‌ای از دست نمی‌رود: اگر یک message به یک node تحویل داده شود، به همه nodes تحویل داده می‌شود.
            </p>
</li>
<li>Totally ordered delivery
            <p>
                Messages به هر node به همان ترتیب تحویل داده می‌شوند.
            </p>
</li>
</ul>
<p>
        یک algorithm صحیح برای total order broadcast باید اطمینان حاصل کند که reliability و ordering properties همیشه برآورده می‌شوند، حتی اگر یک node یا شبکه faulty باشد. Of
    </p>
<p>
        348 | Chapter 9: Consistency and Consensus
    </p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 370" src="page_0370/image_1.png"/></div>
</div>
                <div class="page-number">صفحه 0370</div>
            </div>
        </div>
        <!-- Page 0371 -->
        <div class="chapter" id="page-0371">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        البته، messages در طول network interruption تحویل داده نمی‌شوند، اما یک algorithm می‌تواند دوباره تلاش کند تا messages در نهایت هنگامی که شبکه تعمیر شد، به مقصد برسند (و سپس آن‌ها همچنان باید به ترتیب صحیح تحویل داده شوند).
    </p>
<h4>Using total order broadcast</h4>
<p>
        Consensus services مانند ZooKeeper و etcd در واقع total order broadcast را پیاده‌سازی می‌کنند. این واقعیت یک اشاره است که یک ارتباط قوی بین total order broadcast و consensus وجود دارد، که ما بعداً در این فصل به آن خواهیم پرداخت.
    </p>
<p>
        Total order broadcast دقیقاً همان چیزی است که شما برای database replication نیاز دارید: اگر هر message نشان‌دهنده یک write به database باشد، و هر replica، همان writes را به همان ترتیب پردازش کند، پس replicas با یکدیگر consistent باقی می‌مانند (جدا از هر گونه temporary replication lag). این اصل به عنوان state machine replication [60] شناخته می‌شود، و ما در فصل 11 به آن باز خواهیم گشت.
    </p>
<p>
        به طور مشابه، total order broadcast می‌تواند برای پیاده‌سازی serializable transactions استفاده شود: همانطور که در "Actual Serial Execution" در صفحه 252 بحث شد، اگر هر message نشان‌دهنده یک deterministic transaction باشد که باید به عنوان یک stored procedure اجرا شود، و اگر هر node آن messages را به همان ترتیب پردازش کند، سپس partitions و replicas از database با یکدیگر consistent نگه داشته می‌شوند [61].
    </p>
<p>
        یک جنبه مهم از total order broadcast این است که order در زمان تحویل messages ثابت می‌شود: به یک node اجازه داده نمی‌شود که به صورت retroactively یک message را در یک موقعیت قبلی در order وارد کند، اگر messages بعدی قبلاً تحویل داده شده باشند. این واقعیت، total order broadcast را قوی‌تر از timestamp ordering می‌کند.
    </p>
<p>
        یک راه دیگر برای نگاه کردن به total order broadcast این است که آن را به عنوان یک راه برای ایجاد یک log (همانطور که در یک replication log، transaction log، یا write-ahead log) می‌دانیم: تحویل یک message مانند اضافه کردن به log است. از آنجایی که همه nodes باید همان messages را به همان ترتیب تحویل دهند، همه nodes می‌توانند log را بخوانند و همان sequence از messages را ببینند.
    </p>
<p>
        Total order broadcast همچنین برای پیاده‌سازی یک lock service که fencing tokens را فراهم می‌کند، مفید است ("Fencing tokens" در صفحه 303 را ببینید). هر درخواست برای به دست آوردن lock به عنوان یک message به log اضافه می‌شود، و همه messages به ترتیب متوالی در ترتیبی که در log ظاهر می‌شوند، شماره‌گذاری می‌شوند. سپس sequence number می‌تواند به عنوان یک fencing token عمل کند، زیرا به صورت monotonically increasing است. در ZooKeeper، این sequence number، zxid [15] نامیده می‌شود.
    </p>
<p>
        Ordering Guarantees | 349
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0371</div>
            </div>
        </div>
        <!-- Page 0372 -->
        <div class="chapter" id="page-0372">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<h4>x. In a formal sense, a linearizable read-write register</h4>
<p>
        از نظر رسمی، یک linearizable read-write register یک مسئله "آسان‌تر" است. Total order broadcast معادل consensus [67] است، که هیچ راه‌حل deterministic در asynchronous crash-stop model ندارد [68]، در حالی که یک linearizable read-write register را می‌توان در همان model سیستم پیاده‌سازی کرد [23, 24, 25]. با این حال، پشتیبانی از atomic operations مانند compare-and-set یا increment-and-get در یک register، آن را معادل consensus [28] می‌کند. بنابراین، مشکلات consensus و یک linearizable register ارتباط نزدیکی با هم دارند.
    </p>
<h4>xi. If you don’t wait</h4>
<p>
        اگر شما منتظر نمانید، اما write را بلافاصله پس از اینکه enqueued شد، acknowledge کنید، شما چیزی شبیه به memory consistency model از پردازنده‌های multi-core x86 [43] را دریافت می‌کنید. آن model نه linearizable است و نه sequentially consistent.
    </p>
<h4>Implementing linearizable storage using total order broadcast</h4>
<p>
        همانطور که در شکل 9-4 نشان داده شده است، در یک سیستم linearizable یک total order از operations وجود دارد. آیا این بدان معناست که linearizability همان total order broadcast است؟ کاملاً نه، اما ارتباط نزدیکی بین این دو وجود دارد.x
    </p>
<p>
        Total order broadcast asynchronous است: تضمین می‌شود که messages به طور reliable به ترتیب ثابت تحویل داده می‌شوند، اما هیچ تضمینی در مورد زمان تحویل یک message وجود ندارد (بنابراین یک دریافت‌کننده ممکن است از دیگران عقب بماند). در مقابل، linearizability یک recency guarantee است: تضمین می‌شود که یک read آخرین مقدار نوشته شده را می‌بیند.
    </p>
<p>
        با این حال، اگر شما total order broadcast دارید، می‌توانید linearizable storage را بر روی آن بسازید. به عنوان مثال، شما می‌توانید اطمینان حاصل کنید که usernames به طور منحصر به فرد user accounts را شناسایی می‌کنند.
        تصور کنید که برای هر username ممکن، شما می‌توانید یک linearizable register با یک atomic compare-and-set operation داشته باشید. هر register در ابتدا مقدار null (نشان‌دهنده این که username گرفته نشده است) را دارد. هنگامی که یک user می‌خواهد یک username ایجاد کند، شما یک compare-and-set operation را در register برای آن username اجرا می‌کنید، و آن را بر روی user account ID تنظیم می‌کنید، با این شرط که مقدار قبلی register null باشد. اگر چندین user سعی کنند به طور concurrent همان username را بگیرند، تنها یکی از compare-and-set operations موفق خواهد شد، زیرا دیگران مقداری غیر از null (به دلیل linearizability) را خواهند دید.
    </p>
<p>
        شما می‌توانید چنین یک linearizable compare-and-set operation را به شرح زیر با استفاده از total order broadcast به عنوان یک append-only log پیاده‌سازی کنید [62, 63]:
    </p>
<ol>
<li>Append یک message به log، که به طور موقت نشان می‌دهد usernameی را که می‌خواهید claim کنید.</li>
<li>Read the log، و منتظر بمانید تا message ای که شما اضافه کردید به شما بازگردانده شود.xi</li>
<li>Check for any messages claiming the username that you want. If the first message for your desired username is your own message, then you are successful: you can commit the username claim (perhaps by appending another message to the log) and acknowledge it to the client. If the first message for your desired username is from another user, you abort the operation.</li>
</ol>
<p>
        350 | Chapter 9: Consistency and Consensus
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0372</div>
            </div>
        </div>
        <!-- Page 0373 -->
        <div class="chapter" id="page-0373">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        از آنجایی که ورودی‌های log به همه nodes به همان ترتیب تحویل داده می‌شوند، اگر چندین write concurrent وجود داشته باشد، همه nodes در مورد اینکه کدام یک اول آمده است، توافق خواهند داشت. انتخاب first از writeهای conflicting به عنوان برنده و abort کردن موارد بعدی، تضمین می‌کند که همه nodes در مورد اینکه آیا یک write committed یا aborted شده است، توافق دارند. یک رویکرد مشابه می‌تواند برای پیاده‌سازی serializable multi-object transactions بر روی یک log استفاده شود [62].
    </p>
<p>
        در حالی که این procedure، linearizable writes را تضمین می‌کند، linearizable reads را تضمین نمی‌کند - اگر شما از یک store که به صورت asynchronous از log به‌روزرسانی می‌شود بخوانید، ممکن است stale باشد. (برای دقت، procedure توضیح داده شده در اینجا sequential consistency [47, 64] را فراهم می‌کند، که گاهی اوقات timeline consistency [65, 66] نیز نامیده می‌شود، یک guarantee کمی ضعیف‌تر از linearizability.) برای linearizable کردن reads، چند گزینه وجود دارد:
    </p>
<ul>
<li>
            شما می‌توانید reads را از طریق log با اضافه کردن یک message، خواندن log، و انجام read واقعی هنگامی که message به شما بازگردانده می‌شود، sequence کنید. موقعیت message در log، بنابراین نقطه‌ای را در زمان که read اتفاق می‌افتد، تعریف می‌کند. (Quorum reads در etcd تا حدودی مانند این عمل می‌کند [16].)
        </li>
<li>
            اگر log به شما اجازه می‌دهد موقعیت آخرین log message را به روش linearizable fetch کنید، شما می‌توانید آن موقعیت را query کنید، منتظر بمانید تا تمام entries تا آن موقعیت به شما تحویل داده شوند، و سپس read را انجام دهید. (این ایده پشت operation sync() از ZooKeeper [15] است.)
        </li>
<li>
            شما می‌توانید read خود را از یک replica انجام دهید که به صورت synchronous بر روی writes به‌روزرسانی می‌شود، و بنابراین مطمئن هستید که به روز است. (این تکنیک در chain replication استفاده می‌شود [63]؛ همچنین به "Research on Replication" در صفحه 155 مراجعه کنید.)
        </li>
</ul>
<h4>Implementing total order broadcast using linearizable storage</h4>
<p>
        بخش قبل نشان داد که چگونه یک linearizable compare-and-set operation را از total order broadcast بسازیم. ما همچنین می‌توانیم آن را برعکس کنیم، فرض کنیم که linearizable storage داریم، و نشان دهیم که چگونه total order broadcast را از آن بسازیم.
    </p>
<p>
        ساده‌ترین راه این است که فرض کنید شما یک linearizable register دارید که یک integer را ذخیره می‌کند و یک atomic increment-and-get operation دارد [28]. یا، یک atomic compare-and-set operation نیز این کار را انجام می‌دهد.
    </p>
<p>
        این algorithm ساده است: برای هر messageی که شما می‌خواهید از طریق total order broadcast ارسال کنید، شما integer linearizable را increment-and-get می‌کنید، و سپس مقدار حاصل از register را به عنوان یک sequence number به message متصل می‌کنید. سپس شما می‌توانید message را به تمام nodes ارسال کنید (ارسال مجدد هرگونه messages از دست رفته)، و دریافت‌کنندگان messages را به ترتیب sequence number تحویل خواهند داد.
    </p>
<p>
        توجه داشته باشید که برخلاف Lamport timestamps، اعدادی که شما از incrementing the linearizable register دریافت می‌کنید، یک sequence بدون gap تشکیل می‌دهند. بنابراین، اگر یک node، message 4 را تحویل داده است و یک message ورودی با sequence number 6 دریافت می‌کند، می‌داند که باید منتظر message 5 بماند تا بتواند message 6 را تحویل دهد. همین مورد برای
    </p>
<p>
        Ordering Guarantees | 351
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0373</div>
            </div>
        </div>
        <!-- Page 0374 -->
        <div class="chapter" id="page-0374">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        with Lamport timestamps—در واقع، این تفاوت اصلی بین total order broadcast و timestamp ordering است.
    </p>
<p>
        چقدر سخت می‌تواند باشد که یک integer linearizable را با یک atomic increment-and-get operation بسازیم؟ طبق معمول، اگر همه چیز هرگز شکست نمی‌خورد، این کار آسان خواهد بود: شما می‌توانید آن را فقط در یک variable در یک node نگه دارید. مشکل در handling این وضعیت است که network connections به آن node قطع می‌شوند، و بازیابی مقدار زمانی که آن node دچار failure می‌شود [59]. به طور کلی، اگر شما به اندازه کافی در مورد linearizable sequence number generators فکر کنید، شما ناگزیر به یک consensus algorithm می‌رسید.
    </p>
<p>
        این تصادفی نیست: می‌توان ثابت کرد که یک linearizable compare-and-set (یا increment-and-get) register و total order broadcast هر دو معادل consensus [28, 67] هستند. یعنی اگر شما می‌توانید یکی از این مشکلات را حل کنید، شما می‌توانید آن را به یک راه‌حل برای دیگران تبدیل کنید. این یک insight بسیار عمیق و شگفت‌انگیز است!
    </p>
<p>
        وقت آن است که در نهایت مشکل consensus را مستقیماً حل کنیم، که این کار را در بقیه این فصل انجام خواهیم داد.
    </p>
<h4>Distributed Transactions and Consensus</h4>
<p>
        Consensus یکی از مهم‌ترین و اساسی‌ترین مشکلات در distributed computing است. در ظاهر، ساده به نظر می‌رسد: به طور غیررسمی، هدف این است که چندین node در مورد چیزی توافق کنند. شما ممکن است فکر کنید که این نباید خیلی سخت باشد.
    </p>
<p>
        متأسفانه، بسیاری از سیستم‌های خراب در این باور اشتباه ساخته شده‌اند که این مشکل حل آن آسان است.
    </p>
<p>
        اگرچه consensus بسیار مهم است، اما بخش مربوط به آن در این کتاب دیر ظاهر می‌شود زیرا این موضوع کاملاً ظریف است، و قدردانی از ظرافت‌ها به برخی دانش قبلی نیاز دارد. حتی در جامعه تحقیقاتی آکادمیک، درک consensus تنها به تدریج در طول دهه‌ها متبلور شد، با سوء تفاهم‌های بسیاری در طول مسیر. اکنون که ما در مورد replication (فصل 5)، transactions (فصل 7)، system models (فصل 8)، linearizability، و total order broadcast (این فصل) بحث کرده‌ایم، ما در نهایت آماده هستیم تا مشکل consensus را حل کنیم.
    </p>
<p>
        تعدادی از موقعیت‌ها وجود دارد که در آن‌ها برای nodes مهم است که توافق کنند. به عنوان مثال:
    </p>
<ul>
<li>Leader election
            <p>
                در یک database با single-leader replication، همه nodes نیاز دارند که در مورد اینکه کدام node leader است، توافق کنند. اگر برخی از nodes به دلیل یک network fault نمی‌توانند با دیگران ارتباط برقرار کنند، موقعیت leadership ممکن است مورد مناقشه قرار گیرد. در این حالت، consensus برای جلوگیری از یک failover بد، که منجر به یک split brain situation می‌شود که در آن دو nodes هر دو معتقدند که خودشان leader هستند (به "Handling Node Outages" در صفحه 156 مراجعه کنید)، مهم است. اگر دو leader وجود داشت، آن‌ها هر دو writes را قبول می‌کردند و داده‌های آن‌ها واگرا می‌شد، که منجر به inconsistency و data loss می‌شود.
            </p>
</li>
</ul>
<p>
        352 | Chapter 9: Consistency and Consensus
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0374</div>
            </div>
        </div>
        <!-- Page 0375 -->
        <div class="chapter" id="page-0375">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<h4>xii. Atomic commit</h4>
<p>
        Atomic commit به طور متفاوتی از consensus فرموله شده است: یک atomic transaction فقط در صورتی می‌تواند commit کند که همه شرکت‌کنندگان به commit رأی دهند، و اگر هر شرکت‌کننده‌ای نیاز به abort داشته باشد، باید abort کند. به consensus اجازه داده می‌شود که در مورد هر مقداری که توسط یکی از شرکت‌کنندگان پیشنهاد می‌شود، تصمیم بگیرد. با این حال، atomic commit و consensus به یکدیگر قابل تقلیل هستند [70, 71]. Nonblocking atomic commit از consensus دشوارتر است - به "Three-phase commit" در صفحه 359 مراجعه کنید.
    </p>
<h4>Atomic commit</h4>
<p>
        در یک database که از transactions spanning several nodes یا partitions پشتیبانی می‌کند، ما این مشکل را داریم که یک transaction ممکن است در برخی از nodes شکست بخورد اما در دیگران موفق شود. اگر ما می‌خواهیم atomicity transaction را حفظ کنیم (به معنای ACID؛ به "Atomicity" در صفحه 223 مراجعه کنید)، ما باید همه nodes را وادار کنیم تا در مورد نتیجه transaction توافق کنند: یا همه آن‌ها abort/roll back (اگر مشکلی پیش بیاید) یا همه آن‌ها commit (اگر هیچ مشکلی پیش نیاید). این نمونه از consensus به عنوان atomic commit problemxii شناخته می‌شود.
    </p>
<h4>The Impossibility of Consensus</h4>
<p>
        شما ممکن است در مورد FLP result [68] شنیده باشید - نام‌گذاری شده پس از نویسندگان Fischer, Lynch, and Paterson - که ثابت می‌کند که هیچ الگوریتمی وجود ندارد که همیشه قادر به رسیدن به consensus باشد اگر خطر crash شدن یک node وجود داشته باشد. در یک سیستم distributed، ما باید فرض کنیم که nodes ممکن است crash شوند، بنابراین consensus قابل اطمینان غیرممکن است. با این حال، ما در اینجا هستیم، در مورد الگوریتم‌هایی برای دستیابی به consensus بحث می‌کنیم. اینجا چه خبر است؟
    </p>
<p>
        پاسخ این است که FLP result در asynchronous system model (به "System Model and Reality" در صفحه 306 مراجعه کنید)، یک مدل بسیار محدودکننده که یک algorithm deterministic را فرض می‌کند که نمی‌تواند از هیچ clocks یا timeouts استفاده کند، اثبات شده است. اگر به algorithm اجازه داده شود که از timeouts، یا راه‌های دیگری برای شناسایی nodes مشکوک به crash شده استفاده کند (حتی اگر سوء ظن گاهی اوقات اشتباه باشد)، پس consensus قابل حل می‌شود [67].
        حتی اجازه دادن به algorithm برای استفاده از random numbers برای دور زدن impossibility result کافی است [69].
    </p>
<p>
        بنابراین، اگرچه FLP result در مورد impossibility of consensus از اهمیت نظری زیادی برخوردار است، سیستم‌های distributed معمولاً می‌توانند در عمل به consensus دست یابند.
    </p>
<p>
        در این بخش، ما ابتدا atomic commit problem را با جزئیات بیشتری بررسی خواهیم کرد. به طور خاص، ما در مورد الگوریتم two-phase commit (2PC) بحث خواهیم کرد، که متداول‌ترین راه حل برای atomic commit است و در databases مختلف، messaging systems، و application servers پیاده‌سازی شده است. مشخص می‌شود که 2PC یک نوع از consensus algorithm است - اما یک الگوریتم خیلی خوب نیست [70, 71].
    </p>
<p>
        با یادگیری از 2PC، ما سپس به سمت الگوریتم‌های consensus بهتر، مانند آن‌هایی که در ZooKeeper (Zab) و etcd (Raft) استفاده می‌شوند، حرکت خواهیم کرد.
    </p>
<p>
        Distributed Transactions and Consensus | 353
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0375</div>
            </div>
        </div>
        <!-- Page 0376 -->
        <div class="chapter" id="page-0376">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<h4>Atomic Commit and Two-Phase Commit (2PC)</h4>
<p>
        در فصل 7 ما آموختیم که هدف از atomicity transaction، ارائه semantics ساده در مواردی است که در میانه انجام several writes مشکلی پیش می‌آید. نتیجه یک transaction، یا یک commit موفق است، که در این صورت تمام writesهای transaction پایدار می‌شوند، یا یک abort، که در این صورت تمام writesهای transaction roll back می‌شوند (یعنی لغو یا دور انداخته می‌شوند).
    </p>
<p>
        Atomicity، از transactions شکست خورده جلوگیری می‌کند تا database را با نتایج نیمه‌کاره و حالت نیمه‌به‌روزرسانی‌شده پر کنند. این امر به ویژه برای multi-object transactions (به "Single-Object and Multi-Object Operations" در صفحه 228 مراجعه کنید) و databases که secondary indexes را نگهداری می‌کنند، مهم است. هر secondary index یک data structure جداگانه از داده‌های اولیه است - بنابراین، اگر شما مقداری از داده‌ها را modify می‌کنید، تغییر مربوطه باید در secondary index نیز انجام شود. Atomicity تضمین می‌کند که secondary index با داده‌های اولیه سازگار می‌ماند (اگر index با داده‌های اولیه ناسازگار شود، خیلی مفید نخواهد بود).
    </p>
<h4>From single-node to distributed atomic commit</h4>
<p>
        برای transactions که در یک database node واحد اجرا می‌شوند، atomicity معمولاً توسط storage engine پیاده‌سازی می‌شود. هنگامی که client از database node می‌خواهد تا transaction را commit کند، database، writesهای transaction را پایدار می‌کند (معمولاً در یک write-ahead log؛ به "Making B-trees reliable" در صفحه 82 مراجعه کنید) و سپس یک commit record را به log بر روی disk اضافه می‌کند. اگر database در میانه این process crash کند، transaction از log بازیابی می‌شود زمانی که node راه‌اندازی مجدد می‌شود: اگر commit record با موفقیت قبل از crash به disk نوشته شده باشد، transaction committed در نظر گرفته می‌شود؛ اگر نه، هر گونه writes از آن transaction roll back می‌شود.
    </p>
<p>
        بنابراین، در یک node واحد، commitment transaction به طور حیاتی به ترتیبی که داده‌ها به طور durable به disk نوشته می‌شوند، بستگی دارد: ابتدا داده‌ها، سپس commit record [72]. لحظه تصمیم‌گیری کلیدی برای اینکه آیا transaction commit می‌شود یا abort، لحظه‌ای است که disk نوشتن commit record را به پایان می‌رساند: قبل از آن لحظه، هنوز هم امکان abort وجود دارد (به دلیل crash)، اما بعد از آن لحظه، transaction committed می‌شود (حتی اگر database crash کند). بنابراین، این یک device واحد است (controller از یک disk drive خاص، متصل به یک node خاص) که commit را atomic می‌کند.
    </p>
<p>
        با این حال، اگر چندین node در یک transaction درگیر باشند چه می‌شود؟ به عنوان مثال، شاید شما یک multi-object transaction در یک partitioned database، یا یک term-partitioned secondary index (که در آن index entry ممکن است در یک node متفاوت از primary data باشد؛ به "Partitioning and Secondary Indexes" در صفحه 206 مراجعه کنید) داشته باشید. بیشتر datastores distributed "NoSQL" از چنین distributed transactions پشتیبانی نمی‌کنند، اما سیستم‌های relational clustered مختلف انجام می‌دهند (به "Distributed Transactions in Practice" در صفحه 360 مراجعه کنید).
    </p>
<p>
        در این موارد، کافی نیست که به سادگی یک commit request را به تمام nodes ارسال کنید و به طور independent transaction را در هر یک commit کنید. با انجام این کار، به راحتی می‌تواند
    </p>
<p>
        354 | Chapter 9: Consistency and Consensus
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0376</div>
            </div>
        </div>
        <!-- Page 0377 -->
        <div class="chapter" id="page-0377">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        اتفاق می‌افتد که commit در برخی از nodes موفق می‌شود و در nodesهای دیگر شکست می‌خورد، که این امر ضمانت atomicity را نقض می‌کند:
    </p>
<ul>
<li>برخی از nodes ممکن است یک constraint violation یا conflict را تشخیص دهند، که باعث می‌شود یک abort ضروری شود، در حالی که سایر nodes قادر به commit شدن هستند.</li>
<li>برخی از commit requests ممکن است در شبکه از دست بروند، که در نهایت به دلیل timeout، abort می‌شوند، در حالی که other commit requests به سرانجام می‌رسند.</li>
<li>برخی از nodes ممکن است قبل از اینکه commit record به طور کامل نوشته شود، crash شوند و در بازیابی roll back شوند، در حالی که دیگران با موفقیت commit می‌شوند.</li>
</ul>
<p>
        اگر برخی از nodes transaction را commit کنند اما دیگران آن را abort کنند، nodes با یکدیگر ناسازگار می‌شوند (مانند شکل 7-3). و هنگامی که یک transaction در یک node commit شده است، نمی‌تواند دوباره بازگردانده شود اگر بعداً مشخص شود که در یک node دیگر abort شده است. به همین دلیل، یک node فقط باید هنگامی commit کند که مطمئن است که تمام nodesهای دیگر در transaction نیز قصد commit کردن را دارند.
    </p>
<p>
        یک transaction commit باید غیرقابل برگشت باشد - شما اجازه ندارید نظر خود را تغییر دهید و به صورت retroactively یک transaction را پس از commit شدن آن abort کنید. دلیل این قانون این است که هنگامی که داده‌ای commit شده است، برای دیگر transactions قابل مشاهده می‌شود، و بنابراین other clients ممکن است شروع به تکیه بر آن داده‌ها کنند؛ این اصل، پایه و اساس read committed isolation را تشکیل می‌دهد که در "Read Committed" در صفحه 234 مورد بحث قرار گرفته است. اگر به یک transaction اجازه داده شود که پس از commit شدن abort شود، هر transaction که داده‌های commit شده را می‌خواند، بر اساس داده‌هایی خواهد بود که به صورت retroactively اعلام شده‌اند که وجود نداشته‌اند - بنابراین آن‌ها نیز باید revert شوند.
        (ممکن است که اثرات یک committed transaction بعداً توسط یک transaction دیگر، compensating transaction [73, 74] خنثی شود. با این حال، از دیدگاه database، این یک transaction جداگانه است، و بنابراین هرگونه الزامات correctness cross-transaction، مشکل application است.)
    </p>
<h4>Introduction to two-phase commit</h4>
<p>
        Two-phase commit یک algorithm برای دستیابی به atomic transaction commit در سراسر multiple nodes است - یعنی، برای اطمینان از اینکه یا همه nodes commit می‌کنند یا همه nodes abort می‌کنند. این یک algorithm کلاسیک در distributed databases [13, 35, 75] است. 2PC به صورت داخلی در برخی از databases استفاده می‌شود و همچنین در قالب XA transactions [76, 77] (که به عنوان مثال توسط Java Transaction API پشتیبانی می‌شوند) یا از طریق WS-AtomicTransaction برای SOAP web services [78, 79] در دسترس applications قرار می‌گیرد.
    </p>
<p>
        The basic flow of 2PC در شکل 9-9 نشان داده شده است. به جای یک commit request واحد، مانند یک single-node transaction، process commit/abort در 2PC به دو فاز تقسیم می‌شود (از این رو نام آن).
    </p>
<p>
        Distributed Transactions and Consensus | 355
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0377</div>
            </div>
        </div>
        <!-- Page 0378 -->
        <div class="chapter" id="page-0378">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<figure>
<img alt="شکل 9-9" src="figure9-9.png" style="max-width: 100%;"/>
<figcaption>
            شکل 9-9. A successful execution of two-phase commit (2PC).
        </figcaption>
</figure>
<p>
        Don’t confuse 2PC and 2PL
        Two-phase commit (2PC) و two-phase locking (به "Two-Phase Locking (2PL)" در صفحه 257 مراجعه کنید) دو چیز بسیار متفاوت هستند. 2PC، atomic commit را در یک distributed database فراهم می‌کند، در حالی که 2PL، serializable isolation را فراهم می‌کند. برای جلوگیری از سردرگمی، بهتر است آن‌ها را به عنوان مفاهیم کاملاً جداگانه در نظر بگیریم و از شباهت نامناسب در نام‌ها صرف نظر کنیم.
    </p>
<p>
        2PC از یک component جدید استفاده می‌کند که معمولاً در single-node transactions ظاهر نمی‌شود: یک coordinator (همچنین به عنوان transaction manager شناخته می‌شود). The coordinator اغلب به عنوان یک library در داخل همان application process که درخواست transaction را دارد، پیاده‌سازی می‌شود (به عنوان مثال، در یک Java EE container تعبیه شده است)، اما می‌تواند یک process یا service جداگانه نیز باشد. نمونه‌هایی از این coordinators شامل Narayana, JOTM, BTM, یا MSDTC است.
    </p>
<p>
        یک 2PC transaction با خواندن و نوشتن داده‌ها توسط application در چندین database nodes، به طور معمول، آغاز می‌شود. ما به این database nodes، participants در transaction می‌گوییم. هنگامی که application آماده commit کردن است، the coordinator فاز 1 را شروع می‌کند: آن یک prepare request را به هر یک از nodes ارسال می‌کند، و از آن‌ها می‌پرسد که آیا آن‌ها قادر به commit کردن هستند یا خیر. سپس the coordinator، responses از participants را ردیابی می‌کند:
    </p>
<ul>
<li>
            اگر همه participants پاسخ "yes" دهند، که نشان می‌دهد آن‌ها آماده commit کردن هستند، سپس the coordinator یک commit request را در فاز 2 ارسال می‌کند، و commit در واقع اتفاق می‌افتد.
        </li>
<li>
            اگر هر یک از participants پاسخ "no" دهند، the coordinator یک abort request را در فاز 2 به همه nodes ارسال می‌کند.
        </li>
</ul>
<p>
        این process تا حدودی شبیه مراسم ازدواج سنتی در فرهنگ‌های غربی است: minister از عروس و داماد جداگانه می‌پرسد که آیا هر یک می‌خواهد با دیگری ازدواج کند، و معمولاً پاسخ "I do" را از هر دو دریافت می‌کند. After receiving both
    </p>
<p>
        356 | Chapter 9: Consistency and Consensus
    </p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 378" src="page_0378/image_1.png"/></div>
<div class="page-image"><img alt="Image from page 378" src="page_0378/image_2.png"/></div>
</div>
                <div class="page-number">صفحه 0378</div>
            </div>
        </div>
        <!-- Page 0379 -->
        <div class="chapter" id="page-0379">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        acknowledgments، minister زوج را زن و شوهر اعلام می‌کند: transaction committed می‌شود، و واقعیت خوشایند برای همه شرکت‌کنندگان پخش می‌شود. اگر bride یا groom  "yes" نگویند، مراسم abort می‌شود [73].
    </p>
<h4>A system of promises</h4>
<p>
        از این description کوتاه ممکن است مشخص نباشد که چرا two-phase commit، atomicity را تضمین می‌کند، در حالی که one-phase commit در سراسر several nodes این کار را نمی‌کند. مطمئناً prepare و commit requests می‌توانند به همان آسانی در مورد two-phase از دست بروند. چه چیزی 2PC را متفاوت می‌کند؟
    </p>
<p>
        برای درک اینکه چرا کار می‌کند، ما باید process را کمی با جزئیات بیشتری بررسی کنیم:
    </p>
<ol>
<li>هنگامی که application می‌خواهد یک distributed transaction را آغاز کند، یک transaction ID را از the coordinator درخواست می‌کند. این transaction ID، globally unique است.</li>
<li>application، یک single-node transaction را در هر یک از participants آغاز می‌کند، و globally unique transaction ID را به single-node transaction متصل می‌کند. همه reads و writes در یکی از این single-node transactions انجام می‌شوند. اگر در این مرحله مشکلی پیش بیاید (به عنوان مثال، یک node crash می‌کند یا یک request timeout می‌شود)، the coordinator یا هر یک از participants می‌توانند abort کنند.</li>
<li>هنگامی که application آماده commit کردن است، the coordinator یک prepare request را به تمام participants، که با global transaction ID برچسب‌گذاری شده است، ارسال می‌کند. اگر هر یک از این requests شکست بخورد یا timeout شود، the coordinator یک abort request را برای آن transaction ID به تمام participants ارسال می‌کند.</li>
<li>هنگامی که یک participant، prepare request را دریافت می‌کند، اطمینان حاصل می‌کند که می‌تواند transaction را تحت هر شرایطی به طور قطعی commit کند. این شامل نوشتن تمام transaction data بر روی disk (یک crash، یک power failure، یا تمام شدن فضای disk، یک بهانه قابل قبول برای امتناع از commit کردن در آینده نیست)، و بررسی هر گونه conflicts یا constraint violations. با پاسخ "yes" به the coordinator، node promise می‌دهد که transaction را بدون error commit کند، اگر درخواست شود. به عبارت دیگر، the participant از حق abort کردن transaction دست می‌کشد، اما بدون اینکه واقعاً آن را commit کند.</li>
<li>هنگامی که the coordinator responses را به تمام prepare requests دریافت کرد، یک تصمیم قطعی در مورد commit کردن یا abort کردن transaction (commit کردن فقط در صورتی که همه participants به "yes" رأی داده باشند) می‌گیرد. The coordinator باید آن تصمیم را به transaction log خود بر روی disk بنویسد تا بداند در چه جهتی تصمیم گرفته است در صورتی که متعاقباً crash شود. این، commit point نامیده می‌شود.</li>
<li>هنگامی که تصمیم the coordinator به disk نوشته شد، commit یا abort request به تمام participants ارسال می‌شود. اگر این request شکست بخورد یا timeout شود، the coordinator باید برای همیشه retry کند تا موفق شود. دیگر بازگشتی وجود ندارد: اگر تصمیم این بود که commit کند، آن تصمیم باید اعمال شود، مهم نیست که چه تعداد retry طول می‌کشد. اگر یک participant در این بین crash کرده باشد، transaction خواهد شد
    </li>
<p>
        Distributed Transactions and Consensus | 357
    </p>
</ol></div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0379</div>
            </div>
        </div>
        <!-- Page 0380 -->
        <div class="chapter" id="page-0380">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        mitted در هنگام بازیابی - از آنجایی که participant به "yes" رأی داده است، نمی‌تواند از commit کردن در هنگام بازیابی خودداری کند.
    </p>
<p>
        بنابراین، protocol شامل دو "points of no return" حیاتی است: هنگامی که یک participant به "yes" رأی می‌دهد، promise می‌دهد که قطعا ًبعداً قادر به commit کردن خواهد بود (اگرچه the coordinator همچنان ممکن است انتخاب کند که abort کند)؛ و هنگامی که the coordinator تصمیم می‌گیرد، آن تصمیم غیرقابل برگشت است. آن promises، atomicity از 2PC را تضمین می‌کنند. (Single-node atomic commit، این دو رویداد را در یک مورد تجمیع می‌کند: نوشتن commit record به transaction log.)
    </p>
<p>
        بازگشت به تشبیه ازدواج، قبل از گفتن "I do"، شما و bride/groom شما آزادی دارید که transaction را با گفتن "No way!" (یا چیزی از این قبیل) abort کنید. با این حال، پس از گفتن "I do"، شما نمی‌توانید آن statement را پس بگیرید. اگر شما پس از گفتن "I do" غش کردید و شما نشنیدید که minister کلمات "You are now husband and wife" را می‌گوید، این واقعیت را تغییر نمی‌دهد که transaction committed شده است.
        هنگامی که شما بعداً consciousness را بازیابی می‌کنید، شما می‌توانید متوجه شوید که آیا شما ازدواج کرده‌اید یا نه با query کردن minister برای status از global transaction ID خود، یا شما می‌توانید منتظر the minister’s next retry از commit request (از آنجایی که retries در طول دوره unconsciousness شما ادامه خواهد داشت) شوید.
    </p>
<h4>Coordinator failure</h4>
<p>
        ما در مورد این بحث کردیم که اگر یکی از participants یا شبکه در طول 2PC شکست بخورد چه اتفاقی می‌افتد: اگر هر یک از prepare requests شکست بخورند یا timeout شوند، the coordinator transaction را abort می‌کند؛ اگر هر یک از commit یا abort requests شکست بخورند، the coordinator آن‌ها را برای همیشه retry می‌کند. با این حال، مشخص نیست که اگر the coordinator crash کند چه اتفاقی می‌افتد.
    </p>
<p>
        اگر the coordinator قبل از ارسال prepare requests شکست بخورد، یک participant می‌تواند با خیال راحت transaction را abort کند. اما هنگامی که the participant یک prepare request را دریافت کرده و به "yes" رأی داده است، دیگر نمی‌تواند به طور unilateral abort کند - باید منتظر بماند تا از the coordinator بشنود که آیا transaction commit شده است یا abort شده است. اگر the coordinator crash کند یا شبکه در این مرحله شکست بخورد، the participant نمی‌تواند کاری جز انتظار انجام دهد. A participant’s transaction در این state، in doubt یا uncertain نامیده می‌شود.
    </p>
<p>
        این وضعیت در شکل 9-10 نشان داده شده است. در این مثال خاص، the coordinator در واقع تصمیم به commit کردن گرفت، و database 2 commit request را دریافت کرد. با این حال، the coordinator crash کرد قبل از اینکه بتواند commit request را به database 1 ارسال کند، و بنابراین database 1 نمی‌داند که آیا commit کند یا abort. حتی یک timeout در اینجا کمکی نمی‌کند: اگر database 1 به طور unilateral پس از یک timeout abort کند، در نهایت با database 2 که commit کرده است، ناسازگار خواهد شد. به طور مشابه، commit کردن unilateral نیز ایمن نیست، زیرا یک participant دیگر ممکن است abort کرده باشد.
    </p>
<p>
        358 | Chapter 9: Consistency and Consensus
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0380</div>
            </div>
        </div>
        <!-- Page 0381 -->
        <div class="chapter" id="page-0381">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<figure>
<img alt="شکل 9-10" src="figure9-10.png"/>
<figcaption>
            شکل 9-10. The coordinator crashes بعد از اینکه participants به "yes" رأی دادند. Database 1 نمی‌داند که آیا commit کند یا abort.
        </figcaption>
</figure>
<p>
        بدون شنیدن از the coordinator، the participant هیچ راهی برای دانستن اینکه آیا commit کند یا abort ندارد. در اصل، participants می‌توانند با یکدیگر ارتباط برقرار کنند تا متوجه شوند که هر participant چگونه رأی داده است و به نوعی توافق برسند، اما این بخشی از 2PC protocol نیست.
    </p>
<p>
        تنها راهی که 2PC می‌تواند تکمیل شود، انتظار برای بازیابی the coordinator است. به همین دلیل است که the coordinator باید تصمیم commit یا abort خود را به یک transaction log بر روی disk قبل از ارسال commit یا abort requests به participants بنویسد: هنگامی که the coordinator بازیابی می‌شود، status از همه in-doubt transactions را با خواندن the transaction log خود تعیین می‌کند. هر transactions که یک commit record در the coordinator’s log نداشته باشد، aborted می‌شوند. بنابراین، commit point از 2PC به یک single-node atomic commit منظم در the coordinator می‌رسد.
    </p>
<h4>Three-phase commit</h4>
<p>
        Two-phase commit به دلیل این واقعیت که 2PC می‌تواند در انتظار بازیابی the coordinator گیر کند، یک blocking atomic commit protocol نامیده می‌شود. از نظر تئوری، ممکن است یک atomic commit protocol را nonblocking کنیم، به طوری که اگر یک node شکست بخورد، گیر نکند. با این حال، عملی کردن این کار در عمل چندان ساده نیست.
    </p>
<p>
        به عنوان یک جایگزین برای 2PC، یک algorithm به نام three-phase commit (3PC) پیشنهاد شده است [13, 80]. با این حال، 3PC یک شبکه با bounded delay و nodes با bounded response times را فرض می‌کند؛ در اکثر سیستم‌های عملی با unbounded network delay و process pauses (به فصل 8 مراجعه کنید)، نمی‌تواند atomicity را تضمین کند.
    </p>
<p>
        به طور کلی، nonblocking atomic commit به یک perfect failure detector نیاز دارد [67, 71] - یعنی، یک mechanism قابل اعتماد برای گفتن اینکه آیا یک node crash کرده است یا نه. در یک شبکه با unbounded delay، یک timeout یک failure detector قابل اعتماد نیست، زیرا یک request ممکن است به دلیل یک network problem timeout شود، حتی اگر هیچ node crash نکرده باشد. به همین دلیل، 2PC همچنان مورد استفاده قرار می‌گیرد، با وجود مشکل شناخته شده با the coordinator failure.
    </p>
<p>
        Distributed Transactions and Consensus | 359
    </p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 381" src="page_0381/image_1.png"/></div>
</div>
                <div class="page-number">صفحه 0381</div>
            </div>
        </div>
        <!-- Page 0382 -->
        <div class="chapter" id="page-0382">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<h4>Distributed Transactions in Practice</h4>
<p>
        Distributed transactions، به ویژه آن‌هایی که با two-phase commit پیاده‌سازی شده‌اند، شهرت mixedی دارند. از یک طرف، آن‌ها به عنوان یک safety guarantee مهم دیده می‌شوند که در غیر این صورت دستیابی به آن دشوار خواهد بود؛ از طرف دیگر، آن‌ها به دلیل ایجاد مشکلات عملیاتی، از بین بردن performance، و promise کردن بیش از آنچه می‌توانند ارائه دهند، مورد انتقاد قرار می‌گیرند [81, 82, 83, 84]. بسیاری از cloud services، به دلیل مشکلات عملیاتی که ایجاد می‌کنند، انتخاب می‌کنند که distributed transactions را پیاده‌سازی نکنند [85, 86].
    </p>
<p>
        برخی از پیاده‌سازی‌های distributed transactions، یک performance penalty سنگین را به همراه دارند - به عنوان مثال، گزارش شده است که distributed transactions در MySQL بیش از 10 برابر کندتر از single-node transactions هستند [87]، بنابراین جای تعجب نیست که مردم توصیه می‌کنند از آن‌ها استفاده نکنید. بخش زیادی از هزینه performance که در two-phase commit وجود دارد، به دلیل disk forcing (fsync) اضافی است که برای crash recovery [88] مورد نیاز است، و network round-trips اضافی.
    </p>
<p>
        با این حال، به جای رد کردن کامل distributed transactions، ما باید آن‌ها را با جزئیات بیشتری بررسی کنیم، زیرا درس‌های مهمی از آن‌ها وجود دارد. برای شروع، ما باید در مورد آنچه که از "distributed transactions" منظورمان است، دقیق باشیم. دو نوع کاملاً متفاوت از distributed transactions اغلب با هم ترکیب می‌شوند:
    </p>
<ul>
<li>
            Database-internal distributed transactions
            <p>
                برخی از distributed databases (یعنی، databases که از replication و partitioning در پیکربندی استاندارد خود استفاده می‌کنند) از internal transactions در میان nodes از آن database پشتیبانی می‌کنند. به عنوان مثال، VoltDB و MySQL Cluster’s NDB storage engine از این internal transaction support برخوردار هستند. در این حالت، همه nodes که در transaction شرکت می‌کنند، در حال اجرای همان database software هستند.
            </p>
</li>
<li>
            Heterogeneous distributed transactions
            <p>
                در یک heterogeneous transaction، participants، دو یا چند فناوری مختلف هستند: به عنوان مثال، دو databases از vendorهای مختلف، یا حتی سیستم‌های non-database مانند message brokers. یک distributed transaction در سراسر این سیستم‌ها باید atomic commit را تضمین کند، حتی اگر سیستم‌ها ممکن است کاملاً در زیرساخت متفاوت باشند.
            </p>
</li>
</ul>
<p>
        Database-internal transactions نیازی به سازگاری با هیچ سیستم دیگری ندارند، بنابراین آن‌ها می‌توانند از هر protocol استفاده کنند و optimizations مختص آن technology خاص را اعمال کنند. به همین دلیل، database-internal distributed transactions اغلب می‌توانند به خوبی کار کنند. از سوی دیگر، transactions که technologies heterogeneous را پوشش می‌دهند، بسیار چالش برانگیزتر هستند.
    </p>
<h4>Exactly-once message processing</h4>
<p>
        Heterogeneous distributed transactions به سیستم‌های مختلف اجازه می‌دهند تا به روش‌های قدرتمندی یکپارچه شوند. به عنوان مثال، یک message از یک message queue می‌تواند به عنوان processed acknowledgment شود اگر و فقط اگر database transaction برای پردازش message بود
    </p>
<p>
        360 | Chapter 9: Consistency and Consensus
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0382</div>
            </div>
        </div>
        <!-- Page 0383 -->
        <div class="chapter" id="page-0383">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        successfully committed. This is implemented by atomically committing the message acknowledgment و database writes در یک transaction واحد. با distributed transaction support، این امکان‌پذیر است، حتی اگر message broker و database دو technology نامرتبط باشند که روی ماشین‌های مختلف اجرا می‌شوند.
    </p>
<p>
        اگر delivery message یا database transaction شکست بخورد، هر دو abort می‌شوند، و بنابراین message broker ممکن است با خیال راحت message را بعداً دوباره تحویل دهد. بنابراین، با atomically commit کردن message و side effects از processing آن، ما می‌توانیم اطمینان حاصل کنیم که message به طور موثر exactly once پردازش می‌شود، حتی اگر به چند retries قبل از موفقیت نیاز داشته باشد. The abort، هر side effects از transaction که به طور partially completed است، را دور می‌اندازد.
    </p>
<p>
        چنین یک distributed transaction تنها در صورتی امکان‌پذیر است که همه systems تحت تأثیر transaction قادر به استفاده از همان atomic commit protocol باشند، با این حال. به عنوان مثال، بگویید یک side effect از processing یک message، ارسال یک ایمیل است، و email server از two-phase commit پشتیبانی نمی‌کند: ممکن است این اتفاق بیفتد که ایمیل دو یا چند بار ارسال شود اگر processing message شکست بخورد و retried شود. اما اگر همه side effects از processing یک message در transaction abort roll back شوند، سپس گام processing می‌تواند با خیال راحت retried شود، انگار هیچ اتفاقی نیفتاده است.
    </p>
<p>
        ما در فصل 11 به موضوع exactly-once message processing باز خواهیم گشت. بیایید ابتدا به atomic commit protocol که به چنین heterogeneous distributed transactions اجازه می‌دهد، نگاهی بیندازیم.
    </p>
<h4>XA transactions</h4>
<p>
        X/Open XA (مخفف eXtended Architecture) یک standard برای پیاده‌سازی two-phase commit در سراسر heterogeneous technologies [76, 77] است. این در سال 1991 معرفی شد و به طور گسترده پیاده‌سازی شده است: XA توسط بسیاری از relational databases سنتی (از جمله PostgreSQL، MySQL، DB2، SQL Server، و Oracle) و message brokers (از جمله ActiveMQ، HornetQ، MSMQ، و IBM MQ) پشتیبانی می‌شود.
    </p>
<p>
        XA یک network protocol نیست - این فقط یک C API برای ارتباط با یک transaction coordinator است. Bindings برای این API در زبان‌های دیگر وجود دارد؛ به عنوان مثال، در دنیای Java EE applications، XA transactions با استفاده از Java Transaction API (JTA) پیاده‌سازی می‌شوند، که به نوبه خود توسط بسیاری از drivers برای databases با استفاده از Java Database Connectivity (JDBC) و drivers برای message brokers با استفاده از Java Message Service (JMS) APIs پشتیبانی می‌شود.
    </p>
<p>
        XA فرض می‌کند که application شما از یک network driver یا client library برای ارتباط با participant databases یا messaging services استفاده می‌کند. اگر driver از XA پشتیبانی می‌کند، به این معنی است که آن API XA را فراخوانی می‌کند تا متوجه شود که آیا یک operation باید بخشی از یک distributed transaction باشد - و اگر چنین است، اطلاعات لازم را به database server ارسال می‌کند. The driver همچنین callbacks را نشان می‌دهد که از طریق آن‌ها the coordinator می‌تواند از the participant بخواهد که prepare، commit، یا abort کند.
    </p>
<p>
        Distributed Transactions and Consensus | 361
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0383</div>
            </div>
        </div>
        <!-- Page 0384 -->
        <div class="chapter" id="page-0384">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        The transaction coordinator، XA API را پیاده‌سازی می‌کند. standard مشخص نمی‌کند که چگونه باید پیاده‌سازی شود، اما در عمل the coordinator اغلب به سادگی یک library است که در همان process که application صادر کننده transaction است، بارگذاری می‌شود (نه یک service جداگانه). این، participants در یک transaction را ردیابی می‌کند، responses از participants را پس از درخواست از آن‌ها برای prepare (از طریق یک callback به driver) جمع‌آوری می‌کند، و از یک log بر روی disk local برای ردیابی تصمیم commit/abort برای هر transaction استفاده می‌کند.
    </p>
<p>
        اگر application process crash کند، یا machine که application بر روی آن در حال اجرا است، از بین برود، the coordinator نیز از بین می‌رود. هر participants با transactions prepared اما uncommitted، سپس در doubt گیر می‌کنند. از آنجایی که the coordinator’s log بر روی disk local از application server قرار دارد، آن server باید راه‌اندازی مجدد شود، و the coordinator library باید log را بخواند تا outcome از commit/abort از هر transaction را بازیابی کند. فقط در این صورت است که the coordinator می‌تواند از XA callbacks از database driver استفاده کند تا از participants بخواهد که commit یا abort کنند، در صورت مناسب بودن. The database server نمی‌تواند مستقیماً با the coordinator تماس بگیرد، زیرا همه communicationها باید از طریق client library آن انجام شوند.
    </p>
<h4>Holding locks while in doubt</h4>
<p>
        چرا ما اینقدر در مورد گیر کردن یک transaction در doubt اهمیت می‌دهیم؟ آیا بقیه سیستم نمی‌توانند فقط به کار خود ادامه دهند، و transaction in-doubt را که در نهایت پاک می‌شود، نادیده بگیرند؟
    </p>
<p>
        مشکل با locking است. همانطور که در "Read Committed" در صفحه 234 بحث شد، database transactions معمولاً یک row-level exclusive lock را در هر rows که آن‌ها modify می‌کنند، می‌گیرند، تا از dirty writes جلوگیری کنند. علاوه بر این، اگر شما می‌خواهید serializable isolation، یک database با استفاده از two-phase locking، باید یک shared lock را نیز در هر rows خوانده شده توسط transaction (به "Two-Phase Locking (2PL)" در صفحه 257 مراجعه کنید) بگیرد.
    </p>
<p>
        The database نمی‌تواند آن locks را آزاد کند تا زمانی که transaction commit یا abort شود (به عنوان یک ناحیه سایه‌دار در شکل 9-9 نشان داده شده است). بنابراین، هنگام استفاده از two-phase commit، یک transaction باید locks را در طول زمانی که در doubt است، نگه دارد. اگر the coordinator crash کرده باشد و 20 دقیقه طول بکشد تا دوباره راه‌اندازی شود، آن locks به مدت 20 دقیقه نگه داشته خواهند شد. اگر the coordinator’s log به هر دلیلی به طور کامل از دست برود، آن locks برای همیشه نگه داشته خواهند شد - یا حداقل تا زمانی که این وضعیت به صورت دستی توسط یک administrator حل شود.
    </p>
<p>
        در حالی که آن locks نگه داشته می‌شوند، هیچ transaction دیگری نمی‌تواند آن rows را modify کند. بسته به database، سایر transactions ممکن است حتی از خواندن آن rows مسدود شوند.
        بنابراین، other transactions نمی‌توانند به سادگی به کار خود ادامه دهند - اگر آن‌ها می‌خواهند به همان داده‌ها دسترسی داشته باشند، مسدود خواهند شد. این می‌تواند باعث شود بخش‌های بزرگی از application شما تا زمانی که transaction in-doubt حل شود، غیرقابل دسترس شوند.
    </p>
<p>
        362 | Chapter 9: Consistency and Consensus
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0384</div>
            </div>
        </div>
        <!-- Page 0385 -->
        <div class="chapter" id="page-0385">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<h4>Recovering from coordinator failure</h4>
<p>
        از نظر تئوری، اگر the coordinator crash کند و راه‌اندازی مجدد شود، باید به طور clean state خود را از log بازیابی کند و هر گونه in-doubt transactions را حل کند. با این حال، در عمل، orphaned in-doubt transactions رخ می‌دهد [89, 90] - یعنی، transactions که the coordinator به هر دلیلی نمی‌تواند در مورد نتیجه آن تصمیم بگیرد (به عنوان مثال، به دلیل اینکه transaction log به دلیل یک software bug از دست رفته یا خراب شده است). این transactions را نمی‌توان به طور خودکار حل کرد، بنابراین آن‌ها برای همیشه در database قرار می‌گیرند، locks را نگه می‌دارند و دیگر transactions را مسدود می‌کنند.
    </p>
<p>
        حتی rebooting database servers شما این مشکل را برطرف نمی‌کند، زیرا یک پیاده‌سازی صحیح از 2PC باید locks از یک in-doubt transaction را حتی در سراسر restarts حفظ کند (در غیر این صورت، atomicity guarantee را نقض می‌کند). این یک وضعیت چسبنده است.
    </p>
<p>
        تنها راه خروج این است که یک administrator به صورت دستی تصمیم بگیرد که آیا transactions را commit کند یا roll back. The administrator باید participants از هر in-doubt transaction را بررسی کند، تعیین کند که آیا هر participant قبلاً commit کرده است یا abort کرده است، و سپس همان نتیجه را برای other participants اعمال کند. حل مشکل به طور بالقوه به تلاش دستی زیادی نیاز دارد، و به احتمال زیاد باید تحت فشار بالا و فشار زمان در طول یک production outage جدی انجام شود (در غیر این صورت، چرا the coordinator باید در چنین state بدی باشد؟).
    </p>
<p>
        بسیاری از XA implementations یک emergency escape hatch به نام heuristic decisions دارند: اجازه دادن به یک participant برای تصمیم unilateral به abort یا commit کردن یک in-doubt transaction بدون یک decision قطعی از the coordinator [76, 77, 91]. برای روشن شدن، heuristic در اینجا یک euphemism برای احتمالاً breaking atomicity است، زیرا این سیستم از promises در two-phase commit را نقض می‌کند. بنابراین، heuristic decisions فقط برای خروج از catastrophic situations در نظر گرفته شده‌اند، و نه برای استفاده منظم.
    </p>
<h4>Limitations of distributed transactions</h4>
<p>
        XA transactions مشکل واقعی و مهمی از keeping several participant data systems consistent with each other را حل می‌کنند، اما همانطور که دیده‌ایم، آن‌ها همچنین مشکلات عملیاتی عمده‌ای را معرفی می‌کنند. به طور خاص، درک کلیدی این است که the transaction coordinator، خود یک نوع از database است (که در آن transaction outcomes ذخیره می‌شوند)، و بنابراین نیاز دارد که با همان مراقبتی که با هر database مهم دیگری رفتار می‌شود، با آن برخورد شود:
    </p>
<ul>
<li>
            اگر the coordinator replicated نباشد اما فقط بر روی یک machine واحد اجرا شود، این یک single point of failure برای کل سیستم است (از آنجایی که failure آن باعث می‌شود other application servers در locks که توسط in-doubt transactions نگهداری می‌شوند، مسدود شوند). به طرز تعجب‌آوری، بسیاری از coordinator implementations به طور پیش‌فرض high available نیستند، یا فقط از rudimentary replication support برخوردار هستند.
        </li>
<li>
            بسیاری از server-side applications در یک stateless model توسعه داده می‌شوند (همانطور که توسط HTTP ترجیح داده می‌شود)، با تمام stateهای persistent که در یک database ذخیره می‌شوند، که مزیت دارد
        </li>
</ul>
<p>
        Distributed Transactions and Consensus | 363
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0385</div>
            </div>
        </div>
        <!-- Page 0386 -->
        <div class="chapter" id="page-0386">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        that application servers can be added and removed at will. با این حال، هنگامی که the coordinator بخشی از application server است، این ماهیت deployment را تغییر می‌دهد. ناگهان، the coordinator’s logs به یک بخش حیاتی از durable system state تبدیل می‌شوند - به همان اندازه مهم database خود، زیرا the coordinator logs برای بازیابی in-doubt transactions پس از یک crash مورد نیاز هستند. چنین application servers دیگر stateless نیستند.
    </p>
<ul>
<li>
            از آنجایی که XA نیاز دارد با طیف گسترده‌ای از data systems سازگار باشد، ضرورتاً یک lowest common denominator است. به عنوان مثال، نمی‌تواند deadlocks را در سراسر systemsهای مختلف تشخیص دهد (از آنجایی که این امر به یک protocol استاندارد برای systems نیاز دارد تا اطلاعات در مورد locks که هر transaction در انتظار آن است، را تبادل کنند)، و با SSI کار نمی‌کند (به "Serializable Snapshot Isolation (SSI)" در صفحه 261 مراجعه کنید)، زیرا این امر به یک protocol برای شناسایی conflicts در سراسر different systems نیاز دارد.
        </li>
<li>
            برای database-internal distributed transactions (نه XA)، limitations چندان زیاد نیستند - به عنوان مثال، یک version distributed از SSI امکان‌پذیر است. با این حال، این مشکل همچنان باقی است که برای اینکه 2PC با موفقیت یک transaction را commit کند، همه participants باید پاسخ دهند. در نتیجه، اگر هر بخشی از سیستم خراب شود، transaction نیز شکست می‌خورد. Distributed transactions بنابراین تمایل به تقویت failures دارند، که برخلاف هدف ما از ساختن fault-tolerant systems است.
        </li>
</ul>
<p>
        آیا این حقایق به این معنی است که ما باید تمام امید را برای keeping several systems consistent با یکدیگر کنار بگذاریم؟ کاملاً نه - راه‌های جایگزینی وجود دارد که به ما اجازه می‌دهد همان کار را بدون درد heterogeneous distributed transactions انجام دهیم. ما در فصل‌های 11 و 12 به این موارد باز خواهیم گشت. اما ابتدا، ما باید موضوع consensus را جمع‌بندی کنیم.
    </p>
<h4>Fault-Tolerant Consensus</h4>
<p>
        به طور غیررسمی، consensus به معنای getting several nodes است تا در مورد چیزی توافق کنند. به عنوان مثال، اگر چندین نفر به طور concurrent سعی کنند آخرین صندلی در یک هواپیما را رزرو کنند، یا همان صندلی در یک تئاتر را، یا سعی کنند یک account را با همان username ثبت کنند، سپس یک consensus algorithm می‌تواند برای تعیین اینکه کدام یک از این mutually incompatible operations باید برنده باشد، استفاده شود.
    </p>
<p>
        The consensus problem معمولاً به شرح زیر فرموله می‌شود: یک یا چند nodes ممکن است values را پیشنهاد دهند، و the consensus algorithm در مورد یکی از آن values تصمیم می‌گیرد. در مثال seat-booking، هنگامی که چندین مشتری به طور concurrent در تلاش برای خرید آخرین صندلی هستند، هر node که یک customer request را هندل می‌کند، ممکن است ID از customer را که در حال سرویس‌دهی آن است، پیشنهاد دهد، و decision نشان می‌دهد که کدام یک از آن customers صندلی را گرفت.
    </p>
<p>
        364 | Chapter 9: Consistency and Consensus
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0386</div>
            </div>
        </div>
        <!-- Page 0387 -->
        <div class="chapter" id="page-0387">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<h4>xiii. This particular variant of consensus</h4>
<p>
        This particular variant of consensus is called uniform consensus، که معادل regular consensus در asynchronous systems با unreliable failure detectors است [71]. The academic literature معمولاً به جای nodes، به processes اشاره دارد، اما ما در اینجا برای consistency با بقیه این کتاب از nodes استفاده می‌کنیم.
    </p>
<p>
        در این formalism، یک consensus algorithm باید properties زیر را برآورده کند [25]:xiii
    </p>
<ul>
<li>Uniform agreement
            <p>
                هیچ دو node متفاوت تصمیم نمی‌گیرند.
            </p>
</li>
<li>Integrity
            <p>
                هیچ node دو بار تصمیم نمی‌گیرد.
            </p>
</li>
<li>Validity
            <p>
                اگر یک node، مقدار v را تصمیم بگیرد، سپس v توسط یک node پیشنهاد شده است.
            </p>
</li>
<li>Termination
            <p>
                هر node که crash نکند، در نهایت مقداری را تصمیم می‌گیرد.
            </p>
</li>
</ul>
<p>
        The uniform agreement و integrity properties، ایده اصلی از consensus را تعریف می‌کنند: همه در مورد یک outcome یکسان تصمیم می‌گیرند، و هنگامی که شما تصمیم گرفتید، شما نمی‌توانید نظر خود را تغییر دهید. The validity property، بیشتر برای رد کردن trivial solutions وجود دارد: به عنوان مثال، شما می‌توانید یک algorithm داشته باشید که همیشه null را تصمیم می‌گیرد، مهم نیست چه چیزی پیشنهاد شده است؛ این algorithm، agreement و integrity properties را برآورده می‌کند، اما validity property را نه.
    </p>
<p>
        اگر شما در مورد fault tolerance اهمیت نمی‌دهید، سپس برآورده کردن سه property اول آسان است: شما می‌توانید فقط یک node را به عنوان "dictator" hardcode کنید، و اجازه دهید آن node تمام decisions را انجام دهد. با این حال، اگر آن یک node شکست بخورد، سپس سیستم دیگر نمی‌تواند هیچ تصمیمی بگیرد. در واقع، این همان چیزی است که ما در مورد two-phase commit دیدیم: اگر the coordinator شکست بخورد، in-doubt participants نمی‌توانند تصمیم بگیرند که آیا commit کنند یا abort.
    </p>
<p>
        The termination property، ایده fault tolerance را فرموله می‌کند. این اساساً می‌گوید که یک consensus algorithm نمی‌تواند به سادگی در اطراف بنشیند و برای همیشه هیچ کاری انجام ندهد - به عبارت دیگر، باید progress کند. حتی اگر برخی از nodes شکست بخورند، other nodes هنوز هم باید به یک decision برسند. (Termination یک liveness property است، در حالی که سه property دیگر safety properties هستند - به "Safety and liveness" در صفحه 308 مراجعه کنید.)
    </p>
<p>
        The system model of consensus فرض می‌کند که هنگامی که یک node "crashes"، ناگهان ناپدید می‌شود و هرگز برنمی‌گردد. (به جای یک software crash، تصور کنید که یک زلزله وجود دارد، و datacenter شامل node شما توسط یک landslide نابود می‌شود. شما باید فرض کنید که node شما زیر 30 فوت گل مدفون شده است و هرگز قرار نیست دوباره online شود.) در این system model، هر algorithm که باید منتظر بازیابی یک node باشد، قرار نیست بتواند termination property را برآورده کند. به طور خاص، 2PC الزامات termination را برآورده نمی‌کند.
    </p>
<p>
        Distributed Transactions and Consensus | 365
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0387</div>
            </div>
        </div>
        <!-- Page 0388 -->
        <div class="chapter" id="page-0388">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        البته، اگر همه nodes crash کنند و هیچ‌کدام از آن‌ها در حال اجرا نباشند، پس برای هر algorithm غیرممکن است که در مورد چیزی تصمیم بگیرد. یک limit برای تعداد failures وجود دارد که یک algorithm می‌تواند تحمل کند: در واقع، می‌توان ثابت کرد که هر consensus algorithm حداقل به اکثریت nodes نیاز دارد تا به درستی کار کنند تا termination را تضمین کند [67]. آن اکثریت می‌تواند با خیال راحت یک quorum را تشکیل دهد (به "Quorums for reading and writing" در صفحه 179 مراجعه کنید).
    </p>
<p>
        بنابراین، the termination property منوط به این فرض است که کمتر از نیمی از nodes crash شده‌اند یا غیرقابل دسترس هستند. با این حال، اکثر implementations از consensus اطمینان حاصل می‌کنند که safety properties - agreement, integrity، و validity - همیشه برآورده می‌شوند، حتی اگر اکثریت nodes شکست بخورند یا یک network problem شدید وجود داشته باشد [92]. بنابراین، یک large-scale outage می‌تواند سیستم را از توانایی پردازش requests متوقف کند، اما نمی‌تواند سیستم consensus را با وادار کردن آن به اتخاذ decisions نامعتبر، خراب کند.
    </p>
<p>
        اکثر consensus algorithms فرض می‌کنند که هیچ Byzantine faults وجود ندارد، همانطور که در "Byzantine Faults" در صفحه 304 بحث شد. یعنی، اگر یک node، protocol را به درستی دنبال نکند (به عنوان مثال، اگر messages متناقضی را به nodesهای مختلف ارسال کند)، ممکن است safety properties از protocol را نقض کند. این امکان وجود دارد که consensus را در برابر Byzantine faults مقاوم کنیم تا زمانی که کمتر از یک سوم از nodes، Byzantine-faulty باشند [25, 93]، اما ما فضایی برای بحث در مورد آن algorithms با جزئیات در این کتاب نداریم.
    </p>
<h4>Consensus algorithms and total order broadcast</h4>
<p>
        The best-known fault-tolerant consensus algorithms عبارتند از: Viewstamped Replication (VSR) [94, 95]، Paxos [96, 97, 98, 99]، Raft [22, 100, 101] و Zab [15, 21, 102]. شباهت‌های زیادی بین این algorithms وجود دارد، اما آن‌ها یکسان نیستند [103].
    </p>
<p>
        در این کتاب ما به جزئیات کامل algorithms مختلف نمی‌پردازیم: این کافی است که از برخی از ideas high-level که آن‌ها مشترک هستند، آگاه باشید، مگر اینکه شما در حال پیاده‌سازی یک consensus system خودتان باشید (که احتمالاً توصیه نمی‌شود - این سخت است [98, 104]).
    </p>
<p>
        Most of these algorithms در واقع مستقیماً از formal model که در اینجا توضیح داده شده است استفاده نمی‌کنند (پیشنهاد و تصمیم‌گیری در مورد یک value واحد، در حالی که satisfying agreement, integrity, validity و termination properties). در عوض، آن‌ها در مورد یک sequence از values تصمیم می‌گیرند، که آن‌ها را total order broadcast algorithms می‌کند، همانطور که قبلاً در این فصل بحث شد (به "Total Order Broadcast" در صفحه 348 مراجعه کنید).
    </p>
<p>
        به یاد داشته باشید که total order broadcast نیاز دارد که messages به طور exactly once، به همان ترتیب، به همه nodes تحویل داده شوند. اگر شما به آن فکر کنید، این معادل انجام چندین round از consensus است: در هر round، nodes message را که می‌خواهند در مرحله بعد ارسال کنند، پیشنهاد می‌دهند، و سپس در مورد message بعدی که باید در total order تحویل داده شود، تصمیم می‌گیرند [67].
    </p>
<p>
        بنابراین، total order broadcast معادل repeated rounds از consensus است (هر consensus decision مربوط به یک message delivery):
    </p>
<p>
        366 | Chapter 9: Consistency and Consensus
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0388</div>
            </div>
        </div>
        <!-- Page 0389 -->
        <div class="chapter" id="page-0389">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<ul>
<li>
            Due to the agreement property of consensus، همه nodes تصمیم می‌گیرند که همان messages را به همان ترتیب تحویل دهند.
        </li>
<li>
            Due to the integrity property، messages تکراری نمی‌شوند.
        </li>
<li>
            Due to the validity property، messages خراب نمی‌شوند و از هیچ‌جا ساخته نمی‌شوند.
        </li>
<li>
            Due to the termination property، messages گم نمی‌شوند.
        </li>
</ul>
<p>
        Viewstamped Replication, Raft، و Zab، total order broadcast را به طور مستقیم پیاده‌سازی می‌کنند، زیرا این کار کارآمدتر از انجام repeated rounds از one-value-at-a-time consensus است. در مورد Paxos، این optimization به عنوان Multi-Paxos شناخته می‌شود.
    </p>
<h4>Single-leader replication and consensus</h4>
<p>
        در فصل 5 ما در مورد single-leader replication بحث کردیم (به "Leaders and Followers" در صفحه 152 مراجعه کنید)، که تمام writes را به leader می‌گیرد و آن‌ها را به فالوئرها به همان ترتیب اعمال می‌کند، بنابراین replicas را به‌روز نگه می‌دارد. آیا این اساساً total order broadcast نیست؟ چطور شد که ما در فصل 5 مجبور نبودیم در مورد consensus نگران باشیم؟
    </p>
<p>
        پاسخ به این برمی‌گردد که leader چگونه انتخاب می‌شود. اگر leader به صورت دستی توسط انسان‌ها در تیم عملیاتی شما انتخاب و پیکربندی شود، شما اساساً یک "consensus algorithm" از نوع dictatorial دارید: فقط به یک node اجازه داده می‌شود تا writes را بپذیرد (یعنی، در مورد ترتیب writes در replication log تصمیم‌گیری کند)، و اگر آن node از کار بیفتد، سیستم برای writes غیرقابل دسترس می‌شود تا زمانی که operators به صورت دستی یک node متفاوت را برای leader بودن پیکربندی کنند. چنین سیستمی می‌تواند در عمل به خوبی کار کند، اما the termination property از consensus را برآورده نمی‌کند زیرا برای پیشرفت به intervention انسانی نیاز دارد.
    </p>
<p>
        برخی از databases، automatic leader election و failover را انجام می‌دهند، که یک follower را به عنوان leader جدید ارتقا می‌دهند اگر leader قدیمی شکست بخورد (به "Handling Node Outages" در صفحه 156 مراجعه کنید). این ما را به fault-tolerant total order broadcast نزدیک‌تر می‌کند، و بنابراین به حل consensus.
    </p>
<p>
        با این حال، یک مشکل وجود دارد. ما قبلاً در مورد مشکل split brain بحث کردیم، و گفتیم که همه nodes نیاز دارند که در مورد اینکه leader چه کسی است، توافق کنند - در غیر این صورت دو nodes مختلف می‌توانند هر کدام معتقد باشند که خودشان leader هستند، و در نتیجه database را به یک حالت inconsistent برسانند. بنابراین، ما برای انتخاب یک leader به consensus نیاز داریم. اما اگر the consensus algorithms که در اینجا توضیح داده شده‌اند، در واقع total order broadcast algorithms هستند، و total order broadcast مانند single-leader replication است، و single-leader replication به یک leader نیاز دارد، سپس...
    </p>
<p>
        به نظر می‌رسد که برای انتخاب یک leader، ما ابتدا به یک leader نیاز داریم. برای حل consensus، ما ابتدا باید consensus را حل کنیم. چگونه از این conundrum خارج می‌شویم؟
    </p>
<p>
        Distributed Transactions and Consensus | 367
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0389</div>
            </div>
        </div>
        <!-- Page 0390 -->
        <div class="chapter" id="page-0390">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<h4>Epoch numbering and quorums</h4>
<p>
        همه consensus protocols که تاکنون مورد بحث قرار گرفتند، به طور داخلی از یک leader به شکلی استفاده می‌کنند، اما آن‌ها تضمین نمی‌کنند که leader منحصر به فرد است. در عوض، آن‌ها می‌توانند یک guarantee ضعیف‌تر را ایجاد کنند: the protocols یک epoch number را تعریف می‌کنند (که در Paxos، view number در Viewstamped Replication، و term number در Raft نامیده می‌شود) و تضمین می‌کنند که در هر epoch، leader منحصر به فرد است.
    </p>
<p>
        هر بار که تصور می‌شود leader فعلی مرده است، یک vote بین nodes برای انتخاب یک leader جدید شروع می‌شود. به این election یک epoch number افزایش یافته داده می‌شود، و بنابراین epoch numbers به طور total ordered و monotonically increasing هستند. اگر یک conflict بین دو leader مختلف در دو epoch مختلف وجود داشته باشد (شاید به این دلیل که leader قبلی در واقع پس از همه مرده نبوده است)، سپس leader با epoch number بالاتر غالب می‌شود.
    </p>
<p>
        قبل از اینکه به یک leader اجازه داده شود که در مورد چیزی تصمیم بگیرد، ابتدا باید بررسی کند که آیا leader دیگری با یک epoch number بالاتر وجود ندارد که ممکن است یک decision متناقض بگیرد.
    </p>
<p>
        یک leader چگونه می‌داند که توسط یک node دیگر برکنار نشده است؟ "The Truth Is Defined by the Majority" در صفحه 300 را به یاد بیاورید: یک node لزوماً نمی‌تواند به قضاوت خود اعتماد کند - فقط به این دلیل که یک node فکر می‌کند که leader است، لزوماً به این معنی نیست که other nodes آن را به عنوان leader خود می‌پذیرند.
    </p>
<p>
        در عوض، باید از یک quorum از nodes votes جمع‌آوری کند (به "Quorums for reading and writing" در صفحه 179 مراجعه کنید). برای هر decision که یک leader می‌خواهد انجام دهد، باید مقدار پیشنهادی را به other nodes ارسال کند و منتظر بماند تا یک quorum از nodes به نفع proposal پاسخ دهند. The quorum معمولاً، اما نه همیشه، از اکثریت nodes تشکیل شده است [105]. A node به نفع یک proposal، فقط در صورتی رأی می‌دهد که از هر leader دیگری با epoch بالاتری آگاه نباشد.
    </p>
<p>
        بنابراین، ما دو round از voting داریم: یک بار برای انتخاب یک leader، و بار دوم برای vote بر روی یک leader’s proposal. The key insight این است که quorums برای آن دو votes باید overlapping باشند: اگر یک vote بر روی یک proposal موفق شود، حداقل یکی از nodes که به آن رأی داده‌اند، باید در آخرین leader election نیز شرکت کرده باشند [105]. بنابراین، اگر vote بر روی یک proposal، هیچ epoch با شماره بالاتری را آشکار نکند، leader فعلی می‌تواند نتیجه بگیرد که هیچ leader election با یک epoch number بالاتر رخ نداده است، و بنابراین مطمئن شود که همچنان رهبری را در دست دارد. سپس می‌تواند با خیال راحت value پیشنهادی را تصمیم بگیرد.
    </p>
<p>
        این process voting، سطحی شبیه به two-phase commit به نظر می‌رسد. بزرگترین تفاوت‌ها این است که در 2PC، the coordinator انتخاب نمی‌شود، و اینکه fault-tolerant consensus algorithms فقط به votes از اکثریت nodes نیاز دارند، در حالی که 2PC به یک "yes" vote از هر participant نیاز دارد. علاوه بر این، consensus algorithms یک recovery process را تعریف می‌کنند که توسط آن nodes می‌توانند پس از انتخاب یک leader جدید، به یک state consistent برسند، و اطمینان حاصل شود که safety properties همیشه برآورده می‌شوند. این تفاوت‌ها، کلید correctness و fault tolerance از یک consensus algorithm هستند.
    </p>
<p>
        368 | Chapter 9: Consistency and Consensus
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0390</div>
            </div>
        </div>
        <!-- Page 0391 -->
        <div class="chapter" id="page-0391">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<h4>Limitations of consensus</h4>
<p>
        Consensus algorithms یک پیشرفت بزرگ برای distributed systems هستند: آن‌ها safety properties (agreement, integrity, و validity) مشخصی را به systems که در آن همه چیز نامشخص است، می‌آورند، و با این وجود fault-tolerant باقی می‌مانند (تا زمانی که اکثریت nodes در حال کار و قابل دسترس باشند، قادر به پیشرفت هستند). آن‌ها total order broadcast را فراهم می‌کنند، و بنابراین آن‌ها همچنین می‌توانند linearizable atomic operations را به روشی fault-tolerant پیاده‌سازی کنند ("Implementing linearizable storage using total order broadcast" در صفحه 350 را ببینید).
    </p>
<p>
        با این وجود، آن‌ها در همه جا استفاده نمی‌شوند، زیرا مزایا با هزینه‌ای همراه است.
        process که توسط آن nodes در مورد proposals قبل از تصمیم‌گیری، vote می‌کنند، یک نوع synchronous replication است. همانطور که در "Synchronous Versus Asynchronous Replication" در صفحه 153 بحث شد، databases اغلب برای استفاده از asynchronous replication پیکربندی می‌شوند.
        در این configuration، مقداری از داده‌های committed می‌توانند به طور بالقوه در failover از دست بروند - اما بسیاری از مردم انتخاب می‌کنند که این ریسک را به خاطر performance بهتر بپذیرند.
    </p>
<p>
        Consensus systems همیشه به یک majority strict برای کارکردن نیاز دارند. این بدان معنی است که شما برای تحمل یک failure به حداقل سه node نیاز دارید (دو node باقیمانده از سه، یک majority را تشکیل می‌دهند)، یا حداقل پنج node برای تحمل دو failures (سه node باقیمانده از پنج، یک majority را تشکیل می‌دهند). اگر یک network failure، برخی از nodes را از بقیه جدا کند، تنها portion majority از شبکه می‌تواند progress کند، و بقیه مسدود می‌شوند (همچنین به "The Cost of Linearizability" در صفحه 335 مراجعه کنید).
    </p>
<p>
        اکثر consensus algorithms یک set fixed از nodes را فرض می‌کنند که در voting شرکت می‌کنند، که به این معنی است که شما نمی‌توانید به سادگی nodes را در cluster اضافه یا حذف کنید. Dynamic membership extensions برای consensus algorithms، به set از nodes در cluster اجازه می‌دهد که با گذشت زمان تغییر کند، اما آن‌ها بسیار کمتر از static membership algorithms درک شده‌اند.
    </p>
<p>
        Consensus systems عموماً به timeouts برای شناسایی failed nodes متکی هستند. در محیط‌هایی با network delays بسیار متغیر، به ویژه سیستم‌های geographically distributed، اغلب اتفاق می‌افتد که یک node به اشتباه باور می‌کند که leader به دلیل یک issue network گذرا، شکست خورده است. اگرچه این error به safety properties آسیب نمی‌رساند، اما frequent leader elections منجر به performance وحشتناک می‌شود زیرا سیستم می‌تواند زمان بیشتری را صرف انتخاب یک leader کند تا انجام هر کار مفیدی.
    </p>
<p>
        گاهی اوقات، consensus algorithms به مشکلات network، به ویژه حساس هستند. به عنوان مثال، Raft نشان داده شده است که دارای edge cases ناخوشایندی است [106]: اگر کل شبکه به درستی کار می‌کند به جز یک network link خاص که به طور مداوم unreliable است، Raft می‌تواند به موقعیت‌هایی برسد که leadership به طور مداوم بین دو nodes bounce می‌شود، یا leader فعلی به طور مداوم مجبور به استعفا می‌شود، بنابراین سیستم عملاً هرگز پیشرفت نمی‌کند. Other consensus algorithms مشکلات مشابهی دارند، و طراحی algorithms که نسبت به unreliable networks مقاوم‌تر هستند، هنوز هم یک research problem باز است.
    </p>
<p>
        Distributed Transactions and Consensus | 369
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0391</div>
            </div>
        </div>
        <!-- Page 0392 -->
        <div class="chapter" id="page-0392">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<h4>Membership and Coordination Services</h4>
<p>
        پروژه‌هایی مانند ZooKeeper یا etcd اغلب به عنوان "distributed key-value stores" یا "coordination and configuration services" توصیف می‌شوند. The API از چنین serviceای تقریباً شبیه به database است: شما می‌توانید مقدار یک کلید داده شده را بخوانید و بنویسید، و در keys تکرار کنید. بنابراین اگر آن‌ها اساساً databases هستند، چرا همه تلاش‌ها را برای پیاده‌سازی یک consensus algorithm انجام می‌دهند؟ چه چیزی آن‌ها را از هر نوع دیگری از database متمایز می‌کند؟
    </p>
<p>
        برای درک این موضوع، مفید است که به طور خلاصه بررسی کنیم که چگونه یک service مانند ZooKeeper استفاده می‌شود. به عنوان یک application developer، شما به ندرت نیاز دارید که مستقیماً از ZooKeeper استفاده کنید، زیرا در واقع برای یک database با هدف عمومی مناسب نیست. این احتمال وجود دارد که شما به طور غیرمستقیم از آن از طریق برخی از پروژه‌های دیگر استفاده کنید: به عنوان مثال، HBase، Hadoop YARN، OpenStack Nova، و Kafka همگی به ZooKeeper که در background در حال اجرا است، متکی هستند. این پروژه‌ها از آن چه چیزی به دست می‌آورند؟
    </p>
<p>
        ZooKeeper و etcd برای نگهداری مقادیر کمی از داده‌ها طراحی شده‌اند که می‌توانند کاملاً در حافظه قرار گیرند (اگرچه آن‌ها هنوز هم برای durability به disk می‌نویسند) - بنابراین شما نمی‌خواهید تمام داده‌های application خود را در اینجا ذخیره کنید. آن مقدار کمی از داده‌ها با استفاده از یک fault-tolerant total order broadcast algorithm در سراسر تمام nodes replicated می‌شوند. همانطور که قبلاً بحث شد، total order broadcast دقیقاً همان چیزی است که شما برای database replication نیاز دارید: اگر هر message نشان‌دهنده یک write به database باشد، اعمال همان writes به همان ترتیب، replicas را با یکدیگر consistent نگه می‌دارد.
    </p>
<p>
        ZooKeeper بر اساس سرویس قفل Google’s Chubby [14, 98] مدل‌سازی شده است، که نه تنها total order broadcast (و از این رو consensus)، بلکه یک set جالب از other features را پیاده‌سازی می‌کند که در ساختن distributed systems بسیار مفید هستند:
    </p>
<ul>
<li>Linearizable atomic operations
            <p>
                با استفاده از یک atomic compare-and-set operation، شما می‌توانید یک lock را پیاده‌سازی کنید: اگر چندین node به طور concurrent سعی کنند همان operation را انجام دهند، فقط یکی از آن‌ها موفق خواهد شد. The consensus protocol تضمین می‌کند که operation atomic و linearizable خواهد بود، حتی اگر یک node شکست بخورد یا شبکه در هر نقطه قطع شود. A distributed lock معمولاً به عنوان یک lease پیاده‌سازی می‌شود، که یک زمان انقضا دارد تا در صورت شکست client (به "Process Pauses" در صفحه 295 مراجعه کنید) در نهایت آزاد شود.
            </p>
</li>
<li>Total ordering of operations
            <p>
                همانطور که در "The leader and the lock" در صفحه 301 بحث شد، هنگامی که برخی از منابع توسط یک lock یا lease محافظت می‌شوند، شما به یک fencing token نیاز دارید تا از conflicting با یکدیگر در صورت یک process pause جلوگیری کنید. The fencing token، یک number است که هر بار lock acquired می‌شود، به طور monotonically افزایش می‌یابد. ZooKeeper این را با total ordering کردن تمام operations و دادن به هر operation یک transaction ID (zxid) و version number (cversion) که monotonically increasing است، فراهم می‌کند [15].
            </p>
</li>
</ul>
<p>
        370 | Chapter 9: Consistency and Consensus
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0392</div>
            </div>
        </div>
        <!-- Page 0393 -->
        <div class="chapter" id="page-0393">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<h4>Failure detection</h4>
<p>
        Clients یک session طولانی‌مدت را در ZooKeeper servers حفظ می‌کنند، و client و server به طور دوره‌ای heartbeats را تبادل می‌کنند تا بررسی کنند که node دیگر هنوز زنده است یا خیر.
        حتی اگر connection به طور موقت قطع شود، یا یک ZooKeeper node شکست بخورد، session فعال باقی می‌ماند. با این حال، اگر heartbeats برای مدتی که طولانی‌تر از session timeout است متوقف شود، ZooKeeper اعلام می‌کند که session مرده است. هر locks که توسط یک session نگهداری می‌شود، می‌تواند پیکربندی شود تا به طور خودکار هنگامی که session timeout می‌شود، آزاد شود (ZooKeeper این‌ها را ephemeral nodes می‌نامد).
    </p>
<h4>Change notifications</h4>
<p>
        نه تنها یک client می‌تواند locks و values را که توسط یک client دیگر ایجاد شده‌اند، بخواند، بلکه می‌تواند آن‌ها را برای changes نیز مشاهده کند. بنابراین، یک client می‌تواند متوجه شود که چه زمانی یک client دیگر به cluster می‌پیوندد (بر اساس value که به ZooKeeper می‌نویسد)، یا اگر یک client دیگر شکست بخورد (زیرا session آن timeout می‌شود و ephemeral nodes آن ناپدید می‌شوند). با subscribing به notifications، یک client از poll کردن مکرر برای اطلاع از changes اجتناب می‌کند.
    </p>
<p>
        Of these features, only the linearizable atomic operations واقعاً به consensus نیاز دارند. با این حال، این ترکیب از این features است که systems مانند ZooKeeper را برای coordination distributed بسیار مفید می‌کند.
    </p>
<h4>Allocating work to nodes</h4>
<p>
        یک مثال که در آن the ZooKeeper/Chubby model به خوبی کار می‌کند، این است که اگر شما چندین instance از یک process یا service دارید، و یکی از آن‌ها نیاز دارد به عنوان leader یا primary انتخاب شود. اگر leader شکست بخورد، یکی از other nodes باید بر عهده بگیرد. این البته برای single-leader databases مفید است، اما برای job schedulers و similar stateful systems نیز مفید است.
    </p>
<p>
        مثال دیگری زمانی پیش می‌آید که شما مقداری از resource partitioned (database، message streams، file storage، distributed actor system، و غیره) را دارید و نیاز دارید که تصمیم بگیرید که کدام partition را به کدام node اختصاص دهید. با پیوستن nodesهای جدید به cluster، برخی از partitions نیاز دارند که از nodes موجود به nodesهای جدید منتقل شوند تا load را rebalance کنند (به "Rebalancing Partitions" در صفحه 209 مراجعه کنید). با حذف یا failure nodes، other nodes نیاز دارند که کار nodesهای شکست خورده را بر عهده بگیرند.
    </p>
<p>
        این نوع از tasks را می‌توان با استفاده صحیح از atomic operations, ephemeral nodes، و notifications در ZooKeeper به دست آورد. اگر به درستی انجام شود، این رویکرد به application اجازه می‌دهد تا به طور خودکار از faults بدون human intervention بازیابی شود. این آسان نیست، با وجود ظاهر libraries مانند Apache Curator [17] که برای ارائه ابزارهای سطح بالاتر بر روی ZooKeeper client API ظاهر شده‌اند - اما هنوز هم بسیار بهتر از تلاش برای پیاده‌سازی الگوریتم‌های consensus لازم از ابتدا است، که یک record موفقیت‌آمیز ضعیف دارد [107].
    </p>
<p>
        Distributed Transactions and Consensus | 371
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0393</div>
            </div>
        </div>
        <!-- Page 0394 -->
        <div class="chapter" id="page-0394">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        An application ممکن است در ابتدا فقط بر روی یک node اجرا شود، اما در نهایت ممکن است به هزاران node برسد. تلاش برای انجام majority votes بر روی nodesهای بسیار زیاد، بسیار ناکارآمد خواهد بود. در عوض، ZooKeeper بر روی یک تعداد ثابت از nodes (معمولاً سه یا پنج) اجرا می‌شود و votes اکثریت خود را در میان آن nodes انجام می‌دهد در حالی که از تعداد زیادی از clients به طور بالقوه پشتیبانی می‌کند. بنابراین، ZooKeeper یک راه برای "outsourcing" مقداری از کار هماهنگ کردن nodes (consensus، ordering operations، و failure detection) به یک service خارجی فراهم می‌کند.
    </p>
<p>
        معمولاً، نوع داده‌هایی که توسط ZooKeeper مدیریت می‌شوند، به کندی تغییر می‌کنند: اطلاعاتی مانند "the node در حال اجرا در 10.1.1.23، leader برای partition 7 است" را نشان می‌دهد، که ممکن است در مقیاس زمانی دقیقه یا ساعت تغییر کند. این برای ذخیره state runtime از application در نظر گرفته نشده است، که ممکن است هزاران یا حتی میلیون‌ها بار در ثانیه تغییر کند. اگر state application نیاز به replicated شدن از یک node به node دیگری داشته باشد، می‌توان از other tools (مانند Apache BookKeeper [108]) استفاده کرد.
    </p>
<h4>Service discovery</h4>
<p>
        ZooKeeper, etcd، و Consul، اغلب برای service discovery نیز استفاده می‌شوند - یعنی، برای یافتن اینکه برای رسیدن به یک service خاص، به چه IP addressی نیاز دارید. در محیط‌های cloud datacenter، که در آن رایج است که virtual machines به طور مداوم می‌آیند و می‌روند، شما اغلب از قبل آدرس‌های IP از خدمات خود را نمی‌دانید. در عوض، شما می‌توانید خدمات خود را طوری پیکربندی کنید که وقتی راه‌اندازی می‌شوند، network endpoints خود را در یک service registry ثبت می‌کنند، که در آن می‌توانند توسط other services پیدا شوند.
    </p>
<p>
        با این حال، مشخص نیست که آیا service discovery واقعاً به consensus نیاز دارد یا خیر. DNS روش سنتی برای جستجوی IP address برای یک service name است، و از چندین لایه از caching برای دستیابی به performance و availability خوب استفاده می‌کند. Reads از DNS قطعاً linearizable نیستند، و معمولاً مشکل‌ساز تلقی نمی‌شود اگر نتایج از یک DNS query کمی stale باشند [109]. این مهم‌تر است که DNS به طور reliable در دسترس باشد و در برابر network interruptions مقاوم باشد.
    </p>
<p>
        اگرچه service discovery به consensus نیاز ندارد، leader election دارد. بنابراین، اگر سیستم consensus شما قبلاً می‌داند که leader کیست، سپس می‌تواند منطقی باشد که از آن اطلاعات نیز برای کمک به other services برای کشف اینکه leader کیست، استفاده کنید. برای این منظور، برخی از consensus systems از read-only caching replicas پشتیبانی می‌کنند. این replicas، به صورت asynchronous log از تمام decisions از consensus algorithm را دریافت می‌کنند، اما فعالانه در voting شرکت نمی‌کنند. بنابراین آن‌ها قادر به serving read requests هستند که نیازی به linearizable ندارند.
    </p>
<h4>Membership services</h4>
<p>
        ZooKeeper و دوستان را می‌توان به عنوان بخشی از یک history طولانی از research در membership services مشاهده کرد، که به دهه 1980 بازمی‌گردد و برای ساختن systems بسیار reliable، به عنوان مثال، برای کنترل ترافیک هوایی [110] مهم بوده است.
    </p>
<p>
        372 | Chapter 9: Consistency and Consensus
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0394</div>
            </div>
        </div>
        <!-- Page 0395 -->
        <div class="chapter" id="page-0395">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        یک membership service تعیین می‌کند که کدام nodes در حال حاضر فعال هستند و members زنده از یک cluster هستند. همانطور که در طول فصل 8 دیدیم، به دلیل unbounded network delays، تشخیص قابل اطمینان اینکه آیا یک node دیگر شکست خورده است یا خیر، امکان‌پذیر نیست. با این حال، اگر شما failure detection را با consensus جفت کنید، nodes می‌توانند در مورد اینکه کدام nodes باید زنده یا نه در نظر گرفته شوند، به توافق برسند.
    </p>
<p>
        هنوز هم ممکن است که یک node به اشتباه توسط consensus dead اعلام شود، حتی اگر در واقع زنده باشد. اما با این وجود برای یک سیستم بسیار مفید است که در مورد اینکه کدام nodes، membership فعلی را تشکیل می‌دهند، توافق داشته باشد. به عنوان مثال، انتخاب یک leader می‌تواند به سادگی به معنای انتخاب کمترین شماره‌دار در میان current members باشد، اما این رویکرد اگر nodesهای مختلف نظرات متفاوتی در مورد اینکه members فعلی چه کسانی هستند، داشته باشند، کارساز نخواهد بود.
    </p>
<h4>Summary</h4>
<p>
        در این فصل ما موضوعات consistency و consensus را از زوایای مختلف بررسی کردیم. ما به طور عمیق به linearizability، یک consistency model محبوب، نگاه کردیم: هدف آن این است که داده‌های replicated طوری به نظر برسند که گویی فقط یک کپی وجود دارد، و همه operations بر روی آن به صورت اتمی عمل می‌کنند. اگرچه linearizability جذاب است زیرا درک آن آسان است - باعث می‌شود یک database مانند یک variable در یک برنامه single-threaded رفتار کند - اما این ضعف را دارد که کند است، به ویژه در محیط‌هایی با network delays بزرگ.
    </p>
<p>
        ما همچنین causality را بررسی کردیم، که یک ordering را بر رویدادها در یک سیستم تحمیل می‌کند (چه چیزی قبل از چه چیزی اتفاق افتاده است، بر اساس cause and effect). برخلاف linearizability، که تمام operations را در یک timeline واحد و totally ordered قرار می‌دهد، causality یک consistency model ضعیف‌تر را به ما ارائه می‌دهد: برخی از چیزها می‌توانند concurrent باشند، بنابراین version history مانند یک timeline با branching و merging است. Causal consistency، overhead هماهنگی از linearizability را ندارد و به مشکلات شبکه حساسیت کمتری دارد.
    </p>
<p>
        با این حال، حتی اگر ما causal ordering را capture کنیم (به عنوان مثال با استفاده از Lamport timestamps)، ما دیدیم که برخی از چیزها را نمی‌توان به این روش پیاده‌سازی کرد: در "Timestamp ordering is not sufficient" در صفحه 347 ما به مثال اطمینان از اینکه یک username منحصر به فرد است و رد کردن registrations concurrent برای همان username، پرداختیم. اگر یک node قرار است یک registration را بپذیرد، به نحوی نیاز دارد که بداند که یک node دیگر به طور concurrent در process از ثبت همان نام نیست. این مشکل ما را به سمت consensus سوق داد.
    </p>
<p>
        ما دیدیم که دستیابی به consensus به معنای تصمیم‌گیری در مورد چیزی به گونه‌ای است که همه nodes در مورد آنچه تصمیم گرفته شده است، توافق داشته باشند، و به گونه‌ای که decision غیرقابل برگشت باشد. با مقداری کاوش، مشخص می‌شود که طیف وسیعی از مشکلات در واقع به consensus قابل تقلیل هستند و معادل یکدیگر هستند (به این معنا که اگر شما یک راه‌حل برای یکی از آن‌ها دارید، می‌توانید به راحتی آن را به یک راه‌حل برای یکی دیگر از آن‌ها تبدیل کنید).
        مشکلات معادل شامل موارد زیر است:
    </p>
<p>
        Summary | 373
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0395</div>
            </div>
        </div>
        <!-- Page 0396 -->
        <div class="chapter" id="page-0396">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<ul>
<li>Linearizable compare-and-set registers
            <p>
                The register نیاز دارد به صورت atomic تصمیم بگیرد که آیا مقدار خود را تنظیم کند یا خیر، بر اساس اینکه آیا مقدار فعلی آن با پارامتر داده شده در operation برابر است یا خیر.
            </p>
</li>
<li>Atomic transaction commit
            <p>
                A database باید تصمیم بگیرد که آیا یک distributed transaction را commit کند یا abort.
            </p>
</li>
<li>Total order broadcast
            <p>
                The messaging system باید در مورد ترتیبی که messages را تحویل دهد، تصمیم بگیرد.
            </p>
</li>
<li>Locks and leases
            <p>
                هنگامی که چندین client برای گرفتن یک lock یا lease رقابت می‌کنند، the lock تصمیم می‌گیرد که کدام یک با موفقیت آن را به دست آورده است.
            </p>
</li>
<li>Membership/coordination service
            <p>
                با توجه به یک failure detector (به عنوان مثال، timeouts)، سیستم باید تصمیم بگیرد که کدام nodes زنده هستند، و کدام‌یک باید dead در نظر گرفته شوند زیرا sessions آن‌ها timeout شده است.
            </p>
</li>
<li>Uniqueness constraint
            <p>
                هنگامی که چندین transactions به طور concurrent سعی می‌کنند رکوردهای conflicting را با همان key ایجاد کنند، constraint باید تصمیم بگیرد که کدام یک را اجازه دهد و کدام باید با constraint violation شکست بخورد.
            </p>
</li>
</ul>
<p>
        اگر شما فقط یک node دارید، یا اگر شما مایل به اختصاص قابلیت تصمیم‌گیری به یک node واحد هستید، همه این موارد ساده هستند. این همان چیزی است که در یک single-leader database اتفاق می‌افتد: تمام قدرت برای اتخاذ تصمیمات در leader متمرکز است، که به همین دلیل است که چنین databases قادر به ارائه linearizable operations, uniqueness constraints, a totally ordered replication log، و موارد دیگر هستند.
    </p>
<p>
        با این حال، اگر آن single leader شکست بخورد، یا اگر یک network interruption باعث شود که leader غیرقابل دسترس شود، چنین سیستمی قادر به هیچ گونه progress نمی‌شود. سه راه برای handling آن وضعیت وجود دارد:
    </p>
<ol>
<li>
            انتظار برای بازیابی leader، و پذیرفتن اینکه سیستم در این بین مسدود خواهد شد. بسیاری از XA/JTA transaction coordinators این گزینه را انتخاب می‌کنند. این رویکرد consensus را به طور کامل حل نمی‌کند زیرا the termination property را برآورده نمی‌کند: اگر leader بازیابی نشود، سیستم می‌تواند برای همیشه مسدود شود.
        </li>
<li>
            به صورت دستی fail over کنید با وادار کردن انسان‌ها به انتخاب یک node leader جدید و reconfigure کردن سیستم برای استفاده از آن. بسیاری از relational databases این رویکرد را در پیش می‌گیرند. این یک نوع از consensus توسط "act of God" است - human operator، در خارج از computer system، تصمیم‌گیری می‌کند. سرعت failover توسط سرعتی که انسان‌ها می‌توانند عمل کنند محدود می‌شود، که عموماً کندتر از کامپیوترها است.
        </li>
</ol>
<p>
        374 | Chapter 9: Consistency and Consensus
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0396</div>
            </div>
        </div>
        <!-- Page 0397 -->
        <div class="chapter" id="page-0397">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<ol>
<li>Use an algorithm to automatically choose a new leader.
            <p>
                این رویکرد به یک consensus algorithm نیاز دارد، و توصیه می‌شود از یک algorithm اثبات شده استفاده کنید که شرایط نامطلوب شبکه را به درستی handle کند [107].
            </p>
</li>
</ol>
<p>
        اگرچه یک single-leader database می‌تواند linearizability را بدون اجرای یک consensus algorithm در هر write ارائه دهد، اما همچنان برای حفظ leadership و برای تغییرات leadership به consensus نیاز دارد. بنابراین، به نوعی، داشتن یک leader فقط "kicks the can down the road" است: consensus هنوز هم مورد نیاز است، فقط در یک مکان متفاوت، و کمتر مکرر. خبر خوب این است که algorithms و systems fault-tolerant برای consensus وجود دارد، و ما به طور خلاصه در این فصل در مورد آن‌ها بحث کردیم.
    </p>
<p>
        ابزارهایی مانند ZooKeeper نقش مهمی در ارائه یک consensus "outsourced"، failure detection، و membership service ایفا می‌کنند که applications می‌توانند از آن استفاده کنند. استفاده از آن آسان نیست، اما بسیار بهتر از تلاش برای توسعه algorithms خودتان است که بتوانند در برابر تمام مشکلات مورد بحث در فصل 8 مقاومت کنند. اگر شما متوجه شدید که می‌خواهید یکی از آن چیزهایی را انجام دهید که به consensus قابل تقلیل است، و شما می‌خواهید fault-tolerant باشد، سپس توصیه می‌شود از چیزی مانند ZooKeeper استفاده کنید.
    </p>
<p>
        با این وجود، همه سیستم‌ها لزوماً به consensus نیاز ندارند: به عنوان مثال، سیستم‌های leaderless و multi-leader replication معمولاً از global consensus استفاده نمی‌کنند. The conflicts که در این systems رخ می‌دهد ("Handling Write Conflicts" در صفحه 171 را ببینید) نتیجه نداشتن consensus در سراسر leadersهای مختلف است، اما شاید این اشکالی نداشته باشد: شاید ما به سادگی نیاز داریم که بدون linearizability مقابله کنیم و یاد بگیریم که بهتر با داده‌هایی که دارای branching و merging version histories هستند، کار کنیم.
    </p>
<p>
        این فصل به تحقیقات زیادی در مورد تئوری distributed systems اشاره کرد. اگرچه مقالات و اثبات‌های تئوری همیشه آسان نیستند، و گاهی اوقات فرضیات غیرواقعی را مطرح می‌کنند، اما برای اطلاع‌رسانی از کار عملی در این زمینه بسیار ارزشمند هستند: آن‌ها به ما کمک می‌کنند در مورد آنچه که می‌توان و نمی‌توان انجام داد استدلال کنیم، و به ما کمک می‌کنند راه‌های counterintuitive را که در آن distributed systems اغلب flawed هستند، پیدا کنیم. اگر وقت دارید، بررسی منابع ارزش دارد.
    </p>
<p>
        این ما را به پایان Part II از این کتاب می‌رساند، که در آن ما replication (فصل 5)، partitioning (فصل 6)، transactions (فصل 7)، distributed system failure models (فصل 8)، و در نهایت consistency و consensus (فصل 9) را پوشش دادیم. اکنون که ما یک foundation محکم از تئوری ایجاد کرده‌ایم، در Part III، ما یک بار دیگر به سیستم‌های عملی‌تر خواهیم پرداخت، و در مورد نحوه ساختن applications قدرتمند از heterogeneous building blocks بحث خواهیم کرد.
    </p>
<h4>References</h4>
<p>[1] Peter Bailis and Ali Ghodsi: “Eventual Consistency Today: Limitations, Extensions, and Beyond,” ACM Queue, volume 11, number 3, pages 55-63, March 2013.
        doi:10.1145/2460276.2462076
    </p>
<p>
        Summary | 375
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0397</div>
            </div>
        </div>
        <!-- Page 0398 -->
        <div class="chapter" id="page-0398">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>[2] Prince Mahajan, Lorenzo Alvisi, and Mike Dahlin: “Consistency, Availability, and
        Convergence,” University of Texas at Austin, Department of Computer Science, Tech
        Report UTCS TR-11-22, May 2011.
    </p>
<p>[3] Alex Scotti: “Adventures in Building Your Own Database,” at All Your Base,
        November 2015.
    </p>
<p>[4] Peter Bailis, Aaron Davidson, Alan Fekete, et al.: “Highly Available Transactions:
        Virtues and Limitations,” at 40th International Conference on Very Large Data Bases
        (VLDB), September 2014. Extended version published as pre-print arXiv:1302.0309
        [cs.DB].
    </p>
<p>[5] Paolo Viotti and Marko Vukolić: “Consistency in Non-Transactional Distributed
        Storage Systems,” arXiv:1512.00168, 12 April 2016.
    </p>
<p>[6] Maurice P. Herlihy and Jeannette M. Wing: “Linearizability: A Correctness Con‐
        dition for Concurrent Objects,” ACM Transactions on Programming Languages and
        Systems (TOPLAS), volume 12, number 3, pages 463–492, July 1990. doi:
        10.1145/78969.78972
    </p>
<p>[7] Leslie Lamport: “On interprocess communication,” Distributed Computing, vol‐
        ume 1, number 2, pages 77–101, June 1986. doi:10.1007/BF01786228
    </p>
<p>[8] David K. Gifford: “Information Storage in a Decentralized Computer System,”
        Xerox Palo Alto Research Centers, CSL-81-8, June 1981.
    </p>
<p>[9] Martin Kleppmann: “Please Stop Calling Databases CP or AP,” martin.klepp‐
        mann.com, May 11, 2015.
    </p>
<p>[10] Kyle Kingsbury: “Call Me Maybe: MongoDB Stale Reads,” aphyr.com, April 20,
        2015.
    </p>
<p>[11] Kyle Kingsbury: “Computational Techniques in Knossos,” aphyr.com, May 17,
        2014.
    </p>
<p>[12] Peter Bailis: “Linearizability Versus Serializability,” bailis.org, September 24,
        2014.
    </p>
<p>[13] Philip A. Bernstein, Vassos Hadzilacos, and Nathan Goodman: Concurrency
        Control and Recovery in Database Systems. Addison-Wesley, 1987. ISBN:
        978-0-201-10715-9, available online at research.microsoft.com.
    </p>
<p>[14] Mike Burrows: “The Chubby Lock Service for Loosely-Coupled Distributed Sys‐
        tems,” at 7th USENIX Symposium on Operating System Design and Implementation
        (OSDI), November 2006.
    </p>
<p>[15] Flavio P. Junqueira and Benjamin Reed: ZooKeeper: Distributed Process Coordi‐
        nation. O’Reilly Media, 2013. ISBN: 978-1-449-36130-3
    </p>
<p>[16] “etcd 2.0.12 Documentation,” CoreOS, Inc., 2015.
    </p>
<p>
        376 | Chapter 9: Consistency and Consensus
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0398</div>
            </div>
        </div>
        <!-- Page 0399 -->
        <div class="chapter" id="page-0399">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>[17] “Apache Curator,” Apache Software Foundation, curator.apache.org, 2015.
    </p>
<p>[18] Morali Vallath: Oracle 10g RAC Grid, Services &amp; Clustering. Elsevier Digital
        Press, 2006. ISBN: 978-1-555-58321-7
    </p>
<p>[19] Peter Bailis, Aaron Davidson, Alan Fekete, et al.: “Coordination-Avoiding
        Database Systems,” Proceedings of the VLDB Endowment, volume 8, number 3, pages
        185–196, November 2014.
    </p>
<p>[20] Kyle Kingsbury: “Call Me Maybe: etcd and Consul,” aphyr.com, June 9, 2014.
    </p>
<p>[21] Flavio P. Junqueira, Benjamin C. Reed, and Marco Serafini: “Zab: High-
        Performance Broadcast for Primary-Backup Systems,” at 41st IEEE International
        Conference on Dependable Systems and Networks (DSN), June 2011. doi:10.1109/
        DSN.2011.5958223
    </p>
<p>[22] Diego Ongaro and John K. Ousterhout: “In Search of an Understandable Con‐
        sensus Algorithm (Extended Version),” at USENIX Annual Technical Conference
        (ATC), June 2014.
    </p>
<p>[23] Hagit Attiya, Amotz Bar-Noy, and Danny Dolev: “Sharing Memory Robustly in
        Message-Passing Systems,” Journal of the ACM, volume 42, number 1, pages 124–
        142, January 1995. doi:10.1145/200836.200869
    </p>
<p>[24] Nancy Lynch and Alex Shvartsman: “Robust Emulation of Shared Memory
        Using Dynamic Quorum-Acknowledged Broadcasts,” at 27th Annual International
        Symposium on Fault-Tolerant Computing (FTCS), June 1997. doi:10.1109/FTCS.
        1997.614100
    </p>
<p>[25] Christian Cachin, Rachid Guerraoui, and Luís Rodrigues: Introduction to Relia‐
        ble and Secure Distributed Programming, 2nd edition. Springer, 2011. ISBN:
        978-3-642-15259-7, doi:10.1007/978-3-642-15260-3
    </p>
<p>[26] Sam Elliott, Mark Allen, and Martin Kleppmann: personal communication,
        thread on twitter.com, October 15, 2015.
    </p>
<p>[27] Niklas Ekström, Mikhail Panchenko, and Jonathan Ellis: “Possible Issue with
        Read Repair?,” email thread on cassandra-dev mailing list, October 2012.
    </p>
<p>[28] Maurice P. Herlihy: “Wait-Free Synchronization,” ACM Transactions on Pro‐
        gramming Languages and Systems (TOPLAS), volume 13, number 1, pages 124–149,
        January 1991. doi:10.1145/114005.102808
    </p>
<p>[29] Armando Fox and Eric A. Brewer: “Harvest, Yield, and Scalable Tolerant Sys‐
        tems,” at 7th Workshop on Hot Topics in Operating Systems (HotOS), March 1999.
        doi:10.1109/HOTOS.1999.798396
    </p>
<p>
        Summary | 377
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0399</div>
            </div>
        </div>
        <!-- Page 0400 -->
        <div class="chapter" id="page-0400">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>[30] Seth Gilbert and Nancy Lynch: “Brewer’s Conjecture and the Feasibility of Con‐
        sistent, Available, Partition-Tolerant Web Services,” ACM SIGACT News, volume 33,
        number 2, pages 51–59, June 2002. doi:10.1145/564585.564601
    </p>
<p>[31] Seth Gilbert and Nancy Lynch: “Perspectives on the CAP Theorem,” IEEE Com‐
        puter Magazine, volume 45, number 2, pages 30–36, February 2012. doi:10.1109/MC.
        2011.389
    </p>
<p>[32] Eric A. Brewer: “CAP Twelve Years Later: How the ‘Rules’ Have Changed,” IEEE
        Computer Magazine, volume 45, number 2, pages 23–29, February 2012. doi:
        10.1109/MC.2012.37
    </p>
<p>[33] Susan B. Davidson, Hector Garcia-Molina, and Dale Skeen: “Consistency in Par‐
        titioned Networks,” ACM Computing Surveys, volume 17, number 3, pages 341–370,
        September 1985. doi:10.1145/5505.5508
    </p>
<p>[34] Paul R. Johnson and Robert H. Thomas: “RFC 677: The Maintenance of Dupli‐
        cate Databases,” Network Working Group, January 27, 1975.
    </p>
<p>[35] Bruce G. Lindsay, Patricia Griffiths Selinger, C. Galtieri, et al.: “Notes on Dis‐
        tributed Databases,” IBM Research, Research Report RJ2571(33471), July 1979.
    </p>
<p>[36] Michael J. Fischer and Alan Michael: “Sacrificing Serializability to Attain High
        Availability of Data in an Unreliable Network,” at 1st ACM Symposium on Principles
        of Database Systems (PODS), March 1982. doi:10.1145/588111.588124
    </p>
<p>[37] Eric A. Brewer: “NoSQL: Past, Present, Future,” at QCon San Francisco, Novem‐
        ber 2012.
    </p>
<p>[38] Henry Robinson: “CAP Confusion: Problems with ‘Partition Tolerance,’”
        blog.cloudera.com, April 26, 2010.
    </p>
<p>[39] Adrian Cockcroft: “Migrating to Microservices,” at QCon London, March 2014.
    </p>
<p>[40] Martin Kleppmann: “A Critique of the CAP Theorem,” arXiv:1509.05393, Sep‐
        tember 17, 2015.
    </p>
<p>[41] Nancy A. Lynch: “A Hundred Impossibility Proofs for Distributed Computing,”
        at 8th ACM Symposium on Principles of Distributed Computing (PODC), August
        1989. doi:10.1145/72981.72982
    </p>
<p>[42] Hagit Attiya, Faith Ellen, and Adam Morrison: “Limitations of Highly-Available
        Eventually-Consistent Data Stores,” at ACM Symposium on Principles of Distributed
        Computing (PODC), July 2015. doi:10.1145/2767386.2767419
    </p>
<p>[43] Peter Sewell, Susmit Sarkar, Scott Owens, et al.: “x86-TSO: A Rigorous and Usa‐
        ble Programmer’s Model for x86 Multiprocessors,” Communications of the ACM,
        volume 53, number 7, pages 89–97, July 2010. doi:10.1145/1785414.1785443
    </p>
<p>
        378 | Chapter 9: Consistency and Consensus
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0400</div>
            </div>
        </div>
        <!-- Page 0401 -->
        <div class="chapter" id="page-0401">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>[44] Martin Thompson: “Memory Barriers/Fences,” mechanical-
        sympathy.blogspot.co.uk, July 24, 2011.
    </p>
<p>[45] Ulrich Drepper: “What Every Programmer Should Know About Memory,”
        akkadia.org, November 21, 2007.
    </p>
<p>[46] Daniel J. Abadi: “Consistency Tradeoffs in Modern Distributed Database System
        Design,” IEEE Computer Magazine, volume 45, number 2, pages 37–42, February
        2012. doi:10.1109/MC.2012.33
    </p>
<p>[47] Hagit Attiya and Jennifer L. Welch: “Sequential Consistency Versus Linearizabil‐
        ity,” ACM Transactions on Computer Systems (TOCS), volume 12, number 2, pages
        91–122, May 1994. doi:10.1145/176575.176576
    </p>
<p>[48] Mustaque Ahamad, Gil Neiger, James E. Burns, et al.: “Causal Memory: Defini‐
        tions, Implementation, and Programming,” Distributed Computing, volume 9, num‐
        ber 1, pages 37–49, March 1995. doi:10.1007/BF01784241
    </p>
<p>[49] Wyatt Lloyd, Michael J. Freedman, Michael Kaminsky, and David G. Andersen:
        “Stronger Semantics for Low-Latency Geo-Replicated Storage,” at 10th USENIX Sym‐
        posium on Networked Systems Design and Implementation (NSDI), April 2013.
    </p>
<p>[50] Marek Zawirski, Annette Bieniusa, Valter Balegas, et al.: “SwiftCloud: Fault-
        Tolerant Geo-Replication Integrated All the Way to the Client Machine,” INRIA
        Research Report 8347, August 2013.
    </p>
<p>[51] Peter Bailis, Ali Ghodsi, Joseph M Hellerstein, and Ion Stoica: “Bolt-on Causal
        Consistency,” at ACM International Conference on Management of Data (SIGMOD),
        June 2013.
    </p>
<p>[52] Philippe Ajoux, Nathan Bronson, Sanjeev Kumar, et al.: “Challenges to Adopting
        Stronger Consistency at Scale,” at 15th USENIX Workshop on Hot Topics in Operat‐
        ing Systems (HotOS), May 2015.
    </p>
<p>[53] Peter Bailis: “Causality Is Expensive (and What to Do About It),” bailis.org, Feb‐
        ruary 5, 2014.
    </p>
<p>[54] Ricardo Gonçalves, Paulo Sérgio Almeida, Carlos Baquero, and Victor Fonte:
        “Concise Server-Wide Causality Management for Eventually Consistent Data Stores,”
        at 15th IFIP International Conference on Distributed Applications and Interoperable
        Systems (DAIS), June 2015. doi:10.1007/978-3-319-19129-4_6
    </p>
<p>[55] Rob Conery: “A Better ID Generator for PostgreSQL,” rob.conery.io, May 29,
        2014.
    </p>
<p>[56] Leslie Lamport: “Time, Clocks, and the Ordering of Events in a Distributed Sys‐
        tem,” Communications of the ACM, volume 21, number 7, pages 558–565, July 1978.
        doi:10.1145/359545.359563
    </p>
<p>
        Summary | 379
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0401</div>
            </div>
        </div>
        <!-- Page 0402 -->
        <div class="chapter" id="page-0402">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>[57] Xavier Défago, André Schiper, and Péter Urbán: “Total Order Broadcast and
        Multicast Algorithms: Taxonomy and Survey,” ACM Computing Surveys, volume 36,
        number 4, pages 372–421, December 2004. doi:10.1145/1041680.1041682
    </p>
<p>[58] Hagit Attiya and Jennifer Welch: Distributed Computing: Fundamentals, Simula‐
        tions and Advanced Topics, 2nd edition. John Wiley &amp; Sons, 2004. ISBN:
        978-0-471-45324-6, doi:10.1002/0471478210
    </p>
<p>[59] Mahesh Balakrishnan, Dahlia Malkhi, Vijayan Prabhakaran, et al.: “CORFU: A
        Shared Log Design for Flash Clusters,” at 9th USENIX Symposium on Networked Sys‐
        tems Design and Implementation (NSDI), April 2012.
    </p>
<p>[60] Fred B. Schneider: “Implementing Fault-Tolerant Services Using the State
        Machine Approach: A Tutorial,” ACM Computing Surveys, volume 22, number 4,
        pages 299–319, December 1990.
    </p>
<p>[61] Alexander Thomson, Thaddeus Diamond, Shu-Chun Weng, et al.: “Calvin: Fast
        Distributed Transactions for Partitioned Database Systems,” at ACM International
        Conference on Management of Data (SIGMOD), May 2012.
    </p>
<p>[62] Mahesh Balakrishnan, Dahlia Malkhi, Ted Wobber, et al.: “Tango: Distributed
        Data Structures over a Shared Log,” at 24th ACM Symposium on Operating Systems
        Principles (SOSP), November 2013. doi:10.1145/2517349.2522732
    </p>
<p>[63] Robbert van Renesse and Fred B. Schneider: “Chain Replication for Supporting
        High Throughput and Availability,” at 6th USENIX Symposium on Operating System
        Design and Implementation (OSDI), December 2004.
    </p>
<p>[64] Leslie Lamport: “How to Make a Multiprocessor Computer That Correctly Exe‐
        cutes Multiprocess Programs,” IEEE Transactions on Computers, volume 28, number
        9, pages 690–691, September 1979. doi:10.1109/TC.1979.1675439
    </p>
<p>[65] Enis Söztutar, Devaraj Das, and Carter Shanklin: “Apache HBase High Availabil‐
        ity at the Next Level,” hortonworks.com, January 22, 2015.
    </p>
<p>[66] Brian F Cooper, Raghu Ramakrishnan, Utkarsh Srivastava, et al.: “PNUTS:
        Yahoo!’s Hosted Data Serving Platform,” at 34th International Conference on Very
        Large Data Bases (VLDB), August 2008. doi:10.14778/1454159.1454167
    </p>
<p>[67] Tushar Deepak Chandra and Sam Toueg: “Unreliable Failure Detectors for Reli‐
        able Distributed Systems,” Journal of the ACM, volume 43, number 2, pages 225–267,
        March 1996. doi:10.1145/226643.226647
    </p>
<p>[68] Michael J. Fischer, Nancy Lynch, and Michael S. Paterson: “Impossibility of Dis‐
        tributed Consensus with One Faulty Process,” Journal of the ACM, volume 32, num‐
        ber 2, pages 374–382, April 1985. doi:10.1145/3149.214121
    </p>
<p>
        380 | Chapter 9: Consistency and Consensus
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0402</div>
            </div>
        </div>
        <!-- Page 0403 -->
        <div class="chapter" id="page-0403">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>[69] Michael Ben-Or: “Another Advantage of Free Choice: Completely Asynchro‐
        nous Agreement Protocols,” at 2nd ACM Symposium on Principles of Distributed
        Computing (PODC), August 1983. doi:10.1145/800221.806707
    </p>
<p>[70] Jim N. Gray and Leslie Lamport: “Consensus on Transaction Commit,” ACM
        Transactions on Database Systems (TODS), volume 31, number 1, pages 133–160,
        March 2006. doi:10.1145/1132863.1132867
    </p>
<p>[71] Rachid Guerraoui: “Revisiting the Relationship Between Non-Blocking Atomic
        Commitment and Consensus,” at 9th International Workshop on Distributed Algo‐
        rithms (WDAG), September 1995. doi:10.1007/BFb0022140
    </p>
<p>[72] Thanumalayan Sankaranarayana Pillai, Vijay Chidambaram, Ramnatthan Ala‐
        gappan, et al.: “All File Systems Are Not Created Equal: On the Complexity of Craft‐
        ing Crash-Consistent Applications,” at 11th USENIX Symposium on Operating
        Systems Design and Implementation (OSDI), October 2014.
    </p>
<p>[73] Jim Gray: “The Transaction Concept: Virtues and Limitations,” at 7th Interna‐
        tional Conference on Very Large Data Bases (VLDB), September 1981.
    </p>
<p>[74] Hector Garcia-Molina and Kenneth Salem: “Sagas,” at ACM International Con‐
        ference on Management of Data (SIGMOD), May 1987. doi:10.1145/38713.38742
    </p>
<p>[75] C. Mohan, Bruce G. Lindsay, and Ron Obermarck: “Transaction Management in
        the R* Distributed Database Management System,” ACM Transactions on Database
        Systems, volume 11, number 4, pages 378–396, December 1986. doi:
        10.1145/7239.7266
    </p>
<p>[76] “Distributed Transaction Processing: The XA Specification,” X/Open Company
        Ltd., Technical Standard XO/CAE/91/300, December 1991. ISBN: 978-1-872-63024-3
    </p>
<p>[77] Mike Spille: “XA Exposed, Part II,” jroller.com, April 3, 2004.
    </p>
<p>[78] Ivan Silva Neto and Francisco Reverbel: “Lessons Learned from Implementing
        WS-Coordination and WS-AtomicTransaction,” at 7th IEEE/ACIS International
        Conference on Computer and Information Science (ICIS), May 2008. doi:10.1109/
        ICIS.2008.75
    </p>
<p>[79] James E. Johnson, David E. Langworthy, Leslie Lamport, and Friedrich H. Vogt:
        “Formal Specification of a Web Services Protocol,” at 1st International Workshop on
        Web Services and Formal Methods (WS-FM), February 2004. doi:10.1016/j.entcs.
        2004.02.022
    </p>
<p>[80] Dale Skeen: “Nonblocking Commit Protocols,” at ACM International Conference
        on Management of Data (SIGMOD), April 1981. doi:10.1145/582318.582339
    </p>
<p>[81] Gregor Hohpe: “Your Coffee Shop Doesn’t Use Two-Phase Commit,” IEEE Soft‐
        ware, volume 22, number 2, pages 64–66, March 2005. doi:10.1109/MS.2005.52
    </p>
<p>
        Summary | 381
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0403</div>
            </div>
        </div>
        <!-- Page 0404 -->
        <div class="chapter" id="page-0404">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>[82] Pat Helland: “Life Beyond Distributed Transactions: An Apostate’s Opinion,” at
        3rd Biennial Conference on Innovative Data Systems Research (CIDR), January 2007.
    </p>
<p>[83] Jonathan Oliver: “My Beef with MSDTC and Two-Phase Commits,” blog.jona‐
        thanoliver.com, April 4, 2011.
    </p>
<p>[84] Oren Eini (Ahende Rahien): “The Fallacy of Distributed Transactions,”
        ayende.com, July 17, 2014.
    </p>
<p>[85] Clemens Vasters: “Transactions in Windows Azure (with Service Bus) – An
        Email Discussion,” vasters.com, July 30, 2012.
    </p>
<p>[86] “Understanding Transactionality in Azure,” NServiceBus Documentation, Par‐
        ticular Software, 2015.
    </p>
<p>[87] Randy Wigginton, Ryan Lowe, Marcos Albe, and Fernando Ipar: “Distributed
        Transactions in MySQL,” at MySQL Conference and Expo, April 2013.
    </p>
<p>[88] Mike Spille: “XA Exposed, Part I,” jroller.com, April 3, 2004.
    </p>
<p>[89] Ajmer Dhariwal: “Orphaned MSDTC Transactions (-2 spids),” eraofdata.com,
        December 12, 2008.
    </p>
<p>[90] Paul Randal: “Real World Story of DBCC PAGE Saving the Day,” sqlskills.com,
        June 19, 2013.
    </p>
<p>[91] “in-doubt xact resolution Server Configuration Option,” SQL Server 2016 docu‐
        mentation, Microsoft, Inc., 2016.
    </p>
<p>[92] Cynthia Dwork, Nancy Lynch, and Larry Stockmeyer: “Consensus in the Pres‐
        ence of Partial Synchrony,” Journal of the ACM, volume 35, number 2, pages 288–
        323, April 1988. doi:10.1145/42282.42283
    </p>
<p>[93] Miguel Castro and Barbara H. Liskov: “Practical Byzantine Fault Tolerance and
        Proactive Recovery,” ACM Transactions on Computer Systems, volume 20, number 4,
        pages 396–461, November 2002. doi:10.1145/571637.571640
    </p>
<p>[94] Brian M. Oki and Barbara H. Liskov: “Viewstamped Replication: A New Primary
        Copy Method to Support Highly-Available Distributed Systems,” at 7th ACM Sympo‐
        sium on Principles of Distributed Computing (PODC), August 1988. doi:
        10.1145/62546.62549
    </p>
<p>[95] Barbara H. Liskov and James Cowling: “Viewstamped Replication Revisited,”
        Massachusetts Institute of Technology, Tech Report MIT-CSAIL-TR-2012-021, July
        2012.
    </p>
<p>[96] Leslie Lamport: “The Part-Time Parliament,” ACM Transactions on Computer
        Systems, volume 16, number 2, pages 133–169, May 1998. doi:10.1145/279227.279229
    </p>
<p>
        382 | Chapter 9: Consistency and Consensus
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0404</div>
            </div>
        </div>
        <!-- Page 0405 -->
        <div class="chapter" id="page-0405">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>[97] Leslie Lamport: “Paxos Made Simple,” ACM SIGACT News, volume 32, number
        4, pages 51–58, December 2001.
    </p>
<p>[98] Tushar Deepak Chandra, Robert Griesemer, and Joshua Redstone: “Paxos Made
        Live – An Engineering Perspective,” at 26th ACM Symposium on Principles of Dis‐
        tributed Computing (PODC), June 2007.
    </p>
<p>[99] Robbert van Renesse: “Paxos Made Moderately Complex,” cs.cornell.edu, March
        2011.
    </p>
<p>[100] Diego Ongaro: “Consensus: Bridging Theory and Practice,” PhD Thesis, Stan‐
        ford University, August 2014.
    </p>
<p>[101] Heidi Howard, Malte Schwarzkopf, Anil Madhavapeddy, and Jon Crowcroft:
        “Raft Refloated: Do We Have Consensus?,” ACM SIGOPS Operating Systems Review,
        volume 49, number 1, pages 12–21, January 2015. doi:10.1145/2723872.2723876
    </p>
<p>[102] André Medeiros: “ZooKeeper’s Atomic Broadcast Protocol: Theory and Prac‐
        tice,” Aalto University School of Science, March 20, 2012.
    </p>
<p>[103] Robbert van Renesse, Nicolas Schiper, and Fred B. Schneider: “Vive La Différ‐
        ence: Paxos vs. Viewstamped Replication vs. Zab,” IEEE Transactions on Dependable
        and Secure Computing, volume 12, number 4, pages 472–484, September 2014. doi:
        10.1109/TDSC.2014.2355848
    </p>
<p>[104] Will Portnoy: “Lessons Learned from Implementing Paxos,” blog.willport‐
        noy.com, June 14, 2012.
    </p>
<p>[105] Heidi Howard, Dahlia Malkhi, and Alexander Spiegelman: “Flexible Paxos:
        Quorum Intersection Revisited,” arXiv:1608.06696, August 24, 2016.
    </p>
<p>[106] Heidi Howard and Jon Crowcroft: “Coracle: Evaluating Consensus at the Inter‐
        net Edge,” at Annual Conference of the ACM Special Interest Group on Data Commu‐
        nication (SIGCOMM), August 2015. doi:10.1145/2829988.2790010
    </p>
<p>[107] Kyle Kingsbury: “Call Me Maybe: Elasticsearch 1.5.0,” aphyr.com, April 27,
        2015.
    </p>
<p>[108] Ivan Kelly: “BookKeeper Tutorial,” github.com, October 2014.
    </p>
<p>[109] Camille Fournier: “Consensus Systems for the Skeptical Architect,” at Craft
        Conference, Budapest, Hungary, April 2015.
    </p>
<p>[110] Kenneth P. Birman: “A History of the Virtual Synchrony Replication Model,”
        in Replication: Theory and Practice, Springer LNCS volume 5959, chapter 6, pages
        91–120, 2010. ISBN: 978-3-642-11293-5, doi:10.1007/978-3-642-11294-2_6
    </p>
<p>
        Summary | 383
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0405</div>
            </div>
        </div>
        <!-- Page 0407 -->
        <div class="chapter" id="page-0407">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<h3>PART III</h3>
<h4>Derived Data</h4>
<p>
        در Part I و II از این کتاب، ما از ابتدا تمام ملاحظات اصلی را که به یک distributed database وارد می‌شوند، جمع‌آوری کردیم، از layout of data on disk گرفته تا limits از distributed consistency در حضور faults. با این حال، این بحث فرض می‌کرد که فقط یک database در application وجود دارد.
    </p>
<p>
        در واقعیت، data systems اغلب پیچیده‌تر هستند. در یک application بزرگ شما اغلب نیاز دارید که بتوانید به داده‌ها به روش‌های مختلفی دسترسی داشته باشید و آن‌ها را پردازش کنید، و هیچ database وجود ندارد که بتواند تمام آن نیازهای مختلف را همزمان برآورده کند. بنابراین، applications معمولاً از ترکیبی از چندین datastores، indexes، caches، analytics systems، و غیره مختلف استفاده می‌کنند و mechanisms را برای انتقال داده‌ها از یک store به دیگری پیاده‌سازی می‌کنند.
    </p>
<p>
        در این قسمت نهایی از کتاب، ما مسائل مربوط به integrating multiple different data systems، که به طور بالقوه دارای data models و optimized برای different access patterns هستند، را به یک معماری application منسجم بررسی خواهیم کرد. این جنبه از system-building اغلب توسط vendorهایی که ادعا می‌کنند محصول آن‌ها می‌تواند تمام نیازهای شما را برآورده کند، نادیده گرفته می‌شود. در واقعیت، integrating disparate systems یکی از مهم‌ترین کارهایی است که باید در یک application غیرقابل‌توجه انجام شود.
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0407</div>
            </div>
        </div>
        <!-- Page 0408 -->
        <div class="chapter" id="page-0408">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<h4>Systems of Record and Derived Data</h4>
<p>
        در یک سطح بالا، systems که داده‌ها را ذخیره و پردازش می‌کنند، می‌توانند به دو دسته کلی گروه‌بندی شوند:
    </p>
<ul>
<li>Systems of record
            <p>
                A system of record، که به عنوان source of truth نیز شناخته می‌شود، نسخه معتبر از داده‌های شما را نگه می‌دارد. هنگامی که داده‌های جدید وارد می‌شوند، به عنوان مثال، ورودی کاربر، ابتدا در اینجا نوشته می‌شود.
                هر fact به طور exactly once نشان داده می‌شود (نمایش معمولاً normalized است).
                اگر هر گونه تناقضی بین یک سیستم دیگر و the system of record وجود داشته باشد، سپس مقدار در the system of record (طبق تعریف) صحیح است.
            </p>
</li>
<li>Derived data systems
            <p>
                داده‌ها در یک derived system، نتیجه گرفتن برخی داده‌های موجود از یک سیستم دیگر و transform یا پردازش آن به نوعی است. اگر شما derived data را از دست بدهید، شما می‌توانید آن را از original source دوباره ایجاد کنید. یک مثال کلاسیک، یک cache است: داده‌ها را می‌توان از cache ارائه داد اگر وجود داشته باشد، اما اگر cache حاوی آنچه شما نیاز دارید نباشد، شما می‌توانید به database زیربنایی بازگردید. Denormalized values، indexes، و materialized views نیز در این دسته قرار می‌گیرند. در recommendation systems، داده‌های خلاصه پیش‌بینی‌کننده اغلب از usage logs مشتق می‌شوند.
            </p>
</li>
</ul>
<p>
        Technically speaking، derived data is redundant، به این معنا که اطلاعات موجود را تکرار می‌کند. با این حال، اغلب برای getting good performance بر روی read queries ضروری است. معمولاً denormalized است. شما می‌توانید چندین datasets مختلف را از یک single source مشتق کنید، که شما را قادر می‌سازد تا به داده‌ها از different “points of view” نگاه کنید.
    </p>
<p>
        Not all systems یک تمایز واضح بین systems of record و derived data در معماری خود ایجاد می‌کنند، اما این یک تمایز بسیار مفید است، زیرا جریان داده‌ها را از طریق سیستم شما روشن می‌کند: این نشان می‌دهد که کدام بخش از سیستم چه ورودی‌ها و خروجی‌هایی را دارد، و چگونه به یکدیگر وابسته هستند.
    </p>
<p>
        Most databases, storage engines، و query languages ذاتا ًیا یک system of record یا یک derived system نیستند. A database فقط یک ابزار است: نحوه استفاده شما از آن به شما بستگی دارد. تمایز بین system of record و derived data system، نه به ابزار، بلکه به نحوه استفاده شما از آن در application شما بستگی دارد.
    </p>
<p>
        با روشن بودن اینکه کدام داده‌ها از کدام داده‌های دیگر مشتق شده‌اند، شما می‌توانید clarity را به یک architecture system که در غیر این صورت گیج‌کننده است، بیاورید. این نکته یک theme در حال اجرا در طول این قسمت از کتاب خواهد بود.
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0408</div>
            </div>
        </div>
        <!-- Page 0409 -->
        <div class="chapter" id="page-0409">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<h4>Overview of Chapters</h4>
<p>
        ما در Chapter 10 با بررسی batch-oriented dataflow systems مانند MapReduce شروع خواهیم کرد، و خواهیم دید که چگونه آن‌ها ابزارها و اصول خوبی را برای ساختن large-scale data systems به ما می‌دهند. در Chapter 11 ما آن ایده‌ها را می‌گیریم و آن‌ها را برای data streams اعمال می‌کنیم، که به ما اجازه می‌دهد همان نوع کارها را با تأخیر کمتری انجام دهیم. Chapter 12 کتاب را با بررسی ایده‌هایی در مورد اینکه چگونه ممکن است از این ابزارها برای ساختن applications قابل اعتماد، scalable و maintainable در آینده استفاده کنیم، به پایان می‌رساند.
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0409</div>
            </div>
        </div>
        <!-- Page 0411 -->
        <div class="chapter" id="page-0411">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<h3>CHAPTER 10</h3>
<h4>Batch Processing</h4>
<p>
        یک سیستم نمی‌تواند موفق باشد اگر بیش از حد تحت تأثیر یک فرد قرار گیرد. هنگامی که طراحی اولیه کامل و کاملاً robust شد، آزمایش واقعی آغاز می‌شود زیرا افرادی با دیدگاه‌های مختلف آزمایش‌های خود را انجام می‌دهند.
        —Donald Knuth
    </p>
<p>
        در دو قسمت اول این کتاب ما زیاد در مورد requests و queries و responses یا results مربوطه صحبت کردیم. این سبک از data processing در بسیاری از modern data systems فرض می‌شود: شما چیزی را درخواست می‌کنید، یا یک instruction ارسال می‌کنید، و مدتی بعد سیستم (امیدوارم) یک answer به شما می‌دهد. Databases, caches, search indexes, web servers، و بسیاری از systemsهای دیگر به این صورت کار می‌کنند.
    </p>
<p>
        در چنین online systems، چه یک web browser در حال درخواست یک صفحه باشد یا یک service در حال فراخوانی یک remote API، ما عموماً فرض می‌کنیم که request توسط یک human user راه‌اندازی می‌شود، و اینکه user منتظر response است. آن‌ها نباید خیلی طولانی منتظر بمانند، بنابراین ما توجه زیادی به response time از این systems می‌کنیم ("Describing Perfor‐mance" در صفحه 13 را ببینید).
    </p>
<p>
        وب، و تعداد فزاینده‌ای از HTTP/REST-based APIs، سبک تعامل request/response را آنقدر رایج کرده‌اند که آسان است که آن را بدیهی بگیریم. اما ما باید به یاد داشته باشیم که این تنها راه ساختن systems نیست، و approachesهای دیگر نیز مزایای خود را دارند. بیایید سه نوع مختلف از systems را تشخیص دهیم:
    </p>
<ul>
<li>Services (online systems)
            <p>
                یک service، منتظر arrival یک request یا instruction از یک client می‌ماند. هنگامی که یکی دریافت شد، service تلاش می‌کند تا آن را در سریع‌ترین زمان ممکن handle کند و یک response را برمی‌گرداند. Response time معمولاً معیار اصلی performance از یک service است، و availability اغلب بسیار مهم است (اگر client نتواند به service دسترسی پیدا کند، user احتمالاً یک error message دریافت می‌کند).
            </p>
</li>
</ul>
<p>
        389
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0411</div>
            </div>
        </div>
        <!-- Page 0412 -->
        <div class="chapter" id="page-0412">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        Batch processing systems (offline systems)
        یک batch processing system مقدار زیادی از input data را می‌گیرد، یک job را برای پردازش آن اجرا می‌کند، و مقداری output data تولید می‌کند. Jobs اغلب مدتی طول می‌کشد (از چند دقیقه تا چندین روز)، بنابراین به طور معمول یک user منتظر نیست که job تمام شود. در عوض، batch jobs اغلب برنامه‌ریزی می‌شوند تا به طور دوره‌ای اجرا شوند (به عنوان مثال، یک بار در روز). The primary performance measure از یک batch job معمولاً throughput است (زمانی که برای خرد کردن از طریق یک input dataset با اندازه مشخص طول می‌کشد). ما در این فصل در مورد batch processing بحث می‌کنیم.
    </p>
<p>
        Stream processing systems (near-real-time systems)
        Stream processing جایی بین online و offline/batch processing است (بنابراین گاهی اوقات near-real-time یا nearline processing نامیده می‌شود). مانند یک batch processing system، یک stream processor، inputs را مصرف می‌کند و outputs تولید می‌کند (به جای پاسخ دادن به requests). با این حال، یک stream job بر روی events مدتی پس از وقوع آن‌ها، عمل می‌کند، در حالی که یک batch job بر روی یک set از input data ثابت عمل می‌کند. این تفاوت به stream processing systems اجازه می‌دهد که latency کمتری نسبت به systemsهای batch معادل داشته باشند. از آنجایی که stream processing بر روی batch processing ساخته شده است، ما در فصل 11 در مورد آن بحث می‌کنیم.
    </p>
<p>
        همانطور که در این فصل خواهیم دید، batch processing یک building block مهم در تلاش ما برای ساختن applications قابل اعتماد، scalable و maintainable است. به عنوان مثال، MapReduce، یک batch processing algorithm که در سال 2004 منتشر شد [1]، (شاید بیش از حد با شور و شوق) "the algorithm که Google را آنقدر massively scalable می‌کند" [2] نامیده شد. متعاقباً در سیستم‌های داده‌ای open source مختلف، از جمله Hadoop, CouchDB, و MongoDB پیاده‌سازی شد.
    </p>
<p>
        MapReduce یک programming model نسبتاً low-level در مقایسه با the parallel processing systems است که سال‌ها قبل برای data warehouses توسعه داده شد [3, 4]، اما از نظر مقیاس پردازشی که می‌توانست بر روی commodity hardware به دست آید، یک گام بزرگ به جلو بود. اگرچه اهمیت MapReduce اکنون در حال کاهش است [5]، اما همچنان ارزش درک را دارد، زیرا یک تصویر واضح از اینکه چرا و چگونه batch processing مفید است، ارائه می‌دهد.
    </p>
<p>
        در واقع، batch processing یک form بسیار قدیمی از computing است. مدت‌ها قبل از اینکه کامپیوترهای دیجیتال programmable اختراع شوند، punch card tabulating machines - مانند machines Hollerith که در سرشماری ایالات متحده در سال 1890 [6] استفاده می‌شد - یک form semi-mechanized از batch processing را برای محاسبه aggregate statistics از inputs بزرگ پیاده‌سازی کردند. و MapReduce شباهت عجیبی به machines electromechanical IBM card-sorting دارد که به طور گسترده برای business data processing در دهه‌های 1940 و 1950 استفاده می‌شد [7]. طبق معمول، history تمایل به تکرار خود دارد.
    </p>
<p>
        در این فصل، ما به MapReduce و چندین batch processing algorithms و frameworks دیگر نگاه خواهیم کرد، و بررسی می‌کنیم که چگونه در modern data systems استفاده می‌شوند. اما ابتدا، برای شروع، ما به data processing با استفاده از ابزارهای standard Unix نگاه خواهیم کرد. حتی اگر شما از قبل با آن‌ها آشنا هستید، یک یادآوری در مورد the Unix philosophy ارزش
    </p>
<p>
        390 | Chapter 10: Batch Processing
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0412</div>
            </div>
        </div>
        <!-- Page 0413 -->
        <div class="chapter" id="page-0413">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<h4>i. Some people love to point out</h4>
<p>
        که cat در اینجا غیرضروری است، زیرا input file می‌تواند مستقیماً به عنوان یک argument به awk داده شود. با این حال، linear pipeline هنگام نوشتن به این صورت، مشهودتر است.
    </p>
<p>
        زیرا ایده‌ها و درس‌ها از Unix به large-scale, heterogeneous distributed data systems منتقل می‌شوند.
    </p>
<h4>Batch Processing with Unix Tools</h4>
<p>
        بیایید با یک مثال ساده شروع کنیم. فرض کنید شما یک web server دارید که هر بار که یک request را سرویس می‌دهد، یک خط به یک log file اضافه می‌کند. به عنوان مثال، با استفاده از nginx default access log format، یک خط از log ممکن است به این صورت باشد:
    </p>
<p>
        216.58.210.78 - - [27/Feb/2015:17:55:11 +0000] "GET /css/typography.css HTTP/1.1"
        200 3377 "http://martin.kleppmann.com/" "Mozilla/5.0 (Macintosh; Intel Mac OS X
        10_9_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/40.0.2214.115
        Safari/537.36"
    </p>
<p>
        (این در واقع یک خط است؛ فقط برای خوانایی به چندین خط در اینجا شکسته شده است.)
        اطلاعات زیادی در آن خط وجود دارد. برای تفسیر آن، شما باید به تعریف log format نگاه کنید، که به شرح زیر است:
    </p>
<p>
        $remote_addr - $remote_user [$time_local] "$request"
        $status $body_bytes_sent "$http_referer" "$http_user_agent"
    </p>
<p>
        بنابراین، این یک خط از log نشان می‌دهد که در 27 فوریه 2015، در ساعت 17:55:11 UTC، سرور یک request را برای فایل /css/typography.css از client IP address 216.58.210.78 دریافت کرد. The user احراز هویت نشده بود، بنابراین $remote_user به یک خط تیره (-) تنظیم شده است. The response status برابر 200 بود (یعنی، request موفقیت‌آمیز بود)، و اندازه response برابر 3,377 bytes بود. The web browser، Chrome 40 بود، و فایل را بارگیری کرد زیرا در صفحه در URL http://martin.kleppmann.com/ به آن ارجاع شده بود.
    </p>
<h4>Simple Log Analysis</h4>
<p>
        ابزارهای مختلف می‌توانند این log files را بگیرند و گزارش‌های زیبا در مورد ترافیک وب‌سایت شما تولید کنند، اما به خاطر تمرین، بیایید خودمان را با استفاده از ابزارهای basic Unix بسازیم. به عنوان مثال، فرض کنید شما می‌خواهید پنج صفحه محبوب‌ترین در وب‌سایت خود را پیدا کنید. شما می‌توانید این کار را در یک Unix shell به صورت زیر انجام دهید: i
    </p>
<p>
        cat /var/log/nginx/access.log |
        awk '{print $7}' |
        sort |
        uniq -c |
        sort -r -n |
        head -n 5
    </p>
<ul>
<li>Read the log file.
            <p>
                Batch Processing with Unix Tools | 391
            </p>
</li>
</ul>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0413</div>
            </div>
        </div>
        <!-- Page 0414 -->
        <div class="chapter" id="page-0414">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        هر خط را به fields بر اساس whitespace تقسیم کنید، و فقط هفتمین field را از هر خط، که به طور اتفاقی همان URL درخواستی است، خروجی دهید. در خط مثال ما، این request URL، /css/typography.css است.
    </p>
<p>
        لیست URLهای درخواستی را به ترتیب حروف الفبا مرتب کنید. اگر یک URL، n بار request شده باشد، سپس پس از sorting، فایل حاوی همان URL است که n بار پشت سر هم تکرار شده است.
    </p>
<p>
        The uniq command، خطوط تکراری را در ورودی خود با بررسی اینکه آیا دو خط adjacent یکسان هستند یا خیر، فیلتر می‌کند. The -c option به آن می‌گوید که یک counter نیز خروجی دهد: برای هر URL distinct، گزارش می‌دهد که آن URL چند بار در ورودی ظاهر شده است.
    </p>
<p>
        The second sort با number (-n) در ابتدای هر خط مرتب می‌شود، که تعداد دفعاتی است که URL درخواست شده است. سپس نتایج را به ترتیب reverse (-r) برمی‌گرداند، یعنی با بزرگترین number اول.
    </p>
<p>
        در نهایت، head فقط پنج خط اول (-n 5) از ورودی را خروجی می‌دهد، و بقیه را discard می‌کند.
        خروجی از آن series از commands چیزی شبیه به این است:
    </p>
<p>
        4189 /favicon.ico
        3631 /2013/05/24/improving-security-of-ssh-private-keys.html
        2124 /2012/12/05/schema-evolution-in-avro-protocol-buffers-thrift.html
        1369 /
        915 /css/typography.css
    </p>
<p>
        اگرچه احتمالاً command line قبلی اگر شما با ابزارهای Unix آشنا نیستید، کمی مبهم به نظر می‌رسد، اما بسیار قدرتمند است. این، gigabytes از log files را در عرض چند ثانیه پردازش می‌کند، و شما به راحتی می‌توانید analysis را برای پاسخگویی به نیازهای خود تغییر دهید. به عنوان مثال، اگر شما می‌خواهید فایل‌های CSS را از گزارش حذف کنید، awk argument را به '$7 !~ /\.css$/ {print $7}' تغییر دهید. اگر شما می‌خواهید top client IP addresses را به جای top pages بشمارید، awk argument را به '{print $1}' تغییر دهید. و همینطور الی آخر.
    </p>
<p>
        ما در این کتاب فضایی برای بررسی ابزارهای Unix با جزئیات نداریم، اما یادگیری در مورد آن‌ها بسیار ارزشمند است. به طور شگفت‌آوری بسیاری از data analyses را می‌توان در چند دقیقه با استفاده از ترکیبی از awk, sed, grep, sort, uniq, و xargs انجام داد، و آن‌ها به طور شگفت‌انگیزی عملکرد خوبی دارند [8].
    </p>
<h4>Chain of commands versus custom program</h4>
<p>
        به جای chain of Unix commands، شما می‌توانید یک برنامه ساده برای انجام همان کار بنویسید. به عنوان مثال، در Ruby، ممکن است چیزی شبیه به این باشد:
    </p>
<p>
        392 | Chapter 10: Batch Processing
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0414</div>
            </div>
        </div>
        <!-- Page 0415 -->
        <div class="chapter" id="page-0415">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        counts = Hash.new(0)
        File.open('/var/log/nginx/access.log') do |file|
        file.each do |line|
        url = line.split[6]
        counts[url] += 1
        end
        end
        top5 = counts.map{|url, count| [count, url] }.sort.reverse[0...5]
        top5.each{|count, url| puts "#{count} #{url}" }
        counts یک hash table است که یک counter برای تعداد دفعاتی که ما هر URL را دیده‌ایم، نگهداری می‌کند. A counter به طور پیش‌فرض zero است.
    </p>
<p>
        از هر خط از log، ما URL را به عنوان هفتمین field جدا شده با whitespace در نظر می‌گیریم (شاخص array در اینجا 6 است زیرا arrays از Ruby zero-indexed هستند).
    </p>
<p>
        counter را برای URL در خط فعلی از log افزایش دهید.
    </p>
<p>
        محتوای hash table را بر اساس مقدار counter (به ترتیب descending) مرتب کنید، و پنج entry برتر را بگیرید.
    </p>
<p>
        آن پنج entry برتر را چاپ کنید.
        این برنامه به اندازه chain of Unix pipes، concise نیست، اما نسبتاً readable است، و اینکه کدام یک از این دو را ترجیح می‌دهید تا حدودی به سلیقه بستگی دارد. با این حال، علاوه بر differences syntactic سطحی بین این دو، یک تفاوت بزرگ در execution flow وجود دارد، که اگر شما این analysis را بر روی یک فایل بزرگ اجرا کنید، مشهود می‌شود.
    </p>
<h4>Sorting versus in-memory aggregation</h4>
<p>
        اسکریپت Ruby یک in-memory hash table از URLs را نگه می‌دارد، که در آن هر URL به تعداد دفعاتی که دیده شده است، نگاشت می‌شود. The Unix pipeline example، چنین یک hash table ندارد، اما در عوض به sorting یک لیست از URLs متکی است که در آن چندین occurrence از همان URL به سادگی تکرار می‌شوند.
    </p>
<p>
        کدام approach بهتر است؟ این بستگی به این دارد که شما چند URL مختلف دارید. برای اکثر وب‌سایت‌های کوچک تا متوسط، شما احتمالاً می‌توانید تمام URLsهای distinct، و یک counter برای هر URL، را در (مثلاً) 1 گیگابایت حافظه جای دهید. در این مثال، working set از job (مقدار حافظه‌ای که job نیاز به دسترسی تصادفی به آن دارد) فقط به number از distinct URLs بستگی دارد: اگر یک میلیون log entries برای یک URL واحد وجود داشته باشد، فضای مورد نیاز در hash table همچنان فقط یک URL به اضافه اندازه counter است. اگر این working set به اندازه کافی کوچک باشد، یک in-memory hash table خوب کار می‌کند - حتی بر روی یک laptop.
    </p>
<p>
        از سوی دیگر، اگر working set از job بزرگتر از حافظه موجود باشد، approach sorting این مزیت را دارد که می‌تواند از دیسک‌ها به طور efficient استفاده کند. این the
        Batch Processing with Unix Tools | 393
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0415</div>
            </div>
        </div>
        <!-- Page 0416 -->
        <div class="chapter" id="page-0416">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        همان اصل را دارد که ما در "SSTables and LSM-Trees" در صفحه 76 بحث کردیم: chunks of داده‌ها می‌توانند در حافظه مرتب شوند و به عنوان segment files به disk نوشته شوند، و سپس multiple sorted segments می‌توانند در یک فایل مرتب شده بزرگتر merge شوند. Mergesort، الگوهای دسترسی sequential دارد که بر روی diskها به خوبی عمل می‌کنند. (به یاد داشته باشید که بهینه‌سازی برای sequential I/O یک theme تکراری در فصل 3 بود. همان الگو در اینجا دوباره ظاهر می‌شود.)
    </p>
<p>
        The sort utility در GNU Coreutils (Linux) به طور خودکار datasetsهای بزرگتر از حافظه را با spill کردن به disk handle می‌کند، و به طور خودکار sorting را در سراسر multiple CPU cores parallelizes می‌کند [9]. این بدان معناست که زنجیره ساده از Unix commands که ما قبلاً دیدیم، به راحتی به datasetsهای بزرگ مقیاس می‌شود، بدون اینکه از حافظه خارج شود. The bottleneck احتمالاً سرعت خواندن input file از disk است.
    </p>
<h4>The Unix Philosophy</h4>
<p>
        اتفاقی نیست که ما توانستیم یک log file را با استفاده از یک chain از commands مانند مثال قبلی، کاملاً آسان تجزیه و تحلیل کنیم: این در واقع یکی از ایده‌های اصلی طراحی از Unix بود، و امروزه به طور شگفت‌انگیزی مرتبط باقی می‌ماند. بیایید به آن با جزئیات بیشتری نگاه کنیم تا بتوانیم برخی از ایده‌ها را از Unix قرض بگیریم [10].
    </p>
<p>
        Doug McIlroy، مخترع Unix pipes، ابتدا آن‌ها را در سال 1964 به این صورت توصیف کرد [11]:
        “We should have some ways of connecting programs like [a] garden hose—screw in
        another segment when it becomes necessary to massage data in another way. This is
        the way of I/O also.”
        The plumbing analogy باقی ماند، و ایده connecting programs با pipes، بخشی از آنچه که اکنون به عنوان the Unix philosophy شناخته می‌شود - مجموعه‌ای از design principles که در میان developers و users از Unix محبوب شد، شد. The philosophy در سال 1978 به شرح زیر توصیف شد [12, 13]:
    </p>
<ol>
<li>Make each program do one thing well. To do a new job, build afresh rather than
            complicate old programs by adding new “features”.
        </li>
<li>Expect the output of every program to become the input to another, as yet
            unknown, program. Don’t clutter output with extraneous information. Avoid
            stringently columnar or binary input formats. Don’t insist on interactive input.
        </li>
<li>Design and build software, even operating systems, to be tried early, ideally within
            weeks. Don’t hesitate to throw away the clumsy parts and rebuild them.
        </li>
<li>Use tools in preference to unskilled help to lighten a programming task, even if
            you have to detour to build the tools and expect to throw some of them out after
            you’ve finished using them.
        </li>
</ol>
<p>
        این approach - automation, rapid prototyping, incremental iteration, being friendly
        to experimentation، و breaking down large projects into manageable chunks -
        به طور قابل توجهی شبیه به جنبش‌های Agile و DevOps امروزی است. به طور شگفت‌انگیزی، در چهار دهه گذشته تغییرات کمی داشته است.
    </p>
<p>
        394 | Chapter 10: Batch Processing
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0416</div>
            </div>
        </div>
        <!-- Page 0417 -->
        <div class="chapter" id="page-0417">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<h4>ii. Another example of a uniform interface</h4>
<p>
        یک مثال دیگر از یک uniform interface، URLها و HTTP است، که بنیادهای وب هستند. A URL یک چیز خاص (resource) را در یک وب‌سایت شناسایی می‌کند، و شما می‌توانید به هر URL از هر وب‌سایت دیگری لینک دهید. A user با یک web browser بنابراین می‌تواند به طور یکپارچه بین وب‌سایت‌ها با دنبال کردن لینک‌ها پرش کند، حتی اگر سرورها توسط سازمان‌های کاملاً نامرتبط اداره شوند. این اصل امروزه بدیهی به نظر می‌رسد، اما یک insight کلیدی در ساختن وب به موفقیتی که امروزه دارد بود. systemsهای قبلی، آنقدر uniform نبودند: به عنوان مثال، در دوران bulletin board systems (BBSs)، هر سیستم شماره تلفن و پیکربندی baud rate خود را داشت. یک reference از یک BBS به دیگری باید به شکل یک شماره تلفن و تنظیمات modem باشد؛ user باید قطع می‌کرد، شماره BBS دیگر را می‌گرفت، و سپس به صورت دستی اطلاعاتی را که به دنبال آن بود، پیدا می‌کرد. این امکان وجود نداشت که مستقیماً به برخی از محتواها در داخل یک BBS دیگر لینک داد.
    </p>
<p>
        The sort tool یک مثال عالی از یک برنامه است که یک کار را به خوبی انجام می‌دهد. به جرأت می‌توان گفت که این یک پیاده‌سازی بهتر از sorting است که اکثر زبان‌های برنامه‌نویسی در standard libraries خود دارند (که به disk spill نمی‌کنند و از multiple threads استفاده نمی‌کنند، حتی زمانی که این کار مفید باشد). و با این حال، sort به تنهایی به سختی مفید است. این فقط در ترکیب با other Unix tools، مانند uniq، قدرتمند می‌شود.
    </p>
<p>
        یک Unix shell مانند bash به ما اجازه می‌دهد تا به راحتی این برنامه‌های کوچک را به jobs data processing به طور شگفت‌انگیزی قدرتمند، ترکیب کنیم. حتی اگر بسیاری از این برنامه‌ها توسط گروه‌های مختلفی از افراد نوشته شده باشند، آن‌ها می‌توانند به روش‌های انعطاف‌پذیری به هم بپیوندند. Unix برای فعال کردن این composability چه کاری انجام می‌دهد؟
    </p>
<h4>A uniform interface</h4>
<p>
        اگر شما انتظار دارید که output از یک program به input از یک program دیگر تبدیل شود، این بدان معناست که آن programs باید از همان data format استفاده کنند - به عبارت دیگر، یک interface سازگار. اگر شما می‌خواهید قادر باشید که output از هر program را به input از هر program وصل کنید، این بدان معناست که همه programs باید از همان input/output interface استفاده کنند.
    </p>
<p>
        در Unix، آن interface یک فایل (یا، به طور دقیق‌تر، یک file descriptor) است. A file فقط یک sequence ordered از bytes است. از آنجایی که این یک interface بسیار ساده است، بسیاری از چیزهای مختلف را می‌توان با استفاده از همان interface نشان داد: یک فایل واقعی بر روی filesystem، یک communication channel به یک process دیگر (Unix socket, stdin, stdout)، یک device driver (به عنوان مثال /dev/audio یا /dev/lp0)، یک socket که نشان‌دهنده یک TCP connection است، و غیره. آسان است که این را بدیهی بگیریم، اما در واقع بسیار قابل توجه است که این چیزهای بسیار متفاوت می‌توانند یک uniform interface را به اشتراک بگذارند، بنابراین آن‌ها می‌توانند به راحتی به یکدیگر متصل شوند.ii
        طبق convention، بسیاری از (اما نه همه) Unix programs، این sequence از bytes را به عنوان ASCII text در نظر می‌گیرند. مثال log analysis ما از این fact استفاده کرد: awk, sort, uniq، و head همگی فایل input خود را به عنوان یک لیست از records که توسط \n (newline, ASCII 0x0A) charac-تر جدا شده‌اند، در نظر می‌گیرند. انتخاب \n، arbitrary است - می‌توان گفت، the ASCII record separator 0x1E، یک انتخاب بهتر بود، زیرا برای این منظور در نظر گرفته شده است [14] - اما در هر صورت، این واقعیت که همه این programs بر استفاده از همان record separator، standard شده‌اند، به آن‌ها اجازه می‌دهد که interoperate کنند.
    </p>
<p>
        Batch Processing with Unix Tools | 395
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0417</div>
            </div>
        </div>
        <!-- Page 0418 -->
        <div class="chapter" id="page-0418">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        Parsing از هر record (به عنوان مثال، یک خط از input) نامشخص‌تر است. ابزارهای Unix معمولاً یک خط را به fields بر اساس whitespace یا tab characters تقسیم می‌کنند، اما CSV (comma-separated)، pipe-separated، و encodingsهای دیگر نیز استفاده می‌شود. حتی یک ابزار نسبتاً ساده مانند xargs دارای نیم دوجین command-line options برای مشخص کردن نحوه parsing input آن است.
    </p>
<p>
        The uniform interface از ASCII text، عمدتاً کار می‌کند، اما دقیقاً زیبا نیست: مثال log analysis ما از {print $7} برای extract کردن URL استفاده می‌کرد، که خیلی خوانا نیست. در یک دنیای ایده‌آل، این شاید می‌توانست {print $request_url} یا چیزی از این قبیل باشد. ما بعداً به این ایده باز خواهیم گشت.
    </p>
<p>
        اگرچه کامل نیست، حتی دهه‌ها بعد، the uniform interface از Unix هنوز هم چیزی قابل توجه است. نرم‌افزارهای زیادی به خوبی ابزارهای Unix interoperate و compose نمی‌شوند: شما نمی‌توانید به راحتی محتوای حساب ایمیل خود و history خرید آنلاین خود را از طریق یک ابزار analysis سفارشی به یک spreadsheet و post نتایج به یک social network یا یک wiki، pipe کنید. امروزه داشتن برنامه‌هایی که به روانی ابزارهای Unix با هم کار می‌کنند، یک exception است، نه the norm.
    </p>
<p>
        حتی databases با همان data model، اغلب این کار را آسان نمی‌کنند که داده‌ها را از یک سیستم بیرون بکشید و به دیگری وارد کنید. این عدم integration منجر به Balkanization of data می‌شود.
    </p>
<h4>Separation of logic and wiring</h4>
<p>
        یک ویژگی دیگر از ابزارهای Unix، استفاده آن‌ها از standard input (stdin) و standard output (stdout) است. اگر شما یک برنامه را اجرا می‌کنید و هیچ چیز دیگری را مشخص نمی‌کنید، stdin از صفحه کلید می‌آید و stdout به صفحه نمایش می‌رود. با این حال، شما همچنین می‌توانید input را از یک فایل بگیرید و/یا output را به یک فایل redirect کنید. Pipes به شما اجازه می‌دهند که stdout از یک process را به stdin از یک process دیگر متصل کنید (با یک in-memory buffer کوچک، و بدون نوشتن کل داده‌های intermediate stream به disk).
    </p>
<p>
        یک برنامه هنوز هم می‌تواند files را به طور مستقیم بخواند و بنویسد، اگر به آن نیاز داشته باشد، اما approach Unix، بهتر عمل می‌کند اگر یک برنامه در مورد file paths خاص نگران نباشد و به سادگی از stdin و stdout استفاده کند. این به یک shell user اجازه می‌دهد تا input و output را به هر روشی که می‌خواهند، وصل کنند؛ the program نمی‌داند یا اهمیتی نمی‌دهد که input از کجا می‌آید و output به کجا می‌رود. (می‌توان گفت این یک form از loose coupling, late binding [15]، یا inversion of control [16] است.) جدا کردن input/output wiring از program logic، ترکیب ابزارهای کوچک به systemsهای بزرگتر را آسان‌تر می‌کند.
    </p>
<p>
        شما حتی می‌توانید برنامه‌های خودتان را بنویسید و آن‌ها را با ابزارهای ارائه شده توسط operating system ترکیب کنید. برنامه شما فقط نیاز دارد که input را از stdin بخواند و output را به stdout بنویسد، و می‌تواند در data processing pipelines شرکت کند. در مثال log analysis، شما می‌توانید یک ابزار بنویسید که user-agent strings را به browser identifiersهای منطقی‌تر ترجمه کند، یا یک ابزار که IP addresses را به country codes ترجمه می‌کند، و به سادگی آن را به pipeline متصل کنید. The sort program، اهمیتی نمی‌دهد که آیا با بخش دیگری از operating system یا با یک برنامه که توسط شما نوشته شده است، ارتباط برقرار می‌کند یا خیر.
    </p>
<p>
        396 | Chapter 10: Batch Processing
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0418</div>
            </div>
        </div>
        <!-- Page 0419 -->
        <div class="chapter" id="page-0419">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<h4>iii. Except by using a separate tool</h4>
<p>
        مانند netcat یا curl. Unix، با تلاش برای نشان دادن همه چیز به عنوان فایل‌ها شروع شد، اما BSD sockets API از آن convention [17] منحرف شد. The research operating systems Plan 9 و Inferno در استفاده آن‌ها از فایل‌ها، سازگارتر هستند: آن‌ها یک TCP connection را به عنوان یک فایل در /net/tcp نشان می‌دهند [18].
    </p>
<p>
        با این حال، محدودیت‌هایی برای آنچه شما می‌توانید با stdin و stdout انجام دهید، وجود دارد. برنامه‌هایی که به multiple inputs یا outputs نیاز دارند، ممکن است اما tricky هستند. شما نمی‌توانید output از یک program را به یک network connection [17, 18].iii pipe کنید. اگر یک برنامه مستقیماً فایل‌هایی را برای reading و writing باز کند، یا یک program دیگر را به عنوان یک subprocess شروع کند، یا یک network connection را باز کند، سپس آن I/O توسط خود برنامه wired up می‌شود. هنوز هم می‌تواند configurable باشد (به عنوان مثال، از طریق command-line options)، اما انعطاف‌پذیری wiring up inputs و outputs در یک shell کاهش می‌یابد.
    </p>
<h4>Transparency and experimentation</h4>
<p>
        بخشی از آنچه که ابزارهای Unix را بسیار موفق می‌کند، این است که آن‌ها دیدن اینکه چه اتفاقی می‌افتد را بسیار آسان می‌کنند:
    </p>
<ul>
<li>
            The input files به Unix commands معمولاً به عنوان immutable تلقی می‌شوند. این بدان معناست که شما می‌توانید commands را هر چند بار که می‌خواهید اجرا کنید، و command-line options مختلف را امتحان کنید، بدون آسیب رساندن به input files.
        </li>
<li>
            شما می‌توانید pipeline را در هر نقطه به پایان برسانید، output را به less pipe کنید، و به آن نگاه کنید تا ببینید آیا فرم مورد انتظار را دارد یا خیر. این توانایی برای inspection برای debugging عالی است.
        </li>
<li>
            شما می‌توانید output از یک stage pipeline را به یک فایل بنویسید و از آن فایل به عنوان input به stage بعدی استفاده کنید. این به شما امکان می‌دهد تا stage بعدی را بدون دوباره اجرا کردن کل pipeline، راه‌اندازی مجدد کنید.
        </li>
</ul>
<p>
        بنابراین، حتی اگر ابزارهای Unix بسیار blunt هستند، ابزارهای ساده در مقایسه با یک query optimizer از یک relational database، آن‌ها به طور شگفت‌انگیزی مفید باقی می‌مانند، به ویژه برای experimentation.
    </p>
<p>
        با این حال، بزرگترین limitation از ابزارهای Unix این است که آن‌ها فقط بر روی یک machine واحد اجرا می‌شوند - و این جایی است که ابزارهایی مانند Hadoop وارد می‌شوند.
    </p>
<h4>MapReduce and Distributed Filesystems</h4>
<p>
        MapReduce تا حدودی شبیه به ابزارهای Unix است، اما در سراسر هزاران machines بالقوه distributed شده است. مانند ابزارهای Unix، این یک ابزار نسبتاً blunt, brute-force، اما به طور شگفت‌انگیزی effective است. A single MapReduce job قابل مقایسه با یک process Unix واحد است: این one or more inputs را می‌گیرد و one or more outputs تولید می‌کند.
    </p>
<p>
        همانند اکثر ابزارهای Unix، اجرای یک MapReduce job معمولاً input را تغییر نمی‌دهد و هیچ side effects دیگری به جز تولید output ندارد. The output
    </p>
<p>
        MapReduce and Distributed Filesystems | 397
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0419</div>
            </div>
        </div>
        <!-- Page 0420 -->
        <div class="chapter" id="page-0420">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        iv. One difference is that with HDFS، computing tasks می‌توانند برنامه‌ریزی شوند تا بر روی machine که یک کپی از یک فایل خاص را ذخیره می‌کند، اجرا شوند، در حالی که object stores معمولاً storage و computation را جدا نگه می‌دارند. Reading از یک local disk یک performance advantage دارد اگر network bandwidth یک bottleneck باشد. با این حال توجه داشته باشید که اگر erasure coding استفاده شود، the locality advantage از بین می‌رود، زیرا داده‌ها از چندین machine باید برای بازسازی فایل اصلی ترکیب شوند [20].
    </p>
<p>
        files یک بار، به روش sequential (عدم modification هر قسمت موجود از یک فایل پس از نوشته شدن آن) نوشته می‌شوند.
    </p>
<p>
        در حالی که ابزارهای Unix از stdin و stdout به عنوان input و output استفاده می‌کنند، MapReduce jobs فایل‌ها را بر روی یک distributed filesystem می‌خوانند و می‌نویسند. در پیاده‌سازی Hadoop از MapReduce، آن filesystem، HDFS (Hadoop Distributed File System) نامیده می‌شود، یک reimplementation open source از Google File System (GFS) [19].
    </p>
<p>
        Various other distributed filesystems besides HDFS وجود دارند، مانند GlusterFS و the Quantcast File System (QFS) [20]. Object storage services مانند Amazon S3، Azure Blob Storage، و OpenStack Swift [21] از بسیاری جهات مشابه هستند.iv در این فصل ما بیشتر از HDFS به عنوان یک مثال در حال اجرا استفاده خواهیم کرد، اما principles برای هر distributed filesystem اعمال می‌شود.
    </p>
<p>
        HDFS بر اساس the shared-nothing principle است (به مقدمه Part II مراجعه کنید)، در contrast به the shared-disk approach از Network Attached Storage (NAS) و Storage Area Network (SAN) architectures. Shared-disk storage توسط یک centralized storage appliance پیاده‌سازی می‌شود، که اغلب از hardware custom و زیرساخت network خاص مانند Fibre Channel استفاده می‌کند. از سوی دیگر، the shared-nothing approach به هیچ hardware خاصی نیاز ندارد، فقط کامپیوترهایی که توسط یک datacenter network معمولی متصل شده‌اند.
    </p>
<p>
        HDFS شامل یک daemon process است که بر روی هر machine در حال اجرا است، که یک network service را نشان می‌دهد که به other nodes اجازه می‌دهد به فایل‌های ذخیره شده در آن machine دسترسی داشته باشند (با فرض اینکه هر machine general-purpose در یک datacenter دارای برخی از disks متصل به آن است). A central server به نام NameNode، پیگیری می‌کند که کدام file blocks بر روی کدام machine ذخیره می‌شوند. بنابراین، HDFS از نظر مفهومی یک filesystem بزرگ را ایجاد می‌کند که می‌تواند از فضا بر روی disks از همه machines در حال اجرای the daemon استفاده کند.
    </p>
<p>
        به منظور تحمل machine و disk failures، file blocks بر روی multiple machines replicated می‌شوند. Replication ممکن است به سادگی به معنای چندین کپی از همان داده‌ها بر روی multiple machines، همانطور که در فصل 5، یا یک erasure coding scheme مانند کدهای Reed–Solomon، که به داده‌های از دست رفته اجازه می‌دهد با storage overhead کمتری نسبت به full replication بازیابی شوند [20, 22] باشد. The techniques شبیه به RAID هستند، که redundancy را در سراسر several disks متصل به همان machine فراهم می‌کند؛ تفاوت این است که در یک distributed file‐system، file access و replication بر روی یک datacenter network معمولی بدون hardware خاص انجام می‌شوند.
    </p>
<p>
        398 | Chapter 10: Batch Processing
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0420</div>
            </div>
        </div>
        <!-- Page 0421 -->
        <div class="chapter" id="page-0421">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        HDFS به خوبی مقیاس‌پذیر شده است: در زمان نگارش، بزرگترین HDFS deployments بر روی ده‌ها هزار machine اجرا می‌شوند، با combined storage capacity از صدها پتابایت [23]. Such large scale قابل اجرا شده است زیرا هزینه data storage و دسترسی بر روی HDFS، با استفاده از commodity hardware و open source software، بسیار کمتر از ظرفیت معادل آن بر روی یک dedicated storage appliance [24] است.
    </p>
<h4>MapReduce Job Execution</h4>
<p>
        MapReduce یک programming framework است که شما می‌توانید با آن کد بنویسید تا large datasets را در یک distributed filesystem مانند HDFS پردازش کنید. ساده‌ترین راه برای درک آن، ارجاع به مثال log analysis از web server در "Simple Log Analysis" در صفحه 391 است. الگو از data processing در MapReduce بسیار شبیه به این مثال است:
    </p>
<ol>
<li>Read a set of input files, and break it up into records. In the web server log exam‐
            ple, each record is one line in the log (that is, \n is the record separator).
        </li>
<li>Call the mapper function to extract a key and value from each input record. In
            the preceding example, the mapper function is awk '{print $7}': it extracts the
            URL ($7) as the key, and leaves the value empty.
        </li>
<li>Sort all of the key-value pairs by key. In the log example, this is done by the first
            sort command.
        </li>
<li>Call the reducer function to iterate over the sorted key-value pairs. If there are
            multiple occurrences of the same key, the sorting has made them adjacent in the
            list, so it is easy to combine those values without having to keep a lot of state in
            memory. In the preceding example, the reducer is implemented by the command
            uniq -c, which counts the number of adjacent records with the same key.
        </li>
</ol>
<p>
        Those four steps می‌توانند توسط یک MapReduce job انجام شوند. Steps 2 (map) و 4 (reduce) جایی است که شما کد data processing سفارشی خود را می‌نویسید. Step 1 (breaking files into records) توسط input format parser handle می‌شود. Step 3، the sort step، در MapReduce implicit است - شما مجبور نیستید آن را بنویسید، زیرا output از the mapper همیشه قبل از اینکه به the reducer داده شود، مرتب می‌شود.
    </p>
<p>
        برای ایجاد یک MapReduce job، شما نیاز دارید که دو callback functions، the mapper و reducer، را پیاده‌سازی کنید، که به شرح زیر رفتار می‌کنند (همچنین به "MapReduce Querying" در صفحه 46 مراجعه کنید):
    </p>
<ul>
<li>Mapper
            <p>
                The mapper یک بار برای هر input record فراخوانی می‌شود، و کار آن extract کردن the key و value از input record است. برای هر input، ممکن است هر تعداد از key-value pairs (از جمله هیچ) تولید کند. این stateای را از یک input record به بعدی حفظ نمی‌کند، بنابراین هر record به طور independent handle می‌شود.
            </p>
</li>
</ul>
<p>
        MapReduce and Distributed Filesystems | 399
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0421</div>
            </div>
        </div>
        <!-- Page 0422 -->
        <div class="chapter" id="page-0422">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<ul>
<li>Reducer
            <p>
                The MapReduce framework key-value pairs produced by the mappers را می‌گیرد، تمام values مربوط به همان key را جمع‌آوری می‌کند، و the reducer را با یک iterator بر روی آن collection از values فراخوانی می‌کند. The reducer می‌تواند output records را تولید کند (مانند تعداد occurrences از همان URL).
            </p>
</li>
</ul>
<p>
        In the web server log example, ما یک sort command دوم را در مرحله 5 داشتیم، که URLs را بر اساس تعداد requests رتبه‌بندی می‌کرد. در MapReduce، اگر شما به یک stage sorting دوم نیاز دارید، شما می‌توانید آن را با نوشتن یک MapReduce job دوم و استفاده از output از the first job به عنوان input به the second job، پیاده‌سازی کنید. Viewed like this، نقش از the mapper آماده‌سازی داده‌ها با قرار دادن آن در یک form که برای sorting مناسب است، و نقش از the reducer، پردازش داده‌هایی است که مرتب شده‌اند.
    </p>
<h4>Distributed execution of MapReduce</h4>
<p>
        The main difference from pipelines of Unix commands این است که MapReduce می‌تواند a computation را در سراسر many machines parallelize کند، بدون اینکه شما مجبور باشید کد بنویسید تا به طور صریح the parallelism را handle کنید. The mapper و reducer فقط بر روی یک record در یک زمان عمل می‌کنند؛ آن‌ها نیازی ندارند که بدانند ورودی آن‌ها از کجا می‌آید یا output آن‌ها به کجا می‌رود، بنابراین framework می‌تواند پیچیدگی‌های انتقال داده‌ها بین machines را handle کند.
    </p>
<p>
        امکان استفاده از standard Unix tools به عنوان mappers و reducers در یک computation distributed [25] وجود دارد، اما بیشتر آن‌ها به طور معمول به عنوان functions در یک programming language conventional پیاده‌سازی می‌شوند. در Hadoop MapReduce، the mapper و reducer هر کدام یک class Java هستند که یک interface خاص را پیاده‌سازی می‌کنند. در MongoDB و CouchDB، mappers و reducers، JavaScript functions هستند ("MapReduce Query‐ing" در صفحه 46 را ببینید).
    </p>
<figure>
<img alt="شکل 10-1" src="figure10-1.png" style="max-width: 100%;"/>
<figcaption>
            شکل 10-1 dataflow را در یک Hadoop MapReduce job نشان می‌دهد. Parallelization آن بر اساس partitioning است (فصل 6 را ببینید): ورودی به یک job معمولاً یک directory در HDFS است، و هر فایل یا file block در داخل input directory به عنوان یک separate partition در نظر گرفته می‌شود که می‌تواند توسط یک map task جداگانه پردازش شود (که توسط m 1, m 2، و m 3 در شکل 10-1 مشخص شده است).
        </figcaption>
</figure>
<p>
        Each input file معمولاً صدها مگابایت حجم دارد. The MapReduce scheduler (در نمودار نشان داده نشده است) تلاش می‌کند تا هر mapper را بر روی یکی از machines که یک replica از input file را ذخیره می‌کند، اجرا کند، به شرطی که machine به اندازه کافی RAM و CPU resources برای اجرای the map task داشته باشد [26]. این اصل به عنوان putting the com‐putation near the data شناخته می‌شود [27]: این از کپی کردن input file از طریق شبکه جلوگیری می‌کند، network load را کاهش می‌دهد و locality را افزایش می‌دهد.
    </p>
<p>
        400 | Chapter 10: Batch Processing
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0422</div>
            </div>
        </div>
        <!-- Page 0423 -->
        <div class="chapter" id="page-0423">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<figure>
<img alt="شکل 10-1" src="figure10-1.png"/>
<figcaption>
            شکل 10-1. A MapReduce job با سه mapper و سه reducer.
        </figcaption>
</figure>
<p>
        در اکثر موارد، the application code که باید در map task اجرا شود، هنوز در machine که به آن task از اجرای آن اختصاص داده شده است، وجود ندارد، بنابراین the MapReduce framework ابتدا کد را کپی می‌کند (به عنوان مثال، JAR files در مورد یک برنامه Java) به machines مناسب. سپس map task را شروع می‌کند و خواندن input file را آغاز می‌کند، و یک record را در یک زمان به the mapper callback پاس می‌دهد. The output از the mapper شامل key-value pairs است.
    </p>
<p>
        The reduce side از computation نیز partitioned شده است. در حالی که number از map tasks توسط number از input file blocks تعیین می‌شود، number از reduce tasks توسط job author پیکربندی می‌شود (این می‌تواند با number از map tasks متفاوت باشد). برای اطمینان از اینکه همه key-value pairs با همان key در همان reducer به پایان می‌رسند، framework از یک hash از key برای تعیین اینکه کدام reduce task باید یک key-value pair خاص را دریافت کند، استفاده می‌کند ("Partitioning by Hash of Key" در صفحه 203 را ببینید).
    </p>
<p>
        The key-value pairs باید مرتب شوند، اما احتمالاً the dataset بسیار بزرگ است که با یک sorting algorithm conventional بر روی یک machine واحد مرتب شود. در عوض، sorting در stages انجام می‌شود. اول، هر map task، output خود را بر اساس reducer، بر اساس hash از key، partition می‌کند. هر یک از این partitions به یک فایل مرتب شده بر روی the mapper’s local disk نوشته می‌شود، با استفاده از یک تکنیک مشابه با آنچه ما در "SSTables and LSM-Trees" در صفحه 76 بحث کردیم.
    </p>
<p>
        MapReduce and Distributed Filesystems | 401
    </p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 423" src="page_0423/image_1.png"/></div>
</div>
                <div class="page-number">صفحه 0423</div>
            </div>
        </div>
        <!-- Page 0424 -->
        <div class="chapter" id="page-0424">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        هر زمان که یک mapper خواندن فایل input خود و نوشتن فایل‌های output مرتب‌شده خود را به پایان می‌رساند، the MapReduce scheduler به reducers اطلاع می‌دهد که آن‌ها می‌توانند شروع به واکشی فایل‌های output از آن mapper کنند. The reducers به هر یک از mappers متصل می‌شوند و فایل‌های key-value pairs مرتب‌شده را برای partition خود دانلود می‌کنند. این process از partitioning by reducer, sorting, و کپی کردن data partitions از mappers به reducers به عنوان shuffle شناخته می‌شود [26] (یک اصطلاح گیج‌کننده - برخلاف shuffling a deck of cards، هیچ randomness در MapReduce وجود ندارد).
    </p>
<p>
        The reduce task فایل‌ها را از mappers می‌گیرد و آن‌ها را با هم merge می‌کند، و ترتیب مرتب‌سازی را حفظ می‌کند. بنابراین، اگر mappersهای مختلف رکوردهایی را با همان key تولید کردند، آن‌ها در input از reducer merged شده، مجاور هم خواهند بود.
    </p>
<p>
        The reducer با یک key و یک iterator فراخوانی می‌شود که به طور افزایشی تمام records با همان key را اسکن می‌کند (که ممکن است در برخی موارد، همه در حافظه جا نشوند). The reducer می‌تواند از logic دلخواه برای پردازش این records استفاده کند، و می‌تواند هر تعداد از output records را تولید کند. این output records به یک فایل در distributed filesystem نوشته می‌شوند (معمولاً، یک کپی بر روی disk local از machine در حال اجرای the reducer، با replicas بر روی machinesهای دیگر).
    </p>
<h4>MapReduce workflows</h4>
<p>
        محدوده مشکلاتی که شما می‌توانید با یک MapReduce job واحد حل کنید، محدود است. با ارجاع به مثال log analysis، یک MapReduce job واحد می‌تواند تعداد page views per URL را تعیین کند، اما نه محبوب‌ترین URLs را، زیرا این امر به یک round sorting دوم نیاز دارد.
    </p>
<p>
        بنابراین، بسیار رایج است که MapReduce jobs با هم به workflows، زنجیر شوند، به طوری که output از یک job به input به job بعدی تبدیل می‌شود. The Hadoop MapReduce framework هیچ پشتیبانی خاصی برای workflows ندارد، بنابراین این chaining به طور ضمنی توسط directory name انجام می‌شود: the first job باید پیکربندی شود تا output خود را به یک directory تعیین شده در HDFS بنویسد، و the second job باید پیکربندی شود تا همان directory name را به عنوان input خود بخواند. از نقطه نظر MapReduce framework، آن‌ها دو job مستقل هستند.
    </p>
<p>
        Chained MapReduce jobs، بنابراین کمتر شبیه pipelines از Unix commands هستند (که output از یک process را به عنوان input به یک process دیگر به طور مستقیم، با استفاده از فقط یک in-memory buffer کوچک، منتقل می‌کنند) و بیشتر شبیه به یک sequence از commands هستند که در آن output از هر command به یک فایل temporary نوشته می‌شود، و the next command از فایل temporary می‌خواند. این design مزایا و معایبی دارد، که ما در "Materialization of Intermediate State" در صفحه 419 در مورد آن بحث خواهیم کرد.
    </p>
<p>
        The output از یک batch job، فقط زمانی معتبر در نظر گرفته می‌شود که job با موفقیت تکمیل شده باشد (MapReduce، the partial output از یک job شکست‌خورده را discard می‌کند). بنابراین، یک job در یک workflow می‌تواند فقط زمانی شروع شود که jobs قبلی - یعنی، the jobs که input directories آن را تولید می‌کنند - با موفقیت تکمیل شده باشند. برای handle کردن این dependencies بین job
    </p>
<p>
        402 | Chapter 10: Batch Processing
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0424</div>
            </div>
        </div>
        <!-- Page 0425 -->
        <div class="chapter" id="page-0425">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<h4>v. The joins we talk about in this book</h4>
<p>
        joins که ما در این کتاب در مورد آن‌ها صحبت می‌کنیم، به طور کلی equi-joins هستند، که رایج‌ترین نوع join هستند، که در آن یک record با other records که یک مقدار یکسان در یک field خاص (مانند یک ID) دارند، مرتبط می‌شود. برخی از databases، از انواع عمومی‌تر joins پشتیبانی می‌کنند، به عنوان مثال با استفاده از یک less-than operator به جای یک equality operator، اما ما فضایی برای پوشش آن‌ها در اینجا نداریم.
    </p>
<p>
        executions، various workflow schedulers برای Hadoop توسعه داده شده‌اند، شامل Oozie, Azkaban, Luigi, Airflow، و Pinball [28].
    </p>
<p>
        These schedulers همچنین دارای features management هستند که هنگام حفظ یک collection بزرگ از batch jobs مفید هستند. Workflows که شامل 50 تا 100 MapReduce jobs هستند، هنگام ساختن recommendation systems [29] رایج هستند، و در یک سازمان بزرگ، بسیاری از تیم‌های مختلف ممکن است jobsهای مختلفی را اجرا کنند که output یکدیگر را می‌خوانند.
        Tool support برای مدیریت چنین dataflows پیچیده مهم است.
    </p>
<p>
        Various higher-level tools برای Hadoop، مانند Pig [30]، Hive [31]، Cascading [32]، Crunch [33]، و FlumeJava [34]، همچنین workflows از multiple MapReduce stages را راه‌اندازی می‌کنند که به طور خودکار به درستی به هم متصل می‌شوند.
    </p>
<h4>Reduce-Side Joins and Grouping</h4>
<p>
        ما در مورد joins در فصل 2 در context از data models و query languages بحث کردیم، اما ما در مورد اینکه چگونه joins در واقع پیاده‌سازی می‌شوند، بحث نکردیم. زمان آن فرا رسیده است که ما دوباره آن thread را برداریم.
    </p>
<p>
        در بسیاری از datasets، این رایج است که یک record، یک association با یک record دیگر داشته باشد: یک foreign key در یک relational model، یک document reference در یک document model، یا یک edge در یک graph model. A join، هر زمان که شما کدی دارید که نیاز دارد به records در هر دو طرف آن association (هم record که reference را نگه می‌دارد و هم record که به آن reference می‌شود) دسترسی داشته باشد، ضروری است. همانطور که در فصل 2 بحث شد، denormalization می‌تواند نیاز به joins را کاهش دهد اما عموماً آن را به طور کامل حذف نمی‌کند.v
    </p>
<p>
        در یک database، اگر شما یک query را اجرا کنید که فقط شامل تعداد کمی از records است، database معمولاً از یک index برای یافتن سریع records مورد علاقه استفاده می‌کند (فصل 3 را ببینید). اگر query شامل joins باشد، ممکن است به multiple index lookups نیاز داشته باشد. با این حال، MapReduce هیچ مفهومی از indexes ندارد - حداقل نه به معنای معمول.
    </p>
<p>
        هنگامی که یک MapReduce job، یک set از فایل‌ها را به عنوان input دریافت می‌کند، کل محتوای تمام آن فایل‌ها را می‌خواند؛ یک database، این operation را یک full table scan می‌نامد. اگر شما فقط می‌خواهید تعداد کمی از records را بخوانید، a full table scan در مقایسه با یک index lookup، به طرز وحشتناکی گران است. با این حال، در analytic queries (به "Transaction Processing or Analytics?" در صفحه 90 مراجعه کنید) این رایج است که بخواهید aggregates را بر روی تعداد زیادی از records محاسبه کنید. در این مورد، scanning کل input ممکن است یک چیز کاملاً معقول باشد، به خصوص اگر شما بتوانید processing را در سراسر multiple machines parallelize کنید.
    </p>
<p>
        MapReduce and Distributed Filesystems | 403
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0425</div>
            </div>
        </div>
        <!-- Page 0426 -->
        <div class="chapter" id="page-0426">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        وقتی ما در مورد joins در context از batch processing صحبت می‌کنیم، منظور ما resolving تمام occurrences از یک association در داخل یک dataset است. به عنوان مثال، ما فرض می‌کنیم که یک job، داده‌ها را برای همه users به طور همزمان پردازش می‌کند، نه صرفاً جستجوی داده‌ها برای یک user خاص (که با یک index بسیار کارآمدتر انجام می‌شود).
    </p>
<h4>Example: analysis of user activity events</h4>
<p>
        یک مثال معمول از یک join در یک batch job در شکل 10-2 نشان داده شده است. در سمت چپ یک log از events که چیزهایی را که کاربران logged-in در یک وب‌سایت انجام داده‌اند (که به عنوان activity events یا clickstream data شناخته می‌شود) توصیف می‌کند، و در سمت راست یک database از users قرار دارد. شما می‌توانید در مورد این مثال به عنوان بخشی از یک star schema فکر کنید ("Stars and Snowflakes: Sche‐mas for Analytics" در صفحه 93 را ببینید): log از events، fact table است، و database از user، یکی از dimensions است.
    </p>
<figure>
<img alt="شکل 10-2" src="figure10-2.png"/>
<figcaption>
            شکل 10-2. A join بین یک log از user activity events و یک database از user profiles.
        </figcaption>
</figure>
<p>
        A analytics task ممکن است نیاز داشته باشد که user activity را با user profile information مرتبط کند: به عنوان مثال، اگر profile حاوی age یا date of birth از user باشد، سیستم می‌تواند تعیین کند که کدام صفحات با کدام age groups محبوب‌تر هستند. با این حال، activity events فقط شامل user ID، نه the full user profile information، هستند. Embedding آن profile information در هر activity event واحد، به احتمال زیاد بسیار waste‐ful خواهد بود. بنابراین، activity events باید با user profile database join شوند.
    </p>
<p>
        ساده‌ترین پیاده‌سازی از این join، یکی یکی بر روی activity events می‌رود و database user (بر روی یک remote server) را برای هر user ID که با آن مواجه می‌شود، query می‌کند.
        این امکان‌پذیر است، اما احتمالاً از performance بسیار ضعیفی رنج می‌برد: the processing throughput توسط round-trip time به the database server محدود می‌شود، اثربخشی از یک cache local به شدت به توزیع داده‌ها بستگی دارد، و اجرای تعداد زیادی از queries به صورت parallel می‌تواند به راحتی database را تحت تأثیر قرار دهد [35].
    </p>
<p>
        404 | Chapter 10: Batch Processing
    </p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 426" src="page_0426/image_1.png"/></div>
</div>
                <div class="page-number">صفحه 0426</div>
            </div>
        </div>
        <!-- Page 0427 -->
        <div class="chapter" id="page-0427">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        به منظور دستیابی به throughput خوب در یک batch process، computation باید (تا حد امکان) local به یک machine باشد. Making random-access requests بر روی شبکه برای هر recordی که شما می‌خواهید پردازش کنید، بسیار کند است. علاوه بر این، querying a remote database به این معنی است که the batch job، nondeterministic می‌شود، زیرا داده‌ها در the remote database ممکن است تغییر کنند.
    </p>
<p>
        بنابراین، یک approach بهتر این است که یک کپی از user database (به عنوان مثال، استخراج شده از یک database backup با استفاده از یک ETL process - به "Data Warehousing" در صفحه 91 مراجعه کنید) را بگیرید و آن را در همان distributed filesystem به عنوان log از user activity events قرار دهید. سپس شما database user را در یک set از فایل‌ها در HDFS و the user activity records را در یک set دیگر از فایل‌ها خواهید داشت، و می‌توانید از MapReduce برای گرد هم آوردن تمام recordsهای مرتبط در همان مکان و پردازش آن‌ها به طور efficient استفاده کنید.
    </p>
<h4>Sort-merge joins</h4>
<p>
        به یاد بیاورید که هدف از the mapper extract کردن یک key و value از هر input record است. در مورد شکل 10-2، این key، user ID خواهد بود: یک set از mappers، بر روی activity events (extract کردن user ID به عنوان key و the activity event به عنوان value) می‌رود، در حالی که یک set دیگر از mappers، بر روی user database (extract کردن user ID به عنوان key و date of birth از user به عنوان value) می‌رود. این process در شکل 10-3 نشان داده شده است.
    </p>
<figure>
<img alt="شکل 10-3" src="figure10-3.png"/>
<figcaption>
            شکل 10-3. A reduce-side sort-merge join بر روی user ID. اگر input datasets به multiple files partitioned شوند، هر کدام می‌توانند با multiple mappers به صورت parallel پردازش شوند.
        </figcaption>
</figure>
<p>
        هنگامی که the MapReduce framework، the mapper output را by key partition می‌کند و سپس key-value pairs را sort می‌کند، این اثر را دارد که همه activity events و the user record با همان user ID، در input از the reducer در مجاورت یکدیگر قرار می‌گیرند. The MapReduce job، حتی می‌تواند records را طوری مرتب کند که the reducer همیشه
    </p>
<p>
        MapReduce and Distributed Filesystems | 405
    </p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 427" src="page_0427/image_1.png"/></div>
</div>
                <div class="page-number">صفحه 0427</div>
            </div>
        </div>
        <!-- Page 0428 -->
        <div class="chapter" id="page-0428">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        sees the record from the user database first, followed by the activity events in time‐stamp order - این تکنیک به عنوان a secondary sort شناخته می‌شود [26].
    </p>
<p>
        The reducer می‌تواند سپس منطق join واقعی را به راحتی انجام دهد: the reducer function، یک بار برای هر user ID فراخوانی می‌شود، و به لطف the secondary sort، انتظار می‌رود که first value، the date-of-birth record از user database باشد. The reducer، date of birth را در یک variable local ذخیره می‌کند و سپس بر روی activity events با همان user ID تکرار می‌شود، و pairs از viewed-url و viewer-age-in-years را output می‌دهد. Subsequent MapReduce jobs می‌توانند سپس توزیع از viewer ages را برای هر URL محاسبه کنند، و بر اساس age group cluster کنند.
    </p>
<p>
        از آنجایی که the reducer، همه records را برای یک user ID خاص در یک بار پردازش می‌کند، فقط نیاز دارد که یک user record را در هر زمان در حافظه نگه دارد، و هرگز نیازی ندارد که هیچ requests را از طریق شبکه انجام دهد. این algorithm، به عنوان a sort-merge join شناخته می‌شود، از آنجایی که mapper output توسط key مرتب می‌شود، و سپس reducers لیست‌های مرتب شده از records را از هر دو طرف join با هم merge می‌کنند.
    </p>
<h4>Bringing related data together in the same place</h4>
<p>
        در a sort-merge join، mappers و process sorting اطمینان حاصل می‌کنند که تمام داده‌های لازم برای انجام the join operation برای یک user ID خاص، در همان مکان آورده می‌شوند: یک call واحد به the reducer. با قرار دادن تمام داده‌های مورد نیاز در قبل، the reducer می‌تواند یک piece of code نسبتاً ساده و single-threaded باشد که می‌تواند records را با throughput بالا و memory overhead پایین، churn کند.
    </p>
<p>
        یک راه برای نگاه کردن به این architecture این است که mappers "send messages" را به the reducers. هنگامی که یک mapper، یک key-value pair را emit می‌کند، the key به عنوان destination address عمل می‌کند که value باید به آن تحویل داده شود. حتی اگر key فقط یک رشته arbitrary (نه یک network address واقعی مانند یک IP address و port number) باشد، مانند یک address رفتار می‌کند: تمام key-value pairs با همان key به همان destination تحویل داده می‌شوند (یک call به the reducer).
    </p>
<p>
        استفاده از the MapReduce programming model، جنبه‌های physical network com‐munication از computation (getting the data to the right machine) را از application logic (processing the data once you have it) جدا کرده است. This separation با استفاده معمول از databases تفاوت دارد، که در آن یک request برای fetch data از یک database، اغلب در جایی عمیق در داخل یک piece از application code اتفاق می‌افتد [36]. از آنجایی که MapReduce، تمام network communication را handle می‌کند، همچنین application code را از نگرانی در مورد partial failures، مانند crash از یک node دیگر، محافظت می‌کند: MapReduce tasks شکست‌خورده را بدون تأثیر بر application logic، به صورت transparently retries می‌کند.
    </p>
<h4>GROUP BY</h4>
<p>
        علاوه بر joins، یکی دیگر از استفاده‌های رایج از الگوی "bringing related data to the same place"، grouping records by some key (مانند clause GROUP BY در SQL) است. All
    </p>
<p>
        406 | Chapter 10: Batch Processing
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0428</div>
            </div>
        </div>
        <!-- Page 0429 -->
        <div class="chapter" id="page-0429">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        records با همان key، یک group را تشکیل می‌دهند، و گام بعدی اغلب انجام نوعی aggregation در داخل هر group است - به عنوان مثال:
    </p>
<ul>
<li>Counting the number of records in each group (مانند مثال ما از counting page views، که شما به عنوان یک COUNT(*) aggregation در SQL بیان می‌کنید)</li>
<li>Adding up the values در یک field خاص (SUM(fieldname)) در SQL</li>
<li>Picking the top k records بر اساس یک ranking function</li>
</ul>
<p>
        ساده‌ترین راه برای پیاده‌سازی چنین یک grouping operation با MapReduce، این است که mappers را طوری تنظیم کنید که key-value pairs که تولید می‌کنند از the desired grouping key استفاده کنند. The partitioning و process sorting سپس تمام records با همان key را در همان reducer با هم جمع می‌کند. بنابراین، grouping و joining در زمان پیاده‌سازی بر روی MapReduce، بسیار شبیه به هم به نظر می‌رسند.
    </p>
<p>
        یک استفاده رایج دیگر برای grouping، collating تمام activity events برای یک user session خاص است، به منظور یافتن sequence از actions که user انجام داده است - یک pro‐cess که sessionization [37] نامیده می‌شود. به عنوان مثال، چنین analysis می‌تواند برای مشخص کردن اینکه آیا users که یک version جدید از وب‌سایت شما به آن‌ها نشان داده شده است، بیشتر احتمال دارد خرید کنند تا کسانی که version قدیمی به آن‌ها نشان داده شده است (A/B testing)، یا برای محاسبه اینکه آیا برخی از فعالیت‌های بازاریابی ارزش دارد یا خیر، استفاده شود.
    </p>
<p>
        اگر شما multiple web servers دارید که requestsهای user را handle می‌کنند، activity events برای یک user خاص به احتمال زیاد در log files از various different servers پراکنده شده‌اند. شما می‌توانید sessionization را با استفاده از یک session cookie، user ID، یا یک شناسه مشابه به عنوان grouping key و آوردن تمام activity events برای یک user خاص به یک مکان واحد، در حالی که events از users مختلف را در سراسر partitions مختلف توزیع می‌کنید، پیاده‌سازی کنید.
    </p>
<h4>Handling skew</h4>
<p>
        الگوی "bringing all records with the same key to the same place" اگر مقدار بسیار زیادی از داده‌ها مربوط به یک key واحد وجود داشته باشد، از هم می‌پاشد. به عنوان مثال، در یک social network، اکثر users ممکن است به چند صد نفر متصل باشند، اما تعداد کمی از celebrities ممکن است میلیون‌ها follower داشته باشند. چنین recordsهای database که به طور نامتناسب فعال هستند، به عنوان linchpin objects [38] یا hot keys شناخته می‌شوند.
    </p>
<p>
        جمع‌آوری تمام activity مربوط به یک celebrity (به عنوان مثال، پاسخ به چیزی که آن‌ها پست کرده‌اند) در یک reducer واحد می‌تواند منجر به significant skew (همچنین به عنوان hot spots شناخته می‌شود) شود - یعنی، یک reducer که باید تعداد قابل توجهی از records بیشتری را نسبت به دیگران پردازش کند ("Skewed Workloads and Relieving Hot Spots" در صفحه 205 را ببینید). از آنجایی که یک MapReduce job فقط زمانی تکمیل می‌شود که تمام mappers و reducers آن تکمیل شده باشند، هر jobs بعدی باید منتظر بمانند تا sloweest reducer قبل از اینکه بتوانند شروع شوند، تکمیل شود.
    </p>
<p>
        اگر یک join input دارای hot keys باشد، چند algorithm وجود دارد که شما می‌توانید برای جبران استفاده کنید. به عنوان مثال، the skewed join method در Pig ابتدا یک sampling job را اجرا می‌کند تا تعیین کند که کدام keys، hot هستند [39]. هنگام انجام join واقعی، mappers هر
    </p>
<p>
        MapReduce and Distributed Filesystems | 407
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0429</div>
            </div>
        </div>
        <!-- Page 0430 -->
        <div class="chapter" id="page-0430">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        records مربوط به یک hot key را به یکی از several reducers، که به صورت random انتخاب شده‌اند، ارسال می‌کنند (برخلاف MapReduce conventional، که یک reducer را به طور deterministic بر اساس a hash از key انتخاب می‌کند). برای ورودی دیگر به join، records مربوط به hot key، نیاز به replicated شدن به همه reducers در حال handling آن key [40] دارند.
    </p>
<p>
        این تکنیک، کار handling the hot key را در سراسر several reducers توزیع می‌کند، که به آن اجازه می‌دهد تا بهتر parallelized شود، با هزینه اینکه the other join input باید به multiple reducers replicate شود. The sharded join method در Crunch مشابه است، اما requires hot keys را به طور صریح‌تر مشخص می‌کند تا با استفاده از یک sampling job. این تکنیک نیز بسیار شبیه به یکی از techniques است که ما در "Skewed Workloads and Relieving Hot Spots" در صفحه 205 بحث کردیم، با استفاده از randomization برای کاهش hot spots در یک partitioned data‐base.
    </p>
<p>
        The skewed join optimization از Hive، یک approach جایگزین را در پیش می‌گیرد. این requires hot keys را برای مشخص شدن به طور صریح‌تر در table metadata، و آن records مربوط به those keys را در فایل‌های جداگانه از بقیه ذخیره می‌کند. هنگامی که یک join بر روی آن table انجام می‌شود، آن از a map-side join استفاده می‌کند (به بخش بعدی مراجعه کنید) برای hot keys.
    </p>
<p>
        هنگام grouping records by a hot key و aggregation آن‌ها، شما می‌توانید grouping را در دو مرحله انجام دهید. The first MapReduce stage، records را به یک reducer random ارسال می‌کند، به طوری که هر reducer، grouping را بر روی یک subset از records برای the hot key انجام می‌دهد و یک aggregated value compactتر را per key خروجی می‌دهد. The second MapReduce job سپس، values از تمام the first-stage reducers را به یک value واحد per key، ترکیب می‌کند.
    </p>
<h4>Map-Side Joins</h4>
<p>
        The join algorithms که در بخش قبل توضیح داده شدند، the actual join logic را در reducers انجام می‌دهند، و از این رو به عنوان reduce-side joins شناخته می‌شوند. Mappers نقش آماده‌سازی data ورودی را به عهده دارند: extract کردن the key و value از هر input record، اختصاص دادن the key-value pairs به یک reducer partition، و sorting by key.
    </p>
<p>
        The reduce-side approach این مزیت را دارد که شما نیازی ندارید هیچ فرضی در مورد input data داشته باشید: هر ویژگی و ساختاری که داشته باشد، mappers می‌توانند داده‌ها را برای آماده شدن برای joining آماده کنند. با این حال، the downside این است که تمام آن sorting، کپی کردن به reducers، و merging از reducer inputs می‌تواند بسیار گران‌قیمت باشد.
        بسته به memory buffers موجود، داده‌ها ممکن است چندین بار در هنگام عبور از stages از MapReduce به disk نوشته شوند [37].
    </p>
<p>
        از سوی دیگر، اگر شما می‌توانید فرضیاتی را در مورد input data خود داشته باشید، این امکان وجود دارد که با استفاده از یک so-called map-side join، joins را سریع‌تر کنید. این approach از یک MapReduce job cut-down استفاده می‌کند که در آن هیچ reducer و هیچ sorting وجود ندارد. در عوض، هر mapper به سادگی یک input file block را از distributed filesystem می‌خواند و یک output file را به filesystem می‌نویسد - این همه چیز است.
    </p>
<p>
        408 | Chapter 10: Batch Processing
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0430</div>
            </div>
        </div>
        <!-- Page 0431 -->
        <div class="chapter" id="page-0431">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<h4>vi. This example assumes that there is exactly one entry</h4>
<p>
        برای هر key در hash table، که احتمالاً با یک user database درست است (یک user ID به طور منحصر به فرد یک user را شناسایی می‌کند). به طور کلی، the hash table ممکن است نیاز داشته باشد که شامل several entries با همان key باشد، و join operator تمام matches برای یک key را output می‌دهد.
    </p>
<h4>Broadcast hash joins</h4>
<p>
        ساده‌ترین راه برای انجام یک map-side join، در موردی اعمال می‌شود که یک dataset بزرگ با یک dataset کوچک join می‌شود. به طور خاص، dataset کوچک نیاز دارد که به اندازه کافی کوچک باشد تا بتواند به طور کامل در حافظه در هر یک از mappers بارگذاری شود.
        به عنوان مثال، در مورد شکل 10-2 تصور کنید که user database به اندازه کافی کوچک است که در حافظه جا شود. در این حالت، وقتی یک mapper راه‌اندازی می‌شود، ابتدا می‌تواند user database را از distributed filesystem به یک in-memory hash table بخواند. هنگامی که این کار انجام شد، the mapper می‌تواند activity events را بررسی کند و به سادگی user ID را برای هر event در hash table جستجو کند.vi
    </p>
<p>
        هنوز هم می‌تواند چندین map tasks وجود داشته باشد: یکی برای هر file block از input بزرگ به join (در مثال شکل 10-2، activity events، the large input هستند). هر یک از این mappers، ورودی کوچک را به طور کامل در حافظه بارگذاری می‌کنند.
    </p>
<p>
        این algorithm ساده اما موثر، a broadcast hash join نامیده می‌شود: کلمه broadcast، این واقعیت را منعکس می‌کند که هر mapper برای یک partition از the large input، کل input کوچک را می‌خواند (بنابراین the small input به طور موثر به تمام partitions از the large input "broadcast" می‌شود)، و کلمه hash، استفاده از یک hash table را منعکس می‌کند. این join method توسط Pig (تحت نام "replicated join")، Hive ("MapJoin")، Cascading، و Crunch پشتیبانی می‌شود. همچنین در data warehouse query engines مانند Impala [41] استفاده می‌شود.
    </p>
<p>
        به جای بارگذاری the small join input به یک in-memory hash table، یک جایگزین، ذخیره the small join input در یک read-only index بر روی disk local است [42]. The fre‐quently used parts از این index، در page cache از operating system باقی می‌مانند، بنابراین این approach می‌تواند random-access lookups را تقریباً به سرعت a in-memory hash table، اما بدون نیاز واقعی به dataset برای قرار گرفتن در حافظه، فراهم کند.
    </p>
<h4>Partitioned hash joins</h4>
<p>
        اگر inputs به map-side join به همان روش partitioning شوند، سپس approach hash join می‌تواند به هر partition به طور independent اعمال شود. در مورد شکل 10-2، شما ممکن است برای activity events و user database، هر کدام بر اساس آخرین رقم اعشاری از user ID partition کنید (بنابراین 10 partitions در هر دو طرف وجود دارد). به عنوان مثال، mapper 3 ابتدا تمام users را با یک ID که به 3 ختم می‌شود، به یک hash table بارگذاری می‌کند، و سپس بر روی تمام activity events برای هر user که ID آن به 3 ختم می‌شود، اسکن می‌کند.
    </p>
<p>
        اگر the partitioning به درستی انجام شود، شما می‌توانید مطمئن باشید که تمام records که ممکن است بخواهید join کنید، در همان partition شماره‌گذاری شده قرار دارند، و بنابراین برای هر mapper کافی است که فقط یک partition را از هر یک از input datasets بخواند. این مزیت را دارد که هر mapper می‌تواند مقدار کمتری از داده‌ها را در hash table خود بارگذاری کند.
    </p>
<p>
        MapReduce and Distributed Filesystems | 409
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0431</div>
            </div>
        </div>
        <!-- Page 0432 -->
        <div class="chapter" id="page-0432">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        این approach فقط در صورتی کار می‌کند که هر دو ورودی join دارای number یکسانی از partitions باشند، با records که به partitions بر اساس همان key و همان hash function اختصاص داده شده‌اند. اگر inputs توسط jobsهای MapReduce قبلی تولید شده باشند که قبلاً این grouping را انجام می‌دهند، سپس این می‌تواند یک فرض منطقی برای انجام دادن باشد.
        Partitioned hash joins در Hive به عنوان bucketed map joins شناخته می‌شوند [37].
    </p>
<h4>Map-side merge joins</h4>
<p>
        یک variant دیگر از یک map-side join اعمال می‌شود اگر input datasets، نه تنها به همان روش partitioned شده‌اند، بلکه همچنین بر اساس همان key مرتب شده‌اند. در این حالت، مهم نیست که آیا inputs به اندازه کافی کوچک هستند تا در حافظه جا شوند، زیرا یک mapper می‌تواند همان operation merging را انجام دهد که معمولاً توسط یک reducer انجام می‌شود:
        خواندن هر دو input files به طور افزایشی، به ترتیب از key صعودی، و matching records با همان key.
    </p>
<p>
        اگر یک map-side merge join امکان‌پذیر است، احتمالاً به این معنی است که jobsهای MapReduce قبلی، input datasets را در این form partitioned و مرتب شده قرار داده‌اند. در اصل، این join می‌توانست در مرحله reduce از job قبلی انجام شود. با این حال، ممکن است هنوز هم مناسب باشد که the merge join را در یک map-only job جداگانه انجام دهید، به عنوان مثال اگر the partitioned و sorted datasets برای other purposes علاوه بر این join خاص نیز مورد نیاز باشند.
    </p>
<h4>MapReduce workflows with map-side joins</h4>
<p>
        هنگامی که output از یک MapReduce join توسط jobsهای downstream مصرف می‌شود، انتخاب map-side یا reduce-side join، بر ساختار از output تأثیر می‌گذارد. The output از یک reduce-side join، توسط the join key partitioned و مرتب می‌شود، در حالی که output از یک map-side join، به همان روش the large input partitioned و مرتب می‌شود (از آنجایی که یک map task برای هر file block از the join’s large input، صرف نظر از اینکه آیا a partitioned یا broadcast join استفاده می‌شود، شروع می‌شود).
    </p>
<p>
        همانطور که بحث شد، map-side joins نیز فرضیات بیشتری را در مورد اندازه، sorting، و partitioning از input datasets خود ایجاد می‌کنند. دانستن در مورد physical layout از datasets در distributed filesystem، هنگامی که بهینه سازی join strategies: مهم می‌شود، کافی نیست که فقط the encoding format و نام از directory که داده‌ها در آن ذخیره می‌شوند را بدانید؛ شما همچنین باید number از partitions و the keys که داده‌ها توسط آن‌ها partitioned و sorted شده‌اند را نیز بدانید.
    </p>
<p>
        در the Hadoop ecosystem، این نوع از metadata در مورد the partitioning از datasets، اغلب در HCatalog و the Hive metastore [37] نگهداری می‌شود.
    </p>
<p>
        410 | Chapter 10: Batch Processing
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0432</div>
            </div>
        </div>
        <!-- Page 0433 -->
        <div class="chapter" id="page-0433">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<h3>خروجی جریان‌های کاری Batch</h3>
<p>
        ما در مورد الگوریتم‌های مختلف برای پیاده‌سازی جریان‌های کاری jobs های <strong>MapReduce</strong>
        صحبت کرده‌ایم، اما یک سوال مهم را نادیده گرفتیم: نتیجه‌ی تمام این پردازش‌ها پس از
        اتمام چیست؟ چرا ما در وهله‌ی اول تمام این jobs ها را اجرا می‌کنیم؟
    </p>
<p>
        در مورد پرس و جوهای پایگاه داده، ما اهداف پردازش تراکنش (<strong>OLTP</strong>) را از اهداف تحلیلی
        (نگاه کنید به "پردازش تراکنش یا Analytics؟" در صفحه 90) متمایز کردیم. ما دیدیم که
        queries های <strong>OLTP</strong> عموماً تعداد کمی از رکوردها را با استفاده از <strong>key</strong> ها و
        <strong>indexes</strong> ها جستجو می‌کنند تا آن‌ها را به کاربر ارائه دهند (به عنوان مثال، در یک صفحه
        وب). از سوی دیگر، queries های تحلیلی اغلب تعداد زیادی از رکوردها را اسکن می‌کنند،
        گروه‌بندی‌ها و تجمیع‌ها را انجام می‌دهند، و خروجی اغلب به شکل یک گزارش است: یک
        نمودار که تغییر در یک معیار را در طول زمان نشان می‌دهد، یا 10 آیتم برتر را طبق
        یک رتبه‌بندی، یا یک تفکیک از یک مقدار به زیرمجموعه‌ها. مصرف‌کننده چنین گزارشی
        اغلب یک تحلیلگر یا یک مدیر است که نیاز به تصمیم‌گیری‌های تجاری دارد.
    </p>
<p>
        پردازش <strong>batch</strong> در کجا قرار می‌گیرد؟ نه پردازش تراکنش است و نه analytics. به analytics
        نزدیک‌تر است، زیرا یک فرآیند batch معمولاً بخش‌های بزرگی از یک مجموعه داده ورودی
        را اسکن می‌کند. با این حال، یک جریان کاری از jobs های <strong>MapReduce</strong> با یک query
        <strong>SQL</strong> که برای اهداف تحلیلی استفاده می‌شود یکسان نیست (نگاه کنید به "مقایسه Hadoop با
        پایگاه‌های داده توزیع شده" در صفحه 414). خروجی یک فرآیند batch اغلب یک گزارش
        نیست، بلکه نوعی ساختار دیگر است.
    </p>
<h4>ساخت <strong>indexes</strong> جستجو</h4>
<p>
        استفاده‌ی اصلی <strong>Google</strong> از <strong>MapReduce</strong>، ساخت <strong>indexes</strong> برای موتور جستجوی خود بود،
        که به عنوان یک جریان کاری از 5 تا 10 job <strong>MapReduce</strong> پیاده‌سازی شد [1]. اگرچه
        <strong>Google</strong> بعداً از استفاده از <strong>MapReduce</strong> برای این منظور فاصله گرفت [43]، اما اگر آن را از
        منظر ساخت یک index جستجو بررسی کنید، به درک <strong>MapReduce</strong> کمک می‌کند. (حتی
        امروزه، <strong>Hadoop MapReduce</strong> همچنان یک روش خوب برای ساخت <strong>indexes</strong> برای
        <strong>Lucene/Solr</strong> [44] است.)
    </p>
<p>
        ما به طور مختصر در "جستجوی متن کامل و <strong>indexes</strong> فازی" در صفحه 88 دیدیم که چگونه یک
        index جستجوی متن کامل مانند <strong>Lucene</strong> کار می‌کند: این یک فایل (فرهنگ لغت
        اصطلاحات) است که در آن می‌توانید به طور کارآمد یک کلمه کلیدی خاص را جستجو
        کنید و لیست تمام <strong>IDs</strong> اسناد حاوی آن کلمه کلیدی (لیست پست‌ها) را پیدا کنید. این
        یک دیدگاه بسیار ساده از یک index جستجو است—در واقعیت، نیاز به داده‌های
        اضافی مختلفی دارد تا نتایج جستجو را بر اساس ارتباط، تصحیح غلط‌های املایی،
        حل مترادف‌ها و غیره رتبه‌بندی کند—اما این اصل همچنان پابرجاست.
    </p>
<p>
        اگر نیاز به انجام یک جستجوی متن کامل بر روی یک مجموعه اسناد ثابت دارید،
        آن‌گاه یک فرآیند batch یک راه بسیار موثر برای ساخت <strong>indexes</strong> است:
        <strong>mappers</strong>، مجموعه اسناد را در صورت نیاز تقسیم می‌کنند، هر <strong>reducer</strong> index را
        برای بخش خود می‌سازد و فایل‌های index به سیستم فایل توزیع شده نوشته می‌شوند.
        ساختن چنین <strong>indexes</strong> های تقسیم‌بندی شده (نگاه کنید به "تقسیم‌بندی و <strong>Indexes</strong>
        ثانویه" در صفحه 206) بسیار موازی می‌شود.
    </p>
<p>
<strong>MapReduce</strong> و سیستم‌های فایل توزیع شده
        |
        411
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0433</div>
            </div>
        </div>
        <!-- Page 0434 -->
        <div class="chapter" id="page-0434">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        از آن‌جایی که query کردن یک index جستجو بر اساس keyword یک عملیات read-only است، این فایل‌های
        index پس از ایجاد، <em>immutable</em> هستند.
    </p>
<p>
        اگر مجموعه <em>indexed</em> اسناد تغییر کند، یک گزینه این است که دوره‌ای کل workflow <em>indexing</em> را
        برای کل مجموعه اسناد دوباره اجرا کنید، و فایل‌های index قبلی را به طور کامل با
        فایل‌های index جدید جایگزین کنید، زمانی که این کار انجام شد. این رویکرد
        می‌تواند از نظر محاسباتی گران‌قیمت باشد اگر تنها تعداد کمی از اسناد تغییر کرده
        باشند، اما این مزیت را دارد که فرآیند <em>indexing</em> بسیار آسان است: اسناد وارد می‌شوند،
        indexes خارج می‌شوند.
    </p>
<p>
        به‌طور جایگزین، می‌توان <strong>indexes</strong> را به صورت افزایشی ساخت. همان‌طور که در فصل 3 بحث
        شد، اگر می‌خواهید اسناد را در یک index اضافه، حذف یا به‌روزرسانی کنید، <strong>Lucene</strong> فایل‌های
        segment جدیدی را می‌نویسد و به‌طور ناهمزمان فایل‌های segment را در پس‌زمینه
        ادغام و فشرده می‌کند. ما در فصل 11 در مورد این نوع پردازش افزایشی بیشتر
        خواهیم دید.
    </p>
<h4>ذخیره‌سازی‌های <strong>key-value</strong> به عنوان خروجی فرآیند <strong>batch</strong></h4>
<p>
<strong>Indexes</strong> جستجو تنها یک نمونه از خروجی‌های ممکن یک workflow پردازش <strong>batch</strong> است.
        یکی دیگر از کاربردهای رایج برای پردازش <strong>batch</strong>، ساخت سیستم‌های <strong>machine learning</strong>
        مانند طبقه‌بندها (به عنوان مثال، فیلترهای هرزنامه، تشخیص ناهنجاری، تشخیص
        تصویر) و سیستم‌های پیشنهاد (به عنوان مثال، افرادی که ممکن است بشناسید،
        محصولاتی که ممکن است به آن‌ها علاقه‌مند باشید، یا جستجوهای مرتبط [29]) است.
    </p>
<p>
        خروجی آن jobs های <strong>batch</strong> اغلب نوعی پایگاه داده است: به عنوان مثال، یک پایگاه داده که
        می‌تواند توسط <strong>user ID</strong> query شود تا دوستان پیشنهادی برای آن کاربر به دست آید، یا
        یک پایگاه داده که می‌تواند توسط <strong>product ID</strong> query شود تا لیستی از محصولات مرتبط
        به دست آید [45].
    </p>
<p>
        این پایگاه‌های داده باید از web application که درخواست‌های کاربر را مدیریت
        می‌کند، query شوند، که معمولاً از زیرساخت <strong>Hadoop</strong> جدا است. بنابراین، خروجی از
        فرآیند <strong>batch</strong> چگونه به یک پایگاه داده برمی‌گردد که در آن web application می‌تواند
        آن را query کند؟
    </p>
<p>
        انتخاب واضح‌تر ممکن است استفاده از کتابخانه <strong>client</strong> برای پایگاه داده‌ی مورد علاقه‌تان
        مستقیماً در داخل یک <strong>mapper</strong> یا <strong>reducer</strong> باشد، و مستقیماً از job <strong>batch</strong> به سرور
        پایگاه داده، یک رکورد در یک زمان، بنویسید. این کار خواهد کرد (با فرض این‌که
        قوانین فایروال شما دسترسی مستقیم از محیط <strong>Hadoop</strong> شما به پایگاه‌های داده
        production شما را مجاز می‌کند)، اما به چند دلیل این یک ایده بد است:
    </p>
<ul>
<li>
            همان‌طور که قبلاً در زمینه <strong>joins</strong> بحث شد، ایجاد یک درخواست شبکه برای
            تک تک رکوردها، چندین مرتبه کندتر از توان عملیاتی نرمال یک task <strong>batch</strong> است.
            حتی اگر کتابخانه <strong>client</strong> از <strong>batching</strong> پشتیبانی کند، احتمالاً عملکرد ضعیف
            خواهد بود.
        </li>
<li>
            jobs های <strong>MapReduce</strong> اغلب بسیاری از <strong>tasks</strong> را به صورت موازی اجرا می‌کنند. اگر تمام
            <strong>mappers</strong> یا <strong>reducers</strong> هم‌زمان به یک پایگاه داده خروجی یکسان بنویسند، با
            نرخ مورد انتظار یک فرآیند <strong>batch</strong>، آن پایگاه داده به راحتی می‌تواند تحت
            فشار قرار گیرد، و عملکرد آن برای query
            412
        </li>
</ul>
<p>
        فصل 10: پردازش <strong>Batch</strong>
</p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0434</div>
            </div>
        </div>
        <!-- Page 0435 -->
        <div class="chapter" id="page-0435">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<ul>
<li>
            عملکرد <strong>queries</strong> احتمالاً آسیب خواهد دید. این امر می‌تواند به نوبه خود باعث بروز
            مشکلات عملیاتی در سایر بخش‌های سیستم شود [35].
        </li>
<li>
            به‌طور معمول، <strong>MapReduce</strong> یک تضمین کامل یا هیچ برای خروجی job ارائه می‌دهد: اگر یک
            job با موفقیت انجام شود، نتیجه، خروجی اجرای هر task دقیقاً یک بار است،
            حتی اگر برخی از <strong>tasks</strong> با شکست مواجه شوند و مجبور به تکرار مجدد در طول
            مسیر شوند؛ اگر کل job با شکست مواجه شود، هیچ خروجی تولید نمی‌شود.
            با این حال، نوشتن به یک سیستم خارجی از داخل یک job، اثرات جانبی
            خارجی قابل مشاهده را تولید می‌کند که نمی‌توان آن‌ها را به این روش پنهان
            کرد. بنابراین، شما باید نگران نتایج حاصل از jobs های نیمه‌تمام باشید که برای
            سیستم‌های دیگر قابل مشاهده هستند، و پیچیدگی‌های تلاش‌های <strong>Hadoop</strong>
<strong>task</strong> و اجرای speculative.
        </li>
</ul>
<p>
        یک راه‌حل بسیار بهتر این است که یک پایگاه داده کاملاً جدید را در داخل job
        <strong>batch</strong> بسازید و آن را به عنوان فایل به دایرکتوری خروجی job در سیستم فایل
        توزیع شده بنویسید، درست مانند index های جستجو در بخش آخر. آن فایل‌های
        داده پس از نوشتن، <em>immutable</em> هستند و می‌توانند به‌صورت عمده در سرورهایی
        بارگذاری شوند که query های read-only را مدیریت می‌کنند.
        ذخیره‌سازی‌های <strong>key-value</strong> مختلف از ساخت فایل‌های پایگاه داده در jobs های
        <strong>MapReduce</strong> پشتیبانی می‌کنند، از جمله <strong>Voldemort</strong> [46]، <strong>Terrapin</strong> [47]، <strong>ElephantDB</strong>
        [48]، و بارگذاری <strong>bulk</strong> <strong>HBase</strong> [49].
    </p>
<p>
        ساخت این فایل‌های پایگاه داده یک استفاده خوب از <strong>MapReduce</strong> است: استفاده از یک
        <strong>mapper</strong> برای استخراج یک <strong>key</strong> و سپس مرتب‌سازی بر اساس آن <strong>key</strong>، در حال حاضر
        بخش زیادی از کار مورد نیاز برای ساخت یک index است. از آن‌جایی که بیشتر
        این ذخیره‌سازی‌های <strong>key-value</strong> read-only هستند (فایل‌ها فقط می‌توانند یک بار توسط
        یک job <strong>batch</strong> نوشته شوند و سپس <em>immutable</em> می‌شوند)، ساختارهای داده بسیار ساده
        هستند. به‌عنوان مثال، آن‌ها نیازی به <strong>WAL</strong> ندارند (نگاه کنید به "ایمن کردن
        B-trees" در صفحه 82).
    </p>
<p>
        هنگام بارگذاری داده‌ها در <strong>Voldemort</strong>، سرور به سرویس‌دهی درخواست‌ها به فایل‌های
        داده قدیمی ادامه می‌دهد در حالی که فایل‌های داده جدید از سیستم فایل توزیع
        شده به دیسک محلی سرور کپی می‌شوند. پس از اتمام کپی، سرور به‌صورت
        اتمی به query کردن فایل‌های جدید می‌رود. اگر در این فرآیند مشکلی پیش بیاید،
        می‌تواند به راحتی دوباره به فایل‌های قدیمی برگردد، زیرا هنوز آن‌جا هستند و
        <em>immutable</em> [46].
    </p>
<h4>فلسفه خروجی‌های فرآیند <strong>batch</strong></h4>
<p>
        فلسفه <strong>Unix</strong> که ما قبلاً در این فصل در مورد آن بحث کردیم ("فلسفه <strong>Unix</strong>" در صفحه
        394) با صراحت بسیار در مورد <strong>dataflow</strong>، آزمایش را تشویق می‌کند: یک برنامه ورودی
        خود را می‌خواند و خروجی خود را می‌نویسد. در این فرآیند، ورودی بدون تغییر
        باقی می‌ماند، هر خروجی قبلی به‌طور کامل با خروجی جدید جایگزین می‌شود، و
        هیچ اثر جانبی دیگری وجود ندارد. این بدان معنی است که شما می‌توانید یک
        دستور را هرچند که دوست دارید دوباره اجرا کنید، آن را اصلاح یا <strong>debug</strong> کنید،
        بدون این‌که وضعیت سیستم خود را به هم بریزید.
    </p>
<p>
        مدیریت خروجی از jobs های <strong>MapReduce</strong> از همین فلسفه پیروی می‌کند. با برخورد با
        ورودی‌ها به عنوان <em>immutable</em> و اجتناب از اثرات جانبی (مانند نوشتن به پایگاه‌های
        داده خارجی)، jobs های <strong>batch</strong> نه تنها عملکرد خوبی را به دست می‌آورند، بلکه
        نگهداری آن‌ها نیز بسیار آسان‌تر می‌شود:
    </p>
<p>
<strong>MapReduce</strong> و سیستم‌های فایل توزیع شده
        |
        413
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0435</div>
            </div>
        </div>
        <!-- Page 0436 -->
        <div class="chapter" id="page-0436">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<ul>
<li>
            اگر شما یک <strong>bug</strong> را به کد معرفی کنید و خروجی اشتباه یا خراب شود،
            شما به سادگی می‌توانید به نسخه قبلی کد بازگردید و job را دوباره اجرا
            کنید، و خروجی دوباره صحیح خواهد بود. یا، حتی ساده‌تر، می‌توانید خروجی
            قدیمی را در یک دایرکتوری متفاوت نگه دارید و به سادگی به آن بازگردید.
            پایگاه‌های داده با تراکنش‌های <strong>read-write</strong> این ویژگی را ندارند: اگر شما کد
            اشکال‌دار را مستقر کنید که داده‌های بد را به پایگاه داده می‌نویسد، سپس
            بازگرداندن کد هیچ کاری برای رفع داده‌ها در پایگاه داده انجام نخواهد داد.
            (ایده‌ی توانایی بازیابی از کد اشکال‌دار <strong>human fault tolerance</strong> نامیده
            می‌شود [50].)
        </li>
<li>
            در نتیجه این سهولت در بازگشت، توسعه‌ی <strong>feature</strong> می‌تواند سریع‌تر از
            محیطی که اشتباهات می‌تواند به معنای آسیب برگشت‌ناپذیر باشد، پیش برود. این
            اصل به حداقل رساندن برگشت‌ناپذیری برای توسعه نرم‌افزار <strong>Agile</strong> مفید است
            [51].
        </li>
<li>
            اگر یک <strong>map</strong> یا <strong>reduce task</strong> شکست بخورد، فریم‌ورک <strong>MapReduce</strong>
            به‌طور خودکار آن را دوباره زمان‌بندی می‌کند و دوباره روی همان ورودی اجرا
            می‌کند. اگر شکست به دلیل یک <strong>bug</strong> در کد باشد، همچنان خراب می‌شود و در
            نهایت باعث می‌شود job پس از چند تلاش با شکست مواجه شود؛ اما اگر شکست
            به دلیل یک مشکل گذرا باشد، خطا تحمل می‌شود. این <strong>retry</strong> خودکار تنها به
            این دلیل ایمن است که ورودی‌ها <em>immutable</em> هستند و خروجی‌ها از <strong>tasks</strong>
            شکست‌خورده توسط فریم‌ورک <strong>MapReduce</strong> دور ریخته می‌شوند.
        </li>
<li>
            همان مجموعه فایل‌ها را می‌توان به عنوان ورودی برای jobs های مختلف استفاده
            کرد، از جمله jobs های <strong>monitoring</strong> که معیارها را محاسبه می‌کنند و ارزیابی
            می‌کنند که آیا خروجی یک job ویژگی‌های مورد انتظار را دارد (به عنوان مثال، با
            مقایسه آن با خروجی از اجرای قبلی و اندازه‌گیری تفاوت‌ها).
        </li>
<li>
            مانند ابزارهای <strong>Unix</strong>، jobs های <strong>MapReduce</strong> منطق را از سیم‌کشی جدا
            می‌کنند (پیکربندی دایرکتوری‌های ورودی و خروجی)، که جداسازی
            <strong>concerns</strong> را فراهم می‌کند و امکان استفاده مجدد از کد را فراهم می‌کند: یک
            تیم می‌تواند روی پیاده‌سازی یک job تمرکز کند که یک کار را خوب انجام
            می‌دهد، در حالی که تیم‌های دیگر می‌توانند تصمیم بگیرند که کجا و چه زمانی
            آن job را اجرا کنند.
        </li>
</ul>
<p>
        در این زمینه‌ها، اصول طراحی که برای <strong>Unix</strong> خوب عمل کردند، به نظر می‌رسد
        برای <strong>Hadoop</strong> نیز خوب عمل می‌کنند—اما <strong>Unix</strong> و <strong>Hadoop</strong> نیز از جهاتی متفاوت هستند.
        به عنوان مثال، از آن‌جایی که اکثر ابزارهای <strong>Unix</strong> فایل‌های متنی <em>untyped</em> را
        فرض می‌کنند، باید مقدار زیادی <strong>parsing</strong> ورودی انجام دهند (مثال تحلیل
        log ما در ابتدای فصل از {print $7} برای استخراج <strong>URL</strong> استفاده کرد). در
        <strong>Hadoop</strong>، برخی از آن تبدیل‌های <strong>syntactic</strong> کم‌ارزش با استفاده از فرمت‌های فایل
        ساختاریافته‌تر حذف می‌شوند: <strong>Avro</strong> (نگاه کنید به "<strong>Avro</strong>" در صفحه 122) و <strong>Parquet</strong>
        (نگاه کنید به "<strong>Column-Oriented Storage</strong>" در صفحه 95) اغلب استفاده می‌شوند،
        زیرا آن‌ها <strong>encoding</strong> مبتنی بر <strong>schema</strong> کارآمد را ارائه می‌دهند و امکان تکامل
        schemas آن‌ها را در طول زمان فراهم می‌کنند (نگاه کنید به فصل 4).
    </p>
<h4>مقایسه <strong>Hadoop</strong> با پایگاه‌های داده توزیع شده</h4>
<p>
        همان‌طور که دیدیم، <strong>Hadoop</strong> تا حدودی شبیه یک نسخه توزیع شده از <strong>Unix</strong> است، جایی
        که <strong>HDFS</strong> فایل‌سیستم است و <strong>MapReduce</strong> یک پیاده‌سازی عجیب از یک فرآیند
        <strong>Unix</strong> است.
    </p>
<p>
        414
        |
        فصل 10: پردازش <strong>Batch</strong>
</p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0436</div>
            </div>
        </div>
        <!-- Page 0437 -->
        <div class="chapter" id="page-0437">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        (که اتفاقاً همیشه ابزار <strong>sort</strong> را بین فاز <strong>map</strong> و فاز <strong>reduce</strong> اجرا
        می‌کند). ما دیدیم که چگونه می‌توانید عملیات <strong>join</strong> و <strong>grouping</strong> مختلف را
        بر اساس این <strong>primitives</strong> پیاده‌سازی کنید.
    </p>
<p>
        هنگامی که مقاله <strong>MapReduce</strong> [1] منتشر شد، از یک نظر، اصلاً
        جدید نبود. تمام الگوریتم‌های پردازش و <strong>parallel join</strong> که ما در چند بخش آخر
        بحث کردیم، قبلاً در پایگاه‌های داده‌ی به اصطلاح <strong>massively parallel processing</strong>
        (<strong>MPP</strong>) بیش از یک دهه قبل پیاده‌سازی شده بودند [3, 40]. به عنوان مثال،
        ماشین پایگاه داده <strong>Gamma</strong>، <strong>Teradata</strong> و <strong>Tandem NonStop SQL</strong> پیشگامان در این
        زمینه بودند [52].
    </p>
<p>
        بزرگترین تفاوت این است که پایگاه‌های داده <strong>MPP</strong> بر اجرای <strong>parallel</strong> queries
        <strong>SQL</strong> تحلیلی بر روی یک cluster از ماشین‌ها تمرکز دارند، در حالی که
        ترکیبی از <strong>MapReduce</strong> و یک سیستم فایل توزیع شده [19] چیزی بسیار
        شبیه به یک سیستم عامل <strong>general-purpose</strong> ارائه می‌دهد که می‌تواند
        برنامه‌های دلخواه را اجرا کند.
    </p>
<h4>تنوع ذخیره‌سازی</h4>
<p>
        پایگاه‌های داده از شما می‌خواهند که داده‌ها را مطابق با یک مدل خاص
        ساختاردهی کنید (به عنوان مثال، رابطه‌ای یا اسناد)، در حالی که فایل‌ها در یک
        سیستم فایل توزیع شده فقط دنباله‌ای از بایت‌ها هستند، که می‌توانند با
        استفاده از هر مدل داده و <strong>encoding</strong> نوشته شوند. آن‌ها ممکن است مجموعه‌ای
        از رکوردهای پایگاه داده باشند، اما می‌توانند به همان اندازه متن، تصاویر،
        فیلم‌ها، خوانش‌های سنسور، ماتریس‌های <em>sparse</em>، بردار ویژگی‌ها، توالی‌های
        ژنی یا هر نوع دیگری از داده‌ها باشند.
    </p>
<p>
        به‌طور خلاصه، <strong>Hadoop</strong> امکان تخلیه بی‌رویه داده‌ها را در <strong>HDFS</strong> فراهم کرد، و
        تنها بعداً چگونگی پردازش بیشتر آن را مشخص کرد [53]. در مقابل، پایگاه‌های
        داده <strong>MPP</strong> معمولاً نیاز به مدل‌سازی دقیق داده‌ها و الگوهای query قبل از
        وارد کردن داده‌ها به فرمت ذخیره‌سازی اختصاصی پایگاه داده دارند.
    </p>
<p>
        از دیدگاه یک <em>purist</em>، ممکن است به نظر برسد که این مدل‌سازی و وارد کردن
        دقیق مطلوب است، زیرا به این معنی است که کاربران پایگاه داده داده‌های با
        کیفیت‌تری برای کار دارند. با این حال، در عمل، به نظر می‌رسد که به سادگی
        در دسترس قرار دادن داده‌ها به سرعت—حتی اگر در یک فرمت <em>quirky</em>،
        دشوار برای استفاده، خام باشد—اغلب ارزشمندتر از تلاش برای تصمیم‌گیری
        در مورد مدل داده‌ی ایده‌آل در ابتدا است [54].
    </p>
<p>
        ایده شبیه به یک انبار داده (نگاه کنید به "<strong>Data Warehousing</strong>" در صفحه 91) است:
        به سادگی جمع‌آوری داده‌ها از بخش‌های مختلف یک سازمان بزرگ در یک
        مکان ارزشمند است، زیرا <strong>joins</strong> را در سراسر مجموعه‌داده‌هایی که قبلاً
        متفاوت بودند، امکان‌پذیر می‌کند. طراحی دقیق <strong>schema</strong> مورد نیاز توسط یک
        پایگاه داده <strong>MPP</strong>، جمع‌آوری متمرکز داده‌ها را کند می‌کند؛ جمع‌آوری
        داده‌ها به شکل خام، و نگرانی در مورد طراحی <strong>schema</strong> در آینده،
        اجازه می‌دهد جمع‌آوری داده‌ها سرعت یابد (مفهومی که گاهی اوقات به عنوان
        "<strong>data lake</strong>" یا "<strong>enterprise data hub</strong>" شناخته می‌شود [55]).
    </p>
<p>
        تخلیه بی‌رویه داده‌ها، بار تفسیر داده‌ها را تغییر می‌دهد: به جای مجبور کردن
        تولیدکننده یک مجموعه‌داده برای آوردن آن به یک فرمت استاندارد، تفسیر
        داده‌ها به مشکل مصرف‌کننده تبدیل می‌شود (رویکرد <strong>schema-on-read</strong>
<strong>MapReduce</strong> و سیستم‌های فایل توزیع شده
        |
        415
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0437</div>
            </div>
        </div>
        <!-- Page 0438 -->
        <div class="chapter" id="page-0438">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        [56]؛ نگاه کنید به "انعطاف‌پذیری <strong>Schema</strong> در مدل سند" در صفحه 39). این می‌تواند
        یک مزیت باشد اگر تولیدکننده و مصرف‌کنندگان تیم‌های متفاوتی با
        اولویت‌های مختلف باشند. ممکن است حتی یک مدل داده‌ی ایده‌آل وجود نداشته
        باشد، بلکه دیدگاه‌های متفاوتی از داده‌ها وجود داشته باشد که برای اهداف
        مختلف مناسب هستند. به سادگی تخلیه داده‌ها به شکل خام، امکان چندین
        تبدیل از این دست را فراهم می‌کند. این رویکرد، اصل سوشی نامیده شده است:
        "داده‌های خام بهتر هستند" [57].
    </p>
<p>
        بنابراین، <strong>Hadoop</strong> اغلب برای پیاده‌سازی فرآیندهای <strong>ETL</strong> استفاده شده است (نگاه کنید به
        "<strong>Data Warehousing</strong>" در صفحه 91): داده‌ها از سیستم‌های پردازش تراکنش به شکل
        خام در سیستم فایل توزیع شده ریخته می‌شوند، و سپس jobs های <strong>MapReduce</strong>
        نوشته می‌شوند تا آن داده‌ها را پاکسازی کنند، آن‌ها را به یک فرم رابطه‌ای
        تبدیل کنند، و آن‌ها را برای اهداف تحلیلی به یک انبار داده <strong>MPP</strong> وارد کنند.
        مدل‌سازی داده‌ها همچنان اتفاق می‌افتد، اما در یک مرحله جداگانه است،
        جدا از جمع‌آوری داده‌ها. این تفکیک امکان‌پذیر است زیرا یک سیستم فایل
        توزیع شده از داده‌های رمزگذاری شده در هر فرمتی پشتیبانی می‌کند.
    </p>
<h4>تنوع مدل‌های پردازش</h4>
<p>
        پایگاه‌های داده <strong>MPP</strong>، قطعات نرم‌افزاری یکپارچه و متمرکز هستند که از چیدمان
        ذخیره‌سازی روی دیسک، برنامه‌ریزی query، زمان‌بندی و اجرا مراقبت می‌کنند.
        از آن‌جایی که این مؤلفه‌ها می‌توانند برای نیازهای خاص پایگاه داده تنظیم و
        بهینه شوند، کل سیستم می‌تواند عملکرد بسیار خوبی را در مورد انواع
        queries هایی که برای آن‌ها طراحی شده است، به دست آورد. علاوه بر این،
        زبان query <strong>SQL</strong>، queries های رسا و <strong>semantics</strong> های ظریف را بدون نیاز به
        نوشتن کد امکان‌پذیر می‌کند و آن را برای ابزارهای گرافیکی که توسط
        تحلیلگران کسب‌وکار (مانند <strong>Tableau</strong>) استفاده می‌شوند، در دسترس قرار می‌دهد.
    </p>
<p>
        از سوی دیگر، همه انواع پردازش را نمی‌توان به طور منطقی به عنوان queries
        <strong>SQL</strong> بیان کرد. به عنوان مثال، اگر در حال ساخت سیستم‌های یادگیری ماشین و
        توصیه، یا <strong>indexes</strong> جستجوی متن کامل با مدل‌های رتبه‌بندی مرتبط، یا انجام
        تجزیه و تحلیل تصویر هستید، به احتمال زیاد به یک مدل کلی‌تر از پردازش داده
        نیاز دارید. این نوع پردازش‌ها اغلب بسیار خاص یک برنامه کاربردی خاص هستند
        (به عنوان مثال، <strong>feature engineering</strong> برای یادگیری ماشین، مدل‌های زبان
        طبیعی برای ترجمه ماشینی، توابع تخمین ریسک برای پیش‌بینی کلاهبرداری)،
        بنابراین آن‌ها ناگزیر نیاز به نوشتن کد دارند، نه فقط queries.
    </p>
<p>
<strong>MapReduce</strong> به مهندسان این امکان را داد که به راحتی کد خود را بر روی
        مجموعه‌داده‌های بزرگ اجرا کنند. اگر شما <strong>HDFS</strong> و <strong>MapReduce</strong> دارید، می‌توانید
        یک موتور اجرای query <strong>SQL</strong> را بر روی آن بسازید، و در واقع این کاری است که
        پروژه <strong>Hive</strong> انجام داد [31]. با این حال، شما همچنین می‌توانید بسیاری از اشکال
        دیگر فرآیندهای <strong>batch</strong> را بنویسید که خودشان را به بیان شدن به عنوان یک query
        <strong>SQL</strong>، قرض نمی‌دهند.
    </p>
<p>
        متعاقباً، مردم دریافتند که <strong>MapReduce</strong> برای برخی از انواع پردازش‌ها بیش از حد
        محدودکننده است و عملکرد ضعیفی دارد، بنابراین مدل‌های پردازش مختلف
        دیگری بر روی <strong>Hadoop</strong> توسعه یافتند (ما برخی از آن‌ها را در "فراتر از
        <strong>MapReduce</strong>" در صفحه 419 خواهیم دید). داشتن دو مدل پردازش، <strong>SQL</strong> و
        <strong>MapReduce</strong>، کافی نبود: حتی مدل‌های مختلف بیشتری مورد نیاز بود! و به دلیل
        باز بودن پلتفرم <strong>Hadoop</strong>
        416
        |
        فصل 10: پردازش <strong>Batch</strong>
</p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0438</div>
            </div>
        </div>
        <!-- Page 0439 -->
        <div class="chapter" id="page-0439">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        form، پیاده‌سازی طیف وسیعی از رویکردها امکان‌پذیر بود، که در محدوده‌ی
        یک پایگاه داده <strong>MPP</strong> <em>monolithic</em> امکان‌پذیر نبود [58].
    </p>
<p>
        بسیار مهم است که آن مدل‌های پردازش مختلف همگی می‌توانند بر روی یک
        <strong>cluster</strong> <em>shared-use</em> از ماشین‌ها اجرا شوند، که همگی به فایل‌های یکسان در
        سیستم فایل توزیع شده دسترسی دارند. در رویکرد <strong>Hadoop</strong>، نیازی به وارد کردن
        داده‌ها به چندین سیستم تخصصی مختلف برای انواع مختلف پردازش وجود
        ندارد: سیستم به اندازه‌ی کافی انعطاف‌پذیر است تا از مجموعه‌ای متنوع از
        <strong>workloads</strong> در داخل همان <strong>cluster</strong> پشتیبانی کند. عدم نیاز به جابه‌جایی داده‌ها،
        استخراج ارزش از داده‌ها را بسیار آسان‌تر می‌کند، و آزمایش مدل‌های پردازش
        جدید را بسیار آسان‌تر می‌کند.
    </p>
<p>
        اکوسیستم <strong>Hadoop</strong> شامل هر دو پایگاه داده <strong>OLTP</strong> با دسترسی تصادفی مانند <strong>HBase</strong>
        (نگاه کنید به "<strong>SSTables</strong> و <strong>LSM-Trees</strong>" در صفحه 76) و پایگاه‌های داده تحلیلی
        به سبک <strong>MPP</strong> مانند <strong>Impala</strong> [41] است. نه <strong>HBase</strong> و نه <strong>Impala</strong> از <strong>MapReduce</strong>
        استفاده نمی‌کنند، اما هر دو از <strong>HDFS</strong> برای ذخیره‌سازی استفاده می‌کنند. آن‌ها
        رویکردهای بسیار متفاوتی برای دسترسی و پردازش داده‌ها هستند، اما با این
        وجود می‌توانند هم‌زیستی داشته باشند و در همان سیستم ادغام شوند.
    </p>
<h4>طراحی برای خطاهای مکرر</h4>
<p>
        هنگام مقایسه <strong>MapReduce</strong> با پایگاه‌های داده <strong>MPP</strong>، دو تفاوت دیگر در رویکرد طراحی
        برجسته‌تر است: مدیریت خطاها و استفاده از حافظه و دیسک. فرآیندهای <strong>batch</strong>
        نسبت به سیستم‌های آنلاین به خطاها حساسیت کمتری دارند، زیرا در صورت
        شکست فوراً بر کاربران تأثیر نمی‌گذارند و همیشه می‌توانند دوباره اجرا شوند.
    </p>
<p>
        اگر یک <strong>node</strong> در حین اجرای یک query از کار بیفتد، اکثر پایگاه‌های داده <strong>MPP</strong> کل
        query را متوقف می‌کنند، و یا به کاربر اجازه می‌دهند query را دوباره ارسال
        کند یا به‌طور خودکار آن را دوباره اجرا می‌کنند [3]. از آن‌جایی که queries
        معمولاً حداکثر برای چند ثانیه یا چند دقیقه اجرا می‌شوند، این روش مدیریت
        خطاها قابل قبول است، زیرا هزینه‌ی <strong>retrying</strong> خیلی زیاد نیست. پایگاه‌های داده
        <strong>MPP</strong> ترجیح می‌دهند تا حد امکان داده‌ها را در حافظه نگه دارند (به عنوان مثال،
        با استفاده از <strong>hash joins</strong>) تا از هزینه‌ی خواندن از دیسک جلوگیری کنند.
    </p>
<p>
        از سوی دیگر، <strong>MapReduce</strong> می‌تواند شکست یک <strong>map</strong> یا <strong>reduce task</strong> را بدون تأثیر
        بر کل job با تکرار کار در دانه بندی یک <strong>task</strong> مجزا تحمل کند. همچنین بسیار
        علاقه‌مند است که داده‌ها را روی دیسک بنویسد، تا حدی برای تحمل خطا، و
        تا حدی با این فرض که مجموعه داده‌ها به هر حال بیش از حد بزرگ است که در
        حافظه جا شود.
    </p>
<p>
        رویکرد <strong>MapReduce</strong> برای jobs های بزرگتر مناسب‌تر است: jobs هایی که داده‌های
        زیادی را پردازش می‌کنند و برای مدت زمان طولانی اجرا می‌شوند، که احتمال
        دارد حداقل یک <strong>task</strong> شکست را در طول مسیر تجربه کنند. در این صورت،
        دوباره اجرا کردن کل job به دلیل یک <strong>task</strong> شکست، اتلاف وقت خواهد بود.
        حتی اگر بازیابی در دانه بندی یک <strong>task</strong> مجزا، سربارهایی را معرفی کند که
        پردازش بدون خطا را کندتر می‌کند، اگر میزان شکست <strong>task</strong> به اندازه‌ی کافی
        بالا باشد، همچنان می‌تواند یک <strong>trade-off</strong> منطقی باشد.
    </p>
<p>
        اما این فرضیات چقدر واقع‌بینانه هستند؟ در بیشتر <strong>clusters</strong>، شکست‌های
        ماشین رخ می‌دهد، اما خیلی مکرر نیستند—احتمالاً به اندازه‌ی کافی نادر هستند
        که اکثر jobs ها تجربه نخواهند کرد.
        <strong>MapReduce</strong> و سیستم‌های فایل توزیع شده
        |
        417
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0439</div>
            </div>
        </div>
        <!-- Page 0440 -->
        <div class="chapter" id="page-0440">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        از این‌رو یک شکست ماشین است. آیا واقعاً ارزش دارد که به‌خاطر
        تحمل خطا، <strong>overhead</strong> قابل توجهی را متحمل شویم؟
    </p>
<p>
        برای درک دلایل استفاده‌ی محدود <strong>MapReduce</strong> از حافظه و بازیابی در سطح <strong>task</strong>،
        کمک‌کننده است که به محیطی که <strong>MapReduce</strong> در ابتدا برای آن طراحی شده
        نگاه کنیم. <strong>Google</strong> دارای <strong>datacenters</strong> با استفاده ترکیبی است، که در آن
        سرویس‌های <em>online</em> و jobs های <strong>batch</strong> <em>offline</em> بر روی ماشین‌های یکسان اجرا
        می‌شوند. هر <strong>task</strong> دارای یک تخصیص منبع (هسته‌های <strong>CPU</strong>، <strong>RAM</strong>، فضای
        دیسک و غیره) است که با استفاده از <strong>containers</strong> اعمال می‌شود. هر <strong>task</strong> همچنین
        دارای یک <strong>priority</strong> است، و اگر یک <strong>task</strong> با <strong>priority</strong> بالاتر به منابع بیشتری
        نیاز داشته باشد، <strong>tasks</strong> با <strong>priority</strong> پایین‌تر در همان ماشین می‌توانند متوقف
        (<strong>preempted</strong>) شوند تا منابع آزاد شوند.
        <strong>Priority</strong> همچنین قیمت‌گذاری منابع محاسباتی را تعیین می‌کند: تیم‌ها باید
        برای منابعی که استفاده می‌کنند، پرداخت کنند و فرآیندهای با <strong>priority</strong> بالاتر
        هزینه‌ی بیشتری دارند [59].
    </p>
<p>
        این معماری به منابع محاسباتی غیرتولیدی (<strong>low-priority</strong>) اجازه می‌دهد که
        <em>overcommitted</em> شوند، زیرا سیستم می‌داند که در صورت لزوم می‌تواند
        منابع را پس بگیرد. <em>Overcommitting</em> منابع به نوبه خود امکان استفاده بهتر از
        ماشین‌ها و کارایی بیشتر را در مقایسه با سیستم‌هایی که وظایف تولیدی و غیر
        تولیدی را جدا می‌کنند، فراهم می‌کند. با این حال، از آن‌جایی که jobs های
        <strong>MapReduce</strong> با <strong>low priority</strong> اجرا می‌شوند، این خطر وجود دارد که در هر
        زمانی <strong>preempted</strong> شوند، زیرا یک فرآیند با <strong>priority</strong> بالاتر به منابع آن‌ها نیاز
        دارد. jobs های <strong>Batch</strong> به طور موثر "تکه‌های زیر میز را جمع می‌کنند"، با
        استفاده از هر گونه منابع محاسباتی که پس از این‌که فرآیندهای با <strong>high-priority</strong>
        آن‌چه را که نیاز داشتند، برداشتند، باقی می‌مانند.
    </p>
<p>
        در <strong>Google</strong>، یک <strong>MapReduce task</strong> که به مدت یک ساعت اجرا می‌شود، تقریباً 5٪
        خطر خاتمه یافتن دارد تا فضایی برای یک فرآیند با <strong>high-priority</strong> فراهم شود.
        این نرخ، بیش از یک مرتبه بزرگی بیشتر از نرخ شکست‌ها به دلیل مشکلات
        سخت‌افزاری، راه‌اندازی مجدد ماشین یا دلایل دیگر است [59]. با این نرخ
        <strong>preemptions</strong>، اگر یک job دارای 100 <strong>task</strong> باشد که هر کدام به مدت 10
        دقیقه اجرا می‌شوند، خطر بیش از 50٪ وجود دارد که حداقل یک <strong>task</strong> قبل از
        اتمام متوقف شود.
    </p>
<p>
        و به همین دلیل است که <strong>MapReduce</strong> برای تحمل خاتمه‌ی مکرر <strong>task</strong>
        غیرمنتظره طراحی شده است: این به این دلیل نیست که سخت‌افزار به‌طور خاص
        غیرقابل اعتماد است، بلکه به این دلیل است که آزادی برای خاتمه‌ی دلخواه
        فرآیندها، امکان استفاده بهتر از منابع را در یک <strong>cluster</strong> محاسباتی فراهم
        می‌کند.
    </p>
<p>
        در میان زمان‌بندهای <strong>cluster</strong> منبع باز، <strong>preemption</strong> کمتر مورد استفاده قرار
        می‌گیرد. <strong>CapacityScheduler</strong> از <strong>YARN</strong> از <strong>preemption</strong> برای متعادل کردن
        تخصیص منابع صف‌های مختلف پشتیبانی می‌کند [58]، اما <strong>preemption priority</strong>
        عمومی در <strong>YARN</strong>، <strong>Mesos</strong> یا <strong>Kubernetes</strong> در زمان نوشتن پشتیبانی نمی‌شود
        [60]. در محیطی که <strong>tasks</strong> خیلی کم متوقف می‌شوند، تصمیمات طراحی
        <strong>MapReduce</strong> منطقی‌تر هستند. در بخش بعدی، به برخی از جایگزین‌های
        <strong>MapReduce</strong> نگاه خواهیم کرد که تصمیمات طراحی متفاوتی را اتخاذ می‌کنند.
    </p>
<p>
        418
        |
        فصل 10: پردازش <strong>Batch</strong>
</p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0440</div>
            </div>
        </div>
        <!-- Page 0441 -->
        <div class="chapter" id="page-0441">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<h4>فراتر از <strong>MapReduce</strong></h4>
<p>
        اگرچه <strong>MapReduce</strong> بسیار محبوب شد و در اواخر دهه 2000 مورد توجه زیادی
        قرار گرفت، اما تنها یکی از بسیاری از مدل‌های برنامه‌نویسی ممکن برای
        سیستم‌های توزیع شده است. بسته به حجم داده‌ها، ساختار داده‌ها، و نوع
        پردازشی که با آن‌ها انجام می‌شود، ابزارهای دیگر ممکن است برای بیان یک
        محاسبه مناسب‌تر باشند.
    </p>
<p>
        با این وجود، ما زمان زیادی را در این فصل صرف بحث در مورد <strong>MapReduce</strong>
        کردیم زیرا این یک ابزار یادگیری مفید است، زیرا یک انتزاع نسبتاً واضح و ساده
        بر روی یک سیستم فایل توزیع شده است. یعنی ساده به این معنا که بتوانیم
        درک کنیم چه کار می‌کند، نه به این معنا که استفاده از آن آسان است. کاملاً
        برعکس: پیاده‌سازی یک job پردازش پیچیده با استفاده از <strong>APIs</strong> های خام
        <strong>MapReduce</strong> در واقع بسیار دشوار و طاقت‌فرسا است—به عنوان مثال، شما
        باید هر الگوریتم <strong>join</strong> را از ابتدا پیاده‌سازی کنید [37].
    </p>
<p>
        در پاسخ به دشواری استفاده مستقیم از <strong>MapReduce</strong>، مدل‌های برنامه‌نویسی
        سطح بالاتر مختلف (<strong>Pig</strong>، <strong>Hive</strong>، <strong>Cascading</strong>، <strong>Crunch</strong>) به عنوان
        انتزاع‌هایی بر روی <strong>MapReduce</strong> ایجاد شدند. اگر شما درک کنید که
        <strong>MapReduce</strong> چگونه کار می‌کند، یادگیری آن‌ها نسبتاً آسان است، و
        ساختارهای سطح بالاتر آن‌ها، بسیاری از وظایف پردازش <strong>batch</strong> رایج را به
        طور قابل توجهی آسان‌تر می‌کند.
    </p>
<p>
        با این حال، مشکلاتی نیز در خود مدل اجرای <strong>MapReduce</strong> وجود دارد، که با
        افزودن یک سطح دیگر از انتزاع برطرف نمی‌شوند و خود را به صورت عملکرد
        ضعیف برای برخی از انواع پردازش نشان می‌دهند. از یک طرف، <strong>MapReduce</strong>
        بسیار <strong>robust</strong> است: شما می‌توانید از آن برای پردازش تقریباً مقادیر
        دلخواه بزرگی از داده‌ها در یک سیستم <strong>multi-tenant</strong> غیرقابل اعتماد با
        خاتمه‌های مکرر <strong>task</strong> استفاده کنید، و همچنان job را انجام می‌دهد (اگرچه
        آهسته). از سوی دیگر، ابزارهای دیگر گاهی اوقات چندین مرتبه سریع‌تر برای
        برخی از انواع پردازش هستند.
    </p>
<p>
        در بقیه این فصل، ما به برخی از این جایگزین‌ها برای پردازش <strong>batch</strong>
        نگاه خواهیم کرد. در فصل 11 ما به پردازش جریان می‌رویم، که می‌تواند به
        عنوان راه دیگری برای سرعت بخشیدن به پردازش <strong>batch</strong> در نظر گرفته شود.
    </p>
<h4><strong>Materialization</strong> از حالت <strong>Intermediate</strong></h4>
<p>
        همان‌طور که قبلاً بحث شد، هر job <strong>MapReduce</strong> از هر job دیگری مستقل
        است. نقاط تماس اصلی یک job با بقیه جهان، دایرکتوری‌های ورودی و خروجی
        آن در سیستم فایل توزیع شده است. اگر شما می‌خواهید خروجی یک job به
        ورودی یک job دوم تبدیل شود، شما نیاز دارید دایرکتوری ورودی job دوم را
        به عنوان دایرکتوری خروجی job اول پیکربندی کنید، و یک زمان‌بند
        <strong>workflow</strong> خارجی باید job دوم را تنها پس از تکمیل job اول، شروع کند.
    </p>
<p>
        این تنظیم مناسب است اگر خروجی از job اول، یک مجموعه داده باشد که شما
        می‌خواهید در سازمان خود به طور گسترده منتشر کنید. در این صورت، شما باید
        بتوانید به آن ارجاع دهید
        <strong>Beyond MapReduce</strong>
        |
        419
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0441</div>
            </div>
        </div>
        <!-- Page 0442 -->
        <div class="chapter" id="page-0442">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        با <strong>name</strong> و استفاده مجدد از آن به عنوان ورودی برای چندین job مختلف
        (از جمله jobs های توسعه یافته توسط تیم‌های دیگر). انتشار داده‌ها به یک
        مکان شناخته شده در سیستم فایل توزیع شده، <strong>coupling</strong> آزاد را ممکن می‌سازد
        تا jobs نیازی نداشته باشند که بدانند چه کسی ورودی آن‌ها را تولید یا
        خروجی آن‌ها را مصرف می‌کند (نگاه کنید به "جدا کردن منطق و سیم‌کشی" در
        صفحه 396).
    </p>
<p>
        با این حال، در بسیاری از موارد، شما می‌دانید که خروجی یک job فقط برای
        ورودی یک job دیگر استفاده می‌شود، که توسط همان تیم نگهداری می‌شود. در
        این مورد، فایل‌ها در سیستم فایل توزیع شده به سادگی حالت <strong>intermediate</strong>
        هستند: وسیله‌ای برای انتقال داده‌ها از یک job به job بعدی. در جریان‌های
        کاری پیچیده‌ای که برای ساخت سیستم‌های توصیه شامل 50 یا 100 jobs
        <strong>MapReduce</strong> استفاده می‌شود [29]، حالت <strong>intermediate</strong> زیادی از این
        دست وجود دارد.
    </p>
<p>
        فرآیند نوشتن این حالت <strong>intermediate</strong> به فایل‌ها <strong>materialization</strong> نامیده
        می‌شود. (ما قبلاً در زمینه <strong>materialized views</strong>، در "تجمیع: <strong>Data Cubes</strong>
        و <strong>Materialized Views</strong>" در صفحه 101 با این اصطلاح مواجه شدیم. این به
        معنای مشتاقانه محاسبه کردن نتیجه‌ی یک عملیات و نوشتن آن است، به جای
        محاسبه‌ی آن بر اساس تقاضا در هنگام درخواست.)
    </p>
<p>
        در مقابل، مثال تجزیه و تحلیل <strong>log</strong> در ابتدای فصل از <strong>Unix pipes</strong> برای
        اتصال خروجی یک دستور با ورودی دستور دیگر استفاده کرد. <strong>Pipes</strong> حالت
        <strong>intermediate</strong> را به‌طور کامل <strong>materialize</strong> نمی‌کنند، بلکه به‌طور
        افزایشی خروجی را به ورودی <strong>stream</strong> می‌کنند، با استفاده از تنها یک
        بافر <em>in-memory</em> کوچک.
    </p>
<p>
        رویکرد <strong>MapReduce</strong> برای <strong>materializing</strong> کامل حالت <strong>intermediate</strong>، در
        مقایسه با <strong>Unix pipes</strong>، دارای معایبی است:
    </p>
<ul>
<li>
            یک job <strong>MapReduce</strong> تنها زمانی می‌تواند شروع شود که تمام <strong>tasks</strong>
            در jobs های قبلی (که ورودی‌های آن را تولید می‌کنند) تکمیل شده باشند،
            در حالی که فرآیندهای متصل توسط یک <strong>Unix pipe</strong> همزمان شروع
            می‌شوند، با خروجی که به محض تولید شدن مصرف می‌شود.
            <strong>Skew</strong> یا بار متفاوت بر روی ماشین‌های مختلف به این معنی است که یک job
            اغلب دارای چند <strong>straggler tasks</strong> است که زمان بیشتری نسبت به سایر
            <strong>tasks</strong> طول می‌کشد تا تکمیل شوند. مجبور بودن به انتظار تا تکمیل شدن
            تمام <strong>tasks</strong> از job قبلی، اجرای <strong>workflow</strong> را به عنوان یک کل کند
            می‌کند.
        </li>
<li>
<strong>Mappers</strong> اغلب <em>redundant</em> هستند: آن‌ها فقط همان فایلی را می‌خوانند که
            به تازگی توسط یک <strong>reducer</strong> نوشته شده است، و آن را برای مرحله‌ی
            بعدی تقسیم‌بندی و مرتب‌سازی آماده می‌کنند. در بسیاری از موارد، کد
            <strong>mapper</strong> می‌تواند بخشی از <strong>reducer</strong> قبلی باشد: اگر خروجی <strong>reducer</strong>
            به همان روشی که خروجی <strong>mapper</strong> تقسیم‌بندی و مرتب‌سازی شده بود،
            تقسیم‌بندی و مرتب‌سازی می‌شد، آن‌گاه <strong>reducers</strong> می‌توانستند مستقیماً
            به هم متصل شوند، بدون این‌که با مراحل <strong>mapper</strong> تداخل داشته باشند.
        </li>
<li>
            ذخیره‌سازی حالت <strong>intermediate</strong> در یک سیستم فایل توزیع شده به این معنی
            است که آن فایل‌ها در چندین <strong>node</strong> تکرار می‌شوند، که اغلب برای چنین
            داده‌های موقتی <em>overkill</em> است.
        </li>
</ul>
<p>
        420
        |
        فصل 10: پردازش <strong>Batch</strong>
</p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0442</div>
            </div>
        </div>
        <!-- Page 0443 -->
        <div class="chapter" id="page-0443">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<h4>موتورهای <strong>Dataflow</strong></h4>
<p>
        به منظور رفع این مشکلات با <strong>MapReduce</strong>، چندین موتور اجرا برای
        محاسبات <strong>batch</strong> توزیع شده جدید توسعه یافتند، که شناخته شده‌ترین
        آن‌ها عبارتند از <strong>Spark</strong> [61, 62]، <strong>Tez</strong> [63, 64] و <strong>Flink</strong> [65, 66].
        تفاوت‌های مختلفی در نحوه طراحی آن‌ها وجود دارد، اما آن‌ها یک وجه مشترک
        دارند: آن‌ها یک <strong>workflow</strong> کامل را به عنوان یک job مدیریت می‌کنند،
        به جای این‌که آن را به زیر jobs های مستقل تقسیم کنند.
    </p>
<p>
        از آن‌جایی که آن‌ها به صراحت جریان داده‌ها را از طریق چندین مرحله پردازش
        مدل‌سازی می‌کنند، این سیستم‌ها به عنوان موتورهای <strong>dataflow</strong> شناخته
        می‌شوند. مانند <strong>MapReduce</strong>، آن‌ها با فراخوانی مکرر یک تابع تعریف شده
        توسط کاربر برای پردازش یک رکورد در یک زمان بر روی یک <strong>thread</strong> واحد،
        کار می‌کنند. آن‌ها کار را با تقسیم ورودی‌ها موازی می‌کنند، و خروجی یک
        تابع را از طریق شبکه کپی می‌کنند تا به ورودی یک تابع دیگر تبدیل شود.
    </p>
<p>
        بر خلاف <strong>MapReduce</strong>، این توابع نیازی به ایفای نقش‌های سخت
        متناوب <strong>map</strong> و <strong>reduce</strong> ندارند، بلکه می‌توانند به روش‌های انعطاف‌پذیرتری
        سرهم شوند. ما این توابع را <strong>operators</strong> می‌نامیم، و موتور <strong>dataflow</strong>
        چندین گزینه مختلف برای اتصال خروجی یک <strong>operator</strong> به ورودی <strong>operator</strong>
        دیگر ارائه می‌دهد:
    </p>
<ul>
<li>
            یک گزینه این است که رکوردها را بر اساس <strong>key</strong> دوباره تقسیم‌بندی و
            مرتب‌سازی کنید، مانند مرحله‌ی <strong>shuffle</strong> در <strong>MapReduce</strong> (نگاه کنید به
            "اجرای توزیع شده <strong>MapReduce</strong>" در صفحه 400). این <strong>feature</strong>،
            <strong>sort-merge joins</strong> و گروه‌بندی را به همان روش <strong>MapReduce</strong> امکان‌پذیر
            می‌سازد.
        </li>
<li>
            یک امکان دیگر این است که چندین ورودی را بگیرید و آن‌ها را به همان
            روش تقسیم‌بندی کنید، اما مرتب‌سازی را رد کنید. این کار در <strong>partitioned</strong>
<strong>hash joins</strong>، که تقسیم‌بندی رکوردها مهم است اما ترتیب بی‌اهمیت
            است زیرا ساخت جدول <strong>hash</strong> به هر حال ترتیب را تصادفی می‌کند، باعث
            صرفه‌جویی در تلاش می‌شود.
        </li>
<li>
            برای <strong>broadcast hash joins</strong>، همان خروجی از یک <strong>operator</strong> را می‌توان به
            تمام <strong>partitions</strong> از <strong>join operator</strong> ارسال کرد.
        </li>
</ul>
<p>
        این سبک از موتور پردازش بر اساس سیستم‌های تحقیقاتی مانند <strong>Dryad</strong> [67] و
        <strong>Nephele</strong> [68] استوار است، و چندین مزیت را در مقایسه با مدل
        <strong>MapReduce</strong> ارائه می‌دهد:
    </p>
<ul>
<li>
            کار پرهزینه‌ای مانند مرتب‌سازی تنها باید در مکان‌هایی انجام شود که
            واقعاً مورد نیاز است، نه این‌که همیشه به طور پیش‌فرض بین هر مرحله‌ی
            <strong>map</strong> و <strong>reduce</strong> اتفاق بیفتد.
        </li>
<li>
            هیچ <strong>task</strong> <strong>map</strong> غیرضروری وجود ندارد، زیرا کاری که یک <strong>mapper</strong>
            انجام می‌دهد اغلب می‌تواند در <strong>reducer operator</strong> قبلی گنجانده شود
            (زیرا یک <strong>mapper</strong> تقسیم‌بندی یک مجموعه داده را تغییر نمی‌دهد).
        </li>
<li>
            از آن‌جایی که تمام <strong>joins</strong> و وابستگی‌های داده‌ها در یک <strong>workflow</strong> به
            صراحت اعلام شده‌اند، زمان‌بند یک دید کلی از این‌که چه داده‌هایی در
            کجا مورد نیاز است، دارد، بنابراین می‌تواند بهینه‌سازی‌های <strong>locality</strong> را
            انجام دهد. به عنوان مثال، می‌تواند سعی کند <strong>task</strong> ای را که برخی داده‌ها
            را مصرف می‌کند، در همان ماشینی قرار دهد که <strong>task</strong> آن را تولید می‌کند،
            به طوری که داده‌ها بتوانند
            <strong>Beyond MapReduce</strong>
            |
            421
        </li>
</ul>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0443</div>
            </div>
        </div>
        <!-- Page 0444 -->
        <div class="chapter" id="page-0444">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        مبادله می‌شوند تا از طریق یک <strong>buffer</strong> حافظه‌ی مشترک به اشتراک
        گذاشته شوند، نه این‌که مجبور باشند آن را از طریق شبکه کپی کنند.
    </p>
<ul>
<li>
            معمولاً برای حالت <strong>intermediate</strong> بین <strong>operators</strong> کافی است که در
            حافظه نگهداری شود یا روی دیسک محلی نوشته شود، که به <strong>I/O</strong> کمتری نسبت
            به نوشتن آن در <strong>HDFS</strong> (که در آن باید در چندین ماشین تکرار و روی
            دیسک در هر <strong>replica</strong> نوشته شود) نیاز دارد. <strong>MapReduce</strong> قبلاً از
            این بهینه‌سازی برای خروجی <strong>mapper</strong> استفاده می‌کند، اما موتورهای
            <strong>dataflow</strong> این ایده را به تمام حالت‌های <strong>intermediate</strong> تعمیم
            می‌دهند.
        </li>
<li>
<strong>Operators</strong> می‌توانند به محض آماده شدن ورودی آن‌ها، اجرا را شروع
            کنند؛ نیازی نیست منتظر بمانید تا کل مرحله‌ی قبلی قبل از شروع مرحله‌ی
            بعدی، به پایان برسد.
        </li>
<li>
            فرآیندهای موجود <strong>Java Virtual Machine (JVM)</strong> می‌توانند برای اجرای
            <strong>operators</strong> های جدید مجدداً استفاده شوند، که سربارهای راه‌اندازی
            را در مقایسه با <strong>MapReduce</strong> (که یک <strong>JVM</strong> جدید را برای هر <strong>task</strong>
            راه‌اندازی می‌کند) کاهش می‌دهد.
        </li>
</ul>
<p>
        شما می‌توانید از موتورهای <strong>dataflow</strong> برای پیاده‌سازی محاسبات یکسان
        به‌عنوان <strong>MapReduce workflows</strong> استفاده کنید، و آن‌ها معمولاً به دلیل
        بهینه‌سازی‌های شرح داده شده در اینجا، به‌طور قابل توجهی سریع‌تر اجرا
        می‌شوند. از آن‌جایی که <strong>operators</strong> تعمیمی از <strong>map</strong> و <strong>reduce</strong> هستند،
        همان کد پردازش می‌تواند بر روی هر دو موتور اجرا شود: جریان‌های کاری
        پیاده‌سازی شده در <strong>Pig</strong>، <strong>Hive</strong> یا <strong>Cascading</strong> را می‌توان با یک
        تغییر پیکربندی ساده، بدون تغییر کد، از <strong>MapReduce</strong> به <strong>Tez</strong> یا
        <strong>Spark</strong> سوئیچ کرد [64].
    </p>
<p>
<strong>Tez</strong> یک کتابخانه نسبتاً کم‌حجم است که برای کپی واقعی داده‌ها بین
        <strong>nodes</strong> به سرویس <strong>YARN shuffle</strong> متکی است [58]، در حالی که <strong>Spark</strong>
        و <strong>Flink</strong> چارچوب‌های بزرگی هستند که شامل لایه ارتباط شبکه، زمان‌بند و
        <strong>APIs</strong> های رو به کاربر خودشان می‌شوند.
        ما به زودی در مورد آن <strong>APIs</strong> های سطح بالا بحث خواهیم کرد.
    </p>
<h4>تحمل خطا</h4>
<p>
        یک مزیت <strong>materializing</strong> کامل حالت <strong>intermediate</strong> به یک سیستم فایل توزیع
        شده این است که <em>durable</em> است، که باعث می‌شود تحمل خطا در <strong>MapReduce</strong>
        نسبتاً آسان شود: اگر یک <strong>task</strong> شکست بخورد، می‌توان آن را دوباره در
        ماشین دیگری راه‌اندازی کرد و همان ورودی را دوباره از سیستم فایل
        خواند.
    </p>
<p>
<strong>Spark</strong>، <strong>Flink</strong> و <strong>Tez</strong> از نوشتن حالت <strong>intermediate</strong> به <strong>HDFS</strong> اجتناب
        می‌کنند، بنابراین آن‌ها یک رویکرد متفاوت برای تحمل خطاها در پیش
        می‌گیرند: اگر یک ماشین با شکست مواجه شود و حالت <strong>intermediate</strong> در آن
        ماشین از دست برود، از داده‌های دیگری که هنوز در دسترس هستند دوباره
        محاسبه می‌شود (در صورت امکان، یک مرحله‌ی <strong>intermediary</strong> قبلی، یا در غیر
        این صورت داده‌های ورودی اصلی، که معمولاً در <strong>HDFS</strong> است).
    </p>
<p>
        برای فعال کردن این <strong>recomputation</strong>، فریم‌ورک باید پیگیری کند که چگونه
        یک قطعه داده مشخص محاسبه شده است—از کدام <strong>partitions</strong> ورودی استفاده
        کرده است، و کدام <strong>operators</strong> بر روی آن اعمال شده‌اند. <strong>Spark</strong> از
        انتزاع <strong>resilient distributed dataset (RDD)</strong> برای ردیابی <strong>ancestry</strong> داده‌ها
        استفاده می‌کند [61]، در حالی که <strong>Flink</strong> حالت <strong>operator</strong> را <strong>checkpoints</strong>
        می‌کند و به آن اجازه می‌دهد تا اجرای یک <strong>operator</strong> را که در طول اجرای خود
        دچار خطا شده است، از سر بگیرد [66].
        422
        |
        فصل 10: پردازش <strong>Batch</strong>
</p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0444</div>
            </div>
        </div>
        <!-- Page 0445 -->
        <div class="chapter" id="page-0445">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        هنگام محاسبه مجدد داده‌ها، مهم است که بدانیم آیا محاسبه <em>deterministic</em> است:
        یعنی، با در نظر گرفتن داده‌های ورودی یکسان، آیا <strong>operators</strong> همیشه
        خروجی یکسانی تولید می‌کنند؟ این سوال در صورتی اهمیت دارد که برخی از
        داده‌های از دست رفته قبلاً به <strong>operators</strong>های <em>downstream</em> ارسال شده
        باشند. اگر <strong>operator</strong> راه‌اندازی مجدد شود و داده‌های محاسبه شده مجدد
        با داده‌های اصلی از دست رفته یکسان نباشد، حل تناقض‌ها بین داده‌های
        قدیمی و جدید برای <strong>operators</strong> های <em>downstream</em> بسیار دشوار می‌شود.
        راه‌حل در مورد <strong>operators</strong> های <em>nondeterministic</em> معمولاً این است که
        <strong>operators</strong> های <em>downstream</em> را نیز متوقف کنید و آن‌ها را دوباره روی
        داده‌های جدید اجرا کنید.
    </p>
<p>
        به منظور اجتناب از چنین خطاهای آبشاری، بهتر است <strong>operators</strong> <em>deterministic</em>
        باشند. با این حال توجه داشته باشید که رفتار <em>nondeterministic</em> به طور
        تصادفی وارد می‌شود: به عنوان مثال، بسیاری از زبان‌های برنامه‌نویسی هیچ
        ترتیب خاصی را هنگام تکرار عناصر یک جدول <strong>hash</strong> تضمین نمی‌کنند،
        بسیاری از الگوریتم‌های احتمالی و آماری صریحاً به استفاده از اعداد
        تصادفی متکی هستند، و هرگونه استفاده از ساعت سیستم یا منابع داده
        خارجی <em>nondeterministic</em> است. چنین عللی از <em>nondeterminism</em> باید به
        منظور بازیابی قابل اطمینان از خطاها حذف شوند، به عنوان مثال با تولید
        اعداد شبه تصادفی با استفاده از یک <strong>seed</strong> ثابت.
    </p>
<p>
        بازیابی از خطاها با محاسبه مجدد داده‌ها همیشه پاسخ صحیح نیست: اگر داده‌های
        <em>intermediate</em> بسیار کوچک‌تر از داده‌های منبع باشند، یا اگر محاسبه
        بسیار <strong>CPU</strong>-<em>intensive</em> باشد، احتمالاً <strong>materialize</strong> کردن داده‌های
        <em>intermediate</em> به فایل‌ها ارزان‌تر از محاسبه مجدد آن است.
    </p>
<h4>بحث در مورد <strong>materialization</strong></h4>
<p>
        با بازگشت به قیاس <strong>Unix</strong>، ما دیدیم که <strong>MapReduce</strong> مانند نوشتن
        خروجی هر دستور به یک فایل موقت است، در حالی که موتورهای <strong>dataflow</strong>
        بسیار شبیه به <strong>Unix pipes</strong> هستند. <strong>Flink</strong> به‌ویژه حول ایده‌ی اجرای
        <em>pipelined</em> ساخته شده است: یعنی، به‌طور افزایشی انتقال خروجی یک
        <strong>operator</strong> به <strong>operators</strong> دیگر، و منتظر نماندن تا ورودی قبل از
        شروع پردازش کامل شود.
    </p>
<p>
        یک عملیات مرتب‌سازی ناگزیر باید کل ورودی خود را مصرف کند تا بتواند
        هر خروجی تولید کند، زیرا این امکان وجود دارد که آخرین رکورد ورودی
        همان رکوردی باشد که کمترین <strong>key</strong> را دارد و بنابراین باید اولین رکورد
        خروجی باشد. هر <strong>operator</strong> که نیاز به مرتب‌سازی دارد، بنابراین باید
        حالت را جمع‌آوری کند، حداقل موقتاً. اما بسیاری از بخش‌های دیگر یک
        <strong>workflow</strong> را می‌توان به روش <em>pipelined</em> اجرا کرد.
    </p>
<p>
        هنگامی که job تکمیل شد، خروجی آن باید به مکانی <em>durable</em> برود تا
        کاربران بتوانند آن را پیدا کرده و از آن استفاده کنند—به احتمال زیاد، دوباره
        به سیستم فایل توزیع شده نوشته می‌شود. بنابراین، هنگام استفاده از یک
        موتور <strong>dataflow</strong>، مجموعه‌داده‌های <strong>materialized</strong> روی <strong>HDFS</strong> هنوز
        معمولاً ورودی‌ها و خروجی‌های نهایی یک job هستند. مانند <strong>MapReduce</strong>،
        ورودی‌ها <em>immutable</em> هستند و خروجی کاملاً جایگزین می‌شود.
        بهبود نسبت به <strong>MapReduce</strong> این است که شما خود را از نوشتن تمام
        حالت <strong>intermediate</strong> به سیستم فایل نجات می‌دهید.
        <strong>Beyond MapReduce</strong>
        |
        423
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0445</div>
            </div>
        </div>
        <!-- Page 0446 -->
        <div class="chapter" id="page-0446">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<h4>گراف‌ها و پردازش تکراری</h4>
<p>
        در "مدل‌های داده‌ی شبیه گراف" در صفحه 49 ما در مورد استفاده از گراف‌ها برای
        مدل‌سازی داده‌ها، و استفاده از زبان‌های query گراف برای پیمایش <strong>edges</strong> و
        <strong>vertices</strong> در یک گراف بحث کردیم. بحث در فصل 2 حول استفاده به سبک
        <strong>OLTP</strong> متمرکز بود: اجرای سریع queries ها برای یافتن تعداد کمی از
        <strong>vertices</strong> که با معیارهای خاصی مطابقت دارند.
    </p>
<p>
        همچنین بررسی گراف‌ها در یک <strong>context</strong> پردازش <strong>batch</strong> جالب است، که
        هدف انجام نوعی پردازش یا تجزیه و تحلیل <em>offline</em> بر روی کل گراف است.
        این نیاز اغلب در برنامه‌های <strong>machine learning</strong> مانند موتورهای پیشنهاد
        یا در سیستم‌های رتبه‌بندی ایجاد می‌شود. به عنوان مثال، یکی از مشهورترین
        الگوریتم‌های تجزیه و تحلیل گراف، <strong>PageRank</strong> [69] است، که سعی می‌کند
        محبوبیت یک صفحه وب را بر اساس این‌که کدام صفحات وب دیگر به آن پیوند
        می‌دهند، تخمین بزند. این بخش از فرمولی است که تعیین می‌کند موتورهای
        جستجوی وب نتایج خود را با چه ترتیبی ارائه می‌دهند.
    </p>
<p>
        موتورهای <strong>Dataflow</strong> مانند <strong>Spark</strong>، <strong>Flink</strong> و <strong>Tez</strong> (نگاه کنید به
        "<strong>Materialization</strong> از حالت <strong>Intermediate</strong>" در صفحه 419) معمولاً
        <strong>operators</strong> را در یک job به صورت یک گراف جهت‌دار غیرمدور (<strong>DAG</strong>)
        مرتب می‌کنند. این با پردازش گراف یکسان نیست: در موتورهای <strong>dataflow</strong>،
        جریان داده‌ها از یک <strong>operator</strong> به <strong>operator</strong> دیگر به عنوان یک گراف
        ساختار یافته است، در حالی که خود داده‌ها معمولاً از <strong>tuples</strong> به سبک
        رابطه‌ای تشکیل شده‌اند. در پردازش گراف، خود داده‌ها به شکل یک گراف
        هستند. یک سردرگمی نام‌گذاری ناخوشایند دیگر!
    </p>
<p>
        بسیاری از الگوریتم‌های گراف با پیمایش یک <strong>edge</strong> در یک زمان، پیوستن به یک
        <strong>vertex</strong> با یک <strong>vertex</strong> مجاور به منظور انتشار اطلاعات، و تکرار تا
        زمانی‌که یک شرط برآورده شود—به عنوان مثال، تا زمانی‌که دیگر <strong>edges</strong>
        برای دنبال کردن وجود نداشته باشد، یا تا زمانی‌که برخی از معیارها همگرا
        شوند—بیان می‌شوند. ما یک مثال را در شکل 2-6 دیدیم، که لیستی از تمام
        مکان‌ها در آمریکای شمالی موجود در یک پایگاه داده را با دنبال کردن مکرر
        <strong>edges</strong> نشان می‌دهد که کدام مکان در کدام مکان دیگر قرار دارد (این نوع
        الگوریتم <strong>transitive closure</strong> نامیده می‌شود).
    </p>
<p>
        ذخیره یک گراف در یک سیستم فایل توزیع شده (در فایل‌های حاوی لیست‌های
        <strong>vertices</strong> و <strong>edges</strong>) امکان‌پذیر است، اما این ایده "تکرار تا انجام" را
        نمی‌توان در <strong>MapReduce</strong> ساده بیان کرد، زیرا فقط یک بار از داده‌ها
        عبور می‌کند. بنابراین، این نوع الگوریتم اغلب به سبک تکراری پیاده‌سازی
        می‌شود:
    </p>
<ol>
<li>
            یک زمان‌بند خارجی یک فرآیند <strong>batch</strong> را برای محاسبه یک مرحله از
            الگوریتم اجرا می‌کند.
        </li>
<li>
            هنگامی که فرآیند <strong>batch</strong> تکمیل شد، زمان‌بند بررسی می‌کند که آیا
            تکمیل شده است (بر اساس شرط تکمیل—به عنوان مثال، دیگر <strong>edges</strong>
            برای دنبال کردن وجود ندارد، یا تغییر در مقایسه با تکرار آخر زیر یک
            آستانه است).
        </li>
<li>
            اگر هنوز تمام نشده است، زمان‌بند به مرحله 1 برمی‌گردد و یک دور دیگر
            از فرآیند <strong>batch</strong> را اجرا می‌کند.
        </li>
</ol>
<p>
        424
        |
        فصل 10: پردازش <strong>Batch</strong>
</p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 446" src="page_0446/image_1.png"/></div>
</div>
                <div class="page-number">صفحه 0446</div>
            </div>
        </div>
        <!-- Page 0447 -->
        <div class="chapter" id="page-0447">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        این رویکرد کار می‌کند، اما پیاده‌سازی آن با <strong>MapReduce</strong> اغلب بسیار
        غیرکارآمد است، زیرا <strong>MapReduce</strong> ماهیت تکراری الگوریتم را در نظر
        نمی‌گیرد: همیشه کل مجموعه داده‌های ورودی را می‌خواند و یک مجموعه
        داده‌ی خروجی کاملاً جدید تولید می‌کند، حتی اگر تنها بخش کوچکی از گراف
        نسبت به تکرار آخر تغییر کرده باشد.
    </p>
<h4>مدل پردازش <strong>Pregel</strong></h4>
<p>
        به عنوان یک بهینه‌سازی برای گراف‌های پردازش <strong>batch</strong>، مدل <strong>bulk</strong>
<strong>synchronous parallel (BSP)</strong> از محاسبات [70] محبوب شده است. در میان
        دیگران، توسط <strong>Apache Giraph</strong> [37]، <strong>API</strong> <strong>GraphX</strong> از <strong>Spark</strong> و <strong>API</strong>
<strong>Gelly</strong> از <strong>Flink</strong> [71] پیاده‌سازی شده است. همچنین به عنوان مدل <strong>Pregel</strong>
        شناخته می‌شود، زیرا مقاله <strong>Pregel</strong> از <strong>Google</strong> این رویکرد را برای پردازش
        گراف‌ها محبوب کرد [72].
    </p>
<p>
        به یاد بیاورید که در <strong>MapReduce</strong>، <strong>mappers</strong> به طور مفهومی "یک
        پیام را" به یک فراخوانی خاص از <strong>reducer</strong> "ارسال می‌کنند" زیرا فریم‌ورک
        تمام خروجی‌های <strong>mapper</strong> را با یک <strong>key</strong> یکسان جمع‌آوری می‌کند. یک
        ایده مشابه پشت <strong>Pregel</strong> است: یک <strong>vertex</strong> می‌تواند "یک پیام را" به یک
        <strong>vertex</strong> دیگر "ارسال کند"، و معمولاً این پیام‌ها در امتداد <strong>edges</strong> در یک
        گراف ارسال می‌شوند.
    </p>
<p>
        در هر تکرار، یک تابع برای هر <strong>vertex</strong> فراخوانی می‌شود، و تمام پیام‌هایی
        را که به آن ارسال شده‌اند به آن منتقل می‌کند—بسیار شبیه یک فراخوانی به
        <strong>reducer</strong>. تفاوت با <strong>MapReduce</strong> این است که در مدل <strong>Pregel</strong>، یک
        <strong>vertex</strong> حالت خود را در حافظه از یک تکرار به تکرار بعدی به یاد می‌آورد،
        بنابراین تابع فقط نیاز به پردازش پیام‌های ورودی جدید دارد. اگر هیچ پیامی
        در بخشی از گراف ارسال نشود، نیازی به انجام کار نیست.
    </p>
<p>
        این کمی شبیه مدل <strong>actor</strong> است (نگاه کنید به "فریم‌ورک‌های <strong>actor</strong>
        توزیع شده" در صفحه 138)، اگر شما به هر <strong>vertex</strong> به عنوان یک <strong>actor</strong>
        فکر کنید، با این تفاوت که حالت <strong>vertex</strong> و پیام‌های بین <strong>vertices</strong>،
        تحمل خطا و <em>durable</em> هستند، و ارتباطات در دوره‌های ثابت انجام می‌شود:
        در هر تکرار، فریم‌ورک تمام پیام‌های ارسال شده در تکرار قبلی را تحویل
        می‌دهد. <strong>Actors</strong> معمولاً چنین تضمین زمانی ندارند.
    </p>
<h4>تحمل خطا</h4>
<p>
        این واقعیت که <strong>vertices</strong> فقط می‌توانند با ارسال پیام با یکدیگر ارتباط
        برقرار کنند (نه با query کردن مستقیم یکدیگر) به بهبود عملکرد jobs های
        <strong>Pregel</strong> کمک می‌کند، زیرا پیام‌ها را می‌توان <strong>batched</strong> کرد و انتظار کمتری
        برای برقراری ارتباط وجود دارد. تنها انتظار بین تکرارها است: از آن‌جایی که
        مدل <strong>Pregel</strong> تضمین می‌کند که تمام پیام‌های ارسال شده در یک تکرار در
        تکرار بعدی تحویل داده می‌شوند، تکرار قبلی باید کاملاً تمام شود، و تمام
        پیام‌های آن باید قبل از شروع تکرار بعدی، از طریق شبکه کپی شوند.
    </p>
<p>
        حتی اگر شبکه زیربنایی ممکن است پیام‌ها را حذف، تکراری یا به‌طور دلخواه
        به تأخیر بیندازد (نگاه کنید به "شبکه‌های غیرقابل اعتماد" در صفحه 277)،
        پیاده‌سازی‌های <strong>Pregel</strong> تضمین می‌کنند که پیام‌ها دقیقاً یک بار در
        <strong>vertex</strong> مقصد خود در تکرار زیر پردازش می‌شوند. مانند <strong>MapReduce</strong>،
        فریم‌ورک به‌طور شفاف از خطاها بازیابی می‌کند تا مدل برنامه‌نویسی را برای
        الگوریتم‌ها بر روی <strong>Pregel</strong> ساده کند.
        <strong>Beyond MapReduce</strong>
        |
        425
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0447</div>
            </div>
        </div>
        <!-- Page 0448 -->
        <div class="chapter" id="page-0448">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        این تحمل خطا با <strong>checkpointing</strong> دوره‌ای حالت تمام <strong>vertices</strong> در
        پایان یک تکرار به‌دست می‌آید—یعنی، نوشتن حالت کامل آن‌ها در
        ذخیره‌سازی <em>durable</em>. اگر یک <strong>node</strong> شکست بخورد و حالت <em>in-memory</em>
        آن از دست برود، ساده‌ترین راه‌حل این است که کل محاسبه گراف را به
        آخرین <strong>checkpoint</strong> بازگردانید و محاسبه را دوباره راه‌اندازی کنید. اگر
        الگوریتم <em>deterministic</em> باشد و پیام‌ها <strong>logged</strong> شوند، بازیابی انتخابی
        فقط <strong>partition</strong> که از دست رفته است (مانند آنچه قبلاً برای موتورهای
        <strong>dataflow</strong> بحث کردیم) نیز امکان‌پذیر است [72].
    </p>
<h4>اجرای <strong>Parallel</strong></h4>
<p>
        یک <strong>vertex</strong> نیازی ندارد بداند که بر روی کدام ماشین فیزیکی در حال
        اجرا است. هنگامی که پیام‌هایی را به <strong>vertices</strong> دیگر ارسال می‌کند، به
        سادگی آن‌ها را به یک <strong>vertex ID</strong> ارسال می‌کند. این به فریم‌ورک بستگی
        دارد که گراف را تقسیم‌بندی کند—یعنی، تصمیم بگیرد که کدام <strong>vertex</strong> بر
        روی کدام ماشین اجرا می‌شود، و چگونه پیام‌ها را از طریق شبکه مسیریابی
        کند تا در جای مناسب قرار گیرند.
    </p>
<p>
        از آن‌جایی که مدل برنامه‌نویسی فقط با یک <strong>vertex</strong> در یک زمان سروکار
        دارد (گاهی اوقات "تفکر مانند یک <strong>vertex</strong>" نامیده می‌شود)، فریم‌ورک
        می‌تواند گراف را به روش‌های دلخواه تقسیم‌بندی کند. در حالت ایده‌آل، باید
        به گونه‌ای تقسیم‌بندی شود که <strong>vertices</strong> در صورت نیاز به برقراری ارتباط
        زیاد، در یک ماشین قرار گیرند. با این حال، یافتن چنین تقسیم‌بندی بهینه شده
        دشوار است—در عمل، گراف اغلب به‌سادگی با یک <strong>vertex ID</strong> دلخواه
        تقسیم‌بندی می‌شود، بدون این‌که تلاشی برای گروه‌بندی <strong>vertices</strong> مرتبط
        با هم انجام شود.
    </p>
<p>
        در نتیجه، الگوریتم‌های گراف اغلب دارای سربار ارتباطی <em>cross-machine</em> زیادی
        هستند، و حالت <strong>intermediate</strong> (پیام‌های ارسال شده بین <strong>nodes</strong>)
        اغلب بزرگتر از گراف اصلی است. سربار ارسال پیام‌ها از طریق شبکه می‌تواند
        الگوریتم‌های گراف توزیع شده را به‌طور قابل توجهی کند کند.
    </p>
<p>
        به همین دلیل، اگر گراف شما می‌تواند در حافظه‌ی یک کامپیوتر واحد جا
        شود، به احتمال زیاد یک الگوریتم تک‌ماشینی (حتی شاید تک‌نخی) از یک
        فرآیند <strong>batch</strong> توزیع شده عملکرد بهتری خواهد داشت [73, 74]. حتی اگر
        گراف بزرگتر از حافظه باشد، می‌تواند در دیسک‌های یک کامپیوتر واحد جا
        شود، پردازش تک‌ماشینی با استفاده از یک فریم‌ورک مانند <strong>GraphChi</strong> یک
        گزینه <em>viable</em> است [75]. اگر گراف برای جا شدن در یک ماشین واحد بسیار
        بزرگ است، یک رویکرد توزیع شده مانند <strong>Pregel</strong> اجتناب‌ناپذیر است؛
        موازی‌سازی کارآمد الگوریتم‌های گراف یک حوزه تحقیقاتی مداوم است [76].
    </p>
<h4><strong>APIs</strong> و زبان‌های سطح بالا</h4>
<p>
        در طول سال‌هایی که <strong>MapReduce</strong> برای اولین بار محبوب شد، موتورهای اجرا
        برای پردازش <strong>batch</strong> توزیع شده بالغ شده‌اند. تا کنون، زیرساخت‌ها به
        اندازه‌ی کافی <strong>robust</strong> شده‌اند تا چندین پتابایت از داده‌ها را در <strong>clusters</strong>
        بیش از 10000 ماشین ذخیره و پردازش کنند. از آن‌جایی که مشکل عملکرد
        فیزیکی فرآیندهای <strong>batch</strong> در چنین مقیاسی کم و بیش حل شده است،
        توجه به حوزه‌های دیگر معطوف شده است: بهبود مدل برنامه‌نویسی، بهبود
        کارایی پردازش، و گسترش مجموعه‌ای از مشکلاتی که این فناوری‌ها می‌توانند
        حل کنند.
        426
        |
        فصل 10: پردازش <strong>Batch</strong>
</p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0448</div>
            </div>
        </div>
        <!-- Page 0449 -->
        <div class="chapter" id="page-0449">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        همان‌طور که قبلاً بحث شد، زبان‌ها و <strong>APIs</strong> های سطح بالاتر مانند <strong>Hive</strong>، <strong>Pig</strong>،
        <strong>Cascading</strong> و <strong>Crunch</strong> محبوب شدند زیرا برنامه‌نویسی jobs های
        <strong>MapReduce</strong> به صورت دستی بسیار طاقت‌فرسا است. با ظهور <strong>Tez</strong>، این
        زبان‌های سطح بالا از این مزیت اضافی برخوردار بودند که می‌توانستند بدون
        نیاز به بازنویسی کد job، به موتور اجرای <strong>dataflow</strong> جدید منتقل شوند.
        <strong>Spark</strong> و <strong>Flink</strong> نیز شامل <strong>APIs</strong> <strong>dataflow</strong> سطح بالای خودشان
        هستند، که اغلب از <strong>FlumeJava</strong> [34] الهام می‌گیرند.
    </p>
<p>
        این <strong>APIs</strong> <strong>dataflow</strong> به‌طور کلی از <strong>building blocks</strong> به سبک
        رابطه‌ای برای بیان یک محاسبه استفاده می‌کنند: پیوستن به مجموعه‌داده‌ها
        بر اساس مقدار یک <strong>field</strong>؛ گروه‌بندی <strong>tuples</strong> بر اساس <strong>key</strong>؛ فیلتر کردن
        بر اساس یک شرط؛ و تجمیع <strong>tuples</strong> با شمارش، جمع یا سایر توابع.
        در داخل، این عملیات با استفاده از الگوریتم‌های <strong>join</strong> و گروه‌بندی مختلفی که
        قبلاً در این فصل بحث کردیم، پیاده‌سازی می‌شوند.
    </p>
<p>
        علاوه بر مزیت آشکار نیاز به کد کمتر، این واسط‌های سطح بالا امکان استفاده
        تعاملی را نیز فراهم می‌کنند، که در آن شما کد تجزیه و تحلیل را به‌طور
        افزایشی در یک <strong>shell</strong> می‌نویسید و آن را مکرراً اجرا می‌کنید تا مشاهده کنید
        چه کار می‌کند. این سبک از توسعه هنگام کاوش در یک مجموعه‌داده و آزمایش
        رویکردهایی برای پردازش آن، بسیار مفید است. همچنین یادآور فلسفه <strong>Unix</strong>
        است، که ما در "فلسفه <strong>Unix</strong>" در صفحه 394 مورد بحث قرار دادیم.
    </p>
<p>
        علاوه بر این، این واسط‌های سطح بالا نه تنها باعث می‌شوند انسان‌هایی که از
        سیستم استفاده می‌کنند، مولدتر شوند، بلکه راندمان اجرای job را در سطح
        ماشین نیز بهبود می‌بخشند.
    </p>
<h4>حرکت به سمت زبان‌های query اعلانی</h4>
<p>
        یک مزیت تعیین <strong>joins</strong> به عنوان <strong>relational operators</strong>، در مقایسه با
        نوشتن کدی که <strong>join</strong> را انجام می‌دهد، این است که فریم‌ورک می‌تواند
        ویژگی‌های ورودی‌های <strong>join</strong> را تجزیه و تحلیل کند و به‌طور خودکار
        تصمیم بگیرد که کدام‌یک از الگوریتم‌های <strong>join</strong> فوق برای کار مورد نظر
        مناسب‌تر است. <strong>Hive</strong>، <strong>Spark</strong> و <strong>Flink</strong> دارای بهینه‌سازهای query
        مبتنی بر هزینه هستند که می‌توانند این کار را انجام دهند، و حتی ترتیب
        <strong>joins</strong> را تغییر دهند تا مقدار حالت <strong>intermediate</strong> به حداقل برسد [66, 77,
        78, 79].
    </p>
<p>
        انتخاب الگوریتم <strong>join</strong> می‌تواند تفاوت زیادی در عملکرد یک job <strong>batch</strong>
        ایجاد کند، و خوب است که مجبور نباشید تمام الگوریتم‌های <strong>join</strong> مختلف
        را که در این فصل مورد بحث قرار دادیم، درک و به خاطر بسپارید. این امر
        امکان‌پذیر است اگر <strong>joins</strong> به روشی اعلانی مشخص شوند: برنامه به
        سادگی بیان می‌کند که کدام <strong>joins</strong> مورد نیاز است، و بهینه‌ساز query
        تصمیم می‌گیرد که چگونه می‌توان آن‌ها را به‌بهترین نحو اجرا کرد. ما قبلاً
        به این ایده در "زبان‌های query برای داده‌ها" در صفحه 42 برخورد کردیم.
    </p>
<p>
        با این حال، از راه‌های دیگر، <strong>MapReduce</strong> و جانشینان <strong>dataflow</strong> آن
        بسیار متفاوت از مدل query کاملاً اعلانی <strong>SQL</strong> هستند. <strong>MapReduce</strong>
        حول ایده‌ی <strong>function callbacks</strong> ساخته شده بود: برای هر رکورد یا گروهی
        از رکوردها، یک تابع تعریف شده توسط کاربر (<strong>mapper</strong> یا <strong>reducer</strong>)
        فراخوانی می‌شود، و آن تابع آزاد است که کد دلخواه را فراخوانی کند تا
        تصمیم بگیرد چه چیزی را خروجی دهد. این رویکرد این مزیت را دارد که شما
        می‌توانید
        <strong>Beyond MapReduce</strong>
        |
        427
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0449</div>
            </div>
        </div>
        <!-- Page 0450 -->
        <div class="chapter" id="page-0450">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        بر روی یک اکوسیستم بزرگ از کتابخانه‌های موجود برای انجام کارهایی مانند
        <strong>parsing</strong>، تجزیه و تحلیل زبان طبیعی، تجزیه و تحلیل تصویر، و اجرای
        الگوریتم‌های عددی یا آماری است.
    </p>
<p>
        آزادی برای اجرای آسان کد دلخواه همان چیزی است که از دیرباز سیستم‌های
        پردازش <strong>batch</strong> با میراث <strong>MapReduce</strong> را از پایگاه‌های داده‌ی <strong>MPP</strong>
        متمایز کرده است (نگاه کنید به "مقایسه <strong>Hadoop</strong> با پایگاه‌های داده‌ی
        توزیع شده" در صفحه 414)؛ اگرچه پایگاه‌های داده دارای امکاناتی برای
        نوشتن توابع تعریف شده توسط کاربر هستند، اما اغلب استفاده از آن‌ها
        دست و پا گیر است و با مدیران بسته و سیستم‌های مدیریت وابستگی که در
        بیشتر زبان‌های برنامه‌نویسی به‌طور گسترده مورد استفاده قرار می‌گیرند (مانند
        <strong>Maven</strong> برای <strong>Java</strong>، <strong>npm</strong> برای <strong>JavaScript</strong> و <strong>Rubygems</strong> برای
        <strong>Ruby</strong>) به خوبی یکپارچه نشده‌اند.
    </p>
<p>
        با این حال، موتورهای <strong>dataflow</strong> دریافته‌اند که مزایایی نیز برای گنجاندن
        ویژگی‌های اعلانی بیشتر در زمینه‌هایی فراتر از <strong>joins</strong> وجود دارد. به عنوان
        مثال، اگر یک تابع <strong>callback</strong> فقط شامل یک شرط فیلتر ساده باشد، یا
        فقط چند <strong>field</strong> را از یک رکورد انتخاب کند، سپس در فراخوانی تابع برای
        هر رکورد، <strong>overhead</strong> <strong>CPU</strong> قابل توجهی وجود دارد. اگر چنین عملیات‌های
        فیلتر کردن و <strong>mapping</strong> ساده‌ای به روشی اعلانی بیان شوند، بهینه‌ساز
        query می‌تواند از <strong>layouts</strong> ذخیره‌سازی مبتنی بر <strong>column</strong> (نگاه کنید به
        "ذخیره‌سازی <strong>Column-Oriented</strong>" در صفحه 95) استفاده کند و فقط
        ستون‌های مورد نیاز را از دیسک بخواند. <strong>Hive</strong>، <strong>Spark DataFrames</strong> و
        <strong>Impala</strong> از اجرای <em>vectorized</em> استفاده می‌کنند (نگاه کنید به "پهنای باند
        حافظه و پردازش <em>vectorized</em>" در صفحه 99): تکرار داده‌ها در یک حلقه
        درونی تنگ که برای <strong>CPU caches</strong> مناسب است، و اجتناب از فراخوانی
        توابع. <strong>Spark</strong> <strong>bytecode</strong> <strong>JVM</strong> را تولید می‌کند [79] و <strong>Impala</strong> از
        <strong>LLVM</strong> برای تولید کد <em>native</em> برای این حلقه‌های درونی استفاده می‌کند
        [41].
    </p>
<p>
        با گنجاندن جنبه‌های اعلانی در <strong>APIs</strong> سطح بالای خود، و داشتن
        بهینه‌سازهای query که می‌توانند در طول اجرا از آن‌ها استفاده کنند،
        فریم‌ورک‌های پردازش <strong>batch</strong> شروع به شباهت بیشتر به پایگاه‌های داده‌ی
        <strong>MPP</strong> می‌کنند (و می‌توانند عملکرد قابل مقایسه‌ای را به دست آورند). در
        همان زمان، با داشتن قابلیت توسعه‌پذیری برای اجرای کد دلخواه و خواندن
        داده‌ها در فرمت‌های دلخواه، آن‌ها مزیت انعطاف‌پذیری خود را حفظ
        می‌کنند.
    </p>
<h4>تخصص برای حوزه‌های مختلف</h4>
<p>
        در حالی که قابلیت توسعه‌پذیری برای اجرای کد دلخواه مفید است، موارد
        رایج زیادی نیز وجود دارد که در آن‌ها الگوهای پردازش استاندارد دوباره
        تکرار می‌شوند، و بنابراین ارزش دارد که پیاده‌سازی‌های قابل استفاده مجدد
        از <strong>building blocks</strong> مشترک داشته باشید. به‌طور سنتی، پایگاه‌های داده‌ی
        <strong>MPP</strong> نیازهای تحلیلگران هوش تجاری و گزارش‌دهی کسب‌وکار را برآورده
        کرده‌اند، اما این تنها یکی از حوزه‌هایی است که در آن‌ها از پردازش
        <strong>batch</strong> استفاده می‌شود.
    </p>
<p>
        یک حوزه دیگر با اهمیت فزاینده، الگوریتم‌های آماری و عددی است که برای
        برنامه‌های <strong>machine learning</strong> مانند طبقه‌بندی و سیستم‌های
        توصیه مورد نیاز است. پیاده‌سازی‌های قابل استفاده مجدد در حال ظهور
        هستند: به عنوان مثال، <strong>Mahout</strong> الگوریتم‌های مختلفی را برای یادگیری
        ماشین بر روی <strong>MapReduce</strong>، <strong>Spark</strong> و <strong>Flink</strong> پیاده‌سازی می‌کند، در
        حالی که <strong>MADlib</strong> عملکرد مشابهی را در داخل یک پایگاه داده‌ی <strong>MPP</strong>
        رابطه‌ای (<strong>Apache HAWQ</strong>) پیاده‌سازی می‌کند [54].
        428
        |
        فصل 10: پردازش <strong>Batch</strong>
</p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0450</div>
            </div>
        </div>
        <!-- Page 0451 -->
        <div class="chapter" id="page-0451">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        همچنین الگوریتم‌های مکانی مانند k-نزدیک‌ترین همسایه‌ها [80]، که به دنبال
        مواردی است که در یک فضای چند بعدی به یک مورد داده شده نزدیک هستند—نوعی
        جستجوی شباهت، مفید هستند. جستجوی تقریبی نیز برای الگوریتم‌های
        تجزیه و تحلیل ژنوم مهم است، که نیاز به یافتن رشته‌هایی دارند که شبیه
        به هم هستند اما یکسان نیستند [81].
    </p>
<p>
        موتورهای پردازش <strong>batch</strong> برای اجرای توزیع شده الگوریتم‌ها از طیف
        گسترده‌ای از حوزه‌ها استفاده می‌شوند. با به‌دست آوردن قابلیت‌های داخلی
        و <strong>operators</strong> اعلانی سطح بالا توسط سیستم‌های پردازش <strong>batch</strong>، و با
        تبدیل پایگاه‌های داده‌ی <strong>MPP</strong> به سیستم‌های بیشتر قابل برنامه‌ریزی و
        انعطاف‌پذیر، این دو شروع به شباهت بیشتر به هم می‌کنند: در نهایت، همه
        آن‌ها فقط سیستم‌هایی برای ذخیره‌سازی و پردازش داده‌ها هستند.
    </p>
<h4>خلاصه</h4>
<p>
        در این فصل ما به بررسی موضوع پردازش <strong>batch</strong> پرداختیم. ما با نگاهی به
        ابزارهای <strong>Unix</strong> مانند <strong>awk</strong>، <strong>grep</strong> و <strong>sort</strong> شروع کردیم، و دیدیم که
        چگونه فلسفه طراحی آن ابزارها به <strong>MapReduce</strong> و موتورهای <strong>dataflow</strong>
        جدیدتر منتقل شده است. برخی از این اصول طراحی این است که ورودی‌ها
        <em>immutable</em> هستند، خروجی‌ها قرار است ورودی دیگری (هنوز ناشناخته)
        شوند، و مشکلات پیچیده با ترکیب ابزارهای کوچکی حل می‌شوند که "یک کار
        را خوب انجام می‌دهند".
    </p>
<p>
        در دنیای <strong>Unix</strong>، رابط یکنواختی که به یک برنامه اجازه می‌دهد با دیگری
        ترکیب شود، فایل‌ها و <strong>pipes</strong> است؛ در <strong>MapReduce</strong>، این رابط یک
        سیستم فایل توزیع شده است. ما دیدیم که موتورهای <strong>dataflow</strong>، مکانیسم‌های
        انتقال داده شبیه <strong>pipe</strong> خود را اضافه می‌کنند تا از <strong>materializing</strong> حالت
        <strong>intermediate</strong> به سیستم فایل توزیع شده اجتناب کنند، اما ورودی اولیه و
        خروجی نهایی یک job هنوز معمولاً <strong>HDFS</strong> است.
    </p>
<p>
        دو مشکل اصلی که فریم‌ورک‌های پردازش <strong>batch</strong> توزیع شده باید حل
        کنند عبارتند از:
    </p>
<ul>
<li>
            تقسیم‌بندی
        </li>
<p>
            در <strong>MapReduce</strong>، <strong>mappers</strong> بر اساس بلوک‌های فایل ورودی
            تقسیم‌بندی می‌شوند. خروجی <strong>mappers</strong> دوباره تقسیم‌بندی، مرتب
            و در تعداد قابل تنظیم از <strong>reducer partitions</strong> ادغام می‌شود. هدف از
            این فرآیند جمع‌آوری تمام داده‌های مرتبط—به عنوان مثال، تمام رکوردها
            با یک <strong>key</strong> یکسان—در یک مکان است.
        </p>
<p>
            موتورهای <strong>dataflow</strong> پس از <strong>MapReduce</strong> سعی می‌کنند از مرتب‌سازی
            اجتناب کنند، مگر این‌که لازم باشد، اما در غیر این صورت رویکردی
            مشابه با تقسیم‌بندی دارند.
        </p>
<li>
            تحمل خطا
        </li>
<p>
<strong>MapReduce</strong> اغلب روی دیسک می‌نویسد، که بازیابی از یک <strong>task</strong>
            شکست‌خورده مجزا را بدون راه‌اندازی مجدد کل job آسان می‌کند اما
            اجرا را در مورد بدون شکست کند می‌کند. موتورهای <strong>dataflow</strong>
            کمتر <strong>materialization</strong> از حالت <strong>intermediate</strong> را انجام می‌دهند و
            بیشتر را در حافظه نگه می‌دارند، به این معنی که اگر یک <strong>node</strong> شکست
            بخورد، نیاز به محاسبه مجدد داده‌های بیشتری دارند.
            <strong>Operators</strong> <em>deterministic</em> مقدار داده‌های مورد نیاز برای
            محاسبه مجدد را کاهش می‌دهند.
        </p>
</ul>
<p>
        خلاصه
        |
        429
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0451</div>
            </div>
        </div>
        <!-- Page 0452 -->
        <div class="chapter" id="page-0452">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        ما چندین الگوریتم <strong>join</strong> را برای <strong>MapReduce</strong> مورد بحث قرار دادیم، که
        بیشتر آن‌ها به‌طور داخلی در پایگاه‌های داده‌ی <strong>MPP</strong> و موتورهای
        <strong>dataflow</strong> نیز استفاده می‌شوند. آن‌ها همچنین یک مثال خوب از نحوه
        عملکرد الگوریتم‌های <em>partitioned</em> ارائه می‌دهند:
    </p>
<ul>
<li>
<strong>Sort-merge joins</strong>
</li>
<p>
            هر یک از ورودی‌های در حال <strong>join</strong>، از طریق یک <strong>mapper</strong> می‌گذرد که
            <strong>join key</strong> را استخراج می‌کند. با تقسیم‌بندی، مرتب‌سازی و
            ادغام، تمام رکوردهایی که دارای <strong>key</strong> یکسان هستند، در نهایت به
            فراخوانی یکسان <strong>reducer</strong> می‌رسند. سپس این تابع می‌تواند رکوردهای
            <strong>joined</strong> را خروجی دهد.
        </p>
<li>
<strong>Broadcast hash joins</strong>
</li>
<p>
            یکی از دو ورودی <strong>join</strong> کوچک است، بنابراین تقسیم‌بندی نمی‌شود و
            می‌تواند به‌طور کامل در یک جدول <strong>hash</strong> بارگذاری شود. بنابراین، شما
            می‌توانید یک <strong>mapper</strong> را برای هر <strong>partition</strong> از ورودی <strong>join</strong>
            بزرگ شروع کنید، جدول <strong>hash</strong> را برای ورودی کوچک در هر <strong>mapper</strong>
            بارگذاری کنید، و سپس ورودی بزرگ را یک رکورد در یک زمان اسکن
            کنید، و جدول <strong>hash</strong> را برای هر رکورد query کنید.
        </p>
<li>
<strong>Partitioned hash joins</strong>
</li>
<p>
            اگر دو ورودی <strong>join</strong> به همان روش تقسیم‌بندی شوند (با استفاده از
            همان <strong>key</strong>، همان تابع <strong>hash</strong> و همان تعداد <strong>partitions</strong>)،
            آنگاه رویکرد جدول <strong>hash</strong> می‌تواند به‌طور مستقل برای هر <strong>partition</strong>
            استفاده شود.
        </p>
</ul>
<p>
        موتورهای پردازش <strong>batch</strong> توزیع شده دارای یک مدل برنامه‌نویسی محدود
        عمدی هستند: فرض بر این است که توابع <strong>callback</strong> (مانند <strong>mappers</strong>
        و <strong>reducers</strong>) <em>stateless</em> هستند و هیچ اثر جانبی خارجی قابل مشاهده
        به جز خروجی تعیین شده خود ندارند. این محدودیت به فریم‌ورک اجازه می‌دهد
        تا برخی از مشکلات سخت سیستم‌های توزیع شده را پشت انتزاع خود پنهان
        کند: در مواجهه با خرابی‌ها و مشکلات شبکه، <strong>tasks</strong> را می‌توان با
        اطمینان دوباره امتحان کرد، و خروجی از هر <strong>tasks</strong> شکست‌خورده دور
        ریخته می‌شود. اگر چندین <strong>task</strong> برای یک <strong>partition</strong> موفق شوند، فقط یکی
        از آن‌ها در واقع خروجی خود را قابل مشاهده می‌کند.
    </p>
<p>
        به لطف فریم‌ورک، کد شما در یک job پردازش <strong>batch</strong> نیازی به نگرانی در
        مورد پیاده‌سازی مکانیسم‌های تحمل خطا ندارد: فریم‌ورک می‌تواند تضمین
        کند که خروجی نهایی یک job همانند این است که هیچ خطایی رخ نداده
        است، حتی اگر در واقعیت <strong>tasks</strong> مختلفی مجبور به تکرار مجدد شده
        باشند. این <strong>semantics</strong> های قابل اعتماد بسیار قوی‌تر از آن چیزی است
        که معمولاً در سرویس‌های <em>online</em> دارید که درخواست‌های کاربر را مدیریت
        می‌کنند و به‌عنوان یک اثر جانبی پردازش یک درخواست، در پایگاه‌های
        داده می‌نویسند.
    </p>
<p>
        ویژگی متمایز یک job پردازش <strong>batch</strong> این است که برخی از داده‌های ورودی
        را می‌خواند و برخی داده‌های خروجی را تولید می‌کند، بدون تغییر ورودی—به
        عبارت دیگر، خروجی از ورودی گرفته می‌شود. به‌طور اساسی، داده‌های ورودی
        <em>bounded</em> هستند: دارای اندازه مشخص و ثابت هستند (به عنوان مثال، از
        مجموعه‌ای از فایل‌های <strong>log</strong> در یک نقطه زمانی خاص، یا یک <strong>snapshot</strong>
        از محتویات یک پایگاه داده تشکیل شده است). از آن‌جایی که <em>bounded</em>
        است، یک job می‌داند چه زمانی خواندن کل ورودی را به پایان رسانده است، و
        بنابراین یک job در نهایت زمانی که کارش تمام شد، تکمیل می‌شود.
    </p>
<p>
        در فصل بعد، ما به پردازش <strong>stream</strong> می‌پردازیم، که در آن ورودی
        <em>unbounded</em> است—یعنی، شما هنوز یک job دارید، اما ورودی‌های آن
        جریان‌های بی‌پایان داده‌ها هستند. در
        430
        |
        فصل 10: پردازش <strong>Batch</strong>
</p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0452</div>
            </div>
        </div>
        <!-- Page 0453 -->
        <div class="chapter" id="page-0453">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        در این مورد، یک job هرگز کامل نمی‌شود، زیرا در هر زمانی ممکن است
        هنوز کارهای بیشتری در راه باشد. ما خواهیم دید که پردازش <strong>stream</strong>
        و <strong>batch</strong> از جهاتی مشابه هستند، اما فرض جریان‌های <em>unbounded</em>
        نیز چیزهای زیادی را در مورد چگونگی ساخت سیستم‌ها تغییر می‌دهد.
    </p>
<p>
        مراجع
    </p>
<p>
        [1] <strong>Jeffrey Dean</strong> و <strong>Sanjay Ghemawat</strong>: "<strong>MapReduce</strong>: پردازش
        داده‌ها ساده شده در <strong>Clusters</strong> بزرگ"، در ششمین سمپوزیوم <strong>USENIX</strong> در
        طراحی و پیاده‌سازی سیستم عامل (<strong>OSDI</strong>)، دسامبر 2004.
    </p>
<p>
        [2] <strong>Joel Spolsky</strong>: "مخاطرات <strong>JavaSchools</strong>"، <strong>joelonsoftware.com</strong>،
        25 دسامبر 2005.
    </p>
<p>
        [3] <strong>Shivnath Babu</strong> و <strong>Herodotos Herodotou</strong>: "پایگاه‌های داده
        <strong>Massively Parallel</strong> و سیستم‌های <strong>MapReduce</strong>"، <strong>Foundations and
        Trends in Databases</strong>، جلد 5، شماره 1، صفحات 1–104، نوامبر 2013.
        <strong>doi:10.1561/1900000036</strong>
</p>
<p>
        [4] <strong>David J. DeWitt</strong> و <strong>Michael Stonebraker</strong>: "<strong>MapReduce</strong>: یک گام
        بزرگ به عقب"، در ابتدا در <strong>databasecolumn.vertica.com</strong> منتشر شد، 17
        ژانویه 2008.
    </p>
<p>
        [5] <strong>Henry Robinson</strong>: "فیل یک اسب تروجان بود: درباره‌ی مرگ
        <strong>MapReduce</strong> در <strong>Google</strong>"، <strong>the-paper-trail.org</strong>، 25 ژوئن 2014.
    </p>
<p>
        [6] "ماشین <strong>Hollerith</strong>"، اداره آمار ایالات متحده، <strong>census.gov</strong>.
    </p>
<p>
        [7] "راهنمای مرجع مرتب‌کننده‌های <strong>IBM</strong> 82، 83 و 84"، ویرایش <strong>A24-1034-1</strong>،
        شرکت بین‌المللی ماشین‌های تجاری، ژوئیه 1962.
    </p>
<p>
        [8] <strong>Adam Drake</strong>: "ابزارهای خط فرمان می‌توانند 235 برابر سریع‌تر از
        <strong>Hadoop Cluster</strong> شما باشند"، <strong>aadrake.com</strong>، 25 ژانویه 2014.
    </p>
<p>
        [9] "مستندات <strong>GNU Coreutils</strong> 8.23"، <strong>Free Software Foundation, Inc.</strong>،
        2014.
    </p>
<p>
        [10] <strong>Martin Kleppmann</strong>: "<strong>Kafka</strong>، <strong>Samza</strong> و فلسفه <strong>Unix</strong> از
        داده‌های توزیع شده"، <strong>martin.kleppmann.com</strong>، 5 اوت 2015.
    </p>
<p>
        [11] <strong>Doug McIlroy</strong>: یادداشت داخلی <strong>Bell Labs</strong>، اکتبر 1964. نقل شده در:
        <strong>Dennis M. Richie</strong>: "مشاوره از <strong>Doug McIlroy</strong>"، <strong>cm.bell-labs.com</strong>.
    </p>
<p>
        [12] <strong>M. D. McIlroy</strong>، <strong>E. N. Pinson</strong> و <strong>B. A. Tague</strong>: "سیستم
        <strong>Time-Sharing</strong> <strong>UNIX</strong>: پیشگفتار"، <strong>The Bell System Technical Journal</strong>،
        جلد 57، شماره 6، صفحات 1899–1904، ژوئیه 1978.
    </p>
<p>
        [13] <strong>Eric S. Raymond</strong>: هنر برنامه‌نویسی <strong>UNIX</strong>. <strong>Addison-Wesley</strong>، 2003.
        <strong>ISBN: 978-0-13-142901-7</strong>
</p>
<p>
        [14] <strong>Ronald Duncan</strong>: "فرمت‌های فایل متنی – متن <strong>ASCII Delimited</strong> – نه
        متن <strong>CSV</strong> یا <strong>TAB Delimited</strong>"، <strong>ronaldduncan.wordpress.com</strong>، 31
        اکتبر 2009.
    </p>
<p>
        [15] <strong>Alan Kay</strong>: "آیا 'مهندسی نرم‌افزار' یک <strong>Oxymoron</strong> است؟"،
        <strong>tinlizzie.org</strong>.
    </p>
<p>
        خلاصه
        |
        431
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0453</div>
            </div>
        </div>
        <!-- Page 0454 -->
        <div class="chapter" id="page-0454">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        [16] <strong>Martin Fowler</strong>: "<strong>InversionOfControl</strong>"،
        <strong>martinfowler.com</strong>، 26 ژوئن 2005.
    </p>
<p>
        [17] <strong>Daniel J. Bernstein</strong>: "دو <strong>File Descriptors</strong> برای
        <strong>Sockets</strong>"، <strong>cr.yp.to</strong>.
    </p>
<p>
        [18] <strong>Rob Pike</strong> و <strong>Dennis M. Ritchie</strong>: "معماری <strong>Styx</strong> برای
        سیستم‌های توزیع شده"، <strong>Bell Labs Technical Journal</strong>، جلد 4، شماره 2،
        صفحات 146–152، آوریل 1999.
    </p>
<p>
        [19] <strong>Sanjay Ghemawat</strong>، <strong>Howard Gobioff</strong> و <strong>Shun-Tak Leung</strong>:
        "سیستم فایل <strong>Google</strong>"، در نوزدهمین سمپوزیوم <strong>ACM</strong> در اصول سیستم
        عامل (<strong>SOSP</strong>)، اکتبر 2003. <strong>doi:10.1145/945445.945450</strong>
</p>
<p>
        [20] <strong>Michael Ovsiannikov</strong>، <strong>Silvius Rus</strong>، <strong>Damian Reeves</strong> و همکاران:
        "سیستم فایل <strong>Quantcast</strong>"، <strong>Proceedings of the VLDB Endowment</strong>، جلد
        6، شماره 11، صفحات 1092–1101، اوت 2013.
        <strong>doi:10.14778/2536222.2536234</strong>
</p>
<p>
        [21] "مستندات توسعه‌دهنده <strong>OpenStack Swift 2.6.1</strong>"، <strong>OpenStack
        Foundation</strong>، <strong>docs.openstack.org</strong>، مارس 2016.
    </p>
<p>
        [22] <strong>Zhe Zhang</strong>، <strong>Andrew Wang</strong>، <strong>Kai Zheng</strong> و همکاران: "معرفی
        کدگذاری <strong>HDFS Erasure</strong> در <strong>Apache Hadoop</strong>"،
        <strong>blog.cloudera.com</strong>، 23 سپتامبر 2015.
    </p>
<p>
        [23] <strong>Peter Cnudde</strong>: "<strong>Hadoop</strong> 10 ساله شد"، <strong>yahoohadoop.tumblr.com</strong>،
        5 فوریه 2016.
    </p>
<p>
        [24] <strong>Eric Baldeschwieler</strong>: "فکر کردن در مورد فناوری‌های ذخیره‌سازی
        <strong>HDFS</strong> در مقابل دیگر فناوری‌ها"، <strong>hortonworks.com</strong>، 25 ژوئیه
        2012.
    </p>
<p>
        [25] <strong>Brendan Gregg</strong>: "<strong>Manta</strong>: <strong>Unix</strong> با <strong>Map Reduce</strong> ملاقات
        می‌کند"، <strong>dtrace.org</strong>، 25 ژوئن 2013.
    </p>
<p>
        [26] <strong>Tom White</strong>: <strong>Hadoop</strong>: راهنمای قطعی، چاپ چهارم. <strong>O’Reilly Media</strong>،
        2015. <strong>ISBN: 978-1-491-90163-2</strong>
</p>
<p>
        [27] <strong>Jim N. Gray</strong>: "اقتصاد محاسبات توزیع شده"، گزارش فنی تحقیقات
        <strong>Microsoft</strong> <strong>MSR-TR-2003-24</strong>، مارس 2003.
    </p>
<p>
        [28] <strong>Márton Trencséni</strong>: "<strong>Luigi</strong> در مقابل <strong>Airflow</strong> در مقابل
        <strong>Pinball</strong>"، <strong>bytepawn.com</strong>، 6 فوریه 2016.
    </p>
<p>
        [29] <strong>Roshan Sumbaly</strong>، <strong>Jay Kreps</strong> و <strong>Sam Shah</strong>: "اکوسیستم
        '<strong>Big Data</strong>' در <strong>LinkedIn</strong>"، در کنفرانس بین‌المللی <strong>ACM</strong> در مورد
        مدیریت داده‌ها (<strong>SIGMOD</strong>)، ژوئیه 2013.
        <strong>doi:10.1145/2463676.2463707</strong>
</p>
<p>
        [30] <strong>Alan F. Gates</strong>، <strong>Olga Natkovich</strong>، <strong>Shubham Chopra</strong> و همکاران:
        "ساخت یک سیستم <strong>Dataflow</strong> سطح بالا بر روی <strong>Map-Reduce</strong>:
        تجربه <strong>Pig</strong>"، در سی و پنجمین کنفرانس بین‌المللی در مورد پایگاه‌های
        داده بسیار بزرگ (<strong>VLDB</strong>)، اوت 2009.
    </p>
<p>
        [31] <strong>Ashish Thusoo</strong>، <strong>Joydeep Sen Sarma</strong>، <strong>Namit Jain</strong> و همکاران:
        "<strong>Hive</strong> – یک انبار داده در مقیاس <strong>Petabyte</strong> با استفاده از <strong>Hadoop</strong>"، در
        بیست و ششمین کنفرانس بین‌المللی <strong>IEEE</strong> در مهندسی داده (<strong>ICDE</strong>)، مارس
        2010. <strong>doi:10.1109/ICDE.2010.5447738</strong>
</p>
<p>
        [32] "راهنمای کاربر <strong>Cascading 3.0</strong>"، <strong>Concurrent, Inc.</strong>،
        <strong>docs.cascading.org</strong>، ژانویه 2016.
        432
        |
        فصل 10: پردازش <strong>Batch</strong>
</p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0454</div>
            </div>
        </div>
        <!-- Page 0455 -->
        <div class="chapter" id="page-0455">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        [33] "راهنمای کاربر <strong>Apache Crunch</strong>"، <strong>Apache Software
        Foundation</strong>، <strong>crunch.apache.org</strong>.
    </p>
<p>
        [34] <strong>Craig Chambers</strong>، <strong>Ashish Raniwala</strong>، <strong>Frances Perry</strong> و
        همکاران: "<strong>FlumeJava</strong>: <strong>Pipelines</strong> موازی داده آسان و کارآمد"، در
        سی و یکمین کنفرانس <strong>ACM SIGPLAN</strong> در طراحی و پیاده‌سازی زبان
        برنامه‌نویسی (<strong>PLDI</strong>)، ژوئن 2010.
        <strong>doi:10.1145/1806596.1806638</strong>
</p>
<p>
        [35] <strong>Jay Kreps</strong>: "چرا حالت محلی یک <strong>Primitive</strong> اساسی در پردازش
        <strong>Stream</strong> است"، <strong>oreilly.com</strong>، 31 ژوئیه 2014.
    </p>
<p>
        [36] <strong>Martin Kleppmann</strong>: "بازنگری <strong>Caching</strong> در برنامه‌های وب"،
        <strong>martin.kleppmann.com</strong>، 1 اکتبر 2012.
    </p>
<p>
        [37] <strong>Mark Grover</strong>، <strong>Ted Malaska</strong>، <strong>Jonathan Seidman</strong> و <strong>Gwen
        Shapira</strong>: معماری‌های برنامه <strong>Hadoop</strong>. <strong>O’Reilly Media</strong>، 2015.
        <strong>ISBN: 978-1-491-90004-8</strong>
</p>
<p>
        [38] <strong>Philippe Ajoux</strong>، <strong>Nathan Bronson</strong>، <strong>Sanjeev Kumar</strong> و
        همکاران: "چالش‌ها برای اتخاذ سازگاری قوی‌تر در مقیاس"، در پانزدهمین
        کارگاه <strong>USENIX</strong> در مورد موضوعات داغ در سیستم‌های عامل (<strong>HotOS</strong>)،
        مه 2015.
    </p>
<p>
        [39] <strong>Sriranjan Manjunath</strong>: "<strong>Skewed Join</strong>"، <strong>wiki.apache.org</strong>،
        2009.
    </p>
<p>
        [40] <strong>David J. DeWitt</strong>، <strong>Jeffrey F. Naughton</strong>، <strong>Donovan A.
        Schneider</strong> و <strong>S. Seshadri</strong>: "مدیریت <strong>Skew</strong> عملی در <strong>Parallel
        Joins</strong>"، در هجدهمین کنفرانس بین‌المللی در مورد پایگاه‌های داده بسیار
        بزرگ (<strong>VLDB</strong>)، اوت 1992.
    </p>
<p>
        [41] <strong>Marcel Kornacker</strong>، <strong>Alexander Behm</strong>، <strong>Victor Bittorf</strong> و
        همکاران: "<strong>Impala</strong>: یک موتور <strong>SQL</strong> مدرن و منبع باز برای <strong>Hadoop</strong>"، در
        هفتمین کنفرانس دوسالانه در مورد تحقیقات نوآورانه سیستم‌های داده
        (<strong>CIDR</strong>)، ژانویه 2015.
    </p>
<p>
        [42] <strong>Matthieu Monsch</strong>: "منبع باز <strong>PalDB</strong>، یک همراه سبک وزن برای
        ذخیره‌سازی داده‌های جانبی"، <strong>engineering.linkedin.com</strong>، 26 اکتبر
        2015.
    </p>
<p>
        [43] <strong>Daniel Peng</strong> و <strong>Frank Dabek</strong>: "پردازش افزایشی در مقیاس
        بزرگ با استفاده از تراکنش‌ها و اعلان‌های توزیع شده"، در نهمین کنفرانس
        <strong>USENIX</strong> در مورد طراحی و پیاده‌سازی سیستم‌های عامل (<strong>OSDI</strong>)،
        اکتبر 2010.
    </p>
<p>
        [44] ""راهنمای کاربر <strong>Cloudera Search</strong>"، <strong>Cloudera, Inc.</strong>، سپتامبر
        2015.
    </p>
<p>
        [45] <strong>Lili Wu</strong>، <strong>Sam Shah</strong>، <strong>Sean Choi</strong> و همکاران: "<strong>Browsemaps</strong>:
        فیلتر کردن مشارکتی در <strong>LinkedIn</strong>"، در ششمین کارگاه در مورد
        سیستم‌های توصیه‌گر و وب اجتماعی (<strong>RSWeb</strong>)، اکتبر 2014.
    </p>
<p>
        [46] <strong>Roshan Sumbaly</strong>، <strong>Jay Kreps</strong>، <strong>Lei Gao</strong> و همکاران: "سرو
        داده‌های محاسبه شده <strong>Batch</strong> در مقیاس بزرگ با <strong>Project Voldemort</strong>"،
        در دهمین کنفرانس <strong>USENIX</strong> در مورد فناوری‌های فایل و ذخیره‌سازی
        (<strong>FAST</strong>)، فوریه 2012.
    </p>
<p>
        [47] <strong>Varun Sharma</strong>: "منبع باز <strong>Terrapin</strong>: یک سیستم سرویس‌دهی برای
        داده‌های تولید شده <strong>Batch</strong>"، <strong>engineering.pinterest.com</strong>، 14
        سپتامبر 2015.
        خلاصه
        |
        433
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0455</div>
            </div>
        </div>
        <!-- Page 0456 -->
        <div class="chapter" id="page-0456">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        [48] <strong>Nathan Marz</strong>: "<strong>ElephantDB</strong>"،
        <strong>slideshare.net</strong>، 30 مه 2011.
    </p>
<p>
        [49] <strong>Jean-Daniel (JD) Cryans</strong>: "چگونه: از <strong>HBase Bulk Loading</strong>
        استفاده کنید، و چرا"، <strong>blog.cloudera.com</strong>، 27 سپتامبر 2013.
    </p>
<p>
        [50] <strong>Nathan Marz</strong>: "چگونه تئوری <strong>CAP</strong> را شکست دهیم"،
        <strong>nathanmarz.com</strong>، 13 اکتبر 2011.
    </p>
<p>
        [51] <strong>Molly Bartlett Dishman</strong> و <strong>Martin Fowler</strong>: "معماری
        <strong>Agile</strong>"، در کنفرانس معماری نرم‌افزار <strong>O'Reilly</strong>، مارس 2015.
    </p>
<p>
        [52] <strong>David J. DeWitt</strong> و <strong>Jim N. Gray</strong>: "سیستم‌های پایگاه داده
        <strong>Parallel</strong>: آینده‌ی سیستم‌های پایگاه داده با عملکرد بالا"، <strong>Communications
        of the ACM</strong>، جلد 35، شماره 6، صفحات 85–98، ژوئن 1992.
        <strong>doi:10.1145/129888.129894</strong>
</p>
<p>
        [53] <strong>Jay Kreps</strong>: "اما موضوع <strong>multi-tenancy</strong> در واقع بسیار سخت
        است"، <strong>tweet-storm</strong>، <strong>twitter.com</strong>، 31 اکتبر 2014.
    </p>
<p>
        [54] <strong>Jeffrey Cohen</strong>، <strong>Brian Dolan</strong>، <strong>Mark Dunlap</strong> و همکاران:
        "<strong>MAD Skills</strong>: روش‌های تجزیه و تحلیل جدید برای <strong>Big Data</strong>"،
        <strong>Proceedings of the VLDB Endowment</strong>، جلد 2، شماره 2، صفحات 1481–
        1492، اوت 2009. <strong>doi:10.14778/1687553.1687576</strong>
</p>
<p>
        [55] <strong>Ignacio Terrizzano</strong>، <strong>Peter Schwarz</strong>، <strong>Mary Roth</strong> و
        <strong>John E. Colino</strong>: "<strong>Data Wrangling</strong>: سفر چالش‌برانگیز از وحشی به
        دریاچه"، در هفتمین کنفرانس دوسالانه در مورد تحقیقات نوآورانه
        سیستم‌های داده (<strong>CIDR</strong>)، ژانویه 2015.
    </p>
<p>
        [56] <strong>Paige Roberts</strong>: "به <strong>Schema on Read</strong> یا به <strong>Schema on Write</strong>،
        این سوال <strong>Hadoop Data Lake</strong> است"،
        <strong>adaptivesystemsinc.com</strong>، 2 ژوئیه 2015.
    </p>
<p>
        [57] <strong>Bobby Johnson</strong> و <strong>Joseph Adler</strong>: "اصل <strong>Sushi</strong>: داده‌های خام
        بهتر است"، در <strong>Strata+Hadoop World</strong>، فوریه 2015.
    </p>
<p>
        [58] <strong>Vinod Kumar Vavilapalli</strong>، <strong>Arun C. Murthy</strong>، <strong>Chris Douglas</strong>
        و همکاران: "<strong>Apache Hadoop YARN</strong>: هنوز یک <strong>Resource Negotiator</strong> دیگر"،
        در چهارمین سمپوزیوم <strong>ACM</strong> در مورد محاسبات ابری (<strong>SoCC</strong>)، اکتبر
        2013. <strong>doi:10.1145/2523616.2523633</strong>
</p>
<p>
        [59] <strong>Abhishek Verma</strong>، <strong>Luis Pedrosa</strong>، <strong>Madhukar Korupolu</strong> و
        همکاران: "مدیریت <strong>Cluster</strong> در مقیاس بزرگ در <strong>Google</strong> با <strong>Borg</strong>"، در
        دهمین کنفرانس اروپایی در مورد سیستم‌های کامپیوتری (<strong>EuroSys</strong>)، آوریل
        2015. <strong>doi:10.1145/2741948.2741964</strong>
</p>
<p>
        [60] <strong>Malte Schwarzkopf</strong>: "تکامل معماری‌های زمان‌بندی <strong>Cluster</strong>"،
        <strong>firmanent.io</strong>، 9 مارس 2016.
    </p>
<p>
        [61] <strong>Matei Zaharia</strong>، <strong>Mosharaf Chowdhury</strong>، <strong>Tathagata Das</strong> و
        همکاران: "<strong>Datasets</strong> توزیع شده‌ی مقاوم: یک انتزاع تحمل خطا برای
        محاسبات <strong>Cluster In-Memory</strong>"، در نهمین سمپوزیوم <strong>USENIX</strong> در
        طراحی و پیاده‌سازی سیستم‌های شبکه‌ای (<strong>NSDI</strong>)، آوریل 2012.
    </p>
<p>
        [62] <strong>Holden Karau</strong>، <strong>Andy Konwinski</strong>، <strong>Patrick Wendell</strong> و
        <strong>Matei Zaharia</strong>: <strong>Learning Spark</strong>. <strong>O’Reilly Media</strong>، 2015.
        <strong>ISBN: 978-1-449-35904-1</strong>
        434
        |
        فصل 10: پردازش <strong>Batch</strong>
</p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0456</div>
            </div>
        </div>
        <!-- Page 0457 -->
        <div class="chapter" id="page-0457">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        [63] <strong>Bikas Saha</strong> و <strong>Hitesh Shah</strong>: "<strong>Apache Tez</strong>: تسریع
        پردازش <strong>Query Hadoop</strong>"، در <strong>Hadoop Summit</strong>، ژوئن 2014.
    </p>
<p>
        [64] <strong>Bikas Saha</strong>، <strong>Hitesh Shah</strong>، <strong>Siddharth Seth</strong> و
        همکاران: "<strong>Apache Tez</strong>: یک فریم‌ورک متحدکننده برای مدل‌سازی و
        ساخت برنامه‌های پردازش داده‌ها"، در کنفرانس بین‌المللی <strong>ACM</strong> در مورد
        مدیریت داده‌ها (<strong>SIGMOD</strong>)، ژوئن 2015.
        <strong>doi:10.1145/2723372.2742790</strong>
</p>
<p>
        [65] <strong>Kostas Tzoumas</strong>: "<strong>Apache Flink</strong>: <strong>API</strong>، <strong>Runtime</strong>، و نقشه
        راه پروژه"، <strong>slidehare.net</strong>، 14 ژانویه 2015.
    </p>
<p>
        [66] <strong>Alexander Alexandrov</strong>، <strong>Rico Bergmann</strong>، <strong>Stephan Ewen</strong> و
        همکاران: "پلتفرم <strong>Stratosphere</strong> برای <strong>Big Data Analytics</strong>"، <strong>The
        VLDB Journal</strong>، جلد 23، شماره 6، صفحات 939–964، مه 2014.
        <strong>doi:10.1007/s00778-014-0357-y</strong>
</p>
<p>
        [67] <strong>Michael Isard</strong>، <strong>Mihai Budiu</strong>، <strong>Yuan Yu</strong> و همکاران: "<strong>Dryad</strong>:
        برنامه‌های موازی داده توزیع شده از <strong>Building Blocks</strong> متوالی"، در
        کنفرانس اروپایی در مورد سیستم‌های کامپیوتری (<strong>EuroSys</strong>)، مارس 2007.
        <strong>doi:10.1145/1272996.1273005</strong>
</p>
<p>
        [68] <strong>Daniel Warneke</strong> و <strong>Odej Kao</strong>: "<strong>Nephele</strong>: پردازش داده‌ی
        موازی کارآمد در <strong>Cloud</strong>"، در دومین کارگاه محاسبات <strong>Many-Task</strong> در
        <strong>Grids</strong> و ابرکامپیوترها (<strong>MTAGS</strong>)، نوامبر 2009.
        <strong>doi:10.1145/1646468.1646476</strong>
</p>
<p>
        [69] <strong>Lawrence Page</strong>، <strong>Sergey Brin</strong>، <strong>Rajeev Motwani</strong> و <strong>Terry
        Winograd</strong>: "رتبه‌بندی <strong>PageRank Citation</strong>: نظم بخشیدن به وب"، گزارش
        فنی <strong>Stanford InfoLab</strong> 422، 1999.
    </p>
<p>
        [70] <strong>Leslie G. Valiant</strong>: "یک مدل <strong>Bridging</strong> برای محاسبات <strong>Parallel</strong>"،
        <strong>Communications of the ACM</strong>، جلد 33، شماره 8، صفحات 103–111، اوت
        1990. <strong>doi:10.1145/79173.79181</strong>
</p>
<p>
        [71] <strong>Stephan Ewen</strong>، <strong>Kostas Tzoumas</strong>، <strong>Moritz Kaufmann</strong> و <strong>Volker
        Markl</strong>: "جریان‌های داده‌ی تکراری سریع"، <strong>Proceedings of the VLDB
        Endowment</strong>، جلد 5، شماره 11، صفحات 1268-1279، ژوئیه 2012.
        <strong>doi:10.14778/2350229.2350245</strong>
</p>
<p>
        [72] <strong>Grzegorz Malewicz</strong>، <strong>Matthew H. Austern</strong>، <strong>Aart J. C. Bik</strong> و
        همکاران: "<strong>Pregel</strong>: یک سیستم برای پردازش گراف در مقیاس بزرگ"، در
        کنفرانس بین‌المللی <strong>ACM</strong> در مورد مدیریت داده‌ها (<strong>SIGMOD</strong>)، ژوئن
        2010. <strong>doi:10.1145/1807167.1807184</strong>
</p>
<p>
        [73] <strong>Frank McSherry</strong>، <strong>Michael Isard</strong> و <strong>Derek G. Murray</strong>:
        "مقیاس‌پذیری! اما با چه قیمتی؟"، در پانزدهمین کارگاه <strong>USENIX</strong> در
        مورد موضوعات داغ در سیستم‌های عامل (<strong>HotOS</strong>)، مه 2015.
    </p>
<p>
        [74] <strong>Ionel Gog</strong>، <strong>Malte Schwarzkopf</strong>، <strong>Natacha Crooks</strong> و
        همکاران: "<strong>Musketeer</strong>: همه برای یک، یک برای همه در سیستم‌های پردازش
        داده‌ها"، در دهمین کنفرانس اروپایی در مورد سیستم‌های کامپیوتری
        (<strong>EuroSys</strong>)، آوریل 2015. <strong>doi:10.1145/2741948.2741968</strong>
</p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0457</div>
            </div>
        </div>
        <!-- Page 0458 -->
        <div class="chapter" id="page-0458">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        [75] <strong>Aapo Kyrola</strong>، <strong>Guy Blelloch</strong> و <strong>Carlos
        Guestrin</strong>: "<strong>GraphChi</strong>: محاسبات گراف در مقیاس بزرگ فقط در یک
        <strong>PC</strong>"، در دهمین سمپوزیوم <strong>USENIX</strong> در طراحی و پیاده‌سازی سیستم
        عامل (<strong>OSDI</strong>)، اکتبر 2012.
    </p>
<p>
        [76] <strong>Andrew Lenharth</strong>، <strong>Donald Nguyen</strong> و <strong>Keshav Pingali</strong>:
        "تجزیه و تحلیل گراف <strong>Parallel</strong>"، <strong>Communications of the ACM</strong>، جلد
        59، شماره 5، صفحات 78–87، مه 2016.
        <strong>doi:10.1145/2901919</strong>
</p>
<p>
        [77] <strong>Fabian Hüske</strong>: "نگاهی به اتاق موتور <strong>Apache Flink</strong>"،
        <strong>flink.apache.org</strong>، 13 مارس 2015.
    </p>
<p>
        [78] <strong>Mostafa Mokhtar</strong>: "مروری فنی <strong>Optimizer</strong> مبتنی بر هزینه
        <strong>Hive</strong> 0.14 (<strong>CBO</strong>)"، <strong>hortonworks.com</strong>، 2 مارس 2015.
    </p>
<p>
        [79] <strong>Michael Armbrust</strong>، <strong>Reynold S Xin</strong>، <strong>Cheng Lian</strong> و
        همکاران: "<strong>Spark SQL</strong>: پردازش داده‌های رابطه‌ای در <strong>Spark</strong>"، در
        کنفرانس بین‌المللی <strong>ACM</strong> در مورد مدیریت داده‌ها (<strong>SIGMOD</strong>)، ژوئن
        2015. <strong>doi:10.1145/2723372.2742797</strong>
</p>
<p>
        [80] <strong>Daniel Blazevski</strong>: "کاشت <strong>Quadtrees</strong> برای <strong>Apache Flink</strong>"،
        <strong>insightdataengineering.com</strong>، 25 مارس 2016.
    </p>
<p>
        [81] <strong>Tom White</strong>: "<strong>Genome Analysis Toolkit</strong>: اکنون با استفاده از
        <strong>Apache Spark</strong> برای پردازش داده‌ها"، <strong>blog.cloudera.com</strong>، 6 آوریل
        2016.
        436
        |
        فصل 10: پردازش <strong>Batch</strong>
</p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0458</div>
            </div>
        </div>
        <!-- Page 0461 -->
        <div class="chapter" id="page-0461">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<h3>فصل 11</h3>
<h4>پردازش <strong>Stream</strong></h4>
<p>
        یک سیستم پیچیده که کار می‌کند، به طور قطع از یک سیستم ساده که
        کار می‌کند، تکامل یافته است. گزاره معکوس نیز درست به نظر می‌رسد: یک
        سیستم پیچیده که از ابتدا طراحی شده است هرگز کار نمی‌کند و نمی‌تواند
        کار کند.
        —<strong>John Gall</strong>، <strong>Systemantics</strong> (1975)
    </p>
<p>
        در فصل 10 ما در مورد پردازش <strong>batch</strong> بحث کردیم—تکنیک‌هایی که یک
        مجموعه فایل را به عنوان ورودی می‌خوانند و یک مجموعه جدید از فایل‌های
        خروجی تولید می‌کنند. خروجی، نوعی داده مشتق شده است؛ یعنی، یک
        مجموعه‌داده که در صورت لزوم می‌توان با اجرای مجدد فرآیند <strong>batch</strong> آن
        را دوباره ایجاد کرد. ما دیدیم که چگونه این ایده ساده اما قدرتمند می‌تواند
        برای ایجاد <strong>indexes</strong> جستجو، سیستم‌های توصیه، تجزیه و تحلیل، و
        بیشتر استفاده شود.
    </p>
<p>
        با این حال، یک فرض بزرگ در سراسر فصل 10 باقی ماند: یعنی، این‌که
        ورودی <em>bounded</em> است—یعنی، دارای اندازه مشخص و متناهی—بنابراین
        فرآیند <strong>batch</strong> می‌داند چه زمانی خواندن ورودی خود را به پایان
        رسانده است. به عنوان مثال، عملیات مرتب‌سازی که برای <strong>MapReduce</strong>
        مرکزی است، باید کل ورودی خود را بخواند قبل از این‌که بتواند شروع به
        تولید خروجی کند: ممکن است رکورد ورودی آخر، رکوردی باشد که کمترین
        <strong>key</strong> را دارد، و بنابراین نیاز به این دارد که اولین رکورد خروجی باشد،
        بنابراین شروع زودهنگام خروجی یک گزینه نیست.
    </p>
<p>
        در واقعیت، مقدار زیادی از داده‌ها <em>unbounded</em> هستند زیرا به تدریج در
        طول زمان می‌رسند: کاربران شما داده‌ها را دیروز و امروز تولید کردند، و
        آن‌ها به تولید داده‌های بیشتر در فردا ادامه خواهند داد. مگر این‌که شما
        کسب‌وکار خود را تعطیل کنید، این فرآیند هرگز پایان نمی‌یابد، و بنابراین
        مجموعه‌داده هرگز به معنای واقعی "کامل" نیست [1]. بنابراین، پردازنده‌های
        <strong>batch</strong> باید به‌طور مصنوعی داده‌ها را به قطعاتی با مدت زمان ثابت
        تقسیم کنند: به عنوان مثال، پردازش داده‌های یک روز در پایان هر روز، یا
        پردازش داده‌های یک ساعت در پایان هر ساعت.
    </p>
<p>
        مشکل فرآیندهای <strong>batch</strong> روزانه این است که تغییرات در ورودی تنها یک
        روز بعد در خروجی منعکس می‌شود، که برای بسیاری از کاربران بی‌حوصله
        بسیار کند است. برای کاهش تأخیر، می‌توانیم پردازش را مکرراً اجرا کنیم—به
        عنوان مثال، پردازش داده‌های یک ثانیه در پایان هر ثانیه—یا حتی
        به‌طور مداوم، صرف نظر از زمان ثابت
        439
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0461</div>
            </div>
        </div>
        <!-- Page 0462 -->
        <div class="chapter" id="page-0462">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        قطعات را کاملاً رها می‌کند و به سادگی هر رویداد را در لحظه پردازش می‌کند. این
        ایده پشت پردازش <strong>stream</strong> است.
    </p>
<p>
        به‌طور کلی، یک "<strong>stream</strong>" به داده‌هایی اشاره دارد که به‌طور
        تدریجی در طول زمان در دسترس قرار می‌گیرند. این مفهوم در بسیاری از مکان‌ها
        ظاهر می‌شود: در <strong>stdin</strong> و <strong>stdout</strong> از <strong>Unix</strong>، زبان‌های
        برنامه‌نویسی (لیست‌های <em>lazy</em>) [2]، <strong>APIs</strong> های سیستم فایل (مانند
        <strong>FileInputStream</strong> از <strong>Java</strong>)، اتصالات <strong>TCP</strong>، تحویل صدا و تصویر
        از طریق اینترنت و غیره.
    </p>
<p>
        در این فصل ما به جریان‌های رویداد به عنوان یک مکانیسم مدیریت داده‌ها
        نگاه خواهیم کرد: معادل <em>unbounded</em> و پردازش افزایشی داده‌های <strong>batch</strong>
        که در فصل قبل دیدیم. ما ابتدا بحث خواهیم کرد که چگونه جریان‌ها نشان داده
        می‌شوند، ذخیره می‌شوند و از طریق یک شبکه منتقل می‌شوند. در "پایگاه
        داده‌ها و جریان‌ها" در صفحه 451، ما رابطه‌ی بین جریان‌ها و پایگاه‌های داده
        را بررسی خواهیم کرد. و در نهایت، در "پردازش جریان‌ها" در صفحه 464، ما
        رویکردها و ابزارهایی را برای پردازش مداوم آن جریان‌ها، و راه‌هایی که
        می‌توانند برای ساخت برنامه‌ها استفاده شوند، بررسی خواهیم کرد.
    </p>
<h4>انتقال جریان‌های رویداد</h4>
<p>
        در دنیای پردازش <strong>batch</strong>، ورودی‌ها و خروجی‌های یک job فایل‌ها هستند
        (شاید در یک سیستم فایل توزیع شده). معادل <strong>streaming</strong> چه شکلی
        است؟
    </p>
<p>
        هنگامی که ورودی یک فایل است (یک دنباله از بایت‌ها)، اولین مرحله
        پردازش معمولاً <strong>parse</strong> کردن آن به یک دنباله از رکوردها است. در یک
        <strong>context</strong> پردازش <strong>stream</strong>، یک رکورد معمولاً به عنوان یک رویداد
        شناخته می‌شود، اما اساساً همان چیز است: یک شیء کوچک، خود محصور،
        <em>immutable</em> که حاوی جزئیات چیزی است که در یک نقطه زمانی خاص
        رخ داده است. یک رویداد معمولاً شامل یک <strong>timestamp</strong> است که نشان
        می‌دهد چه زمانی بر اساس یک ساعت <em>time-of-day</em> (نگاه کنید به
        "ساعت‌های <strong>Monotonic</strong> در مقابل <strong>Time-of-Day</strong>" در صفحه 288) رخ
        داده است.
    </p>
<p>
        به عنوان مثال، چیزی که رخ داده است ممکن است یک عملیات باشد که یک
        کاربر انجام داده است، مانند مشاهده یک صفحه یا خرید. همچنین ممکن
        است از یک دستگاه سرچشمه بگیرد، مانند اندازه‌گیری دوره‌ای از یک
        سنسور دما، یا یک معیار استفاده از <strong>CPU</strong>. در مثال "پردازش <strong>Batch</strong> با
        ابزارهای <strong>Unix</strong>" در صفحه 391، هر خط از <strong>log</strong> سرور وب یک رویداد
        است.
    </p>
<p>
        یک رویداد ممکن است به عنوان یک رشته متنی یا <strong>JSON</strong> یا شاید به
        شکلی باینری رمزگذاری شود، همان‌طور که در فصل 4 مورد بحث قرار گرفت.
        این <strong>encoding</strong> به شما امکان می‌دهد یک رویداد را ذخیره کنید، به عنوان
        مثال با پیوست کردن آن به یک فایل، وارد کردن آن در یک جدول رابطه‌ای، یا
        نوشتن آن در یک پایگاه داده <strong>document</strong>. همچنین به شما امکان می‌دهد
        رویداد را از طریق شبکه به یک <strong>node</strong> دیگر ارسال کنید تا آن را پردازش
        کند.
    </p>
<p>
        در پردازش <strong>batch</strong>، یک فایل یک بار نوشته می‌شود و سپس احتمالاً توسط
        jobs های متعدد خوانده می‌شود. به‌طور مشابه، در اصطلاحات <strong>streaming</strong>،
        یک رویداد یک بار توسط یک <strong>producer</strong> (که به عنوان <strong>publisher</strong> یا
        <strong>sender</strong> نیز شناخته می‌شود) تولید می‌شود، و سپس احتمالاً توسط
        مصرف‌کنندگان متعدد (<strong>subscribers</strong> یا <strong>recipients</strong>) [3] پردازش
        می‌شود. در یک سیستم فایل، یک <strong>filename</strong> یک مجموعه از
        440
        |
        فصل 11: پردازش <strong>Stream</strong>
</p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0462</div>
            </div>
        </div>
        <!-- Page 0463 -->
        <div class="chapter" id="page-0463">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        رکوردها مرتبط هستند؛ در یک سیستم <strong>streaming</strong>، رویدادهای مرتبط
        معمولاً با هم در یک <strong>topic</strong> یا <strong>stream</strong> گروه‌بندی می‌شوند.
    </p>
<p>
        در اصل، یک فایل یا پایگاه داده برای اتصال <strong>producers</strong> و
        <strong>consumers</strong> کافی است: یک <strong>producer</strong> هر رویدادی را که تولید
        می‌کند به انبار داده می‌نویسد، و هر <strong>consumer</strong> به‌طور دوره‌ای
        انبار داده را <strong>polls</strong> می‌کند تا رویدادهایی را که از زمان آخرین
        اجرایش ظاهر شده‌اند، بررسی کند. این اساساً همان کاری است که یک
        فرآیند <strong>batch</strong> هنگام پردازش داده‌های یک روز در پایان هر روز انجام
        می‌دهد.
    </p>
<p>
        با این حال، هنگام حرکت به سمت پردازش مداوم با تأخیرهای کم، <strong>polling</strong>
        اگر انبار داده برای این نوع استفاده طراحی نشده باشد، پرهزینه می‌شود. هرچه
        بیشتر <strong>poll</strong> می‌کنید، درصد درخواست‌هایی که رویدادهای جدید را برمی‌گردانند
        کمتر می‌شود، و در نتیجه سربارها بیشتر می‌شود. در عوض، بهتر است
        <strong>consumers</strong> از زمان ظاهر شدن رویدادهای جدید مطلع شوند.
    </p>
<p>
        پایگاه‌های داده به‌طور سنتی این نوع مکانیسم اعلان را چندان خوب
        پشتیبانی نمی‌کنند: پایگاه‌های داده رابطه‌ای معمولاً دارای <strong>triggers</strong>
        هستند، که می‌توانند به یک تغییر (به عنوان مثال، درج یک ردیف در یک
        جدول) واکنش نشان دهند، اما آن‌ها از نظر کاری که می‌توانند انجام دهند
        بسیار محدود هستند و تا حدودی در طراحی پایگاه داده‌ها به‌عنوان یک
        تفکر ثانویه در نظر گرفته شده‌اند [4، 5]. در عوض، ابزارهای تخصصی
        برای هدف تحویل اعلان‌های رویداد توسعه یافته‌اند.
    </p>
<h4>سیستم‌های پیام‌رسانی</h4>
<p>
        یک رویکرد رایج برای اطلاع‌رسانی به <strong>consumers</strong> در مورد رویدادهای
        جدید، استفاده از یک سیستم پیام‌رسانی است: یک <strong>producer</strong> یک
        پیام حاوی رویداد را ارسال می‌کند، که سپس به <strong>consumers</strong> <em>pushed</em>
        می‌شود. ما قبلاً در "<strong>Message-Passing Dataflow</strong>" در صفحه 136 به این
        سیستم‌ها اشاره کردیم، اما اکنون به جزئیات بیشتری می‌پردازیم.
    </p>
<p>
        یک کانال ارتباطی مستقیم مانند یک <strong>pipe</strong> <strong>Unix</strong> یا اتصال <strong>TCP</strong> بین
        <strong>producer</strong> و <strong>consumer</strong>، یک راه ساده برای پیاده‌سازی یک سیستم
        پیام‌رسانی خواهد بود. با این حال، اکثر سیستم‌های پیام‌رسانی این مدل
        اساسی را گسترش می‌دهند. به‌طور خاص، <strong>pipes</strong> <strong>Unix</strong> و <strong>TCP</strong>
        دقیقاً یک فرستنده را با یک گیرنده متصل می‌کنند، در حالی که یک سیستم
        پیام‌رسانی به چندین <strong>producer nodes</strong> اجازه می‌دهد پیام‌ها را به
        همان <strong>topic</strong> ارسال کنند و به چندین <strong>consumer nodes</strong> اجازه می‌دهد
        پیام‌ها را در یک <strong>topic</strong> دریافت کنند.
    </p>
<p>
        در این مدل انتشار/اشتراک، سیستم‌های مختلف رویکردهای گسترده‌ای را
        در پیش می‌گیرند، و یک پاسخ درست برای همه اهداف وجود ندارد. برای
        تمایز بین سیستم‌ها، پرسیدن دو سوال زیر به‌ویژه مفید است:
    </p>
<ol>
<li>
            چه اتفاقی می‌افتد اگر <strong>producers</strong> پیام‌ها را سریع‌تر از
            <strong>consumers</strong> ارسال کنند؟ به‌طور کلی، سه گزینه وجود دارد: سیستم
            می‌تواند پیام‌ها را <em>drop</em> کند، پیام‌ها را در یک صف <strong>buffer</strong>
            کند، یا <strong>backpressure</strong> اعمال کند (که به آن کنترل جریان نیز
            می‌گویند؛ یعنی، مسدود کردن <strong>producer</strong> از ارسال پیام‌های
            بیشتر). به عنوان مثال، <strong>pipes</strong> <strong>Unix</strong> و <strong>TCP</strong> از
            <strong>backpressure</strong> استفاده می‌کنند: آن‌ها دارای یک <strong>buffer</strong> با اندازه
            ثابت کوچک هستند، و اگر
            انتقال جریان‌های رویداد
            |
            441
        </li>
</ol>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0463</div>
            </div>
        </div>
        <!-- Page 0464 -->
        <div class="chapter" id="page-0464">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        آن را پر می‌کند، فرستنده مسدود می‌شود تا زمانی که گیرنده داده‌ها را از
        <strong>buffer</strong> خارج کند (نگاه کنید به "تراکم شبکه و صف‌بندی" در صفحه
        282).
    </p>
<p>
        اگر پیام‌ها در یک صف <strong>buffered</strong> شوند، درک این‌که چه اتفاقی می‌افتد
        با بزرگ شدن آن صف، مهم است. آیا اگر صف دیگر در حافظه جا نشد، سیستم
        از کار می‌افتد، یا پیام‌ها را روی دیسک می‌نویسد؟ اگر چنین است، دسترسی
        به دیسک چگونه بر عملکرد سیستم پیام‌رسانی تأثیر می‌گذارد [6]؟
    </p>
<ol>
<li>
            چه اتفاقی می‌افتد اگر <strong>nodes</strong> از کار بیفتند یا موقتاً <em>offline</em>
            شوند—آیا هیچ پیامی از دست می‌رود؟ همانند پایگاه‌های داده، <em>durability</em>
            ممکن است به ترکیبی از نوشتن روی دیسک و/یا <strong>replication</strong> نیاز
            داشته باشد (به نوار کناری "<strong>Replication</strong> و <strong>Durability</strong>" در
            صفحه 227)، که هزینه‌ای دارد. اگر می‌توانید گاهی اوقات پیام‌ها را از
            دست بدهید، احتمالاً می‌توانید توان عملیاتی بالاتر و تأخیر کمتری را
            در همان سخت‌افزار دریافت کنید.
        </li>
</ol>
<p>
        پذیرفتن یا عدم پذیرفتن از دست رفتن پیام‌ها، بستگی زیادی به برنامه
        دارد. به عنوان مثال، با خوانش‌های حسگر و معیارها که به‌طور دوره‌ای
        منتقل می‌شوند، شاید یک نقطه داده‌ی از دست رفته گاه به گاه مهم
        نباشد، زیرا به هر حال یک مقدار به‌روز شده در مدت زمان کوتاهی بعد ارسال
        خواهد شد. با این حال، مراقب باشید که اگر تعداد زیادی پیام <em>dropped</em>
        شوند، ممکن است فوراً مشخص نشود که معیارها نادرست هستند [7]. اگر
        در حال شمارش رویدادها هستید، این مهم‌تر است که آن‌ها به‌طور قابل
        اطمینانی تحویل داده شوند، زیرا هر پیام از دست رفته به معنای
        شمارنده‌های نادرست است.
    </p>
<p>
        یک ویژگی خوب سیستم‌های پردازش <strong>batch</strong> که ما در فصل 10 بررسی
        کردیم این است که آن‌ها یک تضمین قابلیت اطمینان قوی ارائه می‌دهند:
        <strong>tasks</strong> شکست‌خورده به‌طور خودکار دوباره امتحان می‌شوند، و خروجی
        جزئی از <strong>tasks</strong> شکست‌خورده به‌طور خودکار دور ریخته می‌شود. این بدان
        معنی است که خروجی یکسان است گویی هیچ شکستی رخ نداده است، که به
        ساده‌سازی مدل برنامه‌نویسی کمک می‌کند. در اواخر این فصل ما بررسی
        خواهیم کرد که چگونه می‌توانیم تضمین‌های مشابهی را در یک <strong>context</strong>
<strong>streaming</strong> ارائه دهیم.
    </p>
<h4>پیام‌رسانی مستقیم از <strong>producers</strong> به <strong>consumers</strong></h4>
<p>
        تعدادی از سیستم‌های پیام‌رسانی از ارتباط شبکه مستقیم بین
        <strong>producers</strong> و <strong>consumers</strong> بدون عبور از طریق <strong>nodes</strong>
        واسطه استفاده می‌کنند:
    </p>
<ul>
<li>
<strong>UDP multicast</strong> به‌طور گسترده در صنعت مالی برای جریان‌هایی مانند
            فیدهای بازار سهام استفاده می‌شود، که در آن تأخیر کم مهم است [8]. اگرچه
            خود <strong>UDP</strong> غیرقابل اعتماد است، پروتکل‌های سطح برنامه می‌توانند
            بسته‌های از دست رفته را بازیابی کنند (<strong>producer</strong> باید بسته‌هایی را
            که ارسال کرده است را به خاطر بسپارد تا بتواند آن‌ها را در صورت
            درخواست دوباره ارسال کند).
        </li>
<li>
            کتابخانه‌های پیام‌رسانی بدون <strong>broker</strong> مانند <strong>ZeroMQ</strong> [9] و
            <strong>nanomsg</strong>، رویکردی مشابه اتخاذ می‌کنند و پیام‌رسانی
            انتشار/اشتراک را از طریق <strong>TCP</strong> یا <strong>IP multicast</strong> پیاده‌سازی
            می‌کنند.
        </li>
<li>
<strong>StatsD</strong> [10] و <strong>Brubeck</strong> [7] از پیام‌رسانی <strong>UDP</strong>
            غیرقابل اعتماد برای جمع‌آوری معیارها از تمام ماشین‌های موجود در
            شبکه و نظارت بر آن‌ها استفاده می‌کنند. (در پروتکل <strong>StatsD</strong>،
            معیارهای <strong>counter</strong> تنها در صورتی صحیح هستند که تمام پیام‌ها
            دریافت شوند؛ استفاده از <strong>UDP</strong>، معیارها را در بهترین حالت تقریبی
            می‌کند [11]. همچنین نگاه کنید به "<strong>TCP</strong> در مقابل <strong>UDP</strong>" در صفحه
            283.)
            442
            |
            فصل 11: پردازش <strong>Stream</strong>
</li>
</ul>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0464</div>
            </div>
        </div>
        <!-- Page 0465 -->
        <div class="chapter" id="page-0465">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<ul>
<li>
            اگر <strong>consumer</strong> یک <strong>service</strong> را در شبکه در معرض نمایش قرار
            دهد، <strong>producers</strong> می‌توانند یک درخواست مستقیم <strong>HTTP</strong> یا
            <strong>RPC</strong> (نگاه کنید به "<strong>Dataflow</strong> از طریق <strong>Services</strong>: <strong>REST</strong> و
            <strong>RPC</strong>" در صفحه 131) برای <em>push</em> کردن پیام‌ها به
            <strong>consumer</strong> ارسال کنند. این ایده پشت <strong>webhooks</strong> [12] است،
            الگویی که در آن یک <strong>URL</strong> <strong>callback</strong> از یک <strong>service</strong> در یک
            <strong>service</strong> دیگر ثبت می‌شود، و هر زمان که یک رویداد رخ دهد،
            درخواستی را به آن <strong>URL</strong> ارسال می‌کند.
        </li>
</ul>
<p>
        اگرچه این سیستم‌های پیام‌رسانی مستقیم در موقعیت‌هایی که برای آن‌ها طراحی
        شده‌اند خوب عمل می‌کنند، اما به‌طور کلی به کد برنامه نیاز دارند تا از
        احتمال از دست رفتن پیام‌ها آگاه باشند. خطاهایی که آن‌ها می‌توانند تحمل
        کنند بسیار محدود است: حتی اگر پروتکل‌ها بسته‌هایی را که در شبکه از
        دست رفته‌اند، شناسایی و دوباره ارسال کنند، به‌طور کلی فرض می‌کنند که
        <strong>producers</strong> و <strong>consumers</strong> به‌طور مداوم <em>online</em> هستند.
    </p>
<p>
        اگر یک <strong>consumer</strong> <em>offline</em> باشد، ممکن است پیام‌هایی را که در
        حالی‌که غیرقابل دسترس است، از دست بدهد. برخی از پروتکل‌ها به
        <strong>producer</strong> اجازه می‌دهند تحویل پیام‌های ناموفق را دوباره امتحان
        کند، اما این رویکرد ممکن است در صورت از کار افتادن <strong>producer</strong>،
        شکست بخورد، و <strong>buffer</strong> پیام‌هایی را که قرار بود دوباره امتحان کند،
        از دست بدهد.
    </p>
<h4><strong>Message brokers</strong></h4>
<p>
        یک جایگزین رایج، ارسال پیام‌ها از طریق یک <strong>message broker</strong> (که
        به آن <strong>message queue</strong> نیز گفته می‌شود) است، که اساساً نوعی
        پایگاه داده است که برای مدیریت جریان‌های پیام بهینه شده است [13]. این
        به‌عنوان یک سرور اجرا می‌شود، با <strong>producers</strong> و <strong>consumers</strong> که
        به آن به‌عنوان <strong>clients</strong> متصل می‌شوند. <strong>Producers</strong> پیام‌ها را
        به <strong>broker</strong> می‌نویسند، و <strong>consumers</strong> آن‌ها را با خواندن از
        <strong>broker</strong> دریافت می‌کنند.
    </p>
<p>
        با متمرکز کردن داده‌ها در <strong>broker</strong>، این سیستم‌ها می‌توانند
        <strong>clients</strong> را که می‌آیند و می‌روند (اتصال، قطع اتصال و خرابی) را
        راحت‌تر تحمل کنند، و مسئله‌ی <em>durability</em> به‌جای آن به <strong>broker</strong>
        منتقل می‌شود. برخی از <strong>message brokers</strong>، پیام‌ها را فقط در حافظه
        نگهداری می‌کنند، در حالی که برخی دیگر (بسته به پیکربندی) آن‌ها را روی
        دیسک می‌نویسند تا در صورت خرابی <strong>broker</strong> از بین نروند. در مواجهه با
        <strong>consumers</strong> کند، آن‌ها به‌طور کلی صف‌بندی <em>unbounded</em> را
        مجاز می‌کنند (بر خلاف <em>dropping</em> پیام‌ها یا <strong>backpressure</strong>)،
        اگرچه این انتخاب ممکن است به پیکربندی نیز بستگی داشته باشد.
    </p>
<p>
        پیامد صف‌بندی نیز این است که <strong>consumers</strong> به‌طور کلی
        <em>asynchronous</em> هستند: هنگامی که یک <strong>producer</strong> یک پیام را ارسال
        می‌کند، معمولاً فقط منتظر می‌ماند تا <strong>broker</strong> تأیید کند که پیام را
        <strong>buffered</strong> کرده است و منتظر پردازش پیام توسط
        <strong>consumers</strong> نمی‌ماند. تحویل به <strong>consumers</strong> در یک نقطه زمانی
        نامشخص در آینده اتفاق می‌افتد—اغلب در عرض کسری از ثانیه، اما گاهی
        اوقات اگر یک <strong>queue backlog</strong> وجود داشته باشد، به‌طور قابل توجهی
        دیرتر.
    </p>
<h4><strong>Message brokers</strong> در مقایسه با پایگاه‌های داده</h4>
<p>
        برخی از <strong>message brokers</strong> حتی می‌توانند در پروتکل‌های <strong>two-phase
        commit</strong> با استفاده از <strong>XA</strong> یا <strong>JTA</strong> شرکت کنند (نگاه کنید به
        "تراکنش‌های توزیع شده در عمل" در صفحه 360). این <strong>feature</strong> باعث می‌شود
        انتقال جریان‌های رویداد
        |
        443
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0465</div>
            </div>
        </div>
        <!-- Page 0466 -->
        <div class="chapter" id="page-0466">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        آن‌ها را در طبیعت کاملاً شبیه پایگاه‌های داده می‌سازد، اگرچه هنوز تفاوت‌های
        عملی مهمی بین <strong>message brokers</strong> و پایگاه‌های داده وجود دارد:
    </p>
<ul>
<li>
            پایگاه‌های داده معمولاً داده‌ها را تا زمانی که صریحاً حذف شوند، نگه
            می‌دارند، در حالی که اکثر <strong>message brokers</strong> به‌طور خودکار یک
            پیام را پس از تحویل موفقیت‌آمیز به <strong>consumers</strong> آن حذف
            می‌کنند. چنین <strong>message brokers</strong> برای ذخیره‌سازی داده‌های بلندمدت
            مناسب نیستند.
        </li>
<li>
            از آن‌جایی که آن‌ها پیام‌ها را به‌سرعت حذف می‌کنند، اکثر <strong>message
            brokers</strong> فرض می‌کنند که مجموعه کاری آن‌ها نسبتاً کوچک است—یعنی،
            صف‌ها کوتاه هستند. اگر <strong>broker</strong> نیاز به <strong>buffer</strong> کردن تعداد
            زیادی پیام داشته باشد زیرا <strong>consumers</strong> کند هستند (شاید اگر دیگر در
            حافظه جا نشدند، پیام‌ها را روی دیسک <em>spill</em> کنند)، پردازش هر
            پیام مجزا بیشتر طول می‌کشد، و توان عملیاتی کلی ممکن است کاهش
            یابد [6].
        </li>
<li>
            پایگاه‌های داده اغلب از <strong>indexes</strong> ثانویه و راه‌های مختلفی برای
            جستجوی داده‌ها پشتیبانی می‌کنند، در حالی که <strong>message brokers</strong>
            اغلب از نوعی <strong>subscribing</strong> به زیرمجموعه‌ای از <strong>topics</strong> که با
            برخی الگوها مطابقت دارند، پشتیبانی می‌کنند. مکانیسم‌ها متفاوت هستند،
            اما هر دو اساساً راه‌هایی هستند که یک <strong>client</strong> می‌تواند بخشی از
            داده‌ها را که می‌خواهد در مورد آن‌ها بداند، انتخاب کند.
        </li>
<li>
            هنگام query کردن یک پایگاه داده، نتیجه معمولاً بر اساس یک <strong>snapshot</strong>
            نقطه‌ای از داده‌ها است؛ اگر یک <strong>client</strong> دیگر متعاقباً چیزی را در
            پایگاه داده بنویسد که نتیجه <strong>query</strong> را تغییر دهد، <strong>client</strong> اول
            نمی‌فهمد که نتیجه قبلی‌اش اکنون منسوخ شده است (مگر این‌که
            <strong>query</strong> را تکرار کند، یا برای تغییرات <strong>polls</strong> کند). در مقابل،
            <strong>message brokers</strong> از <strong>queries</strong> دلخواه پشتیبانی نمی‌کنند، اما
            به <strong>clients</strong> هنگام تغییر داده‌ها (یعنی، زمانی که پیام‌های جدید
            در دسترس قرار می‌گیرند) اطلاع می‌دهند.
        </li>
</ul>
<p>
        این دیدگاه سنتی از <strong>message brokers</strong> است، که در استانداردهایی مانند
        <strong>JMS</strong> [14] و <strong>AMQP</strong> [15] محصور شده است و در نرم‌افزارهایی
        مانند <strong>RabbitMQ</strong>، <strong>ActiveMQ</strong>، <strong>HornetQ</strong>، <strong>Qpid</strong>،
        <strong>TIBCO Enterprise Message Service</strong>، <strong>IBM MQ</strong>، <strong>Azure Service
        Bus</strong> و <strong>Google Cloud Pub/Sub</strong> [16] پیاده‌سازی شده است.
    </p>
<h4>چندین <strong>consumer</strong></h4>
<p>
        هنگامی که چندین <strong>consumer</strong> پیام‌ها را در یک <strong>topic</strong> یکسان
        می‌خوانند، دو الگوی اصلی پیام‌رسانی استفاده می‌شود، که در شکل 11-1 نشان
        داده شده است:
    </p>
<ul>
<li>
<strong>Load balancing</strong>
</li>
<p>
            هر پیام به یکی از <strong>consumers</strong> تحویل داده می‌شود، بنابراین
            <strong>consumers</strong> می‌توانند کار پردازش پیام‌ها را در <strong>topic</strong> به
            اشتراک بگذارند. <strong>broker</strong> ممکن است پیام‌ها را به‌طور دلخواه به
            <strong>consumers</strong> اختصاص دهد. این الگو زمانی مفید است که پردازش
            پیام‌ها پرهزینه باشد، و بنابراین شما می‌خواهید بتوانید <strong>consumers</strong>
            را برای موازی‌سازی پردازش اضافه کنید. (در <strong>AMQP</strong>، شما می‌توانید
            <strong>load balancing</strong> را با داشتن <strong>clients</strong> متعدد که از همان صف
            استفاده می‌کنند، پیاده‌سازی کنید، و در <strong>JMS</strong>، این <strong>subscription</strong>
            مشترک نامیده می‌شود.)
            444
            |
            فصل 11: پردازش <strong>Stream</strong>

</p></ul>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0466</div>
            </div>
        </div>
        <!-- Page 0467 -->
        <div class="chapter" id="page-0467">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<ul>
<li>
<strong>Fan-out</strong>
</li>
<p>
            هر پیام به تمام <strong>consumers</strong> تحویل داده می‌شود. <strong>Fan-out</strong> به
            چندین <strong>consumers</strong> مستقل اجازه می‌دهد که هر کدام به همان
            <strong>broadcast</strong> از پیام‌ها "<strong>tune in</strong>" کنند، بدون این‌که بر یکدیگر
            تأثیر بگذارند—معادل <strong>streaming</strong> داشتن چندین job <strong>batch</strong>
            مختلف که همان فایل ورودی را می‌خوانند. (این <strong>feature</strong> توسط <strong>topic
            subscriptions</strong> در <strong>JMS</strong>، و <strong>exchange bindings</strong> در <strong>AMQP</strong>
            ارائه شده است.)
        </p>
</ul>
<p>
        شکل 11-1. (الف) <strong>Load balancing</strong>: به اشتراک گذاشتن کار مصرف
        یک <strong>topic</strong> در بین <strong>consumers</strong>؛ (ب) <strong>fan-out</strong>: تحویل هر پیام
        به چندین <strong>consumer</strong>.
    </p>
<p>
        دو الگو را می‌توان با هم ترکیب کرد: به عنوان مثال، دو گروه مجزا از
        <strong>consumers</strong> ممکن است هر کدام به یک <strong>topic</strong> مشترک شوند، به‌طوری
        که هر گروه به‌طور جمعی تمام پیام‌ها را دریافت می‌کند، اما در داخل هر
        گروه فقط یکی از <strong>nodes</strong> هر پیام را دریافت می‌کند.
    </p>
<h4>تأییدیه‌ها و <strong>redelivery</strong></h4>
<p>
<strong>Consumers</strong> ممکن است در هر زمانی از کار بیفتند، بنابراین ممکن است
        <strong>broker</strong> یک پیام را به یک <strong>consumer</strong> تحویل دهد اما <strong>consumer</strong>
        هرگز آن را پردازش نکند، یا فقط به‌طور جزئی آن را قبل از از کار افتادن
        پردازش کند. به منظور اطمینان از این‌که پیام از بین نمی‌رود،
        <strong>message brokers</strong> از تأییدیه‌ها استفاده می‌کنند: یک <strong>client</strong> باید
        صریحاً به <strong>broker</strong> بگوید که چه زمانی پردازش یک پیام را تمام کرده
        است تا <strong>broker</strong> بتواند آن را از صف حذف کند.
    </p>
<p>
        اگر اتصال به یک <strong>client</strong> بسته شود یا بدون دریافت یک تأییدیه از
        <strong>broker</strong>، <em>timeout</em> شود، فرض می‌کند که پیام پردازش نشده
        است، و بنابراین پیام را دوباره به <strong>consumer</strong> دیگری تحویل می‌دهد.
        (توجه داشته باشید که ممکن است پیام واقعاً به‌طور کامل پردازش شده
        باشد، اما تأییدیه در شبکه از دست رفته است. رسیدگی به این مورد به یک
        پروتکل <strong>atomic commit</strong> نیاز دارد، همان‌طور که در "تراکنش‌های
        توزیع شده در عمل" در صفحه 360 بحث شد.)
        انتقال جریان‌های رویداد
        |
        445
    </p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 467" src="page_0467/image_1.png"/></div>
</div>
                <div class="page-number">صفحه 0467</div>
            </div>
        </div>
        <!-- Page 0468 -->
        <div class="chapter" id="page-0468">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        هنگامی که با <strong>load balancing</strong> ترکیب می‌شود، این رفتار <strong>redelivery</strong>
        تأثیر جالبی بر ترتیب پیام‌ها دارد. در شکل 11-2، <strong>consumers</strong> به‌طور
        کلی پیام‌ها را به ترتیبی که توسط <strong>producers</strong> ارسال شده‌اند، پردازش
        می‌کنند. با این حال، <strong>consumer</strong> 2 در حین پردازش پیام m3 از کار
        می‌افتد، هم‌زمان با این‌که <strong>consumer</strong> 1 پیام m4 را پردازش
        می‌کند. پیام تأیید نشده m3 متعاقباً به <strong>consumer</strong> 1 <strong>redelivered</strong>
        می‌شود، که نتیجه‌ی آن این است که <strong>consumer</strong> 1 پیام‌ها را به ترتیب
        m4، m3، m5 پردازش می‌کند. بنابراین، m3 و m4 به همان ترتیبی که توسط
        <strong>producer</strong> 1 ارسال شده‌اند، تحویل داده نمی‌شوند.
    </p>
<p>
        شکل 11-2. <strong>Consumer</strong> 2 در حین پردازش m3 از کار می‌افتد، بنابراین
        در زمان بعدی به <strong>consumer</strong> 1 <strong>redelivered</strong> می‌شود.
    </p>
<p>
        حتی اگر <strong>message broker</strong> در غیر این صورت سعی کند ترتیب پیام‌ها را
        حفظ کند (همان‌طور که استانداردهای <strong>JMS</strong> و <strong>AMQP</strong>
        مستلزم آن هستند)، ترکیب <strong>load balancing</strong> با <strong>redelivery</strong>
        ناگزیر منجر به <strong>reordering</strong> پیام‌ها می‌شود. برای جلوگیری از این
        مشکل، شما می‌توانید از یک صف جداگانه برای هر <strong>consumer</strong>
        استفاده کنید (یعنی، از <strong>feature</strong> <strong>load balancing</strong> استفاده نکنید).
        <strong>Message reordering</strong> مشکلی نیست اگر پیام‌ها کاملاً مستقل از
        یکدیگر باشند، اما اگر وابستگی‌های علّی بین پیام‌ها وجود داشته باشد، همان‌طور
        که بعداً در این فصل خواهیم دید، می‌تواند مهم باشد.
    </p>
<h4><strong>Partitioned Logs</strong></h4>
<p>
        ارسال یک بسته از طریق شبکه یا درخواست به یک <strong>service</strong> شبکه،
        معمولاً یک عملیات گذرا است که هیچ اثری دائمی از خود به‌جای
        نمی‌گذارد. اگرچه می‌توان آن را به‌طور دائم ثبت کرد (با استفاده از
        <strong>packet capture</strong> و <strong>logging</strong>)، ما معمولاً این‌طور به آن فکر
        نمی‌کنیم. حتی <strong>message brokers</strong> که به‌طور پایدار پیام‌ها را روی دیسک
        می‌نویسند، پس از تحویل آن‌ها به <strong>consumers</strong>، دوباره آن‌ها را
        به‌سرعت حذف می‌کنند، زیرا آن‌ها حول یک ذهنیت پیام‌رسانی گذرا
        ساخته شده‌اند.
        446
        |
        فصل 11: پردازش <strong>Stream</strong>
</p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 468" src="page_0468/image_1.png"/></div>
</div>
                <div class="page-number">صفحه 0468</div>
            </div>
        </div>
        <!-- Page 0469 -->
        <div class="chapter" id="page-0469">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        پایگاه‌های داده و سیستم‌های فایل، رویکردی مخالف را در پیش می‌گیرند:
        انتظار می‌رود که هر چیزی که در یک پایگاه داده یا فایل نوشته می‌شود،
        حداقل تا زمانی که کسی صریحاً انتخاب کند که دوباره آن را حذف
        کند، به‌طور دائم ثبت شود.
    </p>
<p>
        این تفاوت در ذهنیت تأثیر زیادی بر چگونگی ایجاد داده‌های مشتق
        دارد. یک ویژگی اصلی فرآیندهای <strong>batch</strong>، همان‌طور که در فصل 10
        بحث شد، این است که شما می‌توانید آن‌ها را تکراراً اجرا کنید، با
        مراحل پردازش آزمایش کنید، بدون خطر آسیب رساندن به ورودی (از
        آنجایی‌که ورودی <em>read-only</em> است). این در مورد پیام‌رسانی به سبک
        <strong>AMQP/JMS</strong> صدق نمی‌کند: دریافت یک پیام <em>destructive</em> است
        اگر <strong>acknowledgment</strong> باعث شود که از <strong>broker</strong> حذف شود،
        بنابراین شما نمی‌توانید همان <strong>consumer</strong> را دوباره اجرا کنید و انتظار
        داشته باشید که نتیجه یکسانی بگیرید.
    </p>
<p>
        اگر شما یک <strong>consumer</strong> جدید را به یک سیستم پیام‌رسانی اضافه
        می‌کنید، معمولاً فقط شروع به دریافت پیام‌هایی می‌کند که پس از زمان
        ثبت‌نام ارسال شده‌اند؛ هر پیام قبلی از قبل رفته است و نمی‌تواند
        بازیابی شود. این را با فایل‌ها و پایگاه‌های داده مقایسه کنید، که در
        آن شما می‌توانید یک <strong>client</strong> جدید را در هر زمانی اضافه کنید، و
        می‌تواند داده‌هایی را که به‌طور دلخواه در گذشته نوشته شده‌اند (تا
        زمانی‌که صریحاً توسط برنامه بازنویسی یا حذف نشده‌اند) بخواند.
    </p>
<p>
        چرا ما نمی‌توانیم یک <em>hybrid</em> داشته باشیم، که رویکرد ذخیره‌سازی
        <em>durable</em> پایگاه‌های داده را با امکانات اعلان با تأخیر کم پیام‌رسانی
        ترکیب می‌کند؟ این ایده پشت <strong>log-based message brokers</strong> است.
    </p>
<h4>استفاده از <strong>logs</strong> برای ذخیره‌سازی پیام</h4>
<p>
        یک <strong>log</strong> به سادگی یک دنباله‌ی <em>append-only</em> از رکوردها روی
        دیسک است. ما قبلاً در زمینه موتورهای ذخیره‌سازی ساختاریافته مبتنی بر
        <strong>log</strong> و <strong>write-ahead logs</strong> در فصل 3، و در زمینه <strong>replication</strong>
        در فصل 5 در مورد <strong>logs</strong> بحث کردیم.
    </p>
<p>
        از همان ساختار می‌توان برای پیاده‌سازی یک <strong>message broker</strong>
        استفاده کرد: یک <strong>producer</strong> یک پیام را با پیوست کردن آن به انتهای
        <strong>log</strong> ارسال می‌کند، و یک <strong>consumer</strong> پیام‌ها را با خواندن
        <strong>log</strong> به‌صورت متوالی دریافت می‌کند. اگر یک <strong>consumer</strong> به انتهای
        <strong>log</strong> برسد، منتظر یک اعلان می‌شود که یک پیام جدید اضافه شده
        است. ابزار <strong>Unix</strong> <strong>tail -f</strong>، که یک فایل را برای داده‌هایی که
        اضافه می‌شوند، تماشا می‌کند، اساساً مانند این کار می‌کند.
    </p>
<p>
        به منظور مقیاس‌بندی به توان عملیاتی بالاتر از آن‌چه که یک دیسک واحد
        می‌تواند ارائه دهد، <strong>log</strong> را می‌توان <strong>partitioned</strong> کرد (به مفهوم
        فصل 6). سپس <strong>partitions</strong> مختلف را می‌توان در ماشین‌های مختلف
        میزبانی کرد، که هر <strong>partition</strong> را یک <strong>log</strong> جداگانه می‌سازد که
        می‌تواند به‌طور مستقل از <strong>partitions</strong> دیگر خوانده و نوشته شود. سپس
        یک <strong>topic</strong> را می‌توان به عنوان گروهی از <strong>partitions</strong> تعریف کرد که
        همگی پیام‌هایی از یک نوع یکسان را حمل می‌کنند. این رویکرد در شکل
        11-3 نشان داده شده است.
    </p>
<p>
        در داخل هر <strong>partition</strong>، <strong>broker</strong> یک شماره توالی صعودی
        منظم، یا <strong>offset</strong>، را به هر پیام اختصاص می‌دهد (در شکل 11-3،
        اعداد موجود در کادرها <strong>message offsets</strong> هستند). چنین شماره
        توالی‌ای منطقی است زیرا یک <strong>partition</strong> <em>append-only</em> است، بنابراین
        پیام‌های داخل یک <strong>partition</strong> کاملاً مرتب شده‌اند. هیچ تضمینی برای
        ترتیب در بین <strong>partitions</strong> مختلف وجود ندارد.
        انتقال جریان‌های رویداد
        |
        447
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0469</div>
            </div>
        </div>
        <!-- Page 0470 -->
        <div class="chapter" id="page-0470">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        شکل 11-3. <strong>Producers</strong> پیام‌ها را با پیوست کردن آن‌ها به یک فایل
        <strong>topic-partition</strong> ارسال می‌کنند، و <strong>consumers</strong> این
        فایل‌ها را به‌طور متوالی می‌خوانند.
    </p>
<p>
<strong>Apache Kafka</strong> [17, 18]، <strong>Amazon Kinesis Streams</strong> [19] و
        <strong>DistributedLog</strong> توییتر [20, 21]، <strong>message brokers</strong> مبتنی
        بر <strong>log</strong> هستند که به این صورت کار می‌کنند.
        <strong>Google Cloud Pub/Sub</strong> از نظر معماری مشابه است اما یک <strong>API</strong>
        به سبک <strong>JMS</strong> را به‌جای یک انتزاع <strong>log</strong> در معرض نمایش
        قرار می‌دهد [16].
    </p>
<p>
        حتی اگر این <strong>message brokers</strong> تمام پیام‌ها را روی دیسک می‌نویسند،
        آن‌ها قادر به دستیابی به توان عملیاتی میلیون‌ها پیام در ثانیه با
        تقسیم‌بندی در بین چندین ماشین، و تحمل خطا با <strong>replicating</strong> پیام‌ها
        [22، 23] هستند.
    </p>
<h4><strong>Logs</strong> در مقایسه با پیام‌رسانی سنتی</h4>
<p>
        رویکرد مبتنی بر <strong>log</strong>، پیام‌رسانی <strong>fan-out</strong> را به‌طور پیش‌پاافتاده
        پشتیبانی می‌کند، زیرا چندین <strong>consumers</strong> می‌توانند به‌طور
        مستقل <strong>log</strong> را بدون تأثیر بر یکدیگر بخوانند—خواندن یک پیام،
        آن را از <strong>log</strong> حذف نمی‌کند. برای دستیابی به <strong>load balancing</strong> در
        یک گروه از <strong>consumers</strong>، به‌جای اختصاص پیام‌های جداگانه به
        <strong>consumer clients</strong>، <strong>broker</strong> می‌تواند کل <strong>partitions</strong> را به
        <strong>nodes</strong> در گروه <strong>consumer</strong> اختصاص دهد.
    </p>
<p>
        سپس هر <strong>client</strong> تمام پیام‌ها را در <strong>partitions</strong> که به آن
        اختصاص داده شده است، به‌طور متوالی مصرف می‌کند. به‌طور معمول،
        هنگامی که یک <strong>consumer</strong> یک <strong>log partition</strong> را دریافت کرده است،
        پیام‌ها را در <strong>partition</strong> به‌صورت متوالی، به روشی ساده و تک
        <strong>threaded</strong> می‌خواند. این رویکرد <strong>load balancing</strong> درشت دانه
        دارای برخی از معایب است:
        448
        |
        فصل 11: پردازش <strong>Stream</strong>
</p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 470" src="page_0470/image_1.png"/></div>
</div>
                <div class="page-number">صفحه 0470</div>
            </div>
        </div>
        <!-- Page 0471 -->
        <div class="chapter" id="page-0471">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<ul>
<li>
            ممکن است یک طرح <strong>load balancing</strong> ایجاد شود که در آن دو
            <strong>consumer</strong> کار پردازش یک <strong>partition</strong> را با خواندن
            کل مجموعه پیام‌ها به اشتراک می‌گذارند، اما یکی از آن‌ها فقط پیام‌ها را با
            <strong>offsets</strong> با شماره زوج در نظر می‌گیرد در حالی که دیگری با
            <strong>offsets</strong> با شماره فرد سروکار دارد. به‌طور جایگزین، شما می‌توانید
            پردازش پیام را در یک <strong>thread pool</strong> پخش کنید، اما این رویکرد
            مدیریت <strong>consumer offset</strong> را پیچیده می‌کند. به‌طور کلی، پردازش
            تک <strong>threaded</strong> از یک <strong>partition</strong> ترجیح داده می‌شود، و <strong>parallelism</strong>
            را می‌توان با استفاده از <strong>partitions</strong> بیشتر افزایش داد.
        </li>
<li>
            تعداد <strong>nodes</strong> که کار مصرف یک <strong>topic</strong> را به اشتراک
            می‌گذارند، می‌تواند حداکثر برابر با تعداد <strong>log partitions</strong> در آن
            <strong>topic</strong> باشد، زیرا پیام‌ها در یک <strong>partition</strong> یکسان به همان
            <strong>node</strong> تحویل داده می‌شوند.i
        </li>
<li>
            اگر پردازش یک پیام واحد کند باشد، پردازش پیام‌های بعدی را در آن
            <strong>partition</strong> متوقف می‌کند (نوعی مسدود کردن سرصفحه؛ نگاه کنید
            به "شرح عملکرد" در صفحه 13).
        </li>
</ul>
<p>
        بنابراین، در موقعیت‌هایی که پردازش پیام‌ها ممکن است پرهزینه باشد و شما
        می‌خواهید پردازش را به‌صورت <strong>message-by-message</strong> موازی کنید،
        و در جایی که ترتیب پیام‌ها چندان مهم نیست، سبک <strong>JMS/AMQP</strong> از
        <strong>message broker</strong> ترجیح داده می‌شود. از سوی دیگر، در موقعیت‌هایی با
        توان عملیاتی پیام بالا، که در آن پردازش هر پیام سریع است و ترتیب پیام‌ها
        مهم است، رویکرد مبتنی بر <strong>log</strong> بسیار خوب عمل می‌کند.
    </p>
<h4><strong>Consumer offsets</strong></h4>
<p>
        مصرف یک <strong>partition</strong> به‌طور متوالی، گفتن این‌که کدام پیام‌ها
        پردازش شده‌اند را آسان می‌کند: تمام پیام‌هایی با <strong>offset</strong> کمتر از
        <strong>offset</strong> فعلی یک <strong>consumer</strong> قبلاً پردازش شده‌اند، و تمام
        پیام‌هایی با <strong>offset</strong> بزرگتر هنوز دیده نشده‌اند. بنابراین، <strong>broker</strong>
        نیازی به پیگیری تأییدیه‌ها برای هر پیام واحد ندارد—فقط نیاز دارد
        به‌طور دوره‌ای <strong>consumer offsets</strong> را ثبت کند. سربار دفترداری کاهش
        یافته و فرصت‌ها برای <strong>batching</strong> و <strong>pipelining</strong> در این رویکرد به
        افزایش توان عملیاتی سیستم‌های مبتنی بر <strong>log</strong> کمک می‌کند.
    </p>
<p>
        این <strong>offset</strong> در واقع بسیار شبیه به شماره توالی <strong>log</strong> است که
        معمولاً در <strong>replication</strong> پایگاه داده‌ی <strong>single-leader</strong> یافت
        می‌شود، و ما در "راه‌اندازی <strong>Followers</strong> جدید" در صفحه 155 در
        مورد آن بحث کردیم. در <strong>database replication</strong>، شماره توالی <strong>log</strong>
        به یک <strong>follower</strong> اجازه می‌دهد پس از این‌که قطع شد، دوباره به یک
        <strong>leader</strong> متصل شود، و <strong>replication</strong> را بدون رد شدن از هیچ
        نوشته‌ای، از سر بگیرد. دقیقاً همان اصل در اینجا استفاده می‌شود: <strong>message
        broker</strong> مانند یک پایگاه داده <strong>leader</strong> رفتار می‌کند، و <strong>consumer</strong>
        مانند یک <strong>follower</strong>.
    </p>
<p>
        اگر یک <strong>consumer node</strong> از کار بیفتد، یک <strong>node</strong> دیگر در گروه
        <strong>consumer</strong>، <strong>partitions</strong> <strong>consumer</strong> شکست‌خورده را دریافت
        می‌کند، و شروع به مصرف پیام‌ها در آخرین <strong>offset</strong> ثبت شده می‌کند.
        اگر <strong>consumer</strong> پیام‌های بعدی را پردازش کرده بود اما هنوز <strong>offset</strong>
        آن‌ها را ثبت نکرده بود، آن پیام‌ها در هنگام راه‌اندازی مجدد، بار دوم
        پردازش می‌شوند. ما در این فصل در مورد راه‌های مقابله با این مشکل
        بحث خواهیم کرد.
        انتقال جریان‌های رویداد
        |
        449
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0471</div>
            </div>
        </div>
        <!-- Page 0472 -->
        <div class="chapter" id="page-0472">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<h4>استفاده از فضای دیسک</h4>
<p>
        اگر شما فقط به <strong>log</strong> اضافه می‌کنید، در نهایت فضای دیسک شما تمام
        می‌شود. برای بازیابی فضای دیسک، <strong>log</strong> در واقع به <strong>segments</strong>
        تقسیم می‌شود، و هر از چند گاهی <strong>segments</strong> های قدیمی حذف یا به
        فضای بایگانی منتقل می‌شوند. (ما بعداً در مورد یک روش پیچیده‌تر برای
        آزاد کردن فضای دیسک بحث خواهیم کرد.)
    </p>
<p>
        این بدان معنی است که اگر یک <strong>consumer</strong> کند نتواند با سرعت پیام‌ها
        همگام باشد، و آن‌قدر عقب بماند که <strong>consumer offset</strong> آن به یک
        <strong>segment</strong> حذف شده اشاره کند، برخی از پیام‌ها را از دست
        خواهد داد. در واقع، <strong>log</strong> یک <strong>buffer</strong> با اندازه‌ی محدود را
        پیاده‌سازی می‌کند که پیام‌های قدیمی را زمانی که پر می‌شود، دور می‌ریزد،
        که به آن <strong>circular buffer</strong> یا <strong>ring buffer</strong> نیز می‌گویند.
        با این حال، از آن‌جایی که آن <strong>buffer</strong> روی دیسک است، می‌تواند
        کاملاً بزرگ باشد.
    </p>
<p>
        بیایید یک محاسبه سرانگشتی انجام دهیم. در زمان نوشتن، یک هارد
        دیسک بزرگ معمولی دارای ظرفیت 6 <strong>TB</strong> و توان عملیاتی نوشتن
        ترتیبی 150 <strong>MB/s</strong> است. اگر شما با سریع‌ترین سرعت ممکن پیام
        می‌نویسید، حدود 11 ساعت طول می‌کشد تا درایو پر شود. بنابراین،
        دیسک می‌تواند پیام‌های 11 ساعته را <strong>buffer</strong> کند، که پس از آن
        شروع به بازنویسی پیام‌های قدیمی می‌کند. این نسبت یکسان باقی
        می‌ماند، حتی اگر شما از هارد دیسک‌ها و ماشین‌های زیادی استفاده کنید.
        در عمل، استقرارها به‌ندرت از پهنای باند نوشتن کامل دیسک استفاده
        می‌کنند، بنابراین <strong>log</strong> معمولاً می‌تواند یک <strong>buffer</strong> از پیام‌های
        چند روزه یا حتی چند هفته‌ای را نگه دارد.
    </p>
<p>
        صرف نظر از این‌که چه مدت پیام‌ها را حفظ می‌کنید، توان عملیاتی یک <strong>log</strong>
        بیش و کم ثابت باقی می‌ماند، زیرا به هر حال هر پیام روی دیسک
        نوشته می‌شود [18]. این رفتار در تضاد با سیستم‌های پیام‌رسانی است که
        به‌طور پیش‌فرض پیام‌ها را در حافظه نگه می‌دارند و فقط در صورت
        بزرگ‌تر شدن صف، آن‌ها را روی دیسک می‌نویسند: چنین سیستم‌هایی
        هنگامی که صف‌ها کوتاه هستند سریع هستند و هنگامی که شروع به نوشتن
        روی دیسک می‌کنند بسیار کندتر می‌شوند، بنابراین توان عملیاتی به
        مقدار تاریخچه‌ی حفظ شده بستگی دارد.
    </p>
<h4>هنگامی که <strong>consumers</strong> نمی‌توانند با <strong>producers</strong> همگام شوند</h4>
<p>
        در ابتدای "سیستم‌های پیام‌رسانی" در صفحه 441، ما در مورد سه انتخاب
        بحث کردیم که اگر یک <strong>consumer</strong> نتواند با سرعتی که <strong>producers</strong>
        پیام‌ها را ارسال می‌کنند، همگام شود، چه کاری باید انجام داد: <em>dropping</em>
        پیام‌ها، <strong>buffering</strong> یا اعمال <strong>backpressure</strong>. در این
        <em>taxonomy</em>، رویکرد مبتنی بر <strong>log</strong> نوعی <strong>buffering</strong> با یک
        <strong>buffer</strong> بزرگ اما با اندازه ثابت (محدود شده توسط فضای دیسک
        موجود) است.
    </p>
<p>
        اگر یک <strong>consumer</strong> آن‌قدر عقب بیفتد که پیام‌هایی که نیاز دارد
        قدیمی‌تر از آن چیزی باشند که روی دیسک حفظ شده است، نمی‌تواند آن
        پیام‌ها را بخواند—بنابراین <strong>broker</strong> به‌طور موثر پیام‌های
        قدیمی را که به عقب‌تر از اندازه‌ای که <strong>buffer</strong> می‌تواند
        جای دهد، <em>drops</em> می‌کند.
    </p>
<p>
        شما می‌توانید نظارت کنید که یک <strong>consumer</strong> چقدر از سر <strong>log</strong> عقب
        است، و اگر به‌طور قابل توجهی عقب افتاد، یک هشدار را ایجاد کنید. از
        آنجایی‌که <strong>buffer</strong> بزرگ است، زمان کافی برای یک <strong>human
        operator</strong> وجود دارد تا <strong>consumer</strong> کند را برطرف کند و به آن
        اجازه دهد قبل از این‌که شروع به از دست دادن پیام‌ها کند، به سرعت
        برسد.
        450
        |
        فصل 11: پردازش <strong>Stream</strong>
</p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0472</div>
            </div>
        </div>
        <!-- Page 0473 -->
        <div class="chapter" id="page-0473">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        حتی اگر یک <strong>consumer</strong> بیش از حد عقب بیفتد و شروع به از دست دادن
        پیام‌ها کند، فقط آن <strong>consumer</strong> تحت تأثیر قرار می‌گیرد؛ این
        سرویس را برای <strong>consumers</strong> های دیگر مختل نمی‌کند. این واقعیت یک
        مزیت عملیاتی بزرگ است: شما می‌توانید به‌طور آزمایشی یک <strong>log</strong>
        تولیدی را برای اهداف توسعه، آزمایش یا <strong>debugging</strong> مصرف کنید، بدون
        این‌که نگران اختلال در سرویس‌های تولید باشید. هنگامی که یک <strong>consumer</strong>
        خاموش می‌شود یا از کار می‌افتد، مصرف منابع را متوقف می‌کند—تنها
        چیزی که باقی می‌ماند <strong>consumer offset</strong> آن است.
    </p>
<p>
        این رفتار همچنین با <strong>message brokers</strong> سنتی در تضاد است، که در آن
        شما باید مراقب باشید تا هر صفی را که <strong>consumers</strong> آن خاموش
        شده‌اند، حذف کنید—در غیر این صورت آن‌ها به‌طور غیرضروری به انباشت
        پیام‌ها ادامه می‌دهند و حافظه را از <strong>consumers</strong> که هنوز فعال
        هستند، می‌گیرند.
    </p>
<h4>پخش مجدد پیام‌های قدیمی</h4>
<p>
        ما قبلاً اشاره کردیم که با <strong>message brokers</strong> به سبک <strong>AMQP</strong> و
        <strong>JMS</strong>، پردازش و تأیید پیام‌ها یک عملیات <em>destructive</em> است، زیرا
        باعث می‌شود پیام‌ها روی <strong>broker</strong> حذف شوند. از سوی دیگر، در یک
        <strong>message broker</strong> مبتنی بر <strong>log</strong>، مصرف پیام‌ها بیشتر شبیه
        خواندن از یک فایل است: این یک عملیات <em>read-only</em> است که <strong>log</strong>
        را تغییر نمی‌دهد.
    </p>
<p>
        تنها اثر جانبی پردازش، علاوه بر هر خروجی از <strong>consumer</strong>، این است
        که <strong>consumer offset</strong> به جلو می‌رود. اما <strong>offset</strong> تحت
        کنترل <strong>consumer</strong> است، بنابراین در صورت لزوم می‌تواند به راحتی
        دستکاری شود: به عنوان مثال، شما می‌توانید یک کپی از یک <strong>consumer</strong>
        را با <strong>offsets</strong> دیروز شروع کنید و خروجی را در یک مکان
        متفاوت بنویسید، تا ارزش پیام‌های روز گذشته را دوباره پردازش کنید. شما
        می‌توانید این کار را هر تعداد دفعاتی که می‌خواهید تکرار کنید، با تغییر
        کد پردازش.
    </p>
<p>
        این جنبه، پیام‌رسانی مبتنی بر <strong>log</strong> را بیشتر شبیه فرآیندهای <strong>batch</strong>
        فصل قبل می‌سازد، که در آن داده‌های مشتق شده به‌وضوح از داده‌های ورودی
        از طریق یک فرآیند تبدیل تکرارپذیر جدا می‌شوند. این امکان آزمایش بیشتر
        و بازیابی آسان‌تر از خطاها و <strong>bugs</strong> را فراهم می‌کند، که آن را به
        یک ابزار خوب برای ادغام <strong>dataflows</strong> در یک سازمان تبدیل می‌کند
        [24].
    </p>
<h4>پایگاه‌های داده و جریان‌ها</h4>
<p>
        ما برخی مقایسه‌ها را بین <strong>message brokers</strong> و پایگاه‌های داده انجام
        داده‌ایم. اگرچه آن‌ها به‌طور سنتی به‌عنوان دسته‌های جداگانه از ابزارها
        در نظر گرفته شده‌اند، ما دیدیم که <strong>message brokers</strong> مبتنی بر <strong>log</strong>
        در گرفتن ایده‌هایی از پایگاه‌های داده و اعمال آن‌ها در پیام‌رسانی
        موفق بوده‌اند. ما همچنین می‌توانیم برعکس عمل کنیم: ایده‌هایی را از
        پیام‌رسانی و جریان‌ها بگیریم و آن‌ها را در پایگاه‌های داده اعمال کنیم.
    </p>
<p>
        ما قبلاً گفتیم که یک رویداد، رکوردی از چیزی است که در یک نقطه زمانی
        خاص رخ داده است. چیزی که رخ داده ممکن است یک عمل کاربر باشد (به
        عنوان مثال، تایپ یک <strong>query</strong> جستجو)، یا یک خواندن سنسور،
        اما ممکن است یک نوشته در پایگاه داده نیز باشد. این واقعیت که چیزی
        در یک پایگاه داده نوشته شده است، یک رویداد است که می‌تواند ضبط،
        ذخیره و
        پایگاه‌های داده و جریان‌ها
        |
        451
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0473</div>
            </div>
        </div>
        <!-- Page 0474 -->
        <div class="chapter" id="page-0474">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        این مشاهده نشان می‌دهد که ارتباط بین پایگاه‌های داده و جریان‌ها
        بیشتر از فقط ذخیره‌سازی فیزیکی <strong>logs</strong> روی دیسک است—کاملاً اساسی
        است.
    </p>
<p>
        در واقع، یک <strong>replication log</strong> (نگاه کنید به "پیاده‌سازی <strong>Replication
        Logs</strong>" در صفحه 158) یک جریان از رویدادهای نوشتن پایگاه داده است، که
        توسط <strong>leader</strong> در حین پردازش تراکنش‌ها تولید می‌شود. <strong>Followers</strong>
        آن جریان از نوشتن‌ها را در کپی خود از پایگاه داده اعمال می‌کنند و در
        نتیجه به یک کپی دقیق از داده‌های یکسان می‌رسند. رویدادها در <strong>replication
        log</strong>، تغییرات داده‌ای را که رخ داده‌اند، شرح می‌دهند.
    </p>
<p>
        ما همچنین در "<strong>Total Order Broadcast</strong>" در صفحه 348 با اصل <strong>state
        machine replication</strong> روبرو شدیم، که بیان می‌کند: اگر هر رویداد نشان‌دهنده‌ی
        نوشتن در پایگاه داده باشد، و هر <strong>replica</strong> رویدادهای یکسان را به
        ترتیب یکسان پردازش کند، سپس <strong>replicas</strong> همگی در همان حالت نهایی
        به پایان می‌رسند. (فرض بر این است که پردازش یک رویداد یک عملیات
        <em>deterministic</em> است.) این فقط یک مورد دیگر از جریان‌های رویداد است!
    </p>
<p>
        در این بخش ما ابتدا به یک مشکلی که در سیستم‌های داده ناهمگن
        ایجاد می‌شود، نگاه می‌کنیم، و سپس بررسی می‌کنیم که چگونه می‌توانیم
        آن را با آوردن ایده‌هایی از جریان‌های رویداد به پایگاه‌های داده حل
        کنیم.
    </p>
<h4>همگام نگه داشتن سیستم‌ها</h4>
<p>
        همان‌طور که در سراسر این کتاب دیده‌ایم، هیچ سیستم واحدی وجود ندارد
        که بتواند تمام نیازهای ذخیره‌سازی داده‌ها، query کردن و پردازش را
        برآورده کند. در عمل، اکثر برنامه‌های غیر <em>trivial</em> باید چندین فناوری
        مختلف را با هم ترکیب کنند تا نیازهایشان را برآورده کنند: به عنوان
        مثال، استفاده از یک پایگاه داده <strong>OLTP</strong> برای سرویس‌دهی به
        درخواست‌های کاربر، یک <strong>cache</strong> برای سرعت بخشیدن به درخواست‌های
        رایج، یک <strong>full-text index</strong> برای رسیدگی به <strong>search queries</strong> و یک
        انبار داده برای <strong>analytics</strong>. هر یک از این‌ها دارای کپی خودشان از
        داده‌ها هستند، که در نمایش خودشان ذخیره می‌شوند که برای اهداف
        خودشان بهینه شده است.
    </p>
<p>
        از آن‌جایی که داده‌های یکسان یا مرتبط در چندین مکان مختلف ظاهر
        می‌شوند، باید با یکدیگر همگام نگه داشته شوند: اگر یک مورد در
        پایگاه داده به‌روزرسانی شود، باید در <strong>cache</strong>، <strong>search indexes</strong>
        و انبار داده نیز به‌روزرسانی شود. با انبارهای داده، این
        همگام‌سازی معمولاً توسط فرآیندهای <strong>ETL</strong> انجام می‌شود (نگاه کنید به
        "<strong>Data Warehousing</strong>" در صفحه 91)، که اغلب با گرفتن یک کپی کامل از
        پایگاه داده، تبدیل آن و بارگذاری انبوه آن در انبار داده انجام
        می‌شود—به عبارت دیگر، یک فرآیند <strong>batch</strong>. به‌طور مشابه، ما در "خروجی
        جریان‌های کاری <strong>Batch</strong>" در صفحه 411 دیدیم که چگونه <strong>indexes</strong>
        جستجو، سیستم‌های توصیه و سایر سیستم‌های داده مشتق شده ممکن است
        با استفاده از فرآیندهای <strong>batch</strong> ایجاد شوند.
    </p>
<p>
        اگر <strong>dumps</strong> کامل پایگاه داده دوره‌ای خیلی کند هستند، یک جایگزین که
        گاهی اوقات استفاده می‌شود، نوشتن دوگانه است، که در آن کد
        برنامه به‌طور صریح در هر یک از سیستم‌ها هنگام تغییر داده‌ها
        می‌نویسد: به عنوان مثال، ابتدا نوشتن در پایگاه داده، سپس به‌روزرسانی
        index جستجو، سپس باطل کردن ورودی‌های <strong>cache</strong> (یا حتی انجام
        آن نوشته‌ها به‌طور هم‌زمان).
    </p>
<p>
        با این حال، نوشتن دوگانه دارای مشکلات جدی است، که یکی از آن‌ها یک
        <strong>race condition</strong> است که در شکل 11-4 نشان داده شده است. در این
        مثال، دو <strong>clients</strong> به‌طور هم‌زمان می‌خواهند یک
        انتقال جریان‌های رویداد
        |
        452
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0474</div>
            </div>
        </div>
        <!-- Page 0475 -->
        <div class="chapter" id="page-0475">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        مورد X: <strong>client</strong> 1 می‌خواهد مقدار را روی A تنظیم کند، و <strong>client</strong> 2
        می‌خواهد آن را روی B تنظیم کند. هر دو <strong>clients</strong> ابتدا مقدار جدید را
        در پایگاه داده می‌نویسند، سپس آن را در index جستجو می‌نویسند. با توجه به
        زمان‌بندی نامناسب، درخواست‌ها با هم تداخل دارند: پایگاه داده ابتدا نوشته
        شده از <strong>client</strong> 1 را می‌بیند که مقدار را روی A تنظیم می‌کند، سپس
        نوشته شده از <strong>client</strong> 2 را می‌بیند که مقدار را روی B تنظیم می‌کند،
        بنابراین مقدار نهایی در پایگاه داده B است. index جستجو ابتدا نوشته شده
        از <strong>client</strong> 2 را می‌بیند، سپس <strong>client</strong> 1، بنابراین مقدار نهایی در
        index جستجو A است. دو سیستم اکنون به‌طور دائم با یکدیگر ناسازگار
        هستند، حتی اگر هیچ خطایی رخ نداده باشد.
    </p>
<p>
        شکل 11-4. در پایگاه داده، X ابتدا روی A و سپس روی B تنظیم می‌شود، در حالی
        که در index جستجو، نوشتن‌ها به ترتیب معکوس می‌رسند.
    </p>
<p>
        مگر این‌که شما یک مکانیسم تشخیص <strong>concurrency</strong> اضافی داشته
        باشید، مانند <strong>version vectors</strong> که ما در "تشخیص نوشتن‌های
        همزمان" در صفحه 184 بحث کردیم، شما حتی متوجه نخواهید شد که
        نوشتن‌های همزمان رخ داده است—یک مقدار به‌سادگی و بی‌صدا مقدار
        دیگری را بازنویسی می‌کند.
    </p>
<p>
        یکی دیگر از مشکلات <strong>dual writes</strong> این است که یکی از نوشته‌ها ممکن
        است شکست بخورد در حالی که دیگری موفق شود. این یک مشکل تحمل
        خطا است تا یک مشکل <strong>concurrency</strong>، اما همچنین این اثر را دارد که
        دو سیستم با یکدیگر ناسازگار می‌شوند. اطمینان از این‌که آن‌ها یا هر دو
        موفق شوند یا هر دو شکست بخورند، یک مورد از مشکل <strong>atomic commit</strong>
        است، که حل کردن آن پرهزینه است (نگاه کنید به "<strong>Atomic Commit</strong>
        و <strong>Two-Phase Commit (2PC)</strong>" در صفحه 354).
    </p>
<p>
        اگر شما فقط یک پایگاه داده‌ی <em>replicated</em> با یک <strong>leader</strong> واحد دارید،
        سپس آن <strong>leader</strong> ترتیب نوشتن‌ها را تعیین می‌کند، بنابراین رویکرد
        <strong>state machine replication</strong> در بین <strong>replicas</strong> های پایگاه داده
        عمل می‌کند. با این حال، در شکل 11-4 یک <strong>leader</strong> واحد وجود
        ندارد: پایگاه داده ممکن است یک <strong>leader</strong> داشته باشد و index جستجو
        ممکن است یک <strong>leader</strong> داشته باشد، اما هیچ‌کدام دیگری را دنبال
        نمی‌کنند، و بنابراین درگیری‌ها می‌توانند رخ دهند (نگاه کنید به
        "<strong>Multi-Leader Replication</strong>" در صفحه 168).
    </p>
<p>
        اگر واقعاً فقط یک <strong>leader</strong> وجود داشت—به عنوان مثال، پایگاه
        داده—و اگر ما می‌توانستیم index جستجو را یک <strong>follower</strong> از
        پایگاه داده بسازیم، وضعیت بهتر می‌بود. اما آیا این در عمل امکان‌پذیر
        است؟
        پایگاه‌های داده و جریان‌ها
        |
        453
    </p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 475" src="page_0475/image_1.png"/></div>
</div>
                <div class="page-number">صفحه 0475</div>
            </div>
        </div>
        <!-- Page 0476 -->
        <div class="chapter" id="page-0476">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<h4><strong>Change Data Capture</strong></h4>
<p>
        مشکل اصلی با <strong>replication logs</strong> اکثر پایگاه‌های داده این است که آن‌ها
        مدت‌هاست که جزء جزئیات پیاده‌سازی داخلی پایگاه داده در نظر گرفته
        می‌شوند، نه یک <strong>API</strong> عمومی. قرار است <strong>Clients</strong> پایگاه داده را
        از طریق مدل داده و زبان <strong>query</strong> آن query کنند، نه این‌که <strong>replication
        logs</strong> را <strong>parse</strong> کنند و سعی کنند داده‌ها را از آن‌ها استخراج
        کنند.
    </p>
<p>
        برای دهه‌ها، بسیاری از پایگاه‌های داده، به‌سادگی یک راه مستند برای
        دریافت <strong>log</strong> تغییرات نوشته شده در آن‌ها نداشتند. به همین دلیل
        گرفتن تمام تغییرات ایجاد شده در یک پایگاه داده و <strong>replicate</strong> کردن
        آن‌ها به یک فناوری ذخیره‌سازی متفاوت مانند یک index جستجو، <strong>cache</strong>
        یا انبار داده دشوار بود.
    </p>
<p>
        اخیراً، علاقه فزاینده‌ای به <strong>change data capture (CDC)</strong> وجود داشته
        است، که فرآیند مشاهده‌ی تمام تغییرات داده‌ها که در یک پایگاه داده
        نوشته شده‌اند و استخراج آن‌ها به شکلی است که می‌توان آن‌ها را به
        سیستم‌های دیگر <strong>replicated</strong> کرد. <strong>CDC</strong> به‌ویژه در صورتی
        جالب است که تغییرات به‌صورت یک <strong>stream</strong> در دسترس قرار
        گیرند، بلافاصله پس از این‌که نوشته شدند.
    </p>
<p>
        به عنوان مثال، شما می‌توانید تغییرات در یک پایگاه داده را ضبط کنید و
        همان تغییرات را به‌طور مداوم در یک index جستجو اعمال کنید. اگر <strong>log</strong>
        تغییرات به همان ترتیب اعمال شود، شما می‌توانید انتظار داشته باشید
        که داده‌ها در index جستجو با داده‌ها در پایگاه داده مطابقت داشته
        باشند. index جستجو و هر سیستم داده‌ی مشتق شده‌ی دیگری فقط
        <strong>consumers</strong> از <strong>change stream</strong> هستند، همان‌طور که در شکل
        11-5 نشان داده شده است.
    </p>
<p>
        شکل 11-5. گرفتن داده‌ها به ترتیبی که در یک پایگاه داده نوشته شده است، و
        اعمال تغییرات در سیستم‌های دیگر به همان ترتیب.
    </p>
<h4>پیاده‌سازی <strong>change data capture</strong></h4>
<p>
        ما می‌توانیم <strong>log consumers</strong> را سیستم‌های داده‌ی مشتق شده بنامیم، همان‌طور
        که در مقدمه قسمت سوم بحث شد: داده‌های ذخیره شده در index جستجو و
        انبار داده فقط یک دیدگاه دیگر در مورد داده‌ها در سیستم
        <strong>record</strong> هستند. <strong>Change data capture</strong> یک مکانیسم برای
        اطمینان از این است که تمام تغییرات ایجاد شده در سیستم <strong>record</strong> نیز در
        سیستم‌های داده‌ی مشتق شده منعکس می‌شوند، به‌طوری که سیستم‌های
        مشتق شده یک کپی دقیق از داده‌ها را داشته باشند.
        454
        |
        فصل 11: پردازش <strong>Stream</strong>
</p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 476" src="page_0476/image_1.png"/></div>
</div>
                <div class="page-number">صفحه 0476</div>
            </div>
        </div>
        <!-- Page 0477 -->
        <div class="chapter" id="page-0477">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        اساساً، <strong>change data capture</strong> یک پایگاه داده را <strong>leader</strong> (همانی
        که تغییرات از آن ضبط می‌شوند) می‌سازد، و بقیه را به <strong>followers</strong> تبدیل
        می‌کند. یک <strong>message broker</strong> مبتنی بر <strong>log</strong> برای انتقال
        رویدادهای تغییر از پایگاه داده منبع، مناسب است، زیرا ترتیب پیام‌ها را
        حفظ می‌کند (اجتناب از مسئله <strong>reordering</strong> در شکل 11-2).
    </p>
<p>
        از <strong>database triggers</strong> می‌توان برای پیاده‌سازی <strong>change data
        capture</strong> (نگاه کنید به "<strong>Trigger-based replication</strong>" در صفحه
        161) با ثبت <strong>triggers</strong> که تمام تغییرات در جداول داده را مشاهده
        می‌کنند و ورودی‌های مربوطه را به یک جدول <strong>changelog</strong> اضافه
        می‌کنند، استفاده کرد. با این حال، آن‌ها تمایل دارند که شکننده
        باشند و <strong>overheads</strong> عملکرد قابل توجهی داشته باشند. <strong>Parsing</strong>
<strong>replication log</strong> می‌تواند یک رویکرد قوی‌تر باشد، اگرچه با
        چالش‌هایی مانند رسیدگی به تغییرات <strong>schema</strong> نیز همراه است.
    </p>
<p>
<strong>Databus</strong> از <strong>LinkedIn</strong> [25]، <strong>Wormhole</strong> از <strong>Facebook</strong>
        [26] و <strong>Sherpa</strong> از <strong>Yahoo!</strong> [27] از این ایده در مقیاس بزرگ
        استفاده می‌کنند. <strong>Bottled Water</strong>، <strong>CDC</strong> را برای <strong>PostgreSQL</strong> با
        استفاده از یک <strong>API</strong> که <strong>write-ahead log</strong> را رمزگشایی می‌کند،
        پیاده‌سازی می‌کند [28]، <strong>Maxwell</strong> و <strong>Debezium</strong> برای <strong>MySQL</strong>
        با <strong>parsing</strong> کردن <strong>binlog</strong> کاری مشابه انجام می‌دهند [29, 30,
        31]، <strong>Mongoriver</strong>، <strong>oplog</strong> <strong>MongoDB</strong> را می‌خواند [32، 33]، و
        <strong>GoldenGate</strong> امکانات مشابهی را برای <strong>Oracle</strong> ارائه می‌دهد [34، 35].
    </p>
<p>
        مانند <strong>message brokers</strong>، <strong>change data capture</strong> معمولاً
        <em>asynchronous</em> است: پایگاه داده‌ی سیستم <strong>record</strong> منتظر
        اعمال تغییر در <strong>consumers</strong> نمی‌ماند قبل از این‌که آن را
        <strong>commit</strong> کند. این طراحی این مزیت عملیاتی را دارد که افزودن یک
        <strong>consumer</strong> کند، تأثیر زیادی بر سیستم <strong>record</strong> نمی‌گذارد، اما
        این ضرر را دارد که تمام مسائل مربوط به <strong>replication lag</strong> اعمال
        می‌شود (نگاه کنید به "مشکلات <strong>Replication Lag</strong>" در صفحه 161).
    </p>
<h4><strong>Initial snapshot</strong></h4>
<p>
        اگر شما <strong>log</strong> تمام تغییراتی را که تا به حال در یک پایگاه داده ایجاد
        شده است، داشته باشید، می‌توانید کل وضعیت پایگاه داده را با
        پخش مجدد <strong>log</strong> بازسازی کنید. با این حال، در بسیاری از موارد،
        نگه‌داشتن تمام تغییرات برای همیشه به فضای دیسک زیادی نیاز دارد، و
        پخش مجدد آن زمان زیادی می‌برد، بنابراین <strong>log</strong> باید <em>truncated</em>
        شود.
    </p>
<p>
        ساختن یک index متن کامل جدید، به عنوان مثال، نیاز به یک کپی کامل از
        کل پایگاه داده دارد—تنها اعمال <strong>log</strong> از تغییرات اخیر کافی نیست،
        زیرا موارد یا آیتم‌هایی که اخیراً به‌روزرسانی نشده‌اند، از دست می‌روند.
        بنابراین، اگر شما کل تاریخچه <strong>log</strong> را ندارید، شما نیاز دارید با یک
        <strong>snapshot</strong> <em>consistent</em> شروع کنید، همان‌طور که قبلاً در "راه‌اندازی
        <strong>Followers</strong> جدید" در صفحه 155 بحث شد.
    </p>
<p>
<strong>snapshot</strong> از پایگاه داده باید با یک موقعیت یا <strong>offset</strong> شناخته شده
        در <strong>change log</strong> مطابقت داشته باشد، بنابراین شما می‌دانید که از
        چه نقطه‌ای باید اعمال تغییرات را پس از پردازش <strong>snapshot</strong> شروع
        کنید. برخی از ابزارهای <strong>CDC</strong> این <strong>facility snapshot</strong> را ادغام
        می‌کنند، در حالی که برخی دیگر آن را به‌عنوان یک عملیات دستی
        رها می‌کنند.
        پایگاه‌های داده و جریان‌ها
        |
        455
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0477</div>
            </div>
        </div>
        <!-- Page 0478 -->
        <div class="chapter" id="page-0478">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<h4><strong>Log compaction</strong></h4>
<p>
        اگر شما فقط می‌توانید مقدار محدودی از تاریخچه <strong>log</strong> را نگه
        دارید، شما نیاز دارید که هر بار که می‌خواهید یک سیستم داده‌ی مشتق شده
        جدید را اضافه کنید، فرآیند <strong>snapshot</strong> را طی کنید. با این حال،
        <strong>log compaction</strong> یک جایگزین خوب ارائه می‌دهد.
    </p>
<p>
        ما قبلاً در "<strong>Hash Indexes</strong>" در صفحه 72، در زمینه موتورهای
        ذخیره‌سازی ساختاریافته بر اساس <strong>log</strong> (به شکل 3-2 برای یک مثال
        نگاه کنید) در مورد <strong>log compaction</strong> بحث کردیم. اصل ساده
        است: موتور ذخیره‌سازی به‌طور دوره‌ای به‌دنبال رکوردهای <strong>log</strong> با
        <strong>key</strong> یکسان می‌گردد، هر تکراری را دور می‌ریزد و فقط
        آخرین به‌روزرسانی را برای هر <strong>key</strong> نگه می‌دارد. این فرآیند
        <strong>compaction</strong> و ادغام در پس‌زمینه اجرا می‌شود.
    </p>
<p>
        در یک موتور ذخیره‌سازی ساختاریافته مبتنی بر <strong>log</strong>، یک به‌روزرسانی
        با یک مقدار <em>null</em> خاص (یک <em>tombstone</em>) نشان می‌دهد که یک
        <strong>key</strong> حذف شده است، و باعث می‌شود که در طول <strong>log
        compaction</strong> حذف شود. اما تا زمانی‌که یک <strong>key</strong> بازنویسی یا
        حذف نشود، برای همیشه در <strong>log</strong> باقی می‌ماند. فضای دیسک مورد
        نیاز برای چنین <strong>compacted log</strong>، فقط به محتویات فعلی پایگاه
        داده، و نه به تعداد نوشته‌هایی که تا به حال در پایگاه داده رخ داده
        است، بستگی دارد. اگر <strong>key</strong> یکسان مکرراً بازنویسی شود، مقادیر
        قبلی در نهایت <em>garbage-collected</em> خواهند شد، و فقط آخرین مقدار
        حفظ خواهد شد.
    </p>
<p>
        همان ایده در زمینه <strong>log-based message brokers</strong> و <strong>change data
        capture</strong> کار می‌کند. اگر سیستم <strong>CDC</strong> طوری تنظیم شده باشد
        که هر تغییری دارای یک <strong>primary key</strong> باشد، و هر به‌روزرسانی برای
        یک <strong>key</strong>، مقدار قبلی را برای آن <strong>key</strong> جایگزین می‌کند، آن‌گاه
        کافی است که فقط آخرین نوشته را برای یک <strong>key</strong> خاص نگه دارید.
    </p>
<p>
        اکنون، هر زمان که شما بخواهید یک سیستم داده مشتق شده مانند یک
        index جستجو را بازسازی کنید، شما می‌توانید یک <strong>consumer</strong> جدید را
        از <strong>offset</strong> 0 از <strong>topic</strong> <strong>log-compacted</strong> شروع کنید، و
        به‌طور متوالی تمام پیام‌ها را در <strong>log</strong> اسکن کنید. تضمین شده
        است که <strong>log</strong> حاوی آخرین مقدار برای هر <strong>key</strong> در پایگاه داده
        (و شاید برخی از مقادیر قدیمی‌تر) است—به عبارت دیگر، شما می‌توانید
        از آن برای به‌دست آوردن یک کپی کامل از محتویات پایگاه داده بدون
        نیاز به گرفتن یک <strong>snapshot</strong> دیگر از پایگاه داده منبع <strong>CDC</strong>
        استفاده کنید.
    </p>
<p>
        این <strong>feature</strong> <strong>log compaction</strong> توسط <strong>Apache Kafka</strong>
        پشتیبانی می‌شود. همان‌طور که بعداً در این فصل خواهیم دید، این به
        <strong>message broker</strong> اجازه می‌دهد که فقط برای پیام‌رسانی
        <em>transient</em> استفاده نشود، بلکه برای ذخیره‌سازی <em>durable</em> نیز
        استفاده شود.
    </p>
<h4>پشتیبانی <strong>API</strong> برای جریان‌های تغییر</h4>
<p>
        به‌طور فزاینده، پایگاه‌های داده شروع به پشتیبانی از جریان‌های تغییر
        به‌عنوان یک رابط <em>first-class</em>، به‌جای تلاش‌های <strong>CDC</strong>
<em>retrofitted</em> و <em>reverse-engineered</em> معمولی می‌کنند. به عنوان
        مثال، <strong>RethinkDB</strong> به queries اجازه می‌دهد که در مورد تغییرات
        نتایج یک query اعلان دریافت کنند [36]، <strong>Firebase</strong> [37] و
        <strong>CouchDB</strong> [38] همگام‌سازی داده‌ها را بر اساس یک <strong>change
        feed</strong> ارائه می‌دهند که برای برنامه‌ها نیز در دسترس است، و <strong>Meteor</strong>
        از <strong>oplog</strong> <strong>MongoDB</strong> برای <strong>subscribing</strong> به تغییرات
        داده‌ها و به‌روزرسانی <strong>user interface</strong> استفاده می‌کند [39].
    </p>
<p>
<strong>VoltDB</strong> به تراکنش‌ها اجازه می‌دهد که داده‌ها را به‌طور مداوم از
        یک پایگاه داده به‌صورت یک <strong>stream</strong> صادر کنند [40]. پایگاه داده یک
        جریان خروجی را در داده‌های رابطه‌ای نشان می‌دهد
        456
        |
        فصل 11: پردازش <strong>Stream</strong>
</p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0478</div>
            </div>
        </div>
        <!-- Page 0479 -->
        <div class="chapter" id="page-0479">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        مدل را به عنوان یک جدول در نظر بگیرید که تراکنش‌ها می‌توانند <strong>tuples</strong> را در
        آن وارد کنند، اما نمی‌تواند <strong>queried</strong> شود. سپس <strong>stream</strong> از
        <strong>log</strong> <strong>tuples</strong> تشکیل شده است که تراکنش‌های <strong>committed</strong>
        شده در این جدول خاص، به ترتیبی که <strong>committed</strong> شده‌اند،
        نوشته‌اند. <strong>Consumers</strong> خارجی می‌توانند این <strong>log</strong> را به‌صورت
        <em>asynchronously</em> مصرف کنند و از آن برای به‌روزرسانی سیستم‌های داده‌ی
        مشتق شده استفاده کنند.
    </p>
<p>
<strong>Kafka Connect</strong> [41] تلاشی برای ادغام ابزارهای <strong>change data
        capture</strong> برای طیف گسترده‌ای از سیستم‌های پایگاه داده با <strong>Kafka</strong>
        است. هنگامی‌که <strong>stream</strong> رویدادهای تغییر در <strong>Kafka</strong> قرار دارد،
        می‌تواند برای به‌روزرسانی سیستم‌های داده‌ی مشتق شده مانند <strong>indexes</strong>
        جستجو، و همچنین تغذیه در سیستم‌های پردازش <strong>stream</strong>، همان‌طور که در
        ادامه این فصل بحث خواهد شد، استفاده شود.
    </p>
<h4><strong>Event Sourcing</strong></h4>
<p>
        برخی از شباهت‌ها بین ایده‌هایی که در اینجا بحث کردیم و <strong>event
        sourcing</strong> وجود دارد، یک تکنیک که در جامعه‌ی <strong>domain-driven
        design (DDD)</strong> توسعه یافته است [42، 43، 44]. ما <strong>event sourcing</strong>
        را به‌طور خلاصه بحث خواهیم کرد، زیرا برخی از ایده‌های مفید و مرتبط را
        برای سیستم‌های <strong>streaming</strong> در بر می‌گیرد.
    </p>
<p>
        مشابه <strong>change data capture</strong>، <strong>event sourcing</strong> شامل ذخیره
        کردن تمام تغییرات در وضعیت برنامه به عنوان یک <strong>log</strong> از رویدادهای
        تغییر است. بزرگترین تفاوت این است که <strong>event sourcing</strong> ایده را در
        یک سطح انتزاعی متفاوت اعمال می‌کند:
    </p>
<ul>
<li>
            در <strong>change data capture</strong>، برنامه از پایگاه داده به روشی
            <em>mutable</em> استفاده می‌کند، که به‌دلخواه رکوردها را به‌روزرسانی و
            حذف می‌کند. <strong>Log</strong> تغییرات از پایگاه داده در سطح پایین
            استخراج می‌شود (به عنوان مثال، با <strong>parsing</strong> <strong>replication log</strong>)،
            که اطمینان می‌دهد که ترتیب نوشتن‌ها که از پایگاه داده استخراج شده
            است، با ترتیبی که در واقع نوشته شده‌اند مطابقت دارد، و از
            <strong>race condition</strong> در شکل 11-4 اجتناب می‌شود. برنامه‌ای که در
            پایگاه داده می‌نویسد، نیازی ندارد بداند که <strong>CDC</strong> در حال
            رخ دادن است.
        </li>
<li>
            در <strong>event sourcing</strong>، منطق برنامه به‌طور صریح بر اساس
            رویدادهای <em>immutable</em> ساخته شده است که در یک <strong>event log</strong>
            نوشته شده‌اند. در این حالت، <strong>event store</strong> <em>append-only</em> است،
            و به‌روزرسانی‌ها یا حذف‌ها دلسرد یا ممنوع هستند. رویدادها برای
            منعکس کردن چیزهایی که در سطح برنامه رخ داده‌اند، طراحی
            شده‌اند، نه تغییرات حالت سطح پایین.
        </li>
</ul>
<p>
<strong>Event sourcing</strong> یک تکنیک قدرتمند برای مدل‌سازی داده‌ها است: از
        دیدگاه یک برنامه، ثبت اقدامات کاربر به عنوان رویدادهای <em>immutable</em>،
        بیشتر منطقی است، تا ثبت تأثیر آن اقدامات بر یک پایگاه داده‌ی
        <em>mutable</em>. <strong>Event sourcing</strong>، تکامل برنامه‌ها را در طول زمان
        آسان‌تر می‌کند، با آسان‌تر کردن درک این‌که چرا چیزی اتفاق
        افتاده است، به <strong>debugging</strong> کمک می‌کند، و در برابر <strong>bugs</strong>
        برنامه محافظت می‌کند (نگاه کنید به "مزایای رویدادهای <em>immutable</em>" در
        صفحه 460).
    </p>
<p>
        به عنوان مثال، ذخیره رویداد "دانش‌آموز، ثبت نام در دوره‌ی خود را لغو
        کرد" به‌وضوح قصد یک عمل واحد را به روشی خنثی بیان می‌کند، در حالی
        که اثرات جانبی "یک ورودی از جدول ثبت‌نام‌ها حذف شد، و یک دلیل
        لغو به جدول بازخورد دانشجو اضافه شد" شامل فرضیات زیادی در مورد
        نحوه
        پایگاه‌های داده و جریان‌ها
        |
        457
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0479</div>
            </div>
        </div>
        <!-- Page 0480 -->
        <div class="chapter" id="page-0480">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        داده‌ها بعداً استفاده خواهند شد. اگر یک <strong>feature</strong> جدید
        برنامه معرفی شود—به عنوان مثال، "مکان به نفر بعدی در لیست انتظار
        پیشنهاد می‌شود"—رویکرد <strong>event sourcing</strong> به آن اثر جانبی
        جدید اجازه می‌دهد که به‌راحتی از رویداد موجود زنجیر شود.
    </p>
<p>
<strong>Event sourcing</strong> شبیه مدل داده‌ی <strong>chronicle</strong> [45] است، و
        همچنین شباهت‌هایی بین یک <strong>event log</strong> و جدول واقعیت که در
        یک <strong>star schema</strong> پیدا می‌کنید (نگاه کنید به "ستاره‌ها و
        دانه‌های برف: <strong>Schemas</strong> برای <strong>Analytics</strong>" در صفحه 93)
        وجود دارد.
    </p>
<p>
        پایگاه‌های داده‌ی تخصصی مانند <strong>Event Store</strong> [46] برای پشتیبانی
        از برنامه‌هایی که از <strong>event sourcing</strong> استفاده می‌کنند، توسعه
        یافته‌اند، اما به‌طور کلی این رویکرد مستقل از هر ابزار خاصی است. یک
        پایگاه داده‌ی معمولی یا یک <strong>log-based message broker</strong> نیز
        می‌تواند برای ساخت برنامه‌ها در این سبک استفاده شود.
    </p>
<h4>استخراج وضعیت فعلی از <strong>event log</strong></h4>
<p>
        یک <strong>event log</strong> به‌خودی خود چندان مفید نیست، زیرا کاربران
        معمولاً انتظار دارند که وضعیت فعلی یک سیستم را ببینند، نه تاریخچه
        اصلاحات را. به عنوان مثال، در یک وب‌سایت خرید، کاربران انتظار دارند
        که بتوانند محتویات فعلی سبد خرید خود را ببینند، نه یک لیست
        <em>append-only</em> از تمام تغییراتی که تا به حال در سبد خرید خود
        ایجاد کرده‌اند.
    </p>
<p>
        بنابراین برنامه‌هایی که از <strong>event sourcing</strong> استفاده می‌کنند، باید
        <strong>log</strong> رویدادها (نشان‌دهنده‌ی داده‌های نوشته شده در سیستم)
        را بگیرند و آن را به وضعیت برنامه که برای نشان دادن به یک کاربر
        مناسب است، تبدیل کنند (راهی که داده‌ها از سیستم خوانده می‌شوند
        [47]). این تبدیل می‌تواند از منطق دلخواه استفاده کند، اما باید
        <em>deterministic</em> باشد تا شما بتوانید دوباره آن را اجرا کنید و همان
        وضعیت برنامه را از <strong>event log</strong> استخراج کنید.
    </p>
<p>
        همانند <strong>change data capture</strong>، پخش مجدد <strong>event log</strong> به شما
        اجازه می‌دهد تا وضعیت فعلی سیستم را بازسازی کنید. با این حال، <strong>log
        compaction</strong> باید متفاوت مدیریت شود:
    </p>
<ul>
<li>
            یک رویداد <strong>CDC</strong> برای به‌روزرسانی یک رکورد معمولاً شامل
            نسخه کامل جدید از رکورد است، بنابراین مقدار فعلی برای یک
            <strong>primary key</strong> کاملاً توسط جدیدترین رویداد برای آن
            <strong>primary key</strong> تعیین می‌شود، و <strong>log compaction</strong> می‌تواند
            رویدادهای قبلی را برای همان <strong>key</strong> دور بریزد.
        </li>
<li>
            از سوی دیگر، با <strong>event sourcing</strong>، رویدادها در سطح بالاتر
            مدل‌سازی می‌شوند: یک رویداد به‌طور معمول قصد یک عمل کاربر را
            بیان می‌کند، نه مکانیک‌های به‌روزرسانی <strong>state</strong> که در نتیجه
            عمل رخ داده است. در این حالت، رویدادهای بعدی به‌طور معمول
            رویدادهای قبلی را <em>override</em> نمی‌کنند، و بنابراین شما به
            تاریخچه کامل رویدادها برای بازسازی وضعیت نهایی نیاز دارید. <strong>Log
            compaction</strong> به همان روش امکان‌پذیر نیست.
        </li>
</ul>
<p>
        برنامه‌هایی که از <strong>event sourcing</strong> استفاده می‌کنند، معمولاً دارای
        نوعی مکانیسم برای ذخیره <strong>snapshots</strong> از وضعیت فعلی هستند که
        از <strong>log</strong> رویدادها گرفته شده است، بنابراین آن‌ها نیازی به
        پردازش مکرر <strong>full log</strong> ندارند. با این حال، این فقط یک
        بهینه‌سازی عملکرد برای سرعت بخشیدن به خواندن و بازیابی از
        خرابی‌ها است؛ هدف این است که سیستم بتواند تمام رویدادهای خام را برای
        همیشه ذخیره کند و هر زمان که لازم باشد، <strong>full event log</strong> را
        دوباره پردازش کند.
        ما در مورد این فرض در "محدودیت‌های <em>immutability</em>" در صفحه 463
        بحث می‌کنیم.
        پایگاه‌های داده و جریان‌ها
        |
        455
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0480</div>
            </div>
        </div>
        <!-- Page 0481 -->
        <div class="chapter" id="page-0481">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<h4>دستورات و رویدادها</h4>
<p>
        فلسفه <strong>event sourcing</strong> مراقب است که بین رویدادها و
        دستورات تمایز قائل شود [48]. هنگامی که یک درخواست از یک کاربر
        ابتدا می‌رسد، در ابتدا یک دستور است: در این مرحله هنوز هم ممکن
        است شکست بخورد، به عنوان مثال زیرا برخی از شرایط <em>integrity</em>
        نقض می‌شود. برنامه ابتدا باید تأیید کند که می‌تواند دستور را اجرا
        کند. اگر <strong>validation</strong> موفقیت‌آمیز باشد و دستور پذیرفته
        شود، به یک رویداد تبدیل می‌شود، که <em>durable</em> و <em>immutable</em>
        است.
    </p>
<p>
        به عنوان مثال، اگر یک کاربر سعی می‌کند یک نام کاربری خاص را ثبت
        کند، یا یک صندلی در هواپیما یا تئاتر را رزرو کند، سپس برنامه
        باید بررسی کند که آن نام کاربری یا صندلی قبلاً گرفته نشده
        باشد. (ما قبلاً این مثال را در "اجماع تحمل‌کننده‌ی خطا" در صفحه
        364 بحث کردیم.) هنگامی که آن بررسی موفقیت‌آمیز بود، برنامه
        می‌تواند یک رویداد تولید کند تا نشان دهد که یک نام کاربری خاص
        توسط یک <strong>ID</strong> کاربر خاص ثبت شده است، یا این‌که یک
        صندلی خاص برای یک مشتری خاص رزرو شده است.
    </p>
<p>
        در نقطه‌ای که رویداد تولید می‌شود، به یک واقعیت تبدیل می‌شود. حتی
        اگر مشتری بعداً تصمیم بگیرد که رزرو را تغییر دهد یا لغو کند، این
        واقعیت باقی می‌ماند که آن‌ها قبلاً یک رزرو برای یک صندلی خاص
        داشتند، و تغییر یا لغو یک رویداد جداگانه است که بعداً اضافه
        می‌شود.
    </p>
<p>
        به یک <strong>consumer</strong> از <strong>event stream</strong> اجازه داده
        نمی‌شود که یک رویداد را رد کند: تا زمانی که <strong>consumer</strong>
        رویداد را می‌بیند، در حال حاضر یک بخش <em>immutable</em> از
        <strong>log</strong> است، و ممکن است قبلاً توسط <strong>consumers</strong>
        دیگر دیده شده باشد. بنابراین، هر گونه <strong>validation</strong> از یک
        دستور باید به‌صورت <em>synchronously</em> انجام شود، قبل از این‌که به
        یک رویداد تبدیل شود—به عنوان مثال، با استفاده از یک تراکنش
        <em>serializable</em> که به‌طور <em>atomically</em> دستور را تأیید و رویداد را
        منتشر می‌کند.
    </p>
<p>
        به‌طور جایگزین، درخواست کاربر برای رزرو یک صندلی می‌تواند به دو
        رویداد تقسیم شود: ابتدا یک رزرو <em>tentative</em>، و سپس یک رویداد
        تأیید جداگانه پس از تأیید <strong>reservation</strong> (همان‌طور که در
        "پیاده‌سازی ذخیره‌سازی <em>linearizable</em> با استفاده از <strong>total order
        broadcast</strong>" در صفحه 350 بحث شد). این تقسیم به
        <strong>validation</strong> اجازه می‌دهد که در یک فرآیند <em>asynchronous</em>
        انجام شود.
    </p>
<h4>حالت، جریان‌ها، و <strong>Immutability</strong></h4>
<p>
        ما در فصل 10 دیدیم که پردازش <strong>batch</strong> از <em>immutability</em>
        فایل‌های ورودی خود سود می‌برد، بنابراین شما می‌توانید مشاغل
        پردازش آزمایشی را بر روی فایل‌های ورودی موجود اجرا کنید بدون
        ترس از آسیب رساندن به آن‌ها. این اصل <em>immutability</em> همچنین
        همان چیزی است که <strong>event sourcing</strong> و <strong>change data capture</strong>
        را بسیار قدرتمند می‌کند.
    </p>
<p>
        ما به‌طور معمول به پایگاه‌های داده به عنوان ذخیره‌ی وضعیت فعلی
        برنامه فکر می‌کنیم—این نمایش برای خواندن بهینه شده است، و
        معمولاً برای سرویس‌دهی به <strong>queries</strong> راحت‌ترین حالت است.
        ماهیت <strong>state</strong> این است که تغییر می‌کند، بنابراین پایگاه‌های
        داده از به‌روزرسانی و حذف داده‌ها و همچنین درج آن پشتیبانی
        می‌کنند. این چگونه با <em>immutability</em> مطابقت دارد؟
        پایگاه‌های داده و جریان‌ها
        |
        459
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0481</div>
            </div>
        </div>
        <!-- Page 0482 -->
        <div class="chapter" id="page-0482">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        هر زمان که شما <strong>state</strong> ای داشته باشید که تغییر می‌کند، آن
        <strong>state</strong> نتیجه‌ی رویدادهایی است که آن را در طول زمان
        <em>mutated</em> کرده‌اند. به عنوان مثال، لیست صندلی‌های موجود فعلی
        شما نتیجه‌ی رزروهایی است که شما پردازش کرده‌اید، موجودی حساب
        جاری نتیجه‌ی اعتبارات و بدهی‌های حساب است، و نمودار زمان پاسخ
        سرور وب شما یک تجمیع از زمان‌های پاسخ فردی تمام درخواست‌های وب
        است که رخ داده‌اند.
    </p>
<p>
        مهم نیست که <strong>state</strong> چگونه تغییر می‌کند، همیشه یک توالی از رویدادها
        وجود داشته است که باعث آن تغییرات شده‌اند. حتی زمانی که کارها انجام
        و لغو می‌شوند، این واقعیت همچنان صادق است که آن رویدادها رخ داده‌اند.
        ایده‌ی اصلی این است که <strong>mutable state</strong> و یک <strong>log</strong>
<em>append-only</em> از رویدادهای <em>immutable</em> با یکدیگر تضاد
        ندارند: آن‌ها دو روی یک سکه هستند. <strong>Log</strong> از تمام تغییرات،
        <strong>changelog</strong>، تکامل <strong>state</strong> را در طول زمان نشان
        می‌دهد.
    </p>
<p>
        اگر شما از نظر ریاضی مستعد هستید، ممکن است بگویید که وضعیت
        برنامه چیزی است که شما زمانی که یک <strong>event stream</strong> را در طول
        زمان <em>integrate</em> می‌کنید، به دست می‌آورید، و یک <strong>change
        stream</strong> چیزی است که شما زمانی که <strong>state</strong> را بر اساس
        زمان <em>differentiate</em> می‌کنید، به دست می‌آورید، همان‌طور که در شکل
        11-6 نشان داده شده است [49، 50، 51].
    </p>
<p>
        این قیاس دارای محدودیت‌هایی است (به عنوان مثال، مشتق دوم <strong>state</strong>
        معنی‌دار به نظر نمی‌رسد)، اما یک نقطه شروع مفید برای فکر کردن در
        مورد داده‌ها است.
    </p>
<p>
        شکل 11-6. رابطه‌ی بین وضعیت فعلی برنامه و یک <strong>event stream</strong>.
    </p>
<p>
        اگر شما <strong>changelog</strong> را <em>durably</em> ذخیره کنید، این فقط این
        اثر را دارد که <strong>state</strong> را <em>reproducible</em> می‌کند. اگر شما
        <strong>log</strong> رویدادها را سیستم <strong>record</strong> خود در نظر بگیرید، و
        هر <strong>state</strong> <em>mutable</em> را به‌عنوان مشتق شده از آن در نظر
        بگیرید، درک جریان داده‌ها از طریق یک سیستم آسان‌تر می‌شود. همان‌طور
        که <strong>Pat Helland</strong> می‌گوید [52]:
    </p>
<p>
<strong>Transaction logs</strong> تمام تغییرات ایجاد شده در پایگاه داده را ثبت
        می‌کنند. افزونه‌های پرسرعت تنها راه تغییر <strong>log</strong> هستند. از این
        منظر، محتویات پایگاه داده حاوی یک <strong>caching</strong> از آخرین مقادیر
        رکورد در <strong>logs</strong> است. حقیقت، <strong>log</strong> است. پایگاه داده یک
        <strong>cache</strong> از زیرمجموعه‌ای از <strong>log</strong> است. آن زیرمجموعه
        <strong>cached</strong>، آخرین مقدار هر رکورد و مقدار index از <strong>log</strong> است.
    </p>
<p>
<strong>Log compaction</strong>، همان‌طور که در "<strong>Log compaction</strong>" در
        صفحه 456 بحث شد، یک راه برای پل زدن شکاف بین <strong>log</strong> و <strong>database
        state</strong> است: فقط آخرین نسخه از هر رکورد را حفظ می‌کند، و نسخه‌های
        بازنویسی شده را دور می‌اندازد.
    </p>
<h4>مزایای رویدادهای <em>immutable</em></h4>
<p>
<em>Immutability</em> در پایگاه‌های داده یک ایده قدیمی است. به عنوان مثال،
        حسابداران قرن‌هاست که از <em>immutability</em> در دفترداری مالی استفاده
        می‌کنند. هنگامی که یک تراکنش رخ می‌دهد، این
        460
        |
        فصل 11: پردازش <strong>Stream</strong>
</p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 482" src="page_0482/image_1.png"/></div>
</div>
                <div class="page-number">صفحه 0482</div>
            </div>
        </div>
        <!-- Page 0483 -->
        <div class="chapter" id="page-0483">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        ثبت می‌شود در یک <strong>ledger</strong> <em>append-only</em>، که اساساً یک
        <strong>log</strong> از رویدادهایی است که پول، کالا یا خدماتی را که
        جابه‌جا شده‌اند، شرح می‌دهد. حساب‌ها، مانند سود و زیان یا ترازنامه، از
        تراکنش‌های <strong>ledger</strong> با جمع کردن آن‌ها مشتق
        می‌شوند [53].
    </p>
<p>
        اگر اشتباهی رخ دهد، حسابداران تراکنش نادرست را در <strong>ledger</strong> پاک
        نمی‌کنند یا تغییر نمی‌دهند—در عوض، آن‌ها یک تراکنش دیگر اضافه
        می‌کنند که این اشتباه را جبران می‌کند، به عنوان مثال بازپرداخت یک
        هزینه‌ی نادرست. تراکنش نادرست همچنان برای همیشه در <strong>ledger</strong>
        باقی می‌ماند، زیرا ممکن است به دلایل حسابرسی مهم باشد. اگر
        ارقام نادرست، که از <strong>ledger</strong> نادرست استخراج شده‌اند، قبلاً
        منتشر شده باشند، سپس ارقام برای دوره حسابداری بعدی شامل یک
        اصلاحیه می‌شود. این فرآیند در حسابداری کاملاً طبیعی است [54].
    </p>
<p>
        اگرچه این <em>auditability</em> به‌ویژه در سیستم‌های مالی مهم است، اما
        برای بسیاری از سیستم‌های دیگری که مشمول چنین مقررات سختی
        نیستند نیز مفید است. همان‌طور که در "فلسفه خروجی‌های فرآیند
        <strong>batch</strong>" در صفحه 413 بحث شد، اگر شما به‌طور تصادفی کد
        اشکال‌داری را مستقر کنید که داده‌های بد را در یک پایگاه داده
        می‌نویسد، بازیابی بسیار سخت‌تر است اگر کد بتواند به‌صورت
        مخرب داده‌ها را بازنویسی کند. با یک <strong>log</strong> <em>append-only</em> از
        رویدادهای <em>immutable</em>، تشخیص این‌که چه اتفاقی افتاده است و
        بازیابی از مشکل بسیار آسان‌تر است.
    </p>
<p>
        رویدادهای <em>immutable</em> همچنین اطلاعات بیشتری را نسبت به
        وضعیت فعلی ثبت می‌کنند. به عنوان مثال، در یک وب‌سایت خرید،
        یک مشتری ممکن است یک آیتم را به سبد خرید خود اضافه کند و
        سپس دوباره آن را حذف کند. اگرچه رویداد دوم، رویداد اول را از
        نظر تکمیل سفارش لغو می‌کند، اما ممکن است برای اهداف
        <strong>analytics</strong> مفید باشد که بدانیم مشتری در حال بررسی یک
        آیتم خاص بود اما سپس از آن منصرف شد. شاید آن‌ها در آینده
        تصمیم بگیرند آن را بخرند، یا شاید جایگزینی پیدا کردند. این
        اطلاعات در یک <strong>event log</strong> ثبت شده است، اما در یک پایگاه
        داده که آیتم‌ها را هنگام حذف از سبد خرید حذف می‌کند، از بین
        می‌رود [42].
    </p>
<h4>استخراج چندین <strong>views</strong> از همان <strong>event log</strong></h4>
<p>
        علاوه بر این، با جدا کردن <strong>mutable state</strong> از <strong>event log</strong>
<em>immutable</em>، شما می‌توانید چندین نمایش با جهت‌گیری
        <em>read</em> مختلف را از همان <strong>log</strong> رویدادها استخراج کنید. این
        عمل دقیقاً مانند داشتن چندین <strong>consumer</strong> از یک <strong>stream</strong>
        (شکل 11-5) است: به عنوان مثال، پایگاه داده‌ی تحلیلی <strong>Druid</strong>
        مستقیماً از <strong>Kafka</strong> با استفاده از این رویکرد استفاده می‌کند [55]،
        <strong>Pistachio</strong> یک <strong>key-value store</strong> توزیع شده است که از
        <strong>Kafka</strong> به‌عنوان یک <strong>commit log</strong> استفاده می‌کند [56]، و
        <strong>Kafka Connect sinks</strong> می‌تواند داده‌ها را از <strong>Kafka</strong> به
        پایگاه‌های داده و <strong>indexes</strong> مختلف صادر کند [41]. برای بسیاری
        از سیستم‌های ذخیره‌سازی و index، مانند <strong>search servers</strong>، منطقی
        است که ورودی خود را به‌طور مشابه از یک <strong>log</strong> توزیع شده دریافت
        کنند (نگاه کنید به "همگام نگه داشتن سیستم‌ها" در صفحه 452).
    </p>
<p>
        داشتن یک گام ترجمه صریح از یک <strong>event log</strong> به یک پایگاه داده،
        تکامل برنامه شما را در طول زمان آسان‌تر می‌کند: اگر شما
        می‌خواهید یک <strong>feature</strong> جدید را معرفی کنید که داده‌های موجود
        شما را به روشی جدید نشان می‌دهد، شما می‌توانید از <strong>event log</strong>
        برای ساختن یک <strong>view</strong> جداگانه که برای خواندن بهینه شده است
        برای <strong>feature</strong> جدید، و اجرا کردن آن در کنار <strong>Frontend</strong> های
        موجود
        پایگاه‌های داده و جریان‌ها
        |
        457
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0483</div>
            </div>
        </div>
        <!-- Page 0484 -->
        <div class="chapter" id="page-0484">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        سیستم‌ها بدون نیاز به تغییر آن‌ها. اجرای سیستم‌های قدیمی و جدید در کنار هم
        اغلب آسان‌تر از انجام یک <strong>schema migration</strong> پیچیده در یک
        سیستم موجود است.
    </p>
<p>
        هنگامی که دیگر به سیستم قدیمی نیازی نبود، شما به‌سادگی می‌توانید آن
        را خاموش کنید و منابع آن را بازگردانید [47، 57].
    </p>
<p>
        ذخیره‌سازی داده‌ها معمولاً بسیار ساده است اگر شما مجبور نباشید نگران
        چگونگی <strong>queried</strong> و دسترسی به آن باشید؛ بسیاری از پیچیدگی‌های
        طراحی <strong>schema</strong>، index کردن، و <strong>storage engines</strong>
        نتیجه‌ی تمایل به پشتیبانی از الگوهای <strong>query</strong> و دسترسی خاص
        (نگاه کنید به فصل 3) است. به همین دلیل، شما انعطاف‌پذیری زیادی را با
        جدا کردن فرمی که داده‌ها در آن نوشته می‌شوند از فرمی که در آن
        خوانده می‌شوند، و با اجازه دادن به چندین <strong>views</strong> <em>read</em>
        مختلف، به‌دست می‌آورید. این ایده گاهی اوقات به‌عنوان <strong>command query
        responsibility segregation (CQRS)</strong> شناخته می‌شود [42، 58، 59].
    </p>
<p>
        رویکرد سنتی برای طراحی پایگاه داده و <strong>schema</strong> بر اساس مغالطه‌ی
        این است که داده‌ها باید به همان فرمی نوشته شوند که <strong>queried</strong>
        خواهند شد. بحث‌ها در مورد <strong>normalization</strong> و <strong>denormalization</strong>
        (نگاه کنید به "روابط <strong>Many-to-One</strong> و <strong>Many-to-Many</strong>" در
        صفحه 33) تا حد زیادی نامربوط می‌شوند اگر شما می‌توانید داده‌ها را از
        یک <strong>log</strong> رویداد که برای نوشتن بهینه شده است، به وضعیت
        برنامه که برای خواندن بهینه شده است ترجمه کنید: کاملاً منطقی است که
        داده‌ها را در <strong>views</strong> که برای خواندن بهینه شده‌اند،
        <strong>denormalize</strong> کنید، زیرا فرآیند ترجمه یک مکانیسم برای
        همگام نگه داشتن آن با <strong>event log</strong> به شما می‌دهد.
    </p>
<p>
        در "شرح <strong>Load</strong>" در صفحه 11، ما در مورد <strong>home timelines</strong> از
        <strong>Twitter</strong> بحث کردیم، یک <strong>cache</strong> از توییت‌های اخیر
        نوشته شده توسط افرادی که یک کاربر خاص دنبال می‌کند (مانند یک
        صندوق پستی). این یک مثال دیگر از <strong>state</strong> برای خواندن بهینه شده
        است: <strong>home timelines</strong> بسیار <strong>denormalized</strong> هستند،
        زیرا توییت‌های شما در تمام <strong>timelines</strong> افرادی که شما را دنبال
        می‌کنند، تکرار می‌شوند. با این حال، سرویس <strong>fan-out</strong>، این
        <strong>state</strong> تکراری را با توییت‌های جدید و روابط جدید دنبال
        کردن، همگام نگه می‌دارد، که این امر تکرار را مدیریت‌پذیر نگه
        می‌دارد.
    </p>
<h4>کنترل <strong>Concurrency</strong></h4>
<p>
        بزرگترین نقطه ضعف <strong>event sourcing</strong> و <strong>change data capture</strong>
        این است که <strong>consumers</strong> از <strong>event log</strong> معمولاً <em>asynchronous</em>
        هستند، بنابراین این احتمال وجود دارد که یک کاربر ممکن است یک
        نوشته در <strong>log</strong> ایجاد کند، سپس از یک <strong>log-derived view</strong>
        بخواند و متوجه شود که نوشته آن‌ها هنوز در <strong>read view</strong> منعکس
        نشده است. ما قبلاً در "خواندن نوشتن‌های خودتان" در صفحه 162 این
        مشکل و راه‌حل‌های احتمالی را مورد بحث قرار دادیم.
    </p>
<p>
        یک راه‌حل این است که به‌روزرسانی‌های <strong>read view</strong> را
        <em>synchronously</em> با اضافه کردن رویداد به <strong>log</strong> انجام دهیم. این
        امر به یک تراکنش نیاز دارد تا نوشتن‌ها را در یک واحد <em>atomic</em>
        ترکیب کند، بنابراین شما یا باید <strong>event log</strong> و <strong>read view</strong>
        را در همان سیستم ذخیره‌سازی نگه دارید، یا به یک تراکنش توزیع شده
        در سراسر سیستم‌های مختلف نیاز دارید.
    </p>
<p>
        به‌طور جایگزین، شما می‌توانید از رویکردی که در "پیاده‌سازی
        ذخیره‌سازی <em>linearizable</em> با استفاده از <strong>total order broadcast</strong>"
        در صفحه 350 بحث شد، استفاده کنید.
    </p>
<p>
        از سوی دیگر، استخراج وضعیت فعلی از یک <strong>event log</strong> همچنین
        برخی از جنبه‌های کنترل <strong>concurrency</strong> را ساده می‌کند. بخش زیادی
        از نیاز به تراکنش‌های چند شیئی (نگاه کنید به "عملیات
        <strong>Single-Object</strong> و <strong>Multi-Object</strong>" در صفحه 228) از یک
        کاربر واحد ناشی می‌شود
        پایگاه‌های داده و جریان‌ها
        |
        462
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0484</div>
            </div>
        </div>
        <!-- Page 0485 -->
        <div class="chapter" id="page-0485">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        عملی که مستلزم تغییر داده‌ها در چندین مکان مختلف است. با <strong>event sourcing</strong>،
        شما می‌توانید یک رویداد را به گونه‌ای طراحی کنید که یک توصیف خود
        محصور از یک عمل کاربر باشد.
    </p>
<p>
        سپس عمل کاربر فقط به یک <strong>write</strong> در یک مکان نیاز دارد—یعنی
        پیوست کردن رویدادها به <strong>log</strong>—که ساختن آن به صورت <em>atomic</em>
        آسان است.
    </p>
<p>
        اگر <strong>event log</strong> و وضعیت برنامه به یک روش یکسان
        تقسیم‌بندی شوند (به عنوان مثال، پردازش یک رویداد برای یک مشتری
        در <strong>partition</strong> 3 فقط نیاز به به‌روزرسانی <strong>partition</strong> 3 از
        وضعیت برنامه دارد)، سپس یک <strong>log consumer</strong> تک <strong>threaded</strong>
        ساده نیازی به کنترل <strong>concurrency</strong> برای <strong>writes</strong>
        ندارد—با ساخت، فقط یک رویداد را در یک زمان پردازش می‌کند (همچنین
        به "اجرای سریال واقعی" در صفحه 252 مراجعه کنید). <strong>Log</strong>
        عدم <em>determinism</em> از <strong>concurrency</strong> را با تعریف یک ترتیب سریال
        از رویدادها در یک <strong>partition</strong> حذف می‌کند [24]. اگر یک رویداد به
        <strong>partitions</strong> حالت متعدد برخورد کند، کار بیشتری لازم است، که ما
        در فصل 12 در مورد آن بحث خواهیم کرد.
    </p>
<h4>محدودیت‌های <em>immutability</em></h4>
<p>
        بسیاری از سیستم‌هایی که از یک مدل <strong>event-sourced</strong> استفاده
        نمی‌کنند، با این وجود به <em>immutability</em> متکی هستند: پایگاه‌های
        داده‌ی مختلف به‌طور داخلی از ساختارهای داده‌ی <em>immutable</em> یا داده‌های
        چند نسخه‌ای برای پشتیبانی از <strong>point-in-time snapshots</strong>
        استفاده می‌کنند (نگاه کنید به "<strong>Indexes</strong> و <strong>snapshot
        isolation</strong>" در صفحه 241). سیستم‌های کنترل نسخه مانند <strong>Git</strong>،
        <strong>Mercurial</strong> و <strong>Fossil</strong> نیز به داده‌های <em>immutable</em> برای حفظ
        تاریخچه نسخه فایل‌ها متکی هستند.
    </p>
<p>
        تا چه حد نگه‌داشتن یک تاریخچه <em>immutable</em> از تمام تغییرات برای
        همیشه امکان‌پذیر است؟ پاسخ به مقدار <em>churn</em> در مجموعه‌داده بستگی
        دارد. برخی از <strong>workloads</strong> عمدتاً داده‌ها را اضافه می‌کنند و به‌ندرت
        به‌روزرسانی یا حذف می‌کنند؛ آن‌ها به‌راحتی <em>immutable</em> می‌شوند.
        سایر <strong>workloads</strong> دارای نرخ بالایی از به‌روزرسانی‌ها و حذف‌ها در
        یک مجموعه‌داده نسبتاً کوچک هستند؛ در این موارد، تاریخچه
        <em>immutable</em> ممکن است به‌طور چشمگیری بزرگ شود، <em>fragmentation</em>
        ممکن است به یک مسئله تبدیل شود، و عملکرد <strong>compaction</strong> و
        <strong>garbage collection</strong> برای <em>operational robustness</em> بسیار مهم
        می‌شود [60، 61].
    </p>
<p>
        علاوه بر دلایل عملکرد، ممکن است شرایطی وجود داشته باشد که شما نیاز
        داشته باشید داده‌ها را به دلایل اداری حذف کنید، با وجود تمام
        <em>immutability</em>. به عنوان مثال، مقررات حریم خصوصی ممکن است
        حذف اطلاعات شخصی یک کاربر را پس از بستن حساب خود، الزامی
        کند، قوانین حفاظت از داده‌ها ممکن است حذف اطلاعات نادرست را
        الزامی کند، یا یک نشت تصادفی اطلاعات حساس ممکن است نیاز به
        مهار داشته باشد.
    </p>
<p>
        در این شرایط، فقط پیوست کردن رویداد دیگری به <strong>log</strong> برای
        نشان دادن این‌که داده‌های قبلی باید حذف شده در نظر گرفته شوند، کافی
        نیست—شما در واقع می‌خواهید تاریخچه را دوباره بنویسید و وانمود کنید
        که داده‌ها اصلاً نوشته نشده‌اند. به عنوان مثال، <strong>Datomic</strong> این
        ویژگی را <em>excision</em> می‌نامد [62]، و سیستم کنترل نسخه <strong>Fossil</strong>
        یک مفهوم مشابه به نام <em>shunning</em> دارد [63].
    </p>
<p>
        حذف واقعی داده‌ها به‌طور شگفت‌انگیزی دشوار است [64]، زیرا کپی‌ها
        می‌توانند در مکان‌های زیادی وجود داشته باشند: به عنوان مثال،
        <strong>storage engines</strong>، <strong>filesystems</strong>، و <strong>SSDs</strong> اغلب
        به یک مکان جدید می‌نویسند تا این‌که مکان قبلی را بازنویسی کنند [52]،
        و <strong>backups</strong> اغلب عمداً <em>immutable</em> هستند تا از حذف یا
        فساد تصادفی جلوگیری شود. حذف بیشتر یک مسئله‌ی "سخت‌تر کردن
        پایگاه‌های داده و جریان‌ها
        |
        463
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0485</div>
            </div>
        </div>
        <!-- Page 0486 -->
        <div class="chapter" id="page-0486">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        "دشوارتر کردن بازیابی داده‌ها" از "غیرممکن کردن بازیابی داده‌ها" است. با
        این وجود، شما گاهی اوقات باید تلاش کنید، همان‌طور که در "قانون‌گذاری و
        خودتنظیمی" در صفحه 542 خواهیم دید.
    </p>
<h4>پردازش جریان‌ها</h4>
<p>
        تاکنون در این فصل ما در مورد این‌که جریان‌ها از کجا می‌آیند (رویدادهای
        فعالیت کاربر، حسگرها، و نوشته‌ها در پایگاه‌های داده) صحبت کردیم، و
        در مورد این‌که چگونه جریان‌ها منتقل می‌شوند (از طریق پیام‌رسانی
        مستقیم، از طریق <strong>message brokers</strong>، و در <strong>event logs</strong>)
        صحبت کردیم.
    </p>
<p>
        آن‌چه باقی مانده است، بحث در مورد این است که شما پس از داشتن
        <strong>stream</strong> چه کاری می‌توانید انجام دهید—یعنی، شما می‌توانید آن را
        پردازش کنید. به‌طور کلی، سه گزینه وجود دارد:
    </p>
<ol>
<li>
            شما می‌توانید داده‌ها را در رویدادها بگیرید و آن را در یک پایگاه داده،
            <strong>cache</strong>، index جستجو یا سیستم ذخیره‌سازی مشابه بنویسید،
            که از آن‌جا می‌تواند توسط <strong>clients</strong> دیگر query شود. همان‌طور که
            در شکل 11-5 نشان داده شده است، این یک روش خوب برای همگام
            نگه‌داشتن یک پایگاه داده با تغییرات در حال وقوع در سایر بخش‌های
            سیستم است—به‌ویژه اگر <strong>stream consumer</strong> تنها
            <strong>client</strong> باشد که در پایگاه داده می‌نویسد. نوشتن در یک سیستم
            ذخیره‌سازی، معادل <strong>streaming</strong> آن چیزی است که ما در "خروجی
            جریان‌های کاری <strong>Batch</strong>" در صفحه 411 مورد بحث قرار
            دادیم.
        </li>
<li>
            شما می‌توانید رویدادها را به نوعی به کاربران <em>push</em> کنید، به عنوان
            مثال با ارسال <strong>email alerts</strong> یا <strong>push notifications</strong>، یا
            با <strong>streaming</strong> رویدادها به یک <strong>dashboard</strong> <em>real-time</em>
            که در آن نمایش داده می‌شوند. در این حالت، یک انسان <strong>consumer</strong>
            نهایی <strong>stream</strong> است.
        </li>
<li>
            شما می‌توانید یک یا چند <strong>stream</strong> ورودی را پردازش کنید تا یک یا
            چند <strong>stream</strong> خروجی تولید کنید. جریان‌ها ممکن است از یک
            <strong>pipeline</strong> عبور کنند که متشکل از چندین مرحله پردازش است
            قبل از این‌که در نهایت به یک خروجی (گزینه 1 یا 2) ختم شوند.
        </li>
</ol>
<p>
        در بقیه این فصل، ما در مورد گزینه 3 بحث خواهیم کرد: پردازش
        جریان‌ها برای تولید جریان‌های دیگر، مشتق شده. قطعه کدی که
        جریان‌ها را مانند این پردازش می‌کند، به عنوان یک <strong>operator</strong> یا
        یک job شناخته می‌شود. این به‌شدت با فرآیندهای <strong>Unix</strong> و jobs
        <strong>MapReduce</strong> که ما در فصل 10 در مورد آن‌ها بحث کردیم، مرتبط
        است، و الگوی <strong>dataflow</strong> مشابه است: یک پردازنده <strong>stream</strong>
        ، <strong>streams</strong> ورودی را به‌صورت <em>read-only</em> مصرف می‌کند و
        خروجی خود را به یک مکان متفاوت به روشی <em>append-only</em>
        می‌نویسد.
    </p>
<p>
        الگوهای تقسیم‌بندی و <strong>parallelization</strong> در پردازنده‌های <strong>stream</strong>
        نیز بسیار شبیه به الگوهای موجود در <strong>MapReduce</strong> و موتورهای
        <strong>dataflow</strong> که ما در فصل 10 دیدیم، هستند، بنابراین ما این
        موضوعات را در اینجا تکرار نخواهیم کرد. عملیات <strong>mapping</strong>
        اساسی مانند تبدیل و فیلتر کردن رکوردها نیز یکسان عمل می‌کنند.
    </p>
<p>
        یک تفاوت اساسی با jobs های <strong>batch</strong> این است که یک <strong>stream</strong>
        هرگز پایان نمی‌یابد. این تفاوت پیامدهای زیادی دارد: همان‌طور که در
        ابتدای این فصل بحث شد، مرتب‌سازی با یک مجموعه داده‌ی <em>unbounded</em>
        منطقی نیست، و بنابراین <strong>sort-merge joins</strong> (نگاه کنید به
        "<strong>Reduce-Side Joins</strong> و گروه‌بندی" در صفحه 403) نمی‌توانند
        استفاده شوند. مکانیسم‌های تحمل خطا نیز باید
        464
        |
        فصل 11: پردازش <strong>Stream</strong>
</p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0486</div>
            </div>
        </div>
        <!-- Page 0487 -->
        <div class="chapter" id="page-0487">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        تغییر: با یک job <strong>batch</strong> که برای چند دقیقه در حال اجرا است، یک
        <strong>task</strong> شکست‌خورده می‌تواند به‌سادگی از ابتدا راه‌اندازی مجدد
        شود، اما با یک job <strong>stream</strong> که برای چندین سال در حال اجرا
        است، راه‌اندازی مجدد از ابتدا پس از یک <strong>crash</strong> ممکن است یک
        گزینه مناسب نباشد.
    </p>
<h4>موارد استفاده از پردازش <strong>Stream</strong></h4>
<p>
        پردازش <strong>stream</strong> مدت‌هاست که برای اهداف <strong>monitoring</strong> استفاده
        می‌شود، که در آن یک سازمان می‌خواهد اگر چیزهای خاصی اتفاق
        افتادند، هشدار داده شود. به عنوان مثال:
    </p>
<ul>
<li>
            سیستم‌های تشخیص کلاهبرداری باید تعیین کنند که آیا الگوهای
            استفاده از یک کارت اعتباری به‌طور غیرمنتظره‌ای تغییر
            کرده‌اند، و در صورت سرقت احتمالی کارت را مسدود کنند.
        </li>
<li>
            سیستم‌های معاملاتی باید تغییرات قیمت را در یک بازار مالی بررسی
            کنند و معاملات را طبق قوانین مشخص شده اجرا کنند.
        </li>
<li>
            سیستم‌های تولیدی باید وضعیت ماشین‌ها را در یک کارخانه نظارت
            کنند، و در صورت وجود نقص، سریعاً مشکل را شناسایی کنند.
        </li>
<li>
            سیستم‌های نظامی و اطلاعاتی باید فعالیت‌های یک مهاجم بالقوه
            را پیگیری کنند، و اگر نشانه‌هایی از حمله وجود داشته باشد،
            زنگ خطر را به صدا درآورند.
        </li>
</ul>
<p>
        این نوع برنامه‌ها به مطابقت الگو و همبستگی بسیار پیچیده نیاز
        دارند. با این حال، سایر موارد استفاده از پردازش <strong>stream</strong> نیز در
        طول زمان ظاهر شده‌اند. در این بخش ما به طور خلاصه برخی از این
        برنامه‌ها را مقایسه و با هم مقایسه خواهیم کرد.
    </p>
<h4>پردازش رویداد پیچیده</h4>
<p>
        پردازش رویداد پیچیده (<strong>CEP</strong>) رویکردی است که در دهه 1990 برای
        تجزیه و تحلیل جریان‌های رویداد توسعه یافت، به‌ویژه متناسب با
        نوع برنامه‌ای که نیاز به جستجوی الگوهای رویداد خاصی دارد [65، 66].
        مشابه روشی که یک عبارت منظم به شما اجازه می‌دهد الگوهای
        خاصی از کاراکترها را در یک رشته جستجو کنید، <strong>CEP</strong> به شما اجازه
        می‌دهد قوانینی را برای جستجوی الگوهای خاصی از رویدادها در یک
        <strong>stream</strong> مشخص کنید.
    </p>
<p>
        سیستم‌های <strong>CEP</strong> اغلب از یک زبان query اعلانی سطح بالا مانند
        <strong>SQL</strong> یا یک <strong>user interface</strong> گرافیکی برای توصیف الگوهای
        رویدادهایی که باید شناسایی شوند، استفاده می‌کنند. این <strong>queries</strong>
        به یک موتور پردازش ارسال می‌شوند که <strong>streams</strong> ورودی را مصرف
        می‌کند و در داخل یک <strong>state machine</strong> را حفظ می‌کند که
        <strong>matching</strong> مورد نیاز را انجام می‌دهد. هنگامی که یک <strong>match</strong>
        پیدا شد، موتور یک رویداد پیچیده (از این‌رو نام آن) را با جزئیات
        الگوی رویداد که شناسایی شده است، منتشر می‌کند [67].
    </p>
<p>
        در این سیستم‌ها، رابطه‌ی بین <strong>queries</strong> و داده‌ها، در مقایسه با
        پایگاه‌های داده‌ی معمولی، معکوس است. معمولاً، یک پایگاه داده
        داده‌ها را به‌طور دائمی ذخیره می‌کند و با <strong>queries</strong> به عنوان
        <em>transient</em> رفتار می‌کند: هنگامی که یک <strong>query</strong> وارد می‌شود،
        پایگاه داده به‌دنبال داده‌هایی می‌گردد که با <strong>query</strong> مطابقت دارند،
        و سپس زمانی‌که کارش تمام شد، <strong>query</strong> را فراموش می‌کند. موتورهای
        <strong>CEP</strong> این نقش‌ها را معکوس می‌کنند: <strong>queries</strong> بلندمدت
        ذخیره می‌شوند، و رویدادها از <strong>streams</strong> ورودی به‌طور مداوم
        از آن‌ها عبور می‌کنند در جستجوی یک <strong>query</strong> که با یک الگوی
        رویداد مطابقت دارد [68].
        پردازش جریان‌ها
        |
        465
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0487</div>
            </div>
        </div>
        <!-- Page 0488 -->
        <div class="chapter" id="page-0488">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        پیاده‌سازی‌های <strong>CEP</strong> شامل <strong>Esper</strong> [69]، <strong>IBM InfoSphere
        Streams</strong> [70]، <strong>Apama</strong>، <strong>TIBCO StreamBase</strong> و
        <strong>SQLstream</strong> است. پردازنده‌های <strong>stream</strong> توزیع شده مانند
        <strong>Samza</strong> نیز در حال به‌دست آوردن پشتیبانی <strong>SQL</strong> برای <strong>queries</strong>
        اعلانی بر روی جریان‌ها هستند [71].
    </p>
<h4>تجزیه و تحلیل <strong>Stream</strong></h4>
<p>
        یک حوزه‌ی دیگر که در آن از پردازش <strong>stream</strong> استفاده می‌شود، برای
        تجزیه و تحلیل جریان‌ها است. مرز بین <strong>CEP</strong> و تجزیه و تحلیل <strong>stream</strong>
<em>blurry</em> است، اما به‌عنوان یک قانون کلی، تجزیه و تحلیل تمایل دارد که
        کمتر به یافتن توالی رویدادهای خاص علاقه‌مند باشد و بیشتر به سمت
        تجمعات و معیارهای آماری در مورد تعداد زیادی از رویدادها هدایت
        می‌شود—به عنوان مثال:
    </p>
<ul>
<li>
            اندازه‌گیری نرخ برخی از انواع رویداد (چند بار در هر بازه‌ی زمانی
            رخ می‌دهد)
        </li>
<li>
            محاسبه میانگین متحرک یک مقدار در یک دوره‌ی زمانی
        </li>
<li>
            مقایسه آمار فعلی با بازه‌های زمانی قبلی (به عنوان مثال، برای
            تشخیص روندها یا هشدار در مورد معیارهایی که در مقایسه با زمان
            مشابه هفته‌ی گذشته به‌طور غیرعادی بالا یا پایین هستند)
        </li>
</ul>
<p>
        چنین آماری معمولاً در بازه‌های زمانی ثابت محاسبه می‌شود—به عنوان
        مثال، شما ممکن است بخواهید تعداد متوسط <strong>queries</strong> در ثانیه را به یک
        <strong>service</strong> در 5 دقیقه گذشته، و زمان پاسخگویی 99 <em>percentile</em> آن‌ها
        در طول آن دوره بدانید. میانگین‌گیری در طی چند دقیقه، نوسانات بی‌ربط
        را از یک ثانیه به ثانیه بعد هموار می‌کند، در حالی که همچنان یک
        تصویر به موقع از هرگونه تغییر در الگوی ترافیک به شما می‌دهد.
        بازه‌ی زمانی که شما در آن تجمیع می‌کنید، به عنوان یک <strong>window</strong>
        شناخته می‌شود، و ما در "استدلال در مورد زمان" در صفحه 468 با
        <strong>windowing</strong> با جزئیات بیشتری نگاه خواهیم کرد.
    </p>
<p>
        سیستم‌های تجزیه و تحلیل <strong>stream</strong> گاهی اوقات از الگوریتم‌های
        احتمالی، مانند <strong>Bloom filters</strong> (که ما در "بهینه‌سازی‌های
        عملکرد" در صفحه 79 با آن‌ها مواجه شدیم) برای <strong>set membership</strong>،
        <strong>HyperLogLog</strong> [72] برای برآورد <strong>cardinality</strong>، و
        الگوریتم‌های مختلف برآورد <em>percentile</em> (نگاه کنید به "<strong>Percentiles in
        Practice</strong>" در صفحه 16) استفاده می‌کنند. الگوریتم‌های احتمالی
        نتایج تقریبی تولید می‌کنند، اما این مزیت را دارند که به حافظه‌ی
        بسیار کمتری در پردازنده <strong>stream</strong> نسبت به الگوریتم‌های دقیق
        نیاز دارند. این استفاده از الگوریتم‌های <em>approximation</em> گاهی اوقات
        مردم را به این باور می‌رساند که سیستم‌های پردازش <strong>stream</strong> همیشه
        <em>lossy</em> و نادرست هستند، اما این اشتباه است: هیچ چیز ذاتاً تقریبی در
        مورد پردازش <strong>stream</strong> وجود ندارد، و الگوریتم‌های احتمالی صرفاً
        یک بهینه‌سازی هستند [73].
    </p>
<p>
        بسیاری از فریم‌ورک‌های پردازش <strong>stream</strong> توزیع شده‌ی منبع باز با
        تجزیه و تحلیل در ذهن طراحی شده‌اند: به عنوان مثال، <strong>Apache Storm</strong>،
        <strong>Spark Streaming</strong>، <strong>Flink</strong>، <strong>Concord</strong>، <strong>Samza</strong>، و
        <strong>Kafka Streams</strong> [74]. خدمات <strong>hosted</strong> شامل <strong>Google Cloud
        Dataflow</strong> و <strong>Azure Stream Analytics</strong> هستند.
        466
        |
        فصل 11: پردازش <strong>Stream</strong>
</p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0488</div>
            </div>
        </div>
        <!-- Page 0489 -->
        <div class="chapter" id="page-0489">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<h4>حفظ <strong>materialized views</strong></h4>
<p>
        ما در "پایگاه‌های داده و جریان‌ها" در صفحه 451 دیدیم که یک جریان از
        تغییرات در یک پایگاه داده می‌تواند برای به‌روز نگه داشتن سیستم‌های
        داده مشتق شده، مانند <strong>caches</strong>، <strong>search indexes</strong> و انبارهای داده،
        با یک پایگاه داده منبع، استفاده شود. ما می‌توانیم این مثال‌ها را به عنوان
        موارد خاصی از حفظ <strong>materialized views</strong> در نظر بگیریم (نگاه کنید به
        "تجمیع: <strong>Data Cubes</strong> و <strong>Materialized Views</strong>" در صفحه 101):
        استخراج یک <strong>view</strong> جایگزین بر روی برخی مجموعه‌داده‌ها به طوری
        که شما بتوانید آن را به‌طور کارآمد query کنید، و به‌روزرسانی آن
        <strong>view</strong> هر زمان که داده‌های اساسی تغییر می‌کنند [50].
    </p>
<p>
        به‌طور مشابه، در <strong>event sourcing</strong>، وضعیت برنامه با اعمال یک <strong>log</strong>
        از رویدادها حفظ می‌شود؛ در اینجا، وضعیت برنامه نیز نوعی
        <strong>materialized view</strong> است. بر خلاف سناریوهای تجزیه و تحلیل <strong>stream</strong>،
        معمولاً کافی نیست که فقط رویدادها را در یک بازه‌ی زمانی در نظر
        بگیرید: ساختن <strong>materialized view</strong> به‌طور بالقوه به تمام رویدادها در
        طول یک دوره‌ی زمانی دلخواه نیاز دارد، به‌جز هر رویدادی که
        منسوخ شده باشد و ممکن است توسط <strong>log compaction</strong> دور
        ریخته شود (نگاه کنید به "<strong>Log compaction</strong>" در صفحه 456). در
        واقع، شما به یک <strong>window</strong> نیاز دارید که تا ابتدای زمان گسترش
        یابد.
    </p>
<p>
        در اصل، هر پردازنده <strong>stream</strong> می‌تواند برای حفظ <strong>materialized
        view</strong> استفاده شود، اگرچه نیاز به حفظ رویدادها برای همیشه با
        فرضیات برخی از فریم‌ورک‌های <em>analytics-oriented</em> که عمدتاً بر روی
        <strong>windows</strong> با مدت زمان محدود کار می‌کنند، مغایرت دارد.
        <strong>Samza</strong> و <strong>Kafka Streams</strong> از این نوع استفاده، با تکیه بر
        پشتیبانی <strong>log compaction</strong> از <strong>Kafka</strong> پشتیبانی
        می‌کنند [75].
    </p>
<h4>جستجو در <strong>streams</strong></h4>
<p>
        علاوه بر <strong>CEP</strong>، که امکان جستجوی الگوهایی را که شامل رویدادهای
        متعدد می‌شوند، فراهم می‌کند، گاهی اوقات نیاز به جستجوی رویدادهای
        فردی بر اساس معیارهای پیچیده، مانند <strong>full-text search queries</strong>
        وجود دارد.
    </p>
<p>
        به عنوان مثال، خدمات <strong>media monitoring</strong> به فیدهای مقالات خبری و
        پخش از رسانه‌ها <strong>subscribe</strong> می‌کنند، و به‌دنبال هر خبری که
        شرکت‌ها، محصولات یا موضوعات مورد علاقه را ذکر می‌کند،
        می‌گردند. این کار با فرمول‌بندی یک <strong>search query</strong> از قبل، و سپس
        به‌طور مداوم <strong>matching</strong> <strong>stream</strong> از آیتم‌های خبری در برابر
        این <strong>query</strong> انجام می‌شود. ویژگی‌های مشابهی در برخی از وب‌سایت‌ها
        وجود دارد: به عنوان مثال، کاربران وب‌سایت‌های املاک و مستغلات
        می‌توانند درخواست کنند که هنگام ظاهر شدن یک ملک جدید که با
        معیارهای جستجوی آن‌ها مطابقت دارد، در بازار، مطلع شوند. ویژگی
        <strong>percolator</strong> از <strong>Elasticsearch</strong> [76] یک گزینه برای
        پیاده‌سازی این نوع جستجوی <strong>stream</strong> است.
    </p>
<p>
        موتورهای جستجوی معمولی ابتدا اسناد را <strong>index</strong> می‌کنند و سپس
        queries ها را روی <strong>index</strong> اجرا می‌کنند. در مقابل، جستجوی یک
        <strong>stream</strong>، پردازش را برعکس می‌کند: <strong>queries</strong> ذخیره
        می‌شوند، و اسناد از کنار <strong>queries</strong> عبور می‌کنند، مانند
        <strong>CEP</strong>. در ساده‌ترین حالت، شما می‌توانید هر سند را در برابر هر
        <strong>query</strong> آزمایش کنید، اگرچه این کار می‌تواند کند شود اگر شما
        تعداد زیادی <strong>query</strong> داشته باشید. برای بهینه‌سازی فرآیند،
        index کردن <strong>queries</strong> و همچنین اسناد، و در نتیجه محدود
        کردن مجموعه <strong>queries</strong> که ممکن است <strong>match</strong> داشته
        باشند، امکان‌پذیر است [77].
        پایگاه‌های داده و جریان‌ها
        |
        467
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0489</div>
            </div>
        </div>
        <!-- Page 0490 -->
        <div class="chapter" id="page-0490">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        پیام‌رسانی و <strong>RPC</strong>
</p>
<p>
        در "<strong>Message-Passing Dataflow</strong>" در صفحه 136 ما در مورد سیستم‌های
        پیام‌رسانی به‌عنوان جایگزینی برای <strong>RPC</strong> بحث کردیم—یعنی، به‌عنوان
        یک مکانیسم برای ارتباط <strong>services</strong>، که به عنوان مثال در مدل
        <strong>actor</strong> استفاده می‌شود. اگرچه این سیستم‌ها نیز بر اساس پیام‌ها و
        رویدادها هستند، ما معمولاً آن‌ها را به عنوان پردازنده‌های <strong>stream</strong>
        در نظر نمی‌گیریم:
    </p>
<ul>
<li>
            فریم‌ورک‌های <strong>Actor</strong> در درجه‌ی اول یک مکانیسم برای
            مدیریت <strong>concurrency</strong> و اجرای توزیع شده ماژول‌های ارتباطی
            هستند، در حالی که پردازش <strong>stream</strong> در درجه‌ی اول یک تکنیک
            مدیریت داده‌ها است.
        </li>
<li>
            ارتباط بین <strong>actors</strong> اغلب <em>ephemeral</em> و <em>one-to-one</em> است، در
            حالی که <strong>event logs</strong> <em>durable</em> و چند <strong>subscriber</strong>
            هستند.
        </li>
<li>
<strong>Actors</strong> می‌توانند به روش‌های دلخواه (از جمله الگوهای
            درخواست/پاسخ چرخه‌ای) ارتباط برقرار کنند، اما پردازنده‌های
            <strong>stream</strong> معمولاً در <strong>pipelines</strong> غیر چرخه‌ای تنظیم
            می‌شوند که در آن هر <strong>stream</strong> خروجی یک job خاص است، و
            از یک مجموعه تعریف شده از <strong>streams</strong> ورودی مشتق شده
            است.
        </li>
</ul>
<p>
        گفته می‌شود، برخی از زمینه‌های مشترک بین سیستم‌های شبیه <strong>RPC</strong> و
        پردازش <strong>stream</strong> وجود دارد. به عنوان مثال، <strong>Apache Storm</strong>
        دارای یک <strong>feature</strong> است که به آن <strong>distributed RPC</strong>
        می‌گویند، که به <strong>queries</strong> کاربر اجازه می‌دهد به مجموعه‌ای از
        <strong>nodes</strong> منتقل شوند که <strong>streams</strong> رویداد را نیز پردازش
        می‌کنند؛ سپس این <strong>queries</strong> با رویدادها از <strong>streams</strong> ورودی
        تداخل دارند، و نتایج را می‌توان تجمیع کرد و به کاربر بازگرداند [78].
        (همچنین به "پردازش داده‌های چند <strong>partition</strong>" در صفحه 514 مراجعه
        کنید.)
    </p>
<p>
        همچنین می‌توان از فریم‌ورک‌های <strong>actor</strong> برای پردازش جریان‌ها
        استفاده کرد. با این حال، بسیاری از این فریم‌ورک‌ها، تحویل پیام را در
        صورت <strong>crashes</strong> تضمین نمی‌کنند، بنابراین پردازش تحمل خطا
        نیست مگر این‌که شما منطق تکرار اضافی را پیاده‌سازی کنید.
    </p>
<h4>استدلال در مورد زمان</h4>
<p>
        پردازنده‌های <strong>stream</strong> اغلب نیاز به برخورد با زمان دارند، به
        ویژه زمانی که برای اهداف <strong>analytics</strong> استفاده می‌شوند، که
        اغلب از <strong>time windows</strong> مانند "میانگین در 5 دقیقه
        گذشته" استفاده می‌کنند. ممکن است به نظر برسد که معنای "5 دقیقه
        گذشته" باید صریح و روشن باشد، اما متأسفانه این مفهوم به‌طور
        شگفت‌انگیزی پیچیده است.
    </p>
<p>
        در یک فرآیند <strong>batch</strong>، وظایف پردازش به‌سرعت از طریق مجموعه‌ی
        بزرگی از رویدادهای تاریخی <strong>crunch</strong> می‌شوند. اگر نوعی تقسیم بر
        اساس زمان باید رخ دهد، فرآیند <strong>batch</strong> باید به <strong>timestamp</strong>
        تعبیه شده در هر رویداد نگاه کند. نگاه کردن به ساعت سیستم
        ماشینی که فرآیند <strong>batch</strong> را اجرا می‌کند، بی‌فایده است، زیرا
        زمانی که فرآیند اجرا می‌شود هیچ ارتباطی با زمانی که رویدادها واقعاً
        رخ داده‌اند، ندارد.
    </p>
<p>
        یک فرآیند <strong>batch</strong> ممکن است ارزش رویدادهای تاریخی یک سال را در
        عرض چند دقیقه بخواند؛ در بیشتر موارد، جدول زمانی مورد نظر سال
        تاریخ است، نه چند دقیقه پردازش. علاوه بر این، استفاده از
        <strong>timestamps</strong> در رویدادها به پردازش اجازه می‌دهد که
        468
        |
        فصل 11: پردازش <strong>Stream</strong>
</p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0490</div>
            </div>
        </div>
        <!-- Page 0491 -->
        <div class="chapter" id="page-0491">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        ii. تشکر از <strong>Kostas Kloudas</strong> از جامعه <strong>Flink</strong> برای
        ارائه این قیاس.
    </p>
<p>
<em>deterministic</em>: اجرای دوباره‌ی همان فرآیند بر روی ورودی یکسان،
        نتیجه‌ی یکسانی را به دست می‌دهد (نگاه کنید به "تحمل خطا" در صفحه
        422).
    </p>
<p>
        از سوی دیگر، بسیاری از فریم‌ورک‌های پردازش <strong>stream</strong> از ساعت
        سیستم محلی روی ماشین پردازش (زمان پردازش) برای تعیین
        <strong>windowing</strong> استفاده می‌کنند [79]. این رویکرد این مزیت را دارد که
        ساده است، و اگر تأخیر بین ایجاد رویداد و پردازش رویداد به‌طور
        ناچیز کوتاه باشد، منطقی است. با این حال، اگر هر گونه تأخیر
        پردازشی قابل توجهی وجود داشته باشد—یعنی، اگر پردازش ممکن است
        به‌طور محسوسی دیرتر از زمانی که رویداد واقعاً رخ داده است،
        اتفاق بیفتد، این رویکرد از کار می‌افتد.
    </p>
<h4>زمان رویداد در مقابل زمان پردازش</h4>
<p>
        دلایل زیادی وجود دارد که چرا ممکن است پردازش به تأخیر بیفتد:
        صف‌بندی، خطاهای شبکه (نگاه کنید به "شبکه‌های غیرقابل اعتماد" در
        صفحه 277)، یک مشکل عملکردی که منجر به <em>contention</em> در
        <strong>message broker</strong> یا پردازنده می‌شود، راه‌اندازی مجدد
        <strong>stream consumer</strong>، یا <em>reprocessing</em> رویدادهای گذشته (نگاه
        کنید به "پخش مجدد پیام‌های قدیمی" در صفحه 451) در حین بازیابی از
        یک خطا یا پس از رفع یک <strong>bug</strong> در کد.
    </p>
<p>
        علاوه بر این، تأخیر پیام‌ها همچنین می‌تواند منجر به <strong>ordering</strong>
        غیرقابل پیش‌بینی پیام‌ها شود. به عنوان مثال، فرض کنید یک کاربر
        ابتدا یک درخواست وب را انجام می‌دهد (که توسط سرور وب A رسیدگی
        می‌شود)، و سپس یک درخواست دوم (که توسط سرور B رسیدگی
        می‌شود). A و B رویدادهایی را منتشر می‌کنند که درخواست‌هایی را که
        مدیریت کرده‌اند، شرح می‌دهد، اما رویداد B قبل از رویداد A به
        <strong>message broker</strong> می‌رسد. اکنون پردازنده‌های <strong>stream</strong>
        ابتدا رویداد B و سپس رویداد A را خواهند دید، حتی اگر در واقع
        به ترتیب معکوس رخ داده باشند.
    </p>
<p>
        اگر این کمک می‌کند که یک قیاس داشته باشید، فیلم‌های <strong>Star Wars</strong> را
        در نظر بگیرید: قسمت IV در سال 1977، قسمت V در سال 1980، و
        قسمت VI در سال 1983 منتشر شد، که پس از آن قسمت‌های I، II و III
        در سال‌های 1999، 2002 و 2005 به ترتیب منتشر شدند، و قسمت VII
        در سال 2015 [80].ii اگر شما فیلم‌ها را به ترتیبی که منتشر شدند
        تماشا کردید، ترتیبی که در آن شما فیلم‌ها را پردازش کردید، با
        ترتیب روایت آن‌ها ناسازگار است. (شماره قسمت مانند <strong>timestamp</strong>
        رویداد است، و تاریخی که شما فیلم را تماشا کردید، زمان پردازش
        است.) به عنوان انسان، ما می‌توانیم با چنین ناپیوستگی‌هایی مقابله
        کنیم، اما الگوریتم‌های پردازش <strong>stream</strong> باید به‌طور خاص برای
        انطباق با این مسائل زمانی و <strong>ordering</strong> نوشته شوند.
    </p>
<p>
        گیج کردن زمان رویداد و زمان پردازش منجر به داده‌های بد می‌شود. به
        عنوان مثال، فرض کنید شما یک پردازنده <strong>stream</strong> دارید که نرخ
        درخواست‌ها را اندازه‌گیری می‌کند (شمارش تعداد درخواست‌ها در ثانیه).
        اگر شما پردازنده <strong>stream</strong> را دوباره مستقر کنید، ممکن است به
        مدت یک دقیقه خاموش شود و <strong>backlog</strong> رویدادها را هنگام
        بازگشت به کار، پردازش کند. اگر شما نرخ را بر اساس زمان پردازش
        اندازه‌گیری کنید، این‌طور به نظر می‌رسد که یک افزایش ناگهانی
        <em>anomalous</em> از درخواست‌ها در حین پردازش <strong>backlog</strong> وجود
        داشت، در حالی‌که در واقع نرخ واقعی درخواست‌ها ثابت بود (شکل 11-7).
        پردازش جریان‌ها
        |
        469
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0491</div>
            </div>
        </div>
        <!-- Page 0492 -->
        <div class="chapter" id="page-0492">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        شکل 11-7. <strong>Windowing</strong> بر اساس زمان پردازش، مصنوعاتی را به
        دلیل تغییرات در نرخ پردازش معرفی می‌کند.
    </p>
<h4>دانستن این‌که چه زمانی آماده هستید</h4>
<p>
        یک مشکل دشوار هنگام تعریف <strong>windows</strong> از نظر زمان رویداد این
        است که شما هرگز نمی‌توانید مطمئن باشید که تمام رویدادها را برای یک
        <strong>window</strong> خاص دریافت کرده‌اید، یا این‌که آیا هنوز رویدادهایی
        در راه هستند.
    </p>
<p>
        به عنوان مثال، فرض کنید شما رویدادها را در <strong>windows</strong>های یک
        دقیقه‌ای گروه‌بندی می‌کنید تا بتوانید تعداد درخواست‌ها در هر دقیقه را
        شمارش کنید. شما تعدادی رویداد را با <strong>timestamps</strong> که در
        دقیقه 37 از ساعت قرار می‌گیرند، شمارش کرده‌اید، و زمان
        گذشته است؛ اکنون بیشتر رویدادهای ورودی در دقایق 38 و 39 از
        ساعت قرار می‌گیرند. چه زمانی شما اعلام می‌کنید که <strong>window</strong>
        برای دقیقه 37 را تمام کرده‌اید، و مقدار <strong>counter</strong> آن را
        خروجی می‌دهید؟
    </p>
<p>
        شما می‌توانید <em>timeout</em> کنید و بعد از این‌که مدتی هیچ رویداد
        جدیدی را ندیده‌اید، یک <strong>window</strong> را آماده اعلام کنید، اما
        هنوز هم ممکن است اتفاق بیفتد که برخی از رویدادها در جای دیگری روی
        یک ماشین دیگر <strong>buffered</strong> شده‌اند، که به دلیل یک
        <em>network interruption</em> به تأخیر افتاده‌اند. شما باید قادر باشید
        به چنین رویدادهای <em>straggler</em> که پس از این‌که <strong>window</strong>
        قبلاً کامل اعلام شده است، رسیدگی کنید. به‌طور کلی، شما دو
        گزینه دارید [1]:
    </p>
<ol>
<li>
            نادیده گرفتن رویدادهای <em>straggler</em>، زیرا آن‌ها احتمالاً درصد کمی
            از رویدادها را در شرایط عادی تشکیل می‌دهند. شما می‌توانید تعداد
            رویدادهای <em>dropped</em> را به‌عنوان یک معیار پیگیری کنید، و
            در صورت شروع <em>dropping</em> یک مقدار قابل توجهی از داده‌ها، هشدار
            دهید.
        </li>
<li>
            یک اصلاحیه منتشر کنید، یک مقدار به‌روز شده برای <strong>window</strong>
            شامل <em>stragglers</em>. شما همچنین ممکن است نیاز داشته باشید که
            خروجی قبلی را <em>retract</em> کنید.
        </li>
</ol>
<p>
        470
        |
        فصل 11: پردازش <strong>Stream</strong>
</p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 492" src="page_0492/image_1.png"/></div>
</div>
                <div class="page-number">صفحه 0492</div>
            </div>
        </div>
        <!-- Page 0493 -->
        <div class="chapter" id="page-0493">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        در برخی موارد، استفاده از یک پیام ویژه برای نشان دادن این‌که، "از این
        به بعد دیگر هیچ پیامی با <strong>timestamp</strong> زودتر از t وجود
        نخواهد داشت" امکان‌پذیر است، که می‌تواند توسط <strong>consumers</strong>
        برای راه‌اندازی <strong>windows</strong> استفاده شود [81]. با این حال، اگر
        چندین <strong>producer</strong> روی ماشین‌های مختلف در حال تولید رویدادها
        هستند، که هر کدام دارای آستانه‌های <strong>timestamp</strong> حداقل خود
        هستند، <strong>consumers</strong> نیاز دارند که هر <strong>producer</strong> را به‌صورت
        جداگانه پیگیری کنند. اضافه کردن و حذف <strong>producers</strong> در این
        مورد دشوارتر است.
    </p>
<h4>به هر حال از ساعت چه کسی استفاده می‌کنید؟</h4>
<p>
        اختصاص دادن <strong>timestamps</strong> به رویدادها، حتی زمانی که رویدادها
        می‌توانند در چندین نقطه از سیستم <strong>buffered</strong> شوند، دشوارتر
        است. به عنوان مثال، یک برنامه تلفن همراه را در نظر بگیرید که
        رویدادهایی را برای معیارهای استفاده به یک سرور گزارش می‌دهد. این
        برنامه ممکن است در حالی‌که دستگاه <em>offline</em> است، استفاده شود، که
        در این صورت رویدادها را به‌طور محلی روی دستگاه <strong>buffer</strong> می‌کند
        و آن‌ها را زمانی که اتصال به اینترنت دوباره در دسترس قرار گرفت
        (که ممکن است ساعت‌ها یا حتی روزها بعد باشد) به یک سرور ارسال
        می‌کند. برای هر <strong>consumers</strong> از این <strong>stream</strong>، رویدادها
        به‌عنوان <em>stragglers</em> بسیار تأخیردار ظاهر می‌شوند.
    </p>
<p>
        در این <strong>context</strong>، <strong>timestamp</strong> روی رویدادها واقعاً باید
        زمانی باشد که تعامل کاربر رخ داده است، طبق ساعت محلی دستگاه
        تلفن همراه. با این حال، ساعت روی یک دستگاه کنترل‌شده توسط
        کاربر اغلب قابل اعتماد نیست، زیرا ممکن است به‌طور تصادفی یا
        عمدی روی زمان اشتباه تنظیم شده باشد (نگاه کنید به "همگام‌سازی
        ساعت و دقت" در صفحه 289). زمانی که رویداد توسط سرور دریافت
        شد (طبق ساعت سرور) احتمالاً دقیق‌تر است، زیرا سرور تحت کنترل
        شما است، اما از نظر توصیف تعامل کاربر، کم‌اهمیت‌تر است.
    </p>
<p>
        برای تنظیم ساعت‌های نادرست دستگاه، یک رویکرد این است که سه
        <strong>timestamps</strong> را ثبت کنید [82]:
    </p>
<ul>
<li>
            زمانی که رویداد رخ داد، طبق ساعت دستگاه
        </li>
<li>
            زمانی که رویداد به سرور ارسال شد، طبق ساعت دستگاه
        </li>
<li>
            زمانی که رویداد توسط سرور دریافت شد، طبق ساعت سرور
        </li>
</ul>
<p>
        با تفریق <strong>timestamp</strong> دوم از سوم، شما می‌توانید <strong>offset</strong> را
        بین ساعت دستگاه و ساعت سرور تخمین بزنید (با فرض این‌که تأخیر
        شبکه در مقایسه با دقت <strong>timestamp</strong> مورد نیاز، ناچیز
        باشد). سپس شما می‌توانید آن <strong>offset</strong> را به <strong>timestamp</strong>
        رویداد اعمال کنید، و در نتیجه زمان واقعی را که در آن رویداد
        واقعاً رخ داده است، تخمین بزنید (با فرض این‌که <strong>device clock
        offset</strong> بین زمانی که رویداد رخ داده است و زمانی که به سرور
        ارسال شده است، تغییر نکرده باشد).
    </p>
<p>
        این مشکل مختص پردازش <strong>stream</strong> نیست—پردازش <strong>batch</strong>
        از همان مسائل استدلال در مورد زمان رنج می‌برد. این فقط در یک
        <strong>context</strong> <strong>streaming</strong> بیشتر قابل توجه است، که ما
        بیشتر از گذر زمان آگاه هستیم.
        پردازش جریان‌ها
        |
        471
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0493</div>
            </div>
        </div>
        <!-- Page 0494 -->
        <div class="chapter" id="page-0494">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<h4>انواع <strong>windows</strong></h4>
<p>
        هنگامی که شما می‌دانید که چگونه باید <strong>timestamp</strong> یک رویداد را
        تعیین کنید، گام بعدی این است که تصمیم بگیرید که چگونه باید
        <strong>windows</strong> ها را در دوره‌های زمانی تعریف کنید. سپس می‌توان
        از <strong>window</strong> برای تجمیع‌ها استفاده کرد، به عنوان مثال برای
        شمارش رویدادها، یا برای محاسبه‌ی میانگین مقادیر در داخل
        <strong>window</strong>. چندین نوع از <strong>windows</strong> در استفاده‌ی
        رایج هستند [79, 83]:
    </p>
<ul>
<li>
<strong>Tumbling window</strong>
</li>
<p>
            یک <strong>tumbling window</strong> دارای طول ثابتی است، و هر رویداد
            دقیقاً به یک <strong>window</strong> تعلق دارد. به عنوان مثال، اگر شما یک
            <strong>tumbling window</strong> یک دقیقه‌ای دارید، تمام رویدادها با
            <strong>timestamps</strong> بین 10:03:00 و 10:03:59 در یک
            <strong>window</strong> گروه‌بندی می‌شوند، رویدادها بین 10:04:00 و
            10:04:59 در <strong>window</strong> بعدی، و به همین ترتیب. شما می‌توانید
            یک <strong>tumbling window</strong> یک دقیقه‌ای را با گرفتن هر
            <strong>timestamp</strong> رویداد و گرد کردن آن به نزدیک‌ترین دقیقه برای
            تعیین <strong>window</strong> ای که به آن تعلق دارد، پیاده‌سازی کنید.
        </p>
<li>
<strong>Hopping window</strong>
</li>
<p>
            یک <strong>hopping window</strong> نیز دارای طول ثابتی است، اما به
            <strong>windows</strong> اجازه می‌دهد که برای ارائه مقداری <strong>smoothing</strong>
            همپوشانی داشته باشند. به عنوان مثال، یک <strong>window</strong> 5 دقیقه‌ای
            با یک اندازه <strong>hop</strong> از 1 دقیقه شامل رویدادها بین 10:03:00 و
            10:07:59 خواهد بود، سپس <strong>window</strong> بعدی رویدادها را بین
            10:04:00 و 10:08:59 پوشش می‌دهد، و به همین ترتیب. شما می‌توانید
            این <strong>hopping window</strong> را با محاسبه ابتدا <strong>tumbling
            windows</strong> یک دقیقه‌ای، و سپس تجمیع بر روی چندین
            <strong>windows</strong> مجاور، پیاده‌سازی کنید.
        </p>
<li>
<strong>Sliding window</strong>
</li>
<p>
            یک <strong>sliding window</strong> شامل تمام رویدادهایی است که در یک
            فاصله‌ی زمانی رخ می‌دهند. به عنوان مثال، یک <strong>sliding
            window</strong> 5 دقیقه‌ای، رویدادها را در 10:03:39 و 10:08:12
            پوشش می‌دهد، زیرا آن‌ها کمتر از 5 دقیقه از هم فاصله دارند (توجه
            داشته باشید که <strong>windows</strong>های 5 دقیقه‌ای <strong>tumbling</strong> و
            <strong>hopping</strong> این دو رویداد را در یک <strong>window</strong> قرار
            نمی‌دادند، زیرا آن‌ها از <strong>boundaries</strong> ثابت استفاده می‌کنند).
            یک <strong>sliding window</strong> را می‌توان با نگه داشتن یک <strong>buffer</strong>
            از رویدادها که بر اساس زمان مرتب شده‌اند و حذف رویدادهای قدیمی
            هنگامی‌که از <strong>window</strong> منقضی می‌شوند، پیاده‌سازی کرد.
        </p>
<li>
<strong>Session window</strong>
</li>
<p>
            بر خلاف سایر انواع <strong>window</strong>، یک <strong>session window</strong>
            هیچ مدت زمان ثابتی ندارد. در عوض، با گروه‌بندی تمام رویدادها
            برای یک کاربر یکسان که در زمان با هم رخ می‌دهند، تعریف می‌شود،
            و <strong>window</strong> زمانی پایان می‌یابد که کاربر مدتی غیرفعال
            بوده است (به عنوان مثال، اگر هیچ رویدادی برای 30 دقیقه وجود
            نداشته باشد). <strong>Sessionization</strong> یک نیاز رایج برای تجزیه و
            تحلیل وب‌سایت است (نگاه کنید به "<strong>GROUP BY</strong>" در صفحه
            406).
        </p>
</ul>
<h4><strong>Stream Joins</strong></h4>
<p>
        در فصل 10 ما بحث کردیم که چگونه jobs های <strong>batch</strong> می‌توانند
        مجموعه‌داده‌ها را بر اساس <strong>key</strong> <strong>join</strong> کنند، و این‌که چگونه
        چنین <strong>joins</strong> ها بخشی مهم از <strong>data pipelines</strong> را
        تشکیل می‌دهند. از آن‌جایی که پردازش <strong>stream</strong> تعمیم می‌یابد
        472
        |
        فصل 11: پردازش <strong>Stream</strong>
</p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0494</div>
            </div>
        </div>
        <!-- Page 0495 -->
        <div class="chapter" id="page-0495">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
<strong>data pipelines</strong> به پردازش افزایشی مجموعه‌داده‌های <em>unbounded</em>،
        دقیقاً همان نیاز به <strong>joins</strong> در <strong>streams</strong> وجود دارد.
    </p>
<p>
        با این حال، این واقعیت که رویدادهای جدید می‌توانند در هر زمانی در یک
        <strong>stream</strong> ظاهر شوند، <strong>joins</strong> را در <strong>streams</strong>
        چالش‌برانگیزتر از jobs های <strong>batch</strong> می‌کند. برای درک بهتر
        شرایط، اجازه دهید سه نوع مختلف از <strong>joins</strong> را متمایز کنیم:
        <strong>stream-stream joins</strong>، <strong>stream-table joins</strong>، و <strong>table-table
        joins</strong> [84]. در بخش‌های زیر ما هر کدام را با مثال نشان خواهیم
        داد.
    </p>
<ul>
<li>
<strong>Stream-stream join (window join)</strong>
</li>
<p>
            فرض کنید شما یک <strong>feature</strong> جستجو در وب‌سایت خود دارید، و شما
            می‌خواهید روندهای اخیر در <strong>URLs</strong> جستجو شده را تشخیص
            دهید. هر بار که کسی یک <strong>query</strong> جستجو را تایپ می‌کند، شما یک
            رویداد حاوی <strong>query</strong> و نتایج بازگشتی را ثبت می‌کنید. هر بار که
            کسی روی یکی از نتایج جستجو کلیک می‌کند، شما یک رویداد دیگر را
            که کلیک را ثبت می‌کند، <strong>log</strong> می‌کنید. برای محاسبه‌ی
            نرخ <strong>click-through</strong> برای هر <strong>URL</strong> در نتایج جستجو، شما
            باید رویدادهای مربوط به اقدام جستجو و عمل کلیک را کنار هم
            بیاورید، که با داشتن <strong>session ID</strong> یکسان، به هم مرتبط
            هستند. تجزیه و تحلیل‌های مشابه در سیستم‌های تبلیغاتی مورد
            نیاز است [85].
        </p>
<p>
            اگر کاربر جستجوی خود را رها کند، ممکن است هرگز کلیک وجود
            نداشته باشد، و حتی اگر هم وجود داشته باشد، زمان بین جستجو و
            کلیک ممکن است بسیار متغیر باشد: در بسیاری از موارد ممکن است
            چند ثانیه باشد، اما می‌تواند به اندازه‌ی روزها یا هفته‌ها باشد
            (اگر یک کاربر جستجو را اجرا کند، زبانه مرورگر خود را فراموش
            کند، و سپس مدتی بعد به زبانه برگردد و روی یک نتیجه کلیک
            کند). با توجه به تأخیرهای متغیر شبکه، رویداد کلیک ممکن است
            حتی قبل از رویداد جستجو برسد. شما می‌توانید یک <strong>window</strong>
            مناسب برای <strong>join</strong> را انتخاب کنید—به عنوان مثال، شما
            می‌توانید انتخاب کنید که یک کلیک را با یک جستجو <strong>join</strong>
            کنید اگر آن‌ها حداکثر یک ساعت از هم فاصله داشته باشند.
        </p>
<p>
            توجه داشته باشید که جاسازی جزئیات جستجو در رویداد کلیک
            معادل <strong>joining</strong> رویدادها نیست: انجام این کار فقط در
            مورد مواردی به شما می‌گوید که کاربر روی یک نتیجه جستجو کلیک
            کرده است، نه در مورد جستجوهایی که کاربر روی هیچ‌یک از
            نتایج کلیک نکرده است. به منظور اندازه‌گیری کیفیت جستجو، شما
            به نرخ‌های <strong>click-through</strong> دقیق نیاز دارید، که برای آن‌ها به
            هر دو رویداد جستجو و رویداد کلیک نیاز دارید.
        </p>
<p>
            برای پیاده‌سازی این نوع <strong>join</strong>، یک پردازنده <strong>stream</strong>
            باید <strong>state</strong> را حفظ کند: به عنوان مثال، تمام رویدادهایی که
            در یک ساعت گذشته رخ داده‌اند، <strong>indexed</strong> توسط
            <strong>session ID</strong>. هر زمان که یک رویداد جستجو یا رویداد کلیک
            رخ می‌دهد، به <strong>index</strong> مناسب اضافه می‌شود، و
            پردازنده <strong>stream</strong> نیز <strong>index</strong> دیگر را بررسی می‌کند تا
            ببیند آیا رویداد دیگری برای همان <strong>session ID</strong> قبلاً
            رسیده است یا خیر. اگر یک رویداد <strong>matching</strong> وجود داشته
            باشد، شما یک رویداد را منتشر می‌کنید که می‌گوید روی کدام
            نتیجه جستجو کلیک شده است. اگر رویداد جستجو بدون این‌که شما
            یک رویداد کلیک <strong>matching</strong> را ببینید، منقضی شود، شما
            یک رویداد را منتشر می‌کنید که می‌گوید کدام نتایج جستجو
            کلیک نشده‌اند.
        </p>
<li>
<strong>Stream-table join (stream enrichment)</strong>
</li>
<p>
            در "مثال: تجزیه و تحلیل رویدادهای فعالیت کاربر" در صفحه 404 (شکل
            10-2) ما یک مثال از یک job <strong>batch</strong> را دیدیم که دو
            مجموعه‌داده را <strong>joining</strong> می‌کند: مجموعه‌ای از رویدادهای
            فعالیت کاربر و یک پایگاه داده از پروفایل‌های کاربر. طبیعی است که
            رویدادهای فعالیت کاربر را به‌عنوان یک <strong>stream</strong> در نظر
            بگیرید، و همان <strong>join</strong> را به‌طور مداوم در یک پردازنده
            <strong>stream</strong> انجام دهید: ورودی یک
            473
        
</p></ul>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0495</div>
            </div>
        </div>
        <!-- Page 0496 -->
        <div class="chapter" id="page-0496">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
<strong>stream</strong> رویدادهای فعالیت که حاوی یک <strong>ID</strong> کاربر
        هستند، و خروجی یک <strong>stream</strong> از رویدادهای فعالیتی است که در
        آن <strong>ID</strong> کاربر با اطلاعات پروفایل در مورد کاربر افزایش
        یافته است. این فرآیند گاهی اوقات به‌عنوان غنی‌سازی رویدادهای فعالیت
        با اطلاعات از پایگاه داده شناخته می‌شود.
    </p>
<p>
        برای انجام این <strong>join</strong>، فرآیند <strong>stream</strong> باید به یک
        رویداد فعالیت در یک زمان نگاه کند، <strong>ID</strong> کاربر رویداد را در
        پایگاه داده جستجو کند، و اطلاعات پروفایل را به رویداد فعالیت اضافه
        کند. <strong>lookup</strong> پایگاه داده می‌تواند با query کردن یک پایگاه
        داده‌ی راه دور پیاده‌سازی شود؛ با این حال، همان‌طور که در "مثال:
        تجزیه و تحلیل رویدادهای فعالیت کاربر" در صفحه 404 بحث شد، این
        queries های راه دور احتمالاً کند هستند و خطر <em>overloading</em> کردن
        پایگاه داده را دارند [75].
    </p>
<p>
        یک رویکرد دیگر این است که یک کپی از پایگاه داده را در پردازنده
        <strong>stream</strong> بارگذاری کنید تا بتوان آن را به‌صورت محلی بدون
        یک <em>network round-trip</em> <strong>queried</strong> کرد. این تکنیک بسیار
        شبیه به <strong>hash joins</strong> است که ما در "<strong>Map-Side Joins</strong>" در
        صفحه 408 بحث کردیم: کپی محلی پایگاه داده ممکن است یک جدول
        <strong>hash</strong> <em>in-memory</em> باشد اگر به‌اندازه‌ی کافی کوچک باشد، یا
        یک index روی دیسک محلی باشد.
    </p>
<p>
        تفاوت با jobs های <strong>batch</strong> این است که یک job <strong>batch</strong>
        از یک <strong>snapshot</strong> نقطه‌ای از پایگاه داده به عنوان ورودی
        استفاده می‌کند، در حالی که یک پردازنده <strong>stream</strong> طولانی
        مدت است، و محتویات پایگاه داده احتمالاً در طول زمان تغییر
        می‌کند، بنابراین کپی محلی پردازنده <strong>stream</strong> از پایگاه داده
        باید به‌روز نگه داشته شود. این مشکل را می‌توان با <strong>change data
        capture</strong> حل کرد: پردازنده <strong>stream</strong> می‌تواند به یک
        <strong>changelog</strong> از پایگاه داده‌ی پروفایل کاربر و همچنین
        <strong>stream</strong> رویدادهای فعالیت، <strong>subscribe</strong> کند. هنگامی که
        یک پروفایل ایجاد یا اصلاح می‌شود، پردازنده <strong>stream</strong> کپی
        محلی خود را به‌روزرسانی می‌کند. بنابراین، ما یک <strong>join</strong> بین دو
        <strong>streams</strong> به‌دست می‌آوریم: رویدادهای فعالیت و به‌روزرسانی‌های
        پروفایل.
    </p>
<p>
        یک <strong>stream-table join</strong> در واقع بسیار شبیه به یک <strong>stream-stream
        join</strong> است؛ بزرگترین تفاوت این است که برای <strong>changelog</strong>
<strong>stream</strong> جدول، <strong>join</strong> از یک <strong>window</strong> استفاده
        می‌کند که به "ابتدای زمان" (یک <strong>window</strong> از نظر مفهومی بی‌نهایت)
        می‌رسد، با نسخه‌های جدیدتر از رکوردها که نسخه‌های قدیمی‌تر را
        بازنویسی می‌کنند. برای ورودی <strong>stream</strong>، <strong>join</strong> ممکن است
        اصلاً <strong>window</strong> را حفظ نکند.
    </p>
<h4><strong>Table-table join (materialized view maintenance)</strong></h4>
<p>
        به مثال <strong>timeline</strong> <strong>Twitter</strong> که ما در "شرح <strong>Load</strong>" در
        صفحه 11 بحث کردیم، توجه کنید. ما گفتیم که وقتی یک کاربر
        می‌خواهد <strong>home timeline</strong> خود را مشاهده کند، تکرار روی تمام
        افرادی که کاربر دنبال می‌کند، پیدا کردن توییت‌های اخیر آن‌ها، و
        ادغام آن‌ها، بسیار پرهزینه است.
    </p>
<p>
        در عوض، ما یک <strong>timeline cache</strong> می‌خواهیم: نوعی "صندوق
        پستی" برای هر کاربر که توییت‌ها در حین ارسال در آن نوشته
        می‌شوند، به‌طوری‌که خواندن <strong>timeline</strong> یک <strong>lookup</strong>
        واحد است. <strong>Materializing</strong> و حفظ این <strong>cache</strong> به پردازش
        رویداد زیر نیاز دارد:
    </p>
<ul>
<li>
            وقتی کاربر u یک توییت جدید ارسال می‌کند، به <strong>timeline</strong>
            هر کاربری که u را دنبال می‌کند، اضافه می‌شود.
            474
            |
            فصل 11: پردازش <strong>Stream</strong>
</li>
</ul>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0496</div>
            </div>
        </div>
        <!-- Page 0497 -->
        <div class="chapter" id="page-0497">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        iii. اگر شما یک <strong>stream</strong> را به‌عنوان مشتقی از یک جدول در نظر
        بگیرید، همان‌طور که در شکل 11-6، و یک <strong>join</strong> را به‌عنوان
        حاصلضرب دو جدول u·v در نظر بگیرید، یک چیز جالب اتفاق می‌افتد:
        جریان تغییرات به <strong>materialized join</strong> از قانون ضرب
        پیروی می‌کند (u·v)′ = u′v + uv′. به عبارت دیگر: هر تغییری در توییت‌ها
        با دنبال‌کنندگان فعلی <strong>joined</strong> می‌شود، و هر تغییری در
        دنبال‌کنندگان با توییت‌های فعلی [49، 50] <strong>joined</strong> می‌شود.
    </p>
<ul>
<li>
            هنگامی که یک کاربر یک توییت را حذف می‌کند، از <strong>timelines</strong>
            تمام کاربران حذف می‌شود.
        </li>
<li>
            هنگامی که کاربر u1 شروع به دنبال کردن کاربر u2 می‌کند، توییت‌های
            اخیری از u2 به <strong>timeline</strong> u1 اضافه می‌شوند.
        </li>
<li>
            هنگامی که کاربر u1، کاربر u2 را دیگر دنبال نمی‌کند، توییت‌های
            u2 از <strong>timeline</strong> u1 حذف می‌شوند.
        </li>
</ul>
<p>
        برای پیاده‌سازی این <strong>cache maintenance</strong> در یک پردازنده
        <strong>stream</strong>، شما به جریان رویدادها برای توییت‌ها (ارسال و حذف)
        و برای روابط دنبال کردن (دنبال کردن و عدم دنبال کردن) نیاز دارید.
        فرآیند <strong>stream</strong> باید یک پایگاه داده حاوی مجموعه‌ی
        دنبال‌کنندگان برای هر کاربر را حفظ کند تا بداند هنگام رسیدن یک
        توییت جدید، کدام <strong>timelines</strong> باید به‌روز شوند [86].
    </p>
<p>
        یک راه دیگر برای نگاه کردن به این فرآیند <strong>stream</strong> این است که
        یک <strong>materialized view</strong> را برای یک <strong>query</strong> که دو جدول
        (توییت‌ها و دنبال کردن‌ها) را <strong>join</strong> می‌کند، حفظ می‌کند،
        چیزی شبیه به موارد زیر:
    </p>
<pre><code class="language-sql">SELECT follows.follower_id AS timeline_id,
  array_agg(tweets.* ORDER BY tweets.timestamp DESC)
FROM tweets
JOIN follows ON follows.followee_id = tweets.sender_id
GROUP BY follows.follower_id
</code></pre>
<p>
<strong>Join</strong> از <strong>streams</strong>، مستقیماً با <strong>join</strong> جداول در آن
        <strong>query</strong> مطابقت دارد.
        <strong>Timelines</strong> به‌طور موثر یک <strong>cache</strong> از نتیجه این <strong>query</strong> هستند،
        که هر بار که جداول اساسی تغییر می‌کنند، به‌روز می‌شوند.iii
    </p>
<h4>وابستگی به زمان از <strong>joins</strong></h4>
<p>
        سه نوع <strong>joins</strong> که در اینجا توضیح داده شدند (<strong>stream-stream</strong>،
        <strong>stream-table</strong>، و <strong>table-table</strong>) اشتراکات زیادی
        دارند: همه آن‌ها نیاز دارند که پردازنده <strong>stream</strong> مقداری <strong>state</strong>
        را حفظ کند (رویدادهای جستجو و کلیک، پروفایل‌های کاربر، یا لیست
        دنبال‌کنندگان) بر اساس یک ورودی <strong>join</strong>، و آن <strong>state</strong> را در
        پیام‌ها از ورودی <strong>join</strong> دیگر <strong>query</strong> کند.
    </p>
<p>
        ترتیب رویدادهایی که <strong>state</strong> را حفظ می‌کنند مهم است (این‌که آیا
        شما ابتدا دنبال می‌کنید و سپس عدم دنبال کردن، یا برعکس). در یک
        <strong>log</strong> تقسیم‌بندی شده، ترتیب رویدادها در داخل یک
        <strong>partition</strong> واحد حفظ می‌شود، اما به‌طور معمول هیچ تضمینی برای
        ترتیب در بین <strong>streams</strong> یا <strong>partitions</strong> مختلف وجود ندارد.
    </p>
<p>
        این یک سوال ایجاد می‌کند: اگر رویدادها در <strong>streams</strong> مختلف در
        حدود یک زمان مشابه اتفاق بیفتند، به چه ترتیبی پردازش می‌شوند؟ در
        مثال <strong>stream-table join</strong>، اگر یک کاربر پروفایل خود را
        به‌روزرسانی کند، کدام رویدادهای فعالیت با پروفایل قدیمی
        (پردازش شده قبل از به‌روزرسانی پروفایل)، و کدام‌ها با
        پروفایل جدید (پردازش شده پس از
        475
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0497</div>
            </div>
        </div>
        <!-- Page 0498 -->
        <div class="chapter" id="page-0498">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        ویرایش پروفایل)؟ به عبارت دیگر: اگر <strong>state</strong> در طول زمان
        تغییر می‌کند، و شما با برخی از <strong>state</strong> <strong>join</strong>
        می‌کنید، شما از کدام نقطه زمانی برای <strong>join</strong> استفاده
        می‌کنید [45]؟
    </p>
<p>
        چنین وابستگی به زمانی می‌تواند در بسیاری از مکان‌ها رخ دهد. به عنوان
        مثال، اگر شما چیزی می‌فروشید، شما نیاز دارید که نرخ مالیات مناسب را
        برای فاکتورها اعمال کنید، که به کشور یا ایالت، نوع محصول، و تاریخ
        فروش بستگی دارد (از آن‌جایی که نرخ‌های مالیات در طول زمان تغییر
        می‌کنند). هنگام <strong>joining</strong> فروش‌ها به یک جدول از نرخ‌های
        مالیات، شما احتمالاً می‌خواهید با نرخ مالیات در زمان فروش <strong>join</strong>
        کنید، که اگر شما در حال <em>reprocessing</em> داده‌های تاریخی هستید،
        ممکن است با نرخ مالیات فعلی متفاوت باشد.
    </p>
<p>
        اگر ترتیب رویدادها در سراسر <strong>streams</strong> نامشخص باشد،
        <strong>join</strong> <em>nondeterministic</em> می‌شود [87]، که به این معنی
        است که شما نمی‌توانید همان job را دوباره در همان ورودی اجرا کنید و
        لزوماً همان نتیجه را به‌دست آورید: رویدادها در <strong>streams</strong>
        ورودی ممکن است به روشی متفاوت با هم تداخل داشته باشند، زمانی که
        شما دوباره job را اجرا می‌کنید.
    </p>
<p>
        در انبارهای داده، این مسئله به‌عنوان یک <strong>slowly changing
        dimension (SCD)</strong> شناخته می‌شود، و اغلب با استفاده از یک
        شناسه منحصر به فرد برای یک نسخه خاص از رکورد <strong>joined</strong>
        برطرف می‌شود: به عنوان مثال، هر بار که نرخ مالیات تغییر می‌کند، یک
        شناسه جدید به آن داده می‌شود، و فاکتور شامل شناسه برای نرخ
        مالیات در زمان فروش است [88, 89]. این تغییر <strong>join</strong> را
        <em>deterministic</em> می‌کند، اما این نتیجه را دارد که <strong>log compaction</strong>
        امکان‌پذیر نیست، زیرا تمام نسخه‌های رکوردها در جدول باید حفظ
        شوند.
    </p>
<h4>تحمل خطا</h4>
<p>
        در بخش پایانی این فصل، بیایید بررسی کنیم که چگونه پردازنده‌های
        <strong>stream</strong> می‌توانند <strong>faults</strong> را تحمل کنند. ما در فصل 10
        دیدیم که فریم‌ورک‌های پردازش <strong>batch</strong> می‌توانند <strong>faults</strong>
        را نسبتاً آسان تحمل کنند: اگر یک <strong>task</strong> در یک job <strong>MapReduce</strong>
        شکست بخورد، به‌سادگی می‌توان دوباره آن را در یک ماشین دیگر
        شروع کرد، و خروجی <strong>task</strong> شکست‌خورده دور ریخته می‌شود. این
        <strong>retry</strong> شفاف امکان‌پذیر است زیرا فایل‌های ورودی <em>immutable</em>
        هستند، هر <strong>task</strong> خروجی خود را در یک فایل جداگانه روی
        <strong>HDFS</strong> می‌نویسد، و خروجی تنها زمانی قابل مشاهده می‌شود که
        یک <strong>task</strong> با موفقیت تکمیل شود.
    </p>
<p>
        به‌طور خاص، رویکرد <strong>batch</strong> برای تحمل خطا تضمین می‌کند که
        خروجی job <strong>batch</strong> یکسان است گویی هیچ اتفاقی رخ نداده
        است، حتی اگر در واقع برخی از <strong>tasks</strong> از کار افتاده باشند. این‌طور
        به نظر می‌رسد که هر رکورد ورودی دقیقاً یک بار پردازش شده
        است—هیچ رکوردی رد نمی‌شود، و هیچ‌کدام دو بار پردازش نمی‌شوند.
        اگرچه راه‌اندازی مجدد <strong>tasks</strong> به این معنی است که رکوردها در
        واقع ممکن است چندین بار پردازش شوند، اثر قابل مشاهده در خروجی
        این است که گویی آن‌ها فقط یک بار پردازش شده‌اند. این اصل به‌عنوان
        <strong>exactly-once semantics</strong> شناخته می‌شود، اگرچه
        <em>effectively-once</em> یک اصطلاح توصیفی‌تر خواهد بود [90].
    </p>
<p>
        همان مسئله‌ی تحمل خطا در پردازش <strong>stream</strong> ایجاد می‌شود، اما
        رسیدگی به آن آسان‌تر نیست: انتظار تا زمانی که یک <strong>task</strong>
        تکمیل شود قبل از این‌که خروجی آن را قابل مشاهده کنید، یک گزینه
        نیست، زیرا یک <strong>stream</strong> نامحدود است و بنابراین شما هرگز
        نمی‌توانید پردازش آن را تمام کنید.
        پایگاه‌های داده و جریان‌ها
        |
        469
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0498</div>
            </div>
        </div>
        <!-- Page 0499 -->
        <div class="chapter" id="page-0499">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
<strong>Microbatching</strong> و <strong>checkpointing</strong>
</p>
<p>
        یک راه‌حل این است که <strong>stream</strong> را به بلوک‌های کوچک تقسیم
        کنید، و با هر بلوک مانند یک فرآیند <strong>batch</strong> کوچک رفتار
        کنید. این رویکرد <strong>microbatching</strong> نامیده می‌شود، و در
        <strong>Spark Streaming</strong> [91] استفاده می‌شود. اندازه‌ی
        <strong>batch</strong> معمولاً حدود یک ثانیه است، که نتیجه‌ی یک سازش
        عملکردی است: <strong>batches</strong> های کوچک‌تر سربارهای برنامه‌ریزی
        و هماهنگی بیشتری را متحمل می‌شوند، در حالی که <strong>batches</strong>
        های بزرگ‌تر به معنای تأخیر طولانی‌تری قبل از این است که نتایج
        پردازنده <strong>stream</strong> قابل مشاهده شوند.
    </p>
<p>
<strong>Microbatching</strong> به‌طور ضمنی یک <strong>tumbling window</strong> را
        برابر با اندازه <strong>batch</strong> (<strong>windowed</strong> شده توسط زمان
        پردازش، نه <strong>timestamps</strong> رویداد) ارائه می‌دهد؛ هر
        jobs ای که به <strong>windows</strong> بزرگ‌تری نیاز دارد، باید <strong>state</strong>
        را به‌طور صریح از یک <strong>microbatch</strong> به بعدی انتقال
        دهد.
    </p>
<p>
        یک رویکرد دیگر که در <strong>Apache Flink</strong> استفاده می‌شود، این
        است که به‌طور دوره‌ای <strong>checkpoints</strong> <em>rolling</em> از
        <strong>state</strong> ایجاد کنید و آن‌ها را روی ذخیره‌سازی <em>durable</em>
        بنویسید [92، 93]. اگر یک <strong>stream operator</strong> از کار بیفتد،
        می‌تواند از آخرین <strong>checkpoint</strong> خود راه‌اندازی مجدد شود و
        هر خروجی تولید شده بین آخرین <strong>checkpoint</strong> و <strong>crash</strong> را
        دور بریزد. <strong>Checkpoints</strong> توسط <strong>barriers</strong> در
        <strong>message stream</strong>، مشابه <strong>boundaries</strong> بین
        <strong>microbatches</strong>، اما بدون اجبار به یک اندازه‌ی <strong>window</strong>
        خاص، راه‌اندازی می‌شوند.
    </p>
<p>
        در محدوده‌ی فریم‌ورک پردازش <strong>stream</strong>، رویکردهای
        <strong>microbatching</strong> و <strong>checkpointing</strong>، همان
        <strong>exactly-once semantics</strong> را به‌عنوان پردازش <strong>batch</strong>
        فراهم می‌کنند. با این حال، به محض این‌که خروجی، پردازنده <strong>stream</strong>
        را ترک می‌کند (به عنوان مثال، با نوشتن در یک پایگاه داده، ارسال
        پیام به یک <strong>message broker</strong> خارجی، یا ارسال <strong>emails</strong>)،
        فریم‌ورک دیگر قادر به دور ریختن خروجی یک <strong>batch</strong> شکست‌خورده
        نیست. در این حالت، راه‌اندازی مجدد یک <strong>task</strong> شکست‌خورده
        باعث می‌شود که اثر جانبی خارجی دو بار رخ دهد، و <strong>microbatching</strong>
        یا <strong>checkpointing</strong> به‌تنهایی برای جلوگیری از این مشکل کافی
        نیست.
    </p>
<h4><strong>Atomic commit</strong> بازبینی شده</h4>
<p>
        به منظور ایجاد ظاهر پردازش <strong>exactly-once</strong> در حضور
        <strong>faults</strong>، ما باید اطمینان حاصل کنیم که تمام خروجی‌ها و
        اثرات جانبی پردازش یک رویداد، در صورت موفقیت‌آمیز بودن
        پردازش، اعمال می‌شوند. این اثرات شامل هر پیام ارسالی به
        <strong>operators</strong> <em>downstream</em> یا سیستم‌های پیام‌رسانی خارجی
        (شامل <strong>email</strong> یا <strong>push notifications</strong>)، هر نوشته‌ی
        پایگاه داده، هر تغییری در <strong>operator state</strong>، و هر تأییدیه
        پیام‌های ورودی (از جمله حرکت به جلو <strong>consumer offset</strong> در یک
        <strong>log-based message broker</strong>) می‌شود.
    </p>
<p>
        این موارد یا همگی باید <em>atomically</em> رخ دهند، یا هیچ‌کدام نباید رخ
        دهند، اما نباید با یکدیگر از <em>sync</em> خارج شوند. اگر این رویکرد
        آشنا به‌نظر می‌رسد، به این دلیل است که ما آن را در "پردازش پیام
        <strong>exactly-once</strong>" در صفحه 360، در زمینه تراکنش‌های توزیع
        شده و <strong>two-phase commit</strong>، مورد بحث قرار دادیم.
    </p>
<p>
        در فصل 9 ما در مورد مشکلات در پیاده‌سازی‌های سنتی از
        تراکنش‌های توزیع شده، مانند <strong>XA</strong>، بحث کردیم. با این حال،
        در محیط‌های محدودتر، امکان پیاده‌سازی چنین تسهیلات <strong>atomic
        commit</strong> به‌طور کارآمد وجود دارد. این رویکرد
        پردازش جریان‌ها
        |
        477
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0499</div>
            </div>
        </div>
        <!-- Page 0500 -->
        <div class="chapter" id="page-0500">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        که در <strong>Google Cloud Dataflow</strong> [81، 92] و <strong>VoltDB</strong> [94]
        استفاده می‌شود، و برنامه‌هایی برای افزودن <strong>features</strong> مشابه به
        <strong>Apache Kafka</strong> وجود دارد [95، 96]. بر خلاف <strong>XA</strong>، این
        پیاده‌سازی‌ها تلاش نمی‌کنند تراکنش‌هایی را در سراسر فناوری‌های ناهمگن
        ارائه دهند، بلکه آن‌ها را با مدیریت هر دو تغییر <strong>state</strong> و پیام‌رسانی در
        فریم‌ورک پردازش <strong>stream</strong>، داخلی نگه می‌دارند. <strong>Overhead</strong> از
        پروتکل تراکنش را می‌توان با پردازش چندین پیام ورودی در یک
        تراکنش واحد <em>amortized</em> کرد.
    </p>
<h4><strong>Idempotence</strong></h4>
<p>
        هدف ما این است که خروجی جزئی هر <strong>tasks</strong> شکست‌خورده را دور
        بریزیم تا بتوان آن‌ها را بدون این‌که دو بار تأثیر بگذارند، با خیال
        راحت دوباره امتحان کرد. تراکنش‌های توزیع شده یک راه برای دستیابی
        به این هدف هستند، اما یک راه دیگر این است که به <strong>idempotence</strong>
        متکی باشیم [97].
    </p>
<p>
        یک عملیات <em>idempotent</em> عملیاتی است که شما می‌توانید چندین بار
        انجام دهید، و همان اثر را دارد که گویی شما فقط یک بار آن را
        انجام داده‌اید. به عنوان مثال، تنظیم یک <strong>key</strong> در یک ذخیره‌سازی
        <strong>key-value</strong> روی یک مقدار ثابت، <em>idempotent</em> است (نوشتن
        دوباره مقدار به‌سادگی مقدار را با یک مقدار یکسان بازنویسی
        می‌کند)، در حالی که افزایش یک <strong>counter</strong>، <em>idempotent</em>
        نیست (انجام دوباره‌ی <strong>increment</strong> به این معنی است که مقدار دو
        برابر افزایش می‌یابد).
    </p>
<p>
        حتی اگر یک عملیات ذاتاً <em>idempotent</em> نباشد، اغلب می‌توان آن را با
        مقدار کمی <strong>metadata</strong> اضافی، <em>idempotent</em> کرد. به عنوان
        مثال، هنگام مصرف پیام‌ها از <strong>Kafka</strong>، هر پیام دارای یک
        <strong>offset</strong> پایدار و به‌طور یکنواخت افزایشی است. هنگام نوشتن یک
        مقدار در یک پایگاه داده خارجی، شما می‌توانید <strong>offset</strong> از
        پیامی که باعث آخرین <strong>write</strong> با مقدار شد را شامل کنید. بنابراین،
        شما می‌توانید بگویید که آیا یک <strong>update</strong> قبلاً اعمال شده است، و
        از انجام دوباره همان <strong>update</strong> اجتناب کنید.
    </p>
<p>
        مدیریت <strong>state</strong> در <strong>Trident</strong> از <strong>Storm</strong> بر اساس
        یک ایده‌ی مشابه است [78]. تکیه بر <strong>idempotence</strong>، چندین
        فرض را در بر دارد: راه‌اندازی مجدد یک <strong>task</strong> شکست‌خورده باید
        پیام‌های یکسان را به همان ترتیب <em>replay</em> کند (یک <strong>message
        broker</strong> مبتنی بر <strong>log</strong> این کار را انجام می‌دهد)، پردازش
        باید <em>deterministic</em> باشد، و هیچ <strong>node</strong> دیگری نمی‌تواند
        همزمان مقدار یکسانی را به‌روزرسانی کند [98، 99].
    </p>
<p>
        هنگام <em>failing over</em> از یک <strong>node</strong> پردازش به دیگری،
        <strong>fencing</strong> ممکن است مورد نیاز باشد (نگاه کنید به "رهبر و قفل" در
        صفحه 301) برای جلوگیری از تداخل از یک <strong>node</strong> که تصور می‌شود
        مرده است اما در واقع زنده است. با وجود تمام این <em>caveats</em>،
        عملیات <em>idempotent</em> می‌تواند یک راه مؤثر برای دستیابی به
        <strong>exactly-once semantics</strong> فقط با یک <strong>overhead</strong> کوچک
        باشد.
    </p>
<h4>بازسازی <strong>state</strong> پس از یک <strong>failure</strong></h4>
<p>
        هر فرآیند <strong>stream</strong> که به <strong>state</strong> نیاز دارد—به عنوان مثال،
        هر تجمیع <strong>windowed</strong> (مانند <strong>counters</strong>، میانگین‌ها، و
        هیستوگرام‌ها) و هر جدول و <strong>indexes</strong> که برای <strong>joins</strong>
        استفاده می‌شود—باید اطمینان حاصل کند که این <strong>state</strong> می‌تواند
        پس از یک <strong>failure</strong> بازیابی شود.
    </p>
<p>
        یک گزینه این است که <strong>state</strong> را در یک <strong>datastore</strong> راه دور
        نگه دارید و آن را <strong>replicate</strong> کنید، اگرچه <strong>query</strong> کردن
        یک پایگاه داده‌ی راه دور برای هر پیام جداگانه، می‌تواند کند
        باشد، همان‌طور که در
        478
        |
        فصل 11: پردازش <strong>Stream</strong>
</p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0500</div>
            </div>
        </div>
        <!-- Page 0501 -->
        <div class="chapter" id="page-0501">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        "<strong>Stream-table join (stream enrichment)</strong>" در صفحه 473. یک
        جایگزین این است که <strong>state</strong> را محلی برای پردازنده <strong>stream</strong>
        نگه دارید، و آن را به‌طور دوره‌ای <strong>replicate</strong> کنید. سپس، هنگامی که
        پردازنده <strong>stream</strong> در حال بازیابی از یک <strong>failure</strong> است، <strong>task</strong>
        جدید می‌تواند <strong>state</strong> <strong>replicated</strong> شده را بخواند و پردازش را بدون
        از دست دادن داده‌ها از سر بگیرد.
    </p>
<p>
        به عنوان مثال، <strong>Flink</strong> به‌طور دوره‌ای از <strong>state</strong> از
        <strong>operator</strong> ها <strong>snapshots</strong> می‌گیرد و آن‌ها را در
        ذخیره‌سازی <em>durable</em> مانند <strong>HDFS</strong> می‌نویسد [92، 93]؛ <strong>Samza</strong>
        و <strong>Kafka Streams</strong> تغییرات <strong>state</strong> را با ارسال آن‌ها به یک
        <strong>topic</strong> <strong>Kafka</strong> اختصاصی با <strong>log compaction</strong>
        ، مشابه <strong>change data capture</strong>، <strong>replicate</strong> می‌کنند [84،
        100]. <strong>VoltDB</strong> <strong>state</strong> را با پردازش <em>redundantly</em> هر
        پیام ورودی در چندین <strong>node</strong>، <strong>replicate</strong> می‌کند (نگاه کنید
        به "اجرای سریال واقعی" در صفحه 252).
    </p>
<p>
        در برخی موارد، ممکن است حتی لازم نباشد که <strong>state</strong> را
        <strong>replicate</strong> کنید، زیرا می‌توان آن را از <strong>streams</strong> ورودی
        دوباره ساخت. به عنوان مثال، اگر <strong>state</strong> شامل تجمیع‌ها در یک
        <strong>window</strong> نسبتاً کوتاه باشد، ممکن است به‌اندازه‌ی کافی سریع
        باشد که به‌سادگی رویدادهای ورودی مربوط به آن <strong>window</strong> را
        دوباره پخش کنید. اگر <strong>state</strong> یک <strong>replica</strong> محلی از یک
        پایگاه داده باشد، که توسط <strong>change data capture</strong> نگهداری
        می‌شود، پایگاه داده نیز می‌تواند از <strong>change stream</strong> که <strong>log-
        compacted</strong> شده است، دوباره ساخته شود (نگاه کنید به "<strong>Log
        compaction</strong>" در صفحه 456).
    </p>
<p>
        با این حال، همه‌ی این <strong>trade-offs</strong> به ویژگی‌های عملکردی
        زیرساخت اساسی بستگی دارد: در برخی سیستم‌ها، تأخیر شبکه ممکن است
        کمتر از <em>disk access latency</em> باشد، و پهنای باند شبکه ممکن است
        قابل مقایسه با پهنای باند دیسک باشد. هیچ <strong>trade-off</strong>
        ایده‌آل جهانی برای همه‌ی موقعیت‌ها وجود ندارد، و مزایای <strong>state</strong>
        محلی در مقابل از راه دور نیز ممکن است با تکامل فناوری‌های ذخیره‌سازی
        و شبکه‌سازی تغییر کند.
    </p>
<h4>خلاصه</h4>
<p>
        در این فصل ما در مورد <strong>event streams</strong> بحث کردیم، این‌که چه
        اهدافی را دنبال می‌کنند، و چگونه آن‌ها را پردازش کنیم. از جهاتی،
        پردازش <strong>stream</strong> بسیار شبیه به پردازش <strong>batch</strong> است که
        در فصل 10 در مورد آن بحث کردیم، اما به‌طور مداوم بر روی
        <strong>streams</strong> <em>unbounded</em> (بی‌پایان) به‌جای یک ورودی با
        اندازه ثابت انجام می‌شود. از این دیدگاه، <strong>message brokers</strong> و
        <strong>event logs</strong> به‌عنوان معادل <strong>streaming</strong> یک سیستم
        فایل عمل می‌کنند.
    </p>
<p>
        ما مقداری زمان را صرف مقایسه‌ی دو نوع <strong>message brokers</strong>
        کردیم:
    </p>
<ul>
<li>
<strong>Message broker</strong> به سبک <strong>AMQP/JMS</strong>
</li>
<p>
<strong>Broker</strong> پیام‌های جداگانه را به <strong>consumers</strong>
            اختصاص می‌دهد، و <strong>consumers</strong> پیام‌های جداگانه را
            زمانی که با موفقیت پردازش شده‌اند، تأیید می‌کنند. پیام‌ها پس از
            تأیید از <strong>broker</strong> حذف می‌شوند. این رویکرد به‌عنوان
            یک فرم <em>asynchronous</em> از <strong>RPC</strong> مناسب است (همچنین
            نگاه کنید به "<strong>Message-Passing Dataflow</strong>" در صفحه 136)، به
            عنوان مثال در یک صف <strong>task</strong>، که در آن ترتیب دقیق
            پردازش پیام‌ها مهم نیست و جایی که نیازی به بازگشت و
            خواندن دوباره پیام‌های قدیمی پس از پردازش آن‌ها وجود
            ندارد.
        
<p>
            خلاصه
            |
            479
        </p>
</p></ul>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0501</div>
            </div>
        </div>
        <!-- Page 0502 -->
        <div class="chapter" id="page-0502">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
<strong>Log-based message broker</strong>
<strong>Broker</strong> تمام پیام‌ها را در یک <strong>partition</strong> به یک
        <strong>consumer node</strong> اختصاص می‌دهد، و همیشه پیام‌ها را به همان
        ترتیب تحویل می‌دهد. <strong>Parallelism</strong> از طریق <strong>partitioning</strong> به‌دست
        می‌آید، و <strong>consumers</strong> پیشرفت خود را با <strong>checkpointing</strong>
<strong>offset</strong> از آخرین پیام که پردازش کرده‌اند، پیگیری می‌کنند.
        <strong>Broker</strong> پیام‌ها را روی دیسک نگه می‌دارد، بنابراین در صورت
        نیاز، امکان بازگشت و خواندن مجدد پیام‌های قدیمی وجود دارد.
    </p>
<p>
        رویکرد مبتنی بر <strong>log</strong> شباهت‌هایی به <strong>replication logs</strong> دارد که
        در پایگاه‌های داده یافت می‌شود (نگاه کنید به فصل 5) و موتورهای
        ذخیره‌سازی ساختاریافته بر اساس <strong>log</strong> (نگاه کنید به فصل 3). ما
        دیدیم که این رویکرد به‌ویژه برای سیستم‌های پردازش <strong>stream</strong>
        مناسب است که <strong>streams</strong> ورودی را مصرف می‌کنند و <strong>state</strong>
        مشتق شده یا <strong>streams</strong> خروجی مشتق شده را تولید می‌کنند.
    </p>
<p>
        از نظر این‌که جریان‌ها از کجا می‌آیند، ما چندین احتمال را مورد بحث
        قرار دادیم: رویدادهای فعالیت کاربر، سنسورهایی که خوانش‌های
        دوره‌ای را ارائه می‌دهند، و <strong>data feeds</strong> (به عنوان مثال، داده‌های
        بازار در امور مالی) به‌طور طبیعی به عنوان <strong>streams</strong> نشان داده
        می‌شوند. ما دیدیم که این می‌تواند مفید باشد که به نوشتن‌ها در یک
        پایگاه داده به‌عنوان یک <strong>stream</strong> فکر کنیم: ما می‌توانیم
        <strong>changelog</strong>—یعنی، تاریخچه تمام تغییرات ایجاد شده در یک
        پایگاه داده—را به‌طور ضمنی از طریق <strong>change data capture</strong> یا به‌طور
        صریح از طریق <strong>event sourcing</strong> ضبط کنیم. <strong>Log compaction</strong>
        به <strong>stream</strong> اجازه می‌دهد که یک کپی کامل از محتویات یک
        پایگاه داده را حفظ کند.
    </p>
<p>
        نشان دادن پایگاه‌های داده به‌عنوان <strong>streams</strong> فرصت‌های قدرتمندی
        را برای ادغام سیستم‌ها باز می‌کند. شما می‌توانید سیستم‌های داده‌ی
        مشتق شده مانند <strong>search indexes</strong>، <strong>caches</strong>، و سیستم‌های
        <strong>analytics</strong> را با مصرف <strong>log</strong> تغییرات و اعمال آن‌ها در
        سیستم مشتق شده، به‌طور مداوم به‌روز نگه دارید. شما حتی
        می‌توانید با شروع از ابتدا و مصرف <strong>log</strong> تغییرات از ابتدا تا
        انتها، <strong>views</strong> جدیدی را در داده‌های موجود بسازید.
    </p>
<p>
        امکانات حفظ <strong>state</strong> به‌صورت <strong>streams</strong> و پخش مجدد
        پیام‌ها نیز مبنایی برای تکنیک‌هایی هستند که <strong>stream joins</strong> و تحمل
        خطا را در فریم‌ورک‌های مختلف پردازش <strong>stream</strong> فعال می‌کنند. ما در
        مورد چندین هدف از پردازش <strong>stream</strong>، از جمله جستجوی الگوهای
        رویداد (پردازش رویداد پیچیده)، محاسبه‌ی تجمعات <strong>windowed</strong>
        (تجزیه و تحلیل <strong>stream</strong>)، و به‌روز نگه داشتن سیستم‌های داده
        مشتق شده (<strong>materialized views</strong>) بحث کردیم.
    </p>
<p>
        سپس ما در مورد مشکلات استدلال در مورد زمان در یک پردازنده <strong>stream</strong>
        بحث کردیم، از جمله تمایز بین زمان پردازش و <strong>event
        timestamps</strong>، و مشکل رسیدگی به رویدادهای <em>straggler</em> که
        پس از این‌که فکر می‌کردید <strong>window</strong> شما کامل شده است،
        می‌رسند.
    </p>
<p>
        ما سه نوع <strong>joins</strong> را که ممکن است در فرآیندهای <strong>stream</strong>
        ظاهر شوند، متمایز کردیم:
    </p>
<ul>
<li>
<strong>Stream-stream joins</strong>
</li>
<p>
            هر دو <strong>streams</strong> ورودی از رویدادهای فعالیت تشکیل شده‌اند،
            و <strong>join operator</strong> به‌دنبال رویدادهای مرتبطی می‌گردد که
            در یک <strong>window</strong> از زمان رخ می‌دهند. به عنوان مثال،
            ممکن است دو عمل انجام شده توسط یک کاربر یکسان را در عرض
            30 دقیقه از یکدیگر مطابقت دهد.
            480
            |
            فصل 11: پردازش <strong>Stream</strong>

</p></ul>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0502</div>
            </div>
        </div>
        <!-- Page 0503 -->
        <div class="chapter" id="page-0503">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<ul>
<li>
            دو ورودی <strong>join</strong> در واقع ممکن است همان <strong>stream</strong>
            باشد (یک <strong>self-join</strong>) اگر شما بخواهید رویدادهای مرتبط را
            در آن <strong>stream</strong> واحد پیدا کنید.
        </li>
<li>
<strong>Stream-table joins</strong>
</li>
<p>
            یک <strong>stream</strong> ورودی شامل رویدادهای فعالیت است، در حالی‌که
            دیگری یک <strong>changelog</strong> پایگاه داده است. <strong>Changelog</strong>
            یک کپی محلی از پایگاه داده را به‌روز نگه می‌دارد. برای هر رویداد
            فعالیت، <strong>join operator</strong>، پایگاه داده را query می‌کند و یک
            رویداد فعالیت غنی شده را خروجی می‌دهد.
        </p>
<li>
<strong>Table-table joins</strong>
</li>
<p>
            هر دو <strong>streams</strong> ورودی <strong>changelogs</strong> پایگاه داده
            هستند. در این حالت، هر تغییر در یک طرف با آخرین وضعیت طرف
            دیگر <strong>joined</strong> می‌شود. نتیجه یک جریان از تغییرات در
            <strong>materialized view</strong> از <strong>join</strong> بین دو جدول است.
        </p>
</ul>
<p>
        در نهایت، ما در مورد تکنیک‌هایی برای دستیابی به تحمل خطا و
        <strong>exactly-once semantics</strong> در یک پردازنده <strong>stream</strong> بحث
        کردیم. همانند پردازش <strong>batch</strong>، ما باید خروجی جزئی هر
        <strong>task</strong> شکست‌خورده را دور بریزیم. با این حال، از آن‌جایی‌که یک
        فرآیند <strong>stream</strong> طولانی‌مدت است و به‌طور مداوم خروجی تولید
        می‌کند، ما نمی‌توانیم به‌سادگی تمام خروجی را دور بریزیم. در عوض،
        می‌توان از یک مکانیسم بازیابی ظریف‌تر، مبتنی بر <strong>microbatching</strong>
        ، <strong>checkpointing</strong>، تراکنش‌ها، یا نوشتن‌های <em>idempotent</em>
        استفاده کرد.
    </p>
<p>
        مراجع
    </p>
<p>
        [1] <strong>Tyler Akidau</strong>، <strong>Robert Bradshaw</strong>، <strong>Craig
        Chambers</strong> و همکاران: "مدل <strong>Dataflow</strong>: یک رویکرد
        عملی برای متعادل کردن صحت، تأخیر، و هزینه در پردازش داده‌های
        نامحدود و مقیاس بزرگ، نامرتب‌شده"، <strong>Proceedings of the VLDB
        Endowment</strong>، جلد 8، شماره 12، صفحات 1792–1803، اوت 2015.
        <strong>doi:10.14778/2824032.2824076</strong>
</p>
<p>
        [2] <strong>Harold Abelson</strong>، <strong>Gerald Jay Sussman</strong>، و <strong>Julie
        Sussman</strong>: ساختار و تفسیر برنامه‌های کامپیوتری، چاپ دوم.
        <strong>MIT Press</strong>، 1996. <strong>ISBN: 978-0-262-51087-5</strong>، در
        <strong>mitpress.mit.edu</strong> موجود است
    </p>
<p>
        [3] <strong>Patrick Th. Eugster</strong>، <strong>Pascal A. Felber</strong>، <strong>Rachid
        Guerraoui</strong>، و <strong>Anne-Marie Kermarrec</strong>: "بسیاری از
        وجه‌های انتشار/اشتراک"، بررسی‌های <strong>ACM Computing</strong>، جلد 35،
        شماره 2، صفحات 114–131، ژوئن 2003.
        <strong>doi:10.1145/857076.857078</strong>
</p>
<p>
        [4] <strong>Joseph M. Hellerstein</strong> و <strong>Michael Stonebraker</strong>:
        خواندن‌ها در سیستم‌های پایگاه داده، چاپ 4. <strong>MIT Press</strong>، 2005.
        <strong>ISBN: 978-0-262-69314-1</strong>، در <strong>redbook.cs.berkeley.edu</strong>
        موجود است
    </p>
<p>
        [5] <strong>Don Carney</strong>، <strong>Uğur Çetintemel</strong>، <strong>Mitch Cherniack</strong> و
        همکاران: "جریان‌های <strong>Monitoring</strong> – یک کلاس جدید از
        برنامه‌های مدیریت داده‌ها"، در بیست و هشتمین کنفرانس بین‌المللی
        در مورد پایگاه‌های داده بسیار بزرگ (<strong>VLDB</strong>)، اوت 2002.
    </p>
<p>
        [6] <strong>Matthew Sackman</strong>: "<strong>Pushing Back</strong>"، <strong>lshift.net</strong>، 5
        مه 2016.
        خلاصه
        |
        481
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0503</div>
            </div>
        </div>
        <!-- Page 0504 -->
        <div class="chapter" id="page-0504">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        [7] <strong>Vicent Martí</strong>: "<strong>Brubeck</strong>، یک <strong>statsd-Compatible
        Metrics Aggregator</strong>"، <strong>githubengineering.com</strong>، 15 ژوئن
        2015.
    </p>
<p>
        [8] <strong>Seth Lowenberger</strong>: "مشخصات پروتکل <strong>MoldUDP64</strong>
        نسخه 1.00"، <strong>nasdaq-trader.com</strong>، ژوئیه 2009.
    </p>
<p>
        [9] <strong>Pieter Hintjens</strong>: <strong>ZeroMQ</strong> – راهنما. <strong>O’Reilly Media</strong>،
        2013. <strong>ISBN: 978-1-449-33404-8</strong>
</p>
<p>
        [10] <strong>Ian Malpass</strong>: "هر چیزی را اندازه‌گیری کنید، همه‌چیز را
        اندازه‌گیری کنید"، <strong>codeascraft.com</strong>، 15 فوریه 2011.
    </p>
<p>
        [11] <strong>Dieter Plaetinck</strong>: "25 <strong>Gotchas</strong> از <strong>Graphite</strong>،
        <strong>Grafana</strong> و <strong>statsd</strong>"، <strong>blog.raintank.io</strong>، 3
        مارس 2016.
    </p>
<p>
        [12] <strong>Jeff Lindsay</strong>: "<strong>Web Hooks</strong> برای ایجاد انقلاب در وب"،
        <strong>progrium.com</strong>، 3 مه 2007.
    </p>
<p>
        [13] <strong>Jim N. Gray</strong>: "صف‌ها، پایگاه‌های داده هستند"، گزارش فنی
        تحقیقات <strong>Microsoft</strong> <strong>MSR-TR-95-56</strong>، دسامبر 1995.
    </p>
<p>
        [14] <strong>Mark Hapner</strong>، <strong>Rich Burridge</strong>، <strong>Rahul Sharma</strong> و
        همکاران: "مشخصات <strong>JSR-343 Java Message Service (JMS) 2.0</strong>"،
        <strong>jms-spec.java.net</strong>، مارس 2013.
    </p>
<p>
        [15] <strong>Sanjay Aiyagari</strong>، <strong>Matthew Arrott</strong>، <strong>Mark Atwell</strong> و
        همکاران: "<strong>AMQP</strong>: مشخصات پروتکل صف‌بندی پیام پیشرفته"،
        نسخه 0-9-1، نوامبر 2008.
    </p>
<p>
        [16] "<strong>Google Cloud Pub/Sub</strong>: یک سرویس پیام‌رسانی در مقیاس
        <strong>Google</strong>"، <strong>cloud.google.com</strong>، 2016.
    </p>
<p>
        [17] "مستندات <strong>Apache Kafka 0.9</strong>"، <strong>kafka.apache.org</strong>،
        نوامبر 2015.
    </p>
<p>
        [18] <strong>Jay Kreps</strong>، <strong>Neha Narkhede</strong>، و <strong>Jun Rao</strong>: "<strong>Kafka</strong>:
        یک سیستم پیام‌رسانی توزیع شده برای پردازش <strong>Log</strong>"، در ششمین
        کارگاه بین‌المللی در مورد شبکه‌هایی که پایگاه‌های داده را ملاقات
        می‌کنند (<strong>NetDB</strong>)، ژوئن 2011.
    </p>
<p>
        [19] "راهنمای توسعه‌دهنده <strong>Amazon Kinesis Streams</strong>"،
        <strong>docs.aws.amazon.com</strong>، آوریل 2016.
    </p>
<p>
        [20] <strong>Leigh Stewart</strong> و <strong>Sijie Guo</strong>: "ساختن
        <strong>DistributedLog</strong>: سرویس <strong>Log</strong> <em>Replicated</em> با عملکرد
        بالای توییتر"، <strong>blog.twitter.com</strong>، 16 سپتامبر 2015.
    </p>
<p>
        [21] "مستندات <strong>DistributedLog</strong>"، <strong>Twitter, Inc.</strong>،
        <strong>distributedlog.io</strong>، مه 2016.
    </p>
<p>
        [22] <strong>Jay Kreps</strong>: "بنچمارکینگ <strong>Apache Kafka</strong>: 2 میلیون
        نوشته در ثانیه (در سه ماشین ارزان‌قیمت)"،
        <strong>engineering.linkedin.com</strong>، 27 آوریل 2014.
    </p>
<p>
        [23] <strong>Kartik Paramasivam</strong>: "چگونه ما در حال بهبود و پیشرفت
        <strong>Kafka</strong> در <strong>LinkedIn</strong> هستیم"،
        <strong>engineering.linkedin.com</strong>، 2 سپتامبر 2015.
    </p>
<p>
        [24] <strong>Jay Kreps</strong>: "<strong>Log</strong>: آن‌چه که هر مهندس نرم‌افزار باید
        در مورد <strong>Abstraction</strong> متحدکننده‌ی داده‌های بی‌درنگ بداند"،
        <strong>engineering.linkedin.com</strong>، 16 دسامبر 2013.
        482
        |
        فصل 11: پردازش <strong>Stream</strong>
</p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0504</div>
            </div>
        </div>
        <!-- Page 0505 -->
        <div class="chapter" id="page-0505">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        [25] <strong>Shirshanka Das</strong>، <strong>Chavdar Botev</strong>، <strong>Kapil
        Surlaker</strong> و همکاران: "<strong>All Aboard the Databus!</strong>"، در
        سومین سمپوزیوم <strong>ACM</strong> در مورد محاسبات ابری (<strong>SoCC</strong>)، اکتبر
        2012.
    </p>
<p>
        [26] <strong>Yogeshwer Sharma</strong>، <strong>Philippe Ajoux</strong>، <strong>Petchean Ang</strong> و
        همکاران: "<strong>Wormhole</strong>: <strong>Pub-Sub</strong> قابل اعتماد برای
        پشتیبانی از <strong>Services</strong> اینترنتی <strong>Geo-Replicated</strong>"، در
        دوازدهمین سمپوزیوم <strong>USENIX</strong> در طراحی و پیاده‌سازی سیستم‌های
        شبکه‌ای (<strong>NSDI</strong>)، مه 2015.
    </p>
<p>
        [27] <strong>P. P. S. Narayan</strong>: "به‌روزرسانی <strong>Sherpa</strong>"،
        <strong>developer.yahoo.com</strong>، 8 ژوئن،.
    </p>
<p>
        [28] <strong>Martin Kleppmann</strong>: "<strong>Bottled Water</strong>: ادغام <em>Real-Time</em>
        از <strong>PostgreSQL</strong> و <strong>Kafka</strong>"، <strong>martin.kleppmann.com</strong>، 23
        آوریل 2015.
    </p>
<p>
        [29] <strong>Ben Osheroff</strong>: "معرفی <strong>Maxwell</strong>، یک پردازنده
        <strong>mysql-to-kafka Binlog</strong>"، <strong>developer.zendesk.com</strong>، 20
        اوت 2015.
    </p>
<p>
        [30] <strong>Randall Hauch</strong>: "<strong>Debezium 0.2.1</strong> منتشر شد"،
        <strong>debezium.io</strong>، 10 ژوئن 2016.
    </p>
<p>
        [31] <strong>Prem Santosh Udaya Shankar</strong>: "جداول <strong>MySQL</strong>
<strong>Streaming</strong> در زمان واقعی به <strong>Kafka</strong>"،
        <strong>engineeringblog.yelp.com</strong>، 1 اوت 2016.
    </p>
<p>
        [32] "<strong>Mongoriver</strong>"، <strong>Stripe, Inc.</strong>،
        <strong>github.com</strong>، سپتامبر 2014.
    </p>
<p>
        [33] <strong>Dan Harvey</strong>: "<strong>Change Data Capture</strong> با <strong>Mongo + Kafka</strong>"،
        در <strong>Hadoop Users Group UK</strong>، اوت 2015.
    </p>
<p>
        [34] "<strong>Oracle GoldenGate 12c</strong>: دسترسی <em>Real-Time</em> به اطلاعات
        <em>Real-Time</em>"، <strong>Oracle White Paper</strong>، مارس 2015.
    </p>
<p>
        [35] "مبانی <strong>Oracle GoldenGate</strong>: نحوه عملکرد <strong>Oracle GoldenGate</strong>"،
        <strong>Oracle Corporation</strong>، <strong>youtube.com</strong>، نوامبر 2012.
    </p>
<p>
        [36] <strong>Slava Akhmechet</strong>: "پیشرفت وب <em>Realtime</em>"،
        <strong>rethinkdb.com</strong>، 27 ژانویه 2015.
    </p>
<p>
        [37] "مستندات پایگاه داده‌ی <strong>Firebase Realtime</strong>"، <strong>Google, Inc.</strong>،
        <strong>firebase.google.com</strong>، مه 2016.
    </p>
<p>
        [38] "مستندات <strong>Apache CouchDB 1.6</strong>"، <strong>docs.couchdb.org</strong>،
        2014.
    </p>
<p>
        [39] <strong>Matt DeBergalis</strong>: "<strong>Meteor 0.7.0</strong>: <strong>Queries</strong>
        پایگاه داده‌ی مقیاس‌پذیر با استفاده از <strong>MongoDB Oplog</strong>
        به‌جای <strong>Poll-and-Diff</strong>"، <strong>info.meteor.com</strong>، 17 دسامبر
        2013.
    </p>
<p>
        [40] "فصل 15. واردات و صادرات داده‌های زنده"، راهنمای کاربر
        <strong>VoltDB 6.4</strong>، <strong>docs.voltdb.com</strong>، ژوئن 2016.
    </p>
<p>
        [41] <strong>Neha Narkhede</strong>: "معرفی <strong>Kafka Connect</strong>: ساخت
        <strong>Pipelines</strong> داده با <strong>Low-Latency</strong> و مقیاس بزرگ"،
        <strong>confluent.io</strong>، 18 فوریه 2016.
    </p>
<p>
        [42] <strong>Greg Young</strong>: "<strong>CQRS</strong> و <strong>Event Sourcing</strong>"، در
        <strong>Code on the Beach</strong>، اوت 2014.
    </p>
<p>
        [43] <strong>Martin Fowler</strong>: "<strong>Event Sourcing</strong>"،
        <strong>martinfowler.com</strong>، 12 دسامبر 2005.
        خلاصه
        |
        483
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0505</div>
            </div>
        </div>
        <!-- Page 0506 -->
        <div class="chapter" id="page-0506">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        [44] <strong>Vaughn Vernon</strong>: پیاده‌سازی <strong>Domain-Driven Design</strong>.
        <strong>Addison-Wesley Professional</strong>، 2013. <strong>ISBN:
        978-0-321-83457-7</strong>
</p>
<p>
        [45] <strong>H. V. Jagadish</strong>، <strong>Inderpal Singh Mumick</strong>، و <strong>Abraham
        Silberschatz</strong>: "مسائل نگهداری <strong>View</strong> برای مدل داده‌های
        <strong>Chronicle</strong>"، در چهاردهمین سمپوزیوم <strong>ACM SIGACT-SIGMOD-
        SIGART</strong> در مورد اصول سیستم‌های پایگاه داده (<strong>PODS</strong>)، مه
        1995. <strong>doi:10.1145/212433.220201</strong>
</p>
<p>
        [46] "مستندات <strong>Event Store 3.5.0</strong>"، <strong>Event Store LLP</strong>،
        <strong>docs.geteventstore.com</strong>، فوریه 2016.
    </p>
<p>
        [47] <strong>Martin Kleppmann</strong>: درک پردازش <strong>Stream</strong>. گزارش، <strong>O’Reilly
        Media</strong>، مه 2016.
    </p>
<p>
        [48] <strong>Sander Mak</strong>: "معماری‌های <strong>Event-Sourced</strong> با <strong>Akka</strong>"، در
        <strong>JavaOne</strong>، سپتامبر 2014.
    </p>
<p>
        [49] <strong>Julian Hyde</strong>: ارتباط شخصی، ژوئن 2016.
    </p>
<p>
        [50] <strong>Ashish Gupta</strong> و <strong>Inderpal Singh Mumick</strong>: <strong>Materialized
        Views</strong>: تکنیک‌ها، پیاده‌سازی‌ها و برنامه‌ها. <strong>MIT Press</strong>، 1999.
        <strong>ISBN: 978-0-262-57122-7</strong>
</p>
<p>
        [51] <strong>Timothy Griffin</strong> و <strong>Leonid Libkin</strong>: "نگهداری
        افزایشی <strong>Views</strong> با <strong>Duplicates</strong>"، در کنفرانس بین‌المللی
        <strong>ACM</strong> در مورد مدیریت داده‌ها (<strong>SIGMOD</strong>)، مه 1995.
        <strong>doi:10.1145/223784.223849</strong>
</p>
<p>
        [52] <strong>Pat Helland</strong>: "<strong>Immutability</strong> همه‌چیز را تغییر
        می‌دهد"، در هفتمین کنفرانس دوسالانه در مورد تحقیقات نوآورانه
        سیستم‌های داده (<strong>CIDR</strong>)، ژانویه 2015.
    </p>
<p>
        [53] <strong>Martin Kleppmann</strong>: "حسابداری برای دانشمندان کامپیوتر"،
        <strong>martin.kleppmann.com</strong>، 7 مارس 2011.
    </p>
<p>
        [54] <strong>Pat Helland</strong>: "حسابداران از پاک‌کن استفاده نمی‌کنند"،
        <strong>blogs.msdn.com</strong>، 14 ژوئن 2007.
    </p>
<p>
        [55] <strong>Fangjin Yang</strong>: "<strong>Dogfooding</strong> با <strong>Druid</strong>، <strong>Samza</strong>، و
        <strong>Kafka</strong>: <strong>Metametrics</strong> در <strong>Metamarkets</strong>"،
        <strong>metamarkets.com</strong>، 3 ژوئن 2015.
    </p>
<p>
        [56] <strong>Gavin Li</strong>، <strong>Jianqiu Lv</strong> و <strong>Hang Qi</strong>: "<strong>Pistachio</strong>:
        داده‌ها و محاسبات را برای سریع‌ترین محاسبات ابری
        <strong>Co-Locate</strong> کنید"، <strong>yahoohadoop.tumblr.com</strong>، 13 آوریل
        2015.
    </p>
<p>
        [57] <strong>Kartik Paramasivam</strong>: "مشکلات سخت پردازش <strong>Stream</strong>
        —قسمت 1: کشتن <strong>Lambda</strong>"،
        <strong>engineering.linkedin.com</strong>، 27 ژوئن 2016.
    </p>
<p>
        [58] <strong>Martin Fowler</strong>: "<strong>CQRS</strong>"، <strong>martinfowler.com</strong>، 14 ژوئیه
        2011.
    </p>
<p>
        [59] <strong>Greg Young</strong>: "اسناد <strong>CQRS</strong>"، <strong>cqrs.files.wordpress.com</strong>،
        نوامبر 2010.
    </p>
<p>
        [60] <strong>Baron Schwartz</strong>: "<strong>Immutability</strong>، <strong>MVCC</strong> و
        <strong>Garbage Collection</strong>"، <strong>xaprb.com</strong>، 28 دسامبر 2013.
        484
        |
        فصل 11: پردازش <strong>Stream</strong>
</p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0506</div>
            </div>
        </div>
        <!-- Page 0507 -->
        <div class="chapter" id="page-0507">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        [61] <strong>Daniel Eloff</strong>، <strong>Slava Akhmechet</strong>، <strong>Jay Kreps</strong> و
        همکاران: "در مورد: برگرداندن پایگاه داده از درون به بیرون با <strong>Apache
        Samza</strong>"، بحث <strong>Hacker News</strong>،
        <strong>news.ycombinator.com</strong>، 4 مارس 2015.
    </p>
<p>
        [62] "منابع توسعه‌ی <strong>Datomic</strong>: <strong>Excision</strong>"، <strong>Cognitect, Inc.</strong>،
        <strong>docs.datomic.com</strong>.
    </p>
<p>
        [63] "مستندات <strong>Fossil</strong>: حذف محتوا از <strong>Fossil</strong>"،
        <strong>fossil-scm.org</strong>، 2016.
    </p>
<p>
        [64] <strong>Jay Kreps</strong>: "طنز سیستم‌های توزیع شده این است که
        از دست دادن داده‌ها واقعاً آسان است اما حذف داده‌ها به‌طور شگفت‌انگیزی
        دشوار است"، <strong>twitter.com</strong>، 30 مارس 2015.
    </p>
<p>
        [65] <strong>David C. Luckham</strong>: "تفاوت بین <strong>ESP</strong> و <strong>CEP</strong>
        چیست؟"، <strong>complexe-events.com</strong>، 1 اوت 2006.
    </p>
<p>
        [66] <strong>Srinath Perera</strong>: "پردازش <strong>Stream</strong> و پردازش رویداد
        پیچیده (<strong>CEP</strong>) چه تفاوتی دارند؟"، <strong>quora.com</strong>، 3
        دسامبر 2015.
    </p>
<p>
        [67] <strong>Arvind Arasu</strong>، <strong>Shivnath Babu</strong>، و <strong>Jennifer Widom</strong>:
        "زبان <strong>Query</strong> پیوسته‌ی <strong>CQL</strong>: مبانی معنایی و اجرای
        <strong>Query</strong>"، <strong>The VLDB Journal</strong>، جلد 15، شماره 2، صفحات
        121–142، ژوئن 2006. <strong>doi:10.1007/s00778-004-0147-z</strong>
</p>
<p>
        [68] <strong>Julian Hyde</strong>: "داده‌ها در پرواز: چگونه فناوری <strong>SQL
        Streaming</strong> می‌تواند به حل <strong>Web 2.0 Data Crunch</strong> کمک
        کند"، <strong>ACM Queue</strong>، جلد 7، شماره 11، دسامبر 2009.
        <strong>doi:10.1145/1661785.1667562</strong>
</p>
<p>
        [69] "مرجع <strong>Esper</strong>، نسخه 5.4.0"، <strong>EsperTech, Inc.</strong>،
        <strong>espertech.com</strong>، آوریل 2016.
    </p>
<p>
        [70] <strong>Zubair Nabi</strong>، <strong>Eric Bouillet</strong>، <strong>Andrew Bainbridge</strong> و
        <strong>Chris Thomas</strong>: "از <strong>Streams</strong> و <strong>Storms</strong>"، گزارش فنی
        <strong>IBM</strong>، <strong>developer.ibm.com</strong>، آوریل 2014.
    </p>
<p>
        [71] <strong>Milinda Pathirage</strong>، <strong>Julian Hyde</strong>، <strong>Yi Pan</strong>، و <strong>Beth
        Plale</strong>: "<strong>SamzaSQL</strong>: مدیریت داده‌های سریع در مقیاس با
        <strong>Streaming SQL</strong>"، در کارگاه بین‌المللی <strong>IEEE</strong> در مورد
        محاسبات داده‌های بزرگ با عملکرد بالا (<strong>HPBDC</strong>)، مه 2016.
        <strong>doi:10.1109/IPDPSW.2016.141</strong>
</p>
<p>
        [72] <strong>Philippe Flajolet</strong>، <strong>Éric Fusy</strong>، <strong>Olivier Gandouet</strong>، و
        <strong>Frédéric Meunier</strong>: "<strong>HyperLogLog</strong>: تجزیه و تحلیل یک
        الگوریتم برآورد <strong>Cardinality</strong> نزدیک به بهینه"، در کنفرانس
        تجزیه و تحلیل الگوریتم‌ها (<strong>AofA</strong>)، ژوئن 2007.
    </p>
<p>
        [73] <strong>Jay Kreps</strong>: "زیر سوال بردن معماری <strong>Lambda</strong>"،
        <strong>oreilly.com</strong>، 2 ژوئیه 2014.
    </p>
<p>
        [74] <strong>Ian Hellström</strong>: "مروری بر فناوری‌های <strong>Apache Streaming</strong>"،
        <strong>databaseline.wordpress.com</strong>، 12 مارس 2016.
    </p>
<p>
        [75] <strong>Jay Kreps</strong>: "چرا <strong>Local State</strong> یک <strong>Primitive</strong> اساسی در
        پردازش <strong>Stream</strong> است"، <strong>oreilly.com</strong>، 31 ژوئیه 2014.
    </p>
<p>
        [76] <strong>Shay Banon</strong>: "<strong>Percolator</strong>"، <strong>elastic.co</strong>، 8 فوریه
        2011.
    </p>
<p>
        [77] <strong>Alan Woodward</strong> و <strong>Martin Kleppmann</strong>: "جستجوی متن
        کامل <em>Real-Time</em> با <strong>Luwak</strong> و <strong>Samza</strong>"،
        <strong>martin.kleppmann.com</strong>، 13 آوریل 2015.
        خلاصه
        |
        485
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0507</div>
            </div>
        </div>
        <!-- Page 0508 -->
        <div class="chapter" id="page-0508">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        [78] "مستندات <strong>Apache Storm 1.0.1</strong>"، <strong>storm.apache.org</strong>،
        مه 2016.
    </p>
<p>
        [79] <strong>Tyler Akidau</strong>: "جهان فراتر از <strong>Batch</strong>: <strong>Streaming
        102</strong>"، <strong>oreilly.com</strong>، 20 ژانویه 2016.
    </p>
<p>
        [80] <strong>Stephan Ewen</strong>: "تجزیه و تحلیل <strong>Streaming</strong> با
        <strong>Apache Flink</strong>"، در <strong>Kafka Summit</strong>، آوریل 2016.
    </p>
<p>
        [81] <strong>Tyler Akidau</strong>، <strong>Alex Balikov</strong>، <strong>Kaya Bekiroğlu</strong> و
        همکاران: "<strong>MillWheel</strong>: پردازش <strong>Stream</strong> تحمل‌کننده‌ی خطا در
        مقیاس اینترنت"، در سی و نهمین کنفرانس بین‌المللی در مورد پایگاه‌های
        داده بسیار بزرگ (<strong>VLDB</strong>)، اوت 2013.
    </p>
<p>
        [82] <strong>Alex Dean</strong>: "بهبود درک <strong>Snowplow</strong> از زمان"،
        <strong>snowplowanalytics.com</strong>، 15 سپتامبر 2015.
    </p>
<p>
        [83] "<strong>Windowing</strong> (<strong>Azure Stream Analytics</strong>)"، مرجع <strong>Microsoft
        Azure</strong>، <strong>msdn.microsoft.com</strong>، آوریل 2016.
    </p>
<p>
        [84] "مدیریت <strong>State</strong>"، مستندات <strong>Apache Samza 0.10</strong>،
        <strong>samza.apache.org</strong>، دسامبر 2015.
    </p>
<p>
        [85] <strong>Rajagopal Ananthanarayanan</strong>، <strong>Venkatesh Basker</strong>،
        <strong>Sumit Das</strong> و همکاران: "<strong>Photon</strong>: پیوستن مقیاس‌پذیر و
        تحمل‌کننده‌ی خطا از جریان‌های داده‌ی پیوسته"، در کنفرانس بین‌المللی
        <strong>ACM</strong> در مورد مدیریت داده‌ها (<strong>SIGMOD</strong>)، ژوئن 2013.
        <strong>doi:10.1145/2463676.2465272</strong>
</p>
<p>
        [86] <strong>Martin Kleppmann</strong>: "نمایش <strong>Newsfeed</strong> از <strong>Samza</strong>"،
        <strong>github.com</strong>، سپتامبر 2014.
    </p>
<p>
        [87] <strong>Ben Kirwin</strong>: "انجام غیرممکن: الگوهای پیام‌رسانی
        <strong>Exactly-Once</strong> در <strong>Kafka</strong>"، <strong>ben.kirw.in</strong>، 28 نوامبر
        2014.
    </p>
<p>
        [88] <strong>Pat Helland</strong>: "داده‌ها در بیرون در مقابل داده‌ها در داخل"، در
        دومین کنفرانس دوسالانه در مورد تحقیقات نوآورانه سیستم‌های داده
        (<strong>CIDR</strong>)، ژانویه 2005.
    </p>
<p>
        [89] <strong>Ralph Kimball</strong> و <strong>Margy Ross</strong>: <strong>The Data Warehouse
        Toolkit</strong>: راهنمای قطعی برای مدل‌سازی ابعادی، چاپ 3. <strong>John Wiley &amp;
        Sons</strong>، 2013. <strong>ISBN: 978-1-118-53080-1</strong>
</p>
<p>
        [90] <strong>Viktor Klang</strong>: "من عبارت '<strong>effectively-once</strong>' را برای
        پردازش پیام با عملیات <strong>at-least-once</strong> + <em>idempotent</em>
        معرفی می‌کنم"، <strong>twitter.com</strong>، 20 اکتبر 2016.
    </p>
<p>
        [91] <strong>Matei Zaharia</strong>، <strong>Tathagata Das</strong>، <strong>Haoyuan Li</strong> و
        همکاران: "جریان‌های گسسته: یک مدل کارآمد و تحمل‌کننده‌ی خطا
        برای پردازش <strong>Stream</strong> در <strong>Clusters</strong> بزرگ"، در چهارمین
        کنفرانس <strong>USENIX</strong> در مورد موضوعات داغ در محاسبات ابری
        (<strong>HotCloud</strong>)، ژوئن 2012.
    </p>
<p>
        [92] <strong>Kostas Tzoumas</strong>، <strong>Stephan Ewen</strong> و <strong>Robert
        Metzger</strong>: "توان عملیاتی بالا، تأخیر کم، و پردازش <strong>Stream</strong>
<strong>Exactly-Once</strong> با <strong>Apache Flink</strong>"،
        <strong>data-artisans.com</strong>، 5 اوت 2015.
        486
        |
        فصل 11: پردازش <strong>Stream</strong>
</p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0508</div>
            </div>
        </div>
        <!-- Page 0509 -->
        <div class="chapter" id="page-0509">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        [93] <strong>Paris Carbone</strong>، <strong>Gyula Fóra</strong>، <strong>Stephan Ewen</strong> و
        همکاران: "<strong>Lightweight Asynchronous Snapshots</strong> برای <strong>Distributed
        Dataflows</strong>"، <strong>arXiv:1506.08603 [cs.DC]</strong>، 29 ژوئن 2015.
    </p>
<p>
        [94] <strong>Ryan Betts</strong> و <strong>John Hugg</strong>: داده‌های سریع: هوشمند و در
        مقیاس. گزارش، <strong>O’Reilly Media</strong>، اکتبر 2015.
    </p>
<p>
        [95] <strong>Flavio Junqueira</strong>: "درک <strong>Exactly-Once Semantics</strong>"، در
        <strong>Strata+Hadoop World London</strong>، ژوئن 2016.
    </p>
<p>
        [96] <strong>Jason Gustafson</strong>، <strong>Flavio Junqueira</strong>، <strong>Apurva Mehta</strong>،
        <strong>Sriram Subramanian</strong>، و <strong>Guozhang Wang</strong>: "<strong>KIP-98 –
        Exactly Once Delivery and Transactional Messaging</strong>"،
        <strong>cwiki.apache.org</strong>، نوامبر 2016.
    </p>
<p>
        [97] <strong>Pat Helland</strong>: "<strong>Idempotence</strong> یک وضعیت پزشکی
        نیست"، <strong>Communications of the ACM</strong>، جلد 55، شماره 5، صفحه 56،
        مه 2012. <strong>doi:10.1145/2160718.2160734</strong>
</p>
<p>
        [98] <strong>Jay Kreps</strong>: "در مورد: تلاش برای دستیابی به رفتار
        <em>Deterministic</em> در بازیابی/عقب‌نشینی"، ایمیل به لیست پستی
        <strong>samza-dev</strong>، 9 سپتامبر 2014.
    </p>
<p>
        [99] <strong>E. N. (Mootaz) Elnozahy</strong>، <strong>Lorenzo Alvisi</strong>، <strong>Yi-Min
        Wang</strong>، و <strong>David B. Johnson</strong>: "مروری بر پروتکل‌های <strong>Rollback-
        Recovery</strong> در سیستم‌های پیام‌رسانی"، <strong>ACM Computing Surveys</strong>،
        جلد 34، شماره 3، صفحات 375–408، سپتامبر 2002.
        <strong>doi:10.1145/568522.568525</strong>
</p>
<p>
        [100] <strong>Adam Warski</strong>: "<strong>Kafka Streams</strong> – چگونه با چشم‌انداز
        پردازش <strong>Stream</strong> مطابقت دارد؟"، <strong>softwaremill.com</strong>، 1
        ژوئن 2016.
        خلاصه
        |
        487
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0509</div>
            </div>
        </div>
        <!-- Page 0511 -->
        <div class="chapter" id="page-0511">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<h3>فصل 12</h3>
<h4>آینده‌ی سیستم‌های داده</h4>
<p>
        اگر چیزی به دیگری به‌عنوان هدفش مقدر شده باشد، هدف نهایی آن نمی‌تواند
        مشتمل بر حفظ هستی آن باشد. از این رو یک ناخدا، حفظ کشتی که به او
        سپرد شده است را به عنوان یک هدف نهایی در نظر ندارد، زیرا یک کشتی
        به چیز دیگری به‌عنوان هدفش مقدر شده است، یعنی، به دریانوردی.
        (اغلب به این صورت نقل قول می‌شود: اگر بالاترین هدف یک ناخدا، حفظ
        کشتی‌اش بود، آن را برای همیشه در بندر نگه می‌داشت.)
        —<strong>St. Thomas Aquinas</strong>، <strong>Summa Theologica</strong> (1265–1274)
    </p>
<p>
        تاکنون، این کتاب عمدتاً در مورد توصیف چیزها همان‌طور که در حال
        حاضر هستند، بوده است. در این فصل پایانی، ما دیدگاه خود را به سمت
        آینده تغییر خواهیم داد و بحث خواهیم کرد که چگونه باید چیزها
        باشند: من برخی ایده‌ها و رویکردهایی را پیشنهاد خواهم کرد که، به
        عقیده‌ی من، ممکن است به‌طور اساسی راه‌هایی را که ما برنامه‌ها را
        طراحی و ایجاد می‌کنیم، بهبود بخشد.
    </p>
<p>
        نظرات و گمانه‌زنی‌ها در مورد آینده، البته، ذهنی هستند، و بنابراین من
        در این فصل از <strong>first person</strong> استفاده خواهم کرد که در مورد
        نظرات شخصی‌ام می‌نویسم. شما می‌توانید با آن‌ها موافق نباشید و
        نظرات خود را تشکیل دهید، اما امیدوارم که ایده‌های این فصل حداقل
        نقطه‌ی شروعی برای یک بحث سازنده باشند و مقداری روشنی را به مفاهیمی
        که اغلب اشتباه گرفته می‌شوند، بیاورند.
    </p>
<p>
        هدف این کتاب در فصل 1 مشخص شد: بررسی چگونگی ایجاد
        برنامه‌ها و سیستم‌هایی که قابل اعتماد، مقیاس‌پذیر و قابل نگهداری
        هستند. این موضوعات در تمام فصل‌ها اجرا شده است: به عنوان مثال، ما
        در مورد بسیاری از الگوریتم‌های تحمل خطا بحث کردیم که به بهبود
        قابلیت اطمینان کمک می‌کنند، <strong>partitioning</strong> برای بهبود
        مقیاس‌پذیری، و مکانیسم‌های تکامل و انتزاع که قابلیت نگهداری را
        بهبود می‌بخشند. در این فصل ما تمام این ایده‌ها را گرد هم می‌آوریم، و
        روی آن‌ها بنا می‌کنیم تا آینده را تصور کنیم. هدف ما این است که
        چگونگی طراحی برنامه‌هایی را کشف کنیم که بهتر از برنامه‌های امروزی
        هستند—قوی، صحیح، تکامل‌پذیر، و در نهایت برای بشریت مفید
        هستند.
        489
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0511</div>
            </div>
        </div>
        <!-- Page 0512 -->
        <div class="chapter" id="page-0512">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<h4>ادغام داده‌ها</h4>
<p>
        یک موضوع تکراری در این کتاب این بوده است که برای هر مشکل داده شده،
        راه حل‌های متعددی وجود دارد، که همه‌ی آن‌ها دارای جوانب مثبت، منفی
        و <strong>trade-offs</strong> متفاوتی هستند. به عنوان مثال، هنگام بحث
        در مورد <strong>storage engines</strong> در فصل 3، ما ذخیره‌سازی ساختاریافته
        بر اساس <strong>log</strong>، <strong>B-trees</strong> و ذخیره‌سازی مبتنی بر
        <strong>column</strong> را دیدیم. هنگام بحث در مورد <strong>replication</strong> در
        فصل 5، ما رویکردهای <strong>single-leader</strong>، <strong>multi-leader</strong>، و
        <strong>leaderless</strong> را دیدیم.
    </p>
<p>
        اگر شما یک مشکل مانند "من می‌خواهم مقداری داده را ذخیره کنم و بعداً
        آن را دوباره جستجو کنم" دارید، هیچ راه‌حل درستی وجود ندارد، بلکه
        رویکردهای مختلفی وجود دارد که هر کدام در شرایط مختلف مناسب
        هستند. یک پیاده‌سازی نرم‌افزاری معمولاً باید یک رویکرد خاص را انتخاب
        کند. این به‌اندازه‌ی کافی سخت است که یک مسیر کد را <strong>robust</strong> و
        خوب اجرا کنید—تلاش برای انجام همه‌چیز در یک قطعه نرم‌افزار، تقریباً
        تضمین می‌کند که پیاده‌سازی ضعیف خواهد بود.
    </p>
<p>
        بنابراین، مناسب‌ترین انتخاب از ابزار نرم‌افزاری نیز به شرایط بستگی
        دارد. هر قطعه نرم‌افزار، حتی یک پایگاه داده به اصطلاح "<strong>general-
        purpose</strong>"، برای یک الگوی استفاده خاص طراحی شده است.
    </p>
<p>
        با توجه به این تعدد جایگزین‌ها، اولین چالش این است که نمودار بین
        محصولات نرم‌افزاری و شرایطی را که در آن‌ها مناسب هستند، مشخص
        کنید. فروشندگان قابل درک هستند که از گفتن این‌که برای چه نوع
        <strong>workloads</strong> نرم‌افزارشان مناسب نیست، امتناع می‌کنند، اما
        امیدوارم که فصل‌های قبل شما را به سؤالاتی برای خواندن بین خطوط و
        درک بهتر <strong>trade-offs</strong> مجهز کرده باشد.
    </p>
<p>
        با این حال، حتی اگر شما کاملاً نمودار بین ابزارها و شرایط را برای
        استفاده از آن‌ها درک کنید، یک چالش دیگر وجود دارد: در برنامه‌های
        پیچیده، داده‌ها اغلب به چندین روش مختلف استفاده می‌شوند. بعید است
        یک قطعه نرم‌افزار وجود داشته باشد که برای تمام شرایط مختلفی که
        داده‌ها در آن‌ها استفاده می‌شوند، مناسب باشد، بنابراین شما ناگزیر
        می‌شوید که چندین قطعه نرم‌افزار مختلف را با هم جمع کنید تا
        عملکرد برنامه خود را ارائه دهید.
    </p>
<h4>ترکیب ابزارهای تخصصی با مشتق کردن داده‌ها</h4>
<p>
        به عنوان مثال، نیاز به ادغام یک پایگاه داده‌ی <strong>OLTP</strong> با یک
        index جستجوی متن کامل برای رسیدگی به <strong>queries</strong> برای
        <strong>keywords</strong> دلخواه، رایج است. اگرچه برخی از پایگاه‌های داده
        (مانند <strong>PostgreSQL</strong>) شامل یک ویژگی <strong>full-text indexing</strong>
        هستند، که ممکن است برای برنامه‌های ساده کافی باشد [1]،
        امکانات جستجوی پیچیده‌تر به ابزارهای تخصصی بازیابی اطلاعات
        نیاز دارند. برعکس، index های جستجو به‌طور کلی برای یک سیستم
        <em>durable</em> <strong>record</strong> بسیار مناسب نیستند، و بنابراین بسیاری
        از برنامه‌ها نیاز دارند که دو ابزار مختلف را برای برآورده کردن
        تمام الزامات، با هم ترکیب کنند.
    </p>
<p>
        ما به مسئله‌ی ادغام سیستم‌های داده در "همگام نگه داشتن سیستم‌ها"
        در صفحه 452 اشاره کردیم. با افزایش تعداد نمایش‌های مختلف داده‌ها،
        ادغام
        490
        |
        فصل 12: آینده‌ی سیستم‌های داده
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0512</div>
            </div>
        </div>
        <!-- Page 0513 -->
        <div class="chapter" id="page-0513">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        مشکل <strong>integration</strong> داده‌ها سخت‌تر می‌شود. علاوه بر پایگاه
        داده و index جستجو، شاید شما نیاز داشته باشید که کپی‌هایی از داده‌ها را
        در سیستم‌های <strong>analytics</strong> (انبارهای داده، یا سیستم‌های
        پردازش <strong>batch</strong> و <strong>stream</strong>) نگه دارید؛ <strong>caches</strong>
        یا نسخه‌های <strong>denormalized</strong> از اشیایی را که از داده‌های اصلی
        به‌دست آمده‌اند، نگهداری کنید؛ داده‌ها را از طریق یادگیری
        ماشین، طبقه‌بندی، رتبه‌بندی یا سیستم‌های توصیه منتقل
        کنید؛ یا بر اساس تغییرات در داده‌ها، اعلان‌ها را ارسال کنید.
    </p>
<p>
        به‌طور شگفت‌آوری اغلب من می‌بینم که مهندسان نرم‌افزار اظهاراتی
        مانند، "بر اساس تجربه‌ی من، 99٪ از مردم فقط به X نیاز دارند" یا
        "...به X نیاز ندارند" (برای مقادیر مختلف X) را بیان می‌کنند. من فکر
        می‌کنم که این‌گونه اظهارات بیش از این‌که در مورد سودمندی واقعی
        یک فناوری باشد، در مورد تجربه‌ی سخنران است. طیف وسیعی از
        چیزهای مختلفی که شما ممکن است بخواهید با داده‌ها انجام دهید،
        <em>dizzyingly</em> گسترده است. آن‌چه یک فرد یک <strong>feature</strong>
        نامعلوم و بی‌فایده در نظر می‌گیرد، ممکن است یک نیاز اساسی برای
        شخص دیگری باشد. نیاز به ادغام داده‌ها اغلب تنها زمانی آشکار می‌شود
        که شما <em>zoom out</em> کنید و <strong>dataflows</strong> را در سراسر یک
        سازمان کامل در نظر بگیرید.
    </p>
<h4>استدلال در مورد <strong>dataflows</strong></h4>
<p>
        وقتی کپی‌هایی از داده‌های یکسان باید در چندین سیستم ذخیره‌سازی
        برای ارضای الگوهای دسترسی مختلف حفظ شوند، شما باید در مورد
        ورودی‌ها و خروجی‌ها بسیار واضح باشید: داده‌ها ابتدا کجا نوشته
        می‌شوند، و کدام <strong>representations</strong> از کدام منابع مشتق
        شده‌اند؟ چگونه شما داده‌ها را در همه‌ی مکان‌های مناسب، در
        فرمت‌های صحیح قرار می‌دهید؟
    </p>
<p>
        به عنوان مثال، شما ممکن است ترتیبی دهید که داده‌ها ابتدا در یک
        پایگاه داده‌ی <strong>record</strong> سیستم نوشته شوند، و تغییرات
        ایجاد شده در آن پایگاه داده (نگاه کنید به "<strong>Change Data
        Capture</strong>" در صفحه 454) را ضبط کنید و سپس تغییرات را به
        index جستجو به همان ترتیب اعمال کنید. اگر <strong>change data
        capture (CDC)</strong> تنها راه به‌روزرسانی index باشد، شما می‌توانید
        مطمئن باشید که index کاملاً از سیستم <strong>record</strong> مشتق شده است،
        و بنابراین با آن سازگار است (به‌جز <strong>bugs</strong> در نرم‌افزار). نوشتن
        در پایگاه داده تنها راه برای تأمین ورودی جدید در این سیستم است.
    </p>
<p>
        اجازه دادن به برنامه برای نوشتن مستقیم در index جستجو و پایگاه
        داده، مشکل نشان داده شده در شکل 11-4 را معرفی می‌کند، که در آن
        دو <strong>clients</strong> هم‌زمان <strong>writes</strong> متناقض را ارسال
        می‌کنند، و دو سیستم ذخیره‌سازی آن‌ها را به ترتیب متفاوتی
        پردازش می‌کنند. در این حالت، نه پایگاه داده و نه index جستجو
        "مسئول" تعیین ترتیب <strong>writes</strong> نیستند، و بنابراین ممکن است
        تصمیمات متناقضی بگیرند و به‌طور دائم با یکدیگر ناسازگار
        شوند.
    </p>
<p>
        اگر امکان داشته باشد که شما تمام ورودی‌های کاربر را از طریق یک
        سیستم واحد هدایت کنید که در مورد یک <strong>ordering</strong> برای
        تمام <strong>writes</strong> تصمیم می‌گیرد، مشتق کردن <strong>representations</strong>
        دیگر از داده‌ها با پردازش <strong>writes</strong> به همان ترتیب بسیار آسان
        تر می‌شود. این یک کاربرد از رویکرد <strong>state machine replication</strong>
        است که ما در "<strong>Total Order Broadcast</strong>" در صفحه 348 دیدیم.
    </p>
<p>
        این‌که آیا شما از <strong>change data capture</strong> یا یک <strong>event sourcing
        log</strong> استفاده می‌کنید، کمتر از این اصل مهم است که باید در مورد
        یک ترتیب کلی تصمیم بگیرید.
        ادغام داده‌ها
        |
        491
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0513</div>
            </div>
        </div>
        <!-- Page 0514 -->
        <div class="chapter" id="page-0514">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        به‌روزرسانی یک سیستم داده‌ی مشتق شده بر اساس یک <strong>event log</strong>
        اغلب می‌تواند <em>deterministic</em> و <em>idempotent</em> شود (نگاه کنید به
        "<strong>Idempotence</strong>" در صفحه 478)، و بازیابی از <strong>faults</strong> را
        بسیار آسان می‌کند.
    </p>
<h4>داده‌های مشتق شده در مقابل تراکنش‌های توزیع شده</h4>
<p>
        رویکرد کلاسیک برای همگام نگه داشتن سیستم‌های داده‌ی مختلف با یکدیگر،
        شامل تراکنش‌های توزیع شده است، همان‌طور که در "<strong>Atomic Commit</strong>
        و <strong>Two-Phase Commit (2PC)</strong>" در صفحه 354 بحث شد. رویکرد
        استفاده از سیستم‌های داده‌ی مشتق شده در مقایسه با تراکنش‌های
        توزیع شده چگونه است؟
    </p>
<p>
        در یک سطح انتزاعی، آن‌ها با ابزارهای مختلف به یک هدف مشابه دست
        می‌یابند. تراکنش‌های توزیع شده با استفاده از <strong>locks</strong> برای
        <strong>mutual exclusion</strong> (نگاه کنید به "<strong>Two-Phase Locking (2PL)</strong>"
        در صفحه 257) در مورد یک <strong>ordering</strong> از نوشتن‌ها تصمیم می‌گیرند،
        در حالی که <strong>CDC</strong> و <strong>event sourcing</strong> از یک <strong>log</strong> برای
        <strong>ordering</strong> استفاده می‌کنند. تراکنش‌های توزیع شده از
        <strong>atomic commit</strong> برای اطمینان از این‌که تغییرات دقیقاً یک بار
        اعمال می‌شوند، استفاده می‌کنند، در حالی که سیستم‌های مبتنی بر <strong>log</strong>
        اغلب بر اساس <strong>deterministic retry</strong> و <strong>idempotence</strong>
        هستند.
    </p>
<p>
        بزرگترین تفاوت این است که سیستم‌های تراکنش معمولاً
        <strong>linearizability</strong> را ارائه می‌دهند (نگاه کنید به "<strong>Linearizability</strong>"
        در صفحه 324)، که تضمین‌های مفیدی را از جمله خواندن
        نوشتن‌های خودتان را به‌همراه دارد (نگاه کنید به "خواندن
        نوشتن‌های خودتان" در صفحه 162). از سوی دیگر، سیستم‌های
        داده‌ی مشتق شده اغلب به‌طور <em>asynchronously</em> به‌روزرسانی
        می‌شوند، و بنابراین به‌طور پیش‌فرض همان تضمین‌های زمان‌بندی
        را ارائه نمی‌دهند.
    </p>
<p>
        در محیط‌های محدودی که مایل به پرداخت هزینه‌ی تراکنش‌های
        توزیع شده هستند، آن‌ها با موفقیت استفاده شده‌اند. با این حال، من
        فکر می‌کنم که <strong>XA</strong> دارای ویژگی‌های تحمل خطای و عملکرد ضعیفی
        است (نگاه کنید به "تراکنش‌های توزیع شده در عمل" در صفحه 360)،
        که به‌شدت قابلیت استفاده از آن را محدود می‌کند. من معتقدم که
        ممکن است بتوان یک پروتکل بهتر برای تراکنش‌های توزیع شده ایجاد
        کرد، اما دریافت این‌که چنین پروتکلی به‌طور گسترده‌ای پذیرفته
        شود و با ابزارهای موجود ادغام شود، چالش‌برانگیز خواهد بود، و
        به‌زودی اتفاق نخواهد افتاد.
    </p>
<p>
        به‌طوریکه در غیاب پشتیبانی گسترده برای یک پروتکل تراکنش توزیع
        شده‌ی خوب، من معتقدم که داده‌های مشتق شده‌ی مبتنی بر <strong>log</strong>
        امیدوارکننده‌ترین رویکرد برای ادغام سیستم‌های داده‌ی مختلف است. با
        این حال، تضمین‌هایی مانند خواندن نوشتن‌های خودتان مفید هستند، و
        من فکر نمی‌کنم که گفتن به همه "<em>eventual consistency</em> اجتناب‌ناپذیر
        است—آن را بپذیرید و یاد بگیرید که چگونه با آن برخورد کنید" (حداقل
        بدون راهنمایی خوب در مورد چگونگی برخورد با آن)، نتیجه‌بخش
        باشد.
    </p>
<p>
        در "هدف قرار دادن درستی" در صفحه 515 ما در مورد برخی رویکردها
        برای پیاده‌سازی تضمین‌های قوی‌تر بر روی سیستم‌های <em>asynchronously</em>
        مشتق شده، و کار به سمت یک راه‌حل میانی بین تراکنش‌های توزیع شده
        و سیستم‌های مبتنی بر <strong>log asynchronous</strong> بحث خواهیم کرد.
        492
        |
        فصل 12: آینده‌ی سیستم‌های داده
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0514</div>
            </div>
        </div>
        <!-- Page 0515 -->
        <div class="chapter" id="page-0515">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<h4>محدودیت‌های <strong>total ordering</strong></h4>
<p>
        با سیستم‌هایی که به‌اندازه‌ی کافی کوچک هستند، ساخت یک <strong>event log</strong>
        کاملاً مرتب شده کاملاً امکان‌پذیر است (همان‌طور که محبوبیت
        پایگاه‌های داده با <strong>single-leader replication</strong>، که دقیقاً چنین
        <strong>log</strong> ای را می‌سازند، نشان می‌دهد). با این حال، با
        مقیاس‌بندی سیستم‌ها به سمت <strong>workloads</strong> بزرگتر و
        پیچیده‌تر، محدودیت‌ها شروع به ظهور می‌کنند:
    </p>
<ul>
<li>
            در بیشتر موارد، ساخت یک <strong>log</strong> کاملاً مرتب شده، مستلزم
            این است که تمام رویدادها از یک <strong>leader node</strong> واحد عبور
            کنند که در مورد <strong>ordering</strong> تصمیم می‌گیرد. اگر توان
            عملیاتی رویدادها بیشتر از آن چیزی باشد که یک ماشین واحد
            می‌تواند مدیریت کند، شما نیاز دارید که آن را در بین چندین
            ماشین تقسیم‌بندی کنید (نگاه کنید به "<strong>Partitioned Logs</strong>"
            در صفحه 446). ترتیب رویدادها در دو <strong>partitions</strong> مختلف
            بعداً مبهم خواهد بود.
        </li>
<li>
            اگر سرورها در چندین <strong>datacenters</strong> که از نظر جغرافیایی توزیع
            شده‌اند، پخش شوند، به عنوان مثال به منظور تحمل آفلاین شدن
            یک <strong>datacenter</strong> کامل، شما معمولاً یک <strong>leader</strong>
            جداگانه در هر <strong>datacenter</strong> دارید، زیرا تأخیرهای شبکه
            هماهنگی <em>synchronous cross-datacenter</em> را ناکارآمد می‌کند
            (نگاه کنید به "<strong>Multi-Leader Replication</strong>" در صفحه 168).
            این امر یک <strong>ordering</strong> تعریف نشده از رویدادهایی را که در دو
            <strong>datacenters</strong> مختلف منشأ می‌گیرند، نشان می‌دهد.
        </li>
<li>
            هنگامی که برنامه‌ها به عنوان <strong>microservices</strong> مستقر
            می‌شوند (نگاه کنید به "<strong>Dataflow</strong> از طریق <strong>Services</strong>:
            <strong>REST</strong> و <strong>RPC</strong>" در صفحه 131)، یک انتخاب طراحی
            رایج این است که هر <strong>service</strong> و <strong>state</strong> <em>durable</em>
            آن را به‌عنوان یک واحد مستقل مستقر کنید، بدون این‌که هیچ
            <strong>state</strong> <em>durable</em> بین <strong>services</strong> به اشتراک
            گذاشته شود. هنگامی که دو رویداد در <strong>services</strong> مختلف منشأ
            می‌گیرند، هیچ ترتیب تعریف شده‌ای برای آن رویدادها وجود
            ندارد.
        </li>
<li>
            برخی از برنامه‌ها، <strong>state</strong> سمت <strong>client</strong> را حفظ
            می‌کنند که بلافاصله بر اساس ورودی کاربر به‌روزرسانی می‌شود
            (بدون انتظار تأیید از یک سرور)، و حتی به کار <em>offline</em> ادامه
            می‌دهند (نگاه کنید به "<strong>Clients</strong> با عملیات <em>offline</em>" در
            صفحه 170). با چنین برنامه‌هایی، <strong>clients</strong> و سرورها بسیار
            احتمال دارد که رویدادها را به ترتیب‌های مختلف ببینند.
        </li>
</ul>
<p>
        از نظر رسمی، تصمیم‌گیری در مورد یک <strong>total order</strong> از رویدادها،
        به‌عنوان <strong>total order broadcast</strong> شناخته می‌شود، که معادل
        <strong>consensus</strong> است (نگاه کنید به "الگوریتم‌های اجماع و
        <strong>total order broadcast</strong>" در صفحه 366). اکثر الگوریتم‌های
        اجماع برای موقعیت‌هایی طراحی شده‌اند که در آن‌ها توان عملیاتی
        یک <strong>node</strong> واحد برای پردازش کل <strong>stream</strong> از
        رویدادها کافی است، و این الگوریتم‌ها یک مکانیسم برای این‌که
        چندین <strong>nodes</strong> کار <strong>ordering</strong> رویدادها را به
        اشتراک بگذارند، ارائه نمی‌دهند. همچنان یک مشکل تحقیقاتی
        باز است که الگوریتم‌های اجماعی را طراحی کنیم که بتوانند فراتر از
        توان عملیاتی یک <strong>node</strong> واحد مقیاس‌پذیر باشند و در یک محیط
        توزیع شده جغرافیایی به‌خوبی کار کنند.
    </p>
<h4>ترتیب دادن رویدادها برای ضبط <strong>causality</strong></h4>
<p>
        در مواردی که هیچ پیوند علّی بین رویدادها وجود ندارد، فقدان یک
        <strong>total order</strong> مشکل بزرگی نیست، زیرا رویدادهای
        همزمان را می‌توان به‌طور دلخواه مرتب کرد. برخی از موارد دیگر
        آسان هستند: به عنوان مثال، وقتی به‌روزرسانی‌های متعددی از
        یک شیء یکسان وجود دارد، می‌توان آن‌ها را با مسیریابی تمام
        به‌روزرسانی‌ها برای یک <strong>ID</strong> شیء خاص به یک <strong>log</strong>
        یکسان، کاملاً مرتب کرد.
        ادغام داده‌ها
        |
        493
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0515</div>
            </div>
        </div>
        <!-- Page 0516 -->
        <div class="chapter" id="page-0516">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
<strong>partition</strong>. با این حال، وابستگی‌های علّی گاهی اوقات به روش‌های
        ظریف‌تری ایجاد می‌شوند (همچنین به "<strong>Ordering</strong> و <strong>Causality</strong>"
        در صفحه 339 مراجعه کنید).
    </p>
<p>
        به عنوان مثال، یک سرویس شبکه‌ی اجتماعی را در نظر بگیرید، و دو
        کاربر که با هم رابطه داشتند اما اخیراً از هم جدا شده‌اند. یکی از
        کاربران دیگری را به‌عنوان دوست حذف می‌کند، و سپس پیامی را به
        دوستان باقی‌مانده خود ارسال می‌کند و از شریک سابق خود شکایت
        می‌کند.
    </p>
<p>
        قصد کاربر این است که شریک سابقشان نباید پیام بی‌ادبانه را ببیند، زیرا
        پیام پس از لغو وضعیت دوستی ارسال شده است.
    </p>
<p>
        با این حال، در سیستمی که وضعیت دوستی را در یک مکان و پیام‌ها را
        در مکان دیگری ذخیره می‌کند، این وابستگی <strong>ordering</strong> بین
        رویداد <strong>unfriend</strong> و رویداد <strong>message-send</strong> ممکن است
        از دست برود. اگر وابستگی علّی ثبت نشود، یک <strong>service</strong> که
        اعلان‌هایی را در مورد پیام‌های جدید ارسال می‌کند، ممکن است رویداد
        <strong>message-send</strong> را قبل از رویداد <strong>unfriend</strong> پردازش
        کند، و بنابراین به‌طور نادرست یک اعلان را به شریک سابق ارسال
        کند.
    </p>
<p>
        در این مثال، اعلان‌ها به‌طور موثر یک <strong>join</strong> بین پیام‌ها و
        فهرست دوستان هستند، که آن را به مسائل مربوط به زمان <strong>joins</strong> که
        قبلاً بحث کردیم مرتبط می‌کند (نگاه کنید به "وابستگی به زمان
        <strong>joins</strong>" در صفحه 475). متأسفانه، به نظر نمی‌رسد که یک
        پاسخ ساده برای این مشکل وجود داشته باشد [2، 3]. نقاط شروع
        شامل موارد زیر هستند:
    </p>
<ul>
<li>
<strong>Timestamps</strong> منطقی می‌توانند <strong>total ordering</strong> را بدون
            هماهنگی ارائه دهند (نگاه کنید به "<strong>Sequence Number
            Ordering</strong>" در صفحه 343)، بنابراین آن‌ها ممکن است در
            مواردی که <strong>total order broadcast</strong> امکان‌پذیر نیست،
            کمک کنند. با این حال، آن‌ها همچنان نیاز دارند که دریافت‌کنندگان به
            رویدادهایی که خارج از ترتیب تحویل داده می‌شوند، رسیدگی
            کنند، و آن‌ها به <strong>metadata</strong> اضافی نیاز دارند که منتقل
            شوند.
        </li>
<li>
            اگر شما می‌توانید یک رویداد را <strong>log</strong> کنید تا وضعیت
            سیستمی را که کاربر قبل از تصمیم‌گیری مشاهده کرده است، ثبت
            کند، و به آن رویداد یک شناسه‌ی منحصربه‌فرد بدهید، سپس هر
            رویداد بعدی می‌تواند به آن شناسه‌ی رویداد ارجاع دهد تا
            وابستگی علّی را ثبت کند [4].
            ما به این ایده در "خوانش‌ها هم رویداد هستند" در صفحه 513
            بازخواهیم گشت.
        </li>
<li>
            الگوریتم‌های <strong>conflict resolution</strong> (نگاه کنید به "<strong>Automatic
            Conflict Resolution</strong>" در صفحه 174) به پردازش رویدادهایی
            که به ترتیب غیرمنتظره تحویل داده می‌شوند، کمک می‌کنند. آن‌ها
            برای حفظ <strong>state</strong> مفید هستند، اما اگر اقدامات دارای اثرات
            جانبی خارجی باشند (مانند ارسال یک اعلان به یک کاربر)،
            کمکی نمی‌کنند.
        </li>
</ul>
<p>
        شاید، با گذشت زمان، الگوهایی برای توسعه برنامه ظاهر شود که به
        وابستگی‌های علّی اجازه می‌دهد که به‌طور کارآمد ضبط شوند، و
        <strong>state</strong> مشتق شده به‌درستی حفظ شود، بدون این‌که تمام
        رویدادها را مجبور به عبور از گلوگاه <strong>total order broadcast</strong>
        کند.
    </p>
<h4><strong>Batch</strong> و پردازش <strong>Stream</strong></h4>
<p>
        من می‌گویم که هدف ادغام داده‌ها این است که اطمینان حاصل شود که
        داده‌ها در جای مناسب در همه‌ی مکان‌های مناسب قرار می‌گیرند. انجام
        این کار مستلزم مصرف ورودی‌ها، تبدیل، <strong>joining</strong>، فیلتر کردن،
        تجمیع، آموزش مدل‌ها، ارزیابی، و در نهایت نوشتن در
        494
        |
        فصل 12: آینده‌ی سیستم‌های داده
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0516</div>
            </div>
        </div>
        <!-- Page 0517 -->
        <div class="chapter" id="page-0517">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        خروجی‌های مناسب. پردازنده‌های <strong>batch</strong> و <strong>stream</strong>
        ابزارهایی برای دستیابی به این هدف هستند.
    </p>
<p>
        خروجی‌های فرآیندهای <strong>batch</strong> و <strong>stream</strong>
        مجموعه‌داده‌های مشتق شده مانند <strong>search indexes</strong>،
        <strong>materialized views</strong>، توصیه‌هایی برای نشان دادن به
        کاربران، معیارهای تجمعی و غیره هستند (نگاه کنید به "خروجی جریان‌های
        کاری <strong>Batch</strong>" در صفحه 411 و "موارد استفاده از پردازش
        <strong>Stream</strong>" در صفحه 465).
    </p>
<p>
        همان‌طور که در فصل 10 و فصل 11 دیدیم، پردازش <strong>batch</strong> و
        <strong>stream</strong>، اصول مشترک زیادی دارند، و تفاوت اساسی اصلی
        این است که پردازنده‌های <strong>stream</strong> بر روی مجموعه‌داده‌های
        <em>unbounded</em> عمل می‌کنند در حالی که ورودی‌های فرآیند <strong>batch</strong>
        دارای اندازه‌ی مشخص و متناهی هستند. همچنین تفاوت‌های
        جزئی زیادی در روش‌های پیاده‌سازی موتورهای پردازش وجود دارد، اما این
        تمایزها در حال محو شدن هستند.
    </p>
<p>
<strong>Spark</strong>، پردازش <strong>stream</strong> را بر روی یک موتور پردازش
        <strong>batch</strong> با تقسیم <strong>stream</strong> به <strong>microbatches</strong>
        انجام می‌دهد، در حالی که <strong>Apache Flink</strong>، پردازش <strong>batch</strong>
        را بر روی یک موتور پردازش <strong>stream</strong> انجام می‌دهد [5]. در
        اصل، یک نوع از پردازش را می‌توان بر روی دیگری شبیه‌سازی کرد، اگرچه
        ویژگی‌های عملکردی متفاوت است: به عنوان مثال، <strong>microbatching</strong>
        ممکن است در <strong>hopping</strong> یا <strong>sliding windows</strong> عملکرد
        ضعیفی داشته باشد [6].
    </p>
<h4>حفظ <strong>state</strong> مشتق شده</h4>
<p>
        پردازش <strong>batch</strong> دارای یک طعم عملکردی بسیار قوی است (حتی اگر
        کد به زبان برنامه‌نویسی <em>functional</em> نوشته نشده باشد): توابع
        <em>deterministic</em> و خالص را تشویق می‌کند که خروجی آن‌ها فقط به
        ورودی بستگی دارد و هیچ اثر جانبی دیگری به‌جز خروجی‌های صریح
        ندارند، ورودی‌ها را به‌عنوان <em>immutable</em> و خروجی‌ها را
        <em>append-only</em> در نظر می‌گیرند.
    </p>
<p>
        پردازش <strong>stream</strong> مشابه است، اما <strong>operators</strong> را
        برای اجازه دادن به <strong>state</strong> مدیریت شده و تحمل خطا
        (نگاه کنید به "بازسازی <strong>state</strong> پس از یک <strong>failure</strong>" در
        صفحه 478) گسترش می‌دهد.
    </p>
<p>
        اصل توابع <em>deterministic</em> با ورودی‌ها و خروجی‌های مشخص
        نه‌تنها برای تحمل خطا خوب است (نگاه کنید به "<strong>Idempotence</strong>"
        در صفحه 478)، بلکه استدلال در مورد <strong>dataflows</strong> در یک
        سازمان را نیز ساده می‌کند [7]. مهم نیست که داده‌های مشتق شده یک
        index جستجو، یک مدل آماری، یا یک <strong>cache</strong> باشد، این مفید
        است که به <strong>data pipelines</strong> فکر کنیم که یک چیز را از دیگری
        مشتق می‌کنند، تغییرات <strong>state</strong> را در یک سیستم از طریق کد
        برنامه عملکردی <em>push</em> می‌کنند و اثرات را در سیستم‌های
        مشتق شده اعمال می‌کنند.
    </p>
<p>
        در اصل، سیستم‌های داده‌ی مشتق شده می‌توانند به‌صورت
        <em>synchronously</em> نگه‌داری شوند، درست مانند این‌که یک پایگاه داده
        رابطه‌ای <strong>indexes</strong> ثانویه را به‌صورت <em>synchronously</em>
        در داخل همان تراکنش به‌عنوان <strong>writes</strong> در جدولی که
        <strong>indexed</strong> می‌شود، به‌روزرسانی می‌کند. با این حال،
        <em>asynchrony</em> همان چیزی است که سیستم‌های مبتنی بر
        <strong>event logs</strong> را <strong>robust</strong> می‌سازد: به یک خطا در یک
        بخش از سیستم اجازه می‌دهد که به‌صورت محلی مهار شود، در حالی
        که تراکنش‌های توزیع شده در صورت شکست هر یک از شرکت‌کنندگان
        متوقف می‌شوند، بنابراین آن‌ها تمایل به تقویت <strong>failures</strong> با
        گسترش آن‌ها به بقیه‌ی سیستم دارند (نگاه کنید به "محدودیت‌های
        تراکنش‌های توزیع شده" در صفحه 363).
    </p>
<p>
        ما در "<strong>Partitioning</strong> و <strong>Secondary Indexes</strong>" در صفحه
        206 دیدیم که <strong>indexes</strong> ثانویه اغلب از مرزهای <strong>partition</strong>
        عبور می‌کنند. یک سیستم تقسیم‌بندی شده با <strong>indexes</strong> ثانویه یا
        پایگاه داده‌های
        495
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0517</div>
            </div>
        </div>
        <!-- Page 0518 -->
        <div class="chapter" id="page-0518">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        باید <strong>writes</strong> را به <strong>partitions</strong> متعدد ارسال
        کند (اگر index بر اساس <strong>term</strong> تقسیم‌بندی شده باشد) یا
        <strong>reads</strong> را به تمام <strong>partitions</strong> (اگر index بر اساس
        سند تقسیم‌بندی شده باشد) ارسال کند. این نوع ارتباط <em>cross-partition</em>
        نیز قابل اعتماد و مقیاس‌پذیر است اگر index <em>asynchronously</em>
        نگه‌داری شود [8] (همچنین به "پردازش داده‌های چند <strong>partition</strong>" در
        صفحه 514 مراجعه کنید).
    </p>
<h4>پردازش مجدد داده‌ها برای تکامل برنامه</h4>
<p>
        هنگام نگه‌داری داده‌های مشتق شده، پردازش <strong>batch</strong> و پردازش
        <strong>stream</strong> هر دو مفید هستند. پردازش <strong>stream</strong> به
        تغییرات در ورودی اجازه می‌دهد تا با تأخیر کم در <strong>views</strong> مشتق
        شده منعکس شوند، در حالی که پردازش <strong>batch</strong> به مقادیر زیادی از
        داده‌های تاریخی انباشته شده اجازه می‌دهد تا برای استخراج <strong>views</strong>
        جدید بر روی یک مجموعه‌داده موجود، دوباره پردازش شوند.
    </p>
<p>
        به‌طور خاص، پردازش مجدد داده‌های موجود، یک مکانیسم خوب برای حفظ
        یک سیستم، تکامل آن برای پشتیبانی از <strong>features</strong> جدید و
        تغییر الزامات فراهم می‌کند (نگاه کنید به فصل 4). بدون پردازش مجدد،
        تکامل <strong>schema</strong> به تغییرات ساده‌ای مانند افزودن یک <strong>field</strong>
        اختیاری جدید به یک رکورد، یا افزودن یک نوع جدید از رکورد محدود
        می‌شود. این مورد هم در یک <strong>schema-on-write</strong> و هم در یک
        <strong>context</strong> <strong>schema-on-read</strong> وجود دارد (نگاه کنید به
        "انعطاف‌پذیری <strong>Schema</strong> در مدل سند" در صفحه 39). از سوی
        دیگر، با پردازش مجدد می‌توان یک مجموعه‌داده را در یک مدل کاملاً
        متفاوت برای خدمت‌رسانی بهتر به الزامات جدید، بازسازی کرد.
    </p>
<h4>مهاجرت <strong>Schema</strong> در راه‌آهن</h4>
<p>
        "مهاجرت‌های <strong>schema</strong>" در مقیاس بزرگ در سیستم‌های غیر
        کامپیوتری نیز رخ می‌دهد. به عنوان مثال، در روزهای اول ساخت راه‌آهن
        در انگلستان قرن نوزدهم، استانداردهای مختلفی برای <strong>gauge</strong> (فاصله
        بین دو ریل) وجود داشت. قطارهایی که برای یک <strong>gauge</strong> ساخته شده
        بودند، نمی‌توانستند روی ریل‌های <strong>gauge</strong> دیگر حرکت کنند، که
        اتصالات ممکن در شبکه‌ی قطار را محدود می‌کرد [9].
    </p>
<p>
        پس از این‌که در سال 1846، یک <strong>standard gauge</strong> واحد در نهایت
        تصمیم‌گیری شد، ریل‌هایی با <strong>gauges</strong> دیگر باید
        تبدیل می‌شدند—اما چگونه شما این کار را بدون خاموش کردن خط
        قطار برای ماه‌ها یا سال‌ها انجام می‌دهید؟ راه‌حل این است که ابتدا
        ریل را با افزودن یک ریل سوم، به <strong>dual gauge</strong> یا <strong>mixed
        gauge</strong> تبدیل کنید. این تبدیل را می‌توان به‌تدریج انجام داد، و
        هنگامی که این کار انجام شد، قطارهایی با هر دو <strong>gauges</strong>
        می‌توانند روی خط حرکت کنند، با استفاده از دو ریل از سه ریل. در
        نهایت، هنگامی که تمام قطارها به <strong>standard gauge</strong> تبدیل شده‌اند،
        ریل که <strong>gauge</strong> غیر استاندارد را فراهم می‌کند، می‌تواند حذف
        شود.
    </p>
<p>
        "پردازش مجدد" ریل‌های موجود به این روش، و اجازه دادن به نسخه‌های
        قدیمی و جدید برای وجود در کنار هم، تغییر <strong>gauge</strong> را به‌تدریج در
        طول سال‌ها امکان‌پذیر می‌کند. با این وجود، این یک تعهد پرهزینه است،
        به همین دلیل است که <strong>gauges</strong> غیر استاندارد هنوز هم امروز
        وجود دارند. به عنوان مثال، سیستم <strong>BART</strong> در منطقه‌ی خلیج
        <strong>San Francisco</strong> از یک <strong>gauge</strong> متفاوت از اکثریت ایالات
        متحده استفاده می‌کند.
        496
        |
        فصل 12: آینده‌ی سیستم‌های داده
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0518</div>
            </div>
        </div>
        <!-- Page 0519 -->
        <div class="chapter" id="page-0519">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
<strong>Views</strong> مشتق شده، تکامل تدریجی را ممکن می‌سازند. اگر شما
        می‌خواهید یک مجموعه‌داده را بازسازی کنید، شما نیازی به انجام
        مهاجرت به‌عنوان یک تغییر ناگهانی ندارید. در عوض، شما می‌توانید
        <strong>schema</strong> قدیمی و <strong>schema</strong> جدید را در کنار هم به‌عنوان
        دو <strong>views</strong> که به‌طور مستقل از داده‌های اساسی مشتق
        شده‌اند، حفظ کنید. سپس شما می‌توانید شروع به انتقال تعداد کمی از
        کاربران به <strong>view</strong> جدید کنید تا عملکرد آن را آزمایش کنید و
        هرگونه <strong>bugs</strong> را پیدا کنید، در حالی که اکثر کاربران همچنان
        به <strong>view</strong> قدیمی هدایت می‌شوند. به‌تدریج، شما می‌توانید
        نسبت کاربرانی را که به <strong>view</strong> جدید دسترسی دارند، افزایش
        دهید، و در نهایت می‌توانید <strong>view</strong> قدیمی را <em>drop</em>
        کنید [10].
    </p>
<p>
        زیبایی چنین مهاجرت تدریجی این است که هر مرحله از فرآیند در صورت
        بروز مشکل، به‌راحتی قابل برگشت است: شما همیشه یک سیستم
        در حال کار دارید که می‌توانید به آن بازگردید.
    </p>
<p>
        با کاهش خطر آسیب برگشت‌ناپذیر، شما می‌توانید در مورد پیش رفتن
        مطمئن‌تر باشید، و بنابراین سریع‌تر برای بهبود سیستم خود اقدام
        کنید [11].
    </p>
<h4>معماری <strong>lambda</strong></h4>
<p>
        اگر پردازش <strong>batch</strong> برای پردازش مجدد داده‌های تاریخی
        استفاده می‌شود، و پردازش <strong>stream</strong> برای پردازش
        به‌روزرسانی‌های اخیر استفاده می‌شود، پس چگونه این دو را ترکیب
        می‌کنید؟ معماری <strong>lambda</strong> [12] یک پیشنهاد در این
        زمینه است که توجه زیادی را به‌خود جلب کرده است.
    </p>
<p>
        ایده‌ی اصلی معماری <strong>lambda</strong> این است که داده‌های ورودی
        باید با پیوست کردن رویدادهای <em>immutable</em> به یک
        مجموعه‌داده که همیشه در حال رشد است، ثبت شوند، مشابه
        <strong>event sourcing</strong> (نگاه کنید به "<strong>Event Sourcing</strong>"
        در صفحه 457). از این رویدادها، <strong>views</strong> با <em>read-optimized</em>
        مشتق می‌شوند. معماری <strong>lambda</strong> پیشنهاد می‌کند که دو
        سیستم مختلف را به‌صورت موازی اجرا کنید:
        یک سیستم پردازش <strong>batch</strong> مانند <strong>Hadoop MapReduce</strong>،
        و یک سیستم پردازش <strong>stream</strong> جداگانه مانند <strong>Storm</strong>.
    </p>
<p>
        در رویکرد <strong>lambda</strong>، پردازنده <strong>stream</strong>، رویدادها را
        مصرف می‌کند و به‌سرعت یک به‌روزرسانی تقریبی از <strong>view</strong>
        را تولید می‌کند؛ پردازنده <strong>batch</strong> بعداً همان مجموعه
        رویدادها را مصرف می‌کند و یک نسخه اصلاح‌شده از <strong>view</strong>
        مشتق شده را تولید می‌کند. استدلال پشت این طراحی این است که
        پردازش <strong>batch</strong> ساده‌تر است و بنابراین کمتر مستعد <strong>bugs</strong>
        است، در حالی که تصور می‌شود پردازنده‌های <strong>stream</strong>،
        کمتر قابل اعتماد هستند و ساختن آن‌ها برای تحمل خطا سخت‌تر
        است (نگاه کنید به "تحمل خطا" در صفحه 476). علاوه بر این،
        فرآیند <strong>stream</strong> می‌تواند از الگوریتم‌های تقریبی سریع
        استفاده کند در حالی‌که فرآیند <strong>batch</strong> از الگوریتم‌های دقیق
        آهسته‌تر استفاده می‌کند.
    </p>
<p>
        معماری <strong>lambda</strong> یک ایده‌ی تأثیرگذار بود که طراحی سیستم‌های
        داده را به سمت بهتر شدن شکل داد، به‌ویژه با محبوب‌سازی اصل
        مشتق کردن <strong>views</strong> بر روی جریان‌های رویدادهای <em>immutable</em>
        و پردازش مجدد رویدادها در صورت نیاز. با این حال، من همچنین
        فکر می‌کنم که تعدادی از مشکلات عملی دارد:
    </p>
<ul>
<li>
            داشتن نیاز به حفظ منطق یکسان برای اجرا در هر دو فریم‌ورک
            پردازش <strong>batch</strong> و <strong>stream</strong>، تلاش
            اضافی قابل توجهی است. اگرچه کتابخانه‌هایی مانند
            <strong>Summingbird</strong> [13] یک انتزاع برای محاسبات فراهم
            می‌کنند که می‌توانند در هر دو <strong>context</strong> <strong>batch</strong> یا
            <strong>streaming</strong> اجرا شوند، پیچیدگی عملیاتی <strong>debugging</strong>،
            <strong>tuning</strong>، و حفظ دو سیستم مختلف باقی می‌ماند [14].
            497
        </li>
</ul>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0519</div>
            </div>
        </div>
        <!-- Page 0520 -->
        <div class="chapter" id="page-0520">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<ul>
<li>
            از آن‌جایی‌که <strong>stream pipeline</strong> و <strong>batch pipeline</strong>
            خروجی‌های جداگانه‌ای تولید می‌کنند، آن‌ها باید برای پاسخ به
            درخواست‌های کاربر ادغام شوند. اگر محاسبه، یک تجمیع ساده در
            یک <strong>tumbling window</strong> باشد، این ادغام کاملاً آسان است، اما
            اگر <strong>view</strong> با استفاده از عملیات پیچیده‌تری مانند <strong>joins</strong> و
            <strong>sessionization</strong> مشتق شده باشد، یا اگر خروجی یک سری زمانی
            نباشد، به‌طور قابل توجهی سخت‌تر می‌شود.
        </li>
<li>
            اگرچه داشتن توانایی پردازش مجدد کل مجموعه‌داده تاریخی عالی
            است، اما انجام این کار به‌طور مکرر در مجموعه‌داده‌های بزرگ،
            پرهزینه است. بنابراین، <strong>batch pipeline</strong> اغلب نیاز دارد که برای
            پردازش <strong>batches</strong> افزایشی تنظیم شود (به عنوان مثال، یک ساعت
            ارزش داده‌ها در پایان هر ساعت) به‌جای پردازش مجدد همه‌چیز. این
            امر مشکلات مطرح شده در "استدلال در مورد زمان" در صفحه 468 را
            ایجاد می‌کند، مانند رسیدگی به <em>stragglers</em> و رسیدگی به
            <strong>windows</strong> که از مرزها بین <strong>batches</strong> عبور
            می‌کنند.
        </li>
<p>
            افزایش دادن یک محاسبه‌ی <strong>batch</strong>، پیچیدگی را اضافه
            می‌کند، و آن را بیشتر شبیه لایه‌ی <strong>streaming</strong> می‌کند، که در
            تضاد با هدف نگه داشتن لایه‌ی <strong>batch</strong> تا حد ممکن
            ساده است.
        </p>
</ul>
<h4>یکپارچه‌سازی پردازش <strong>batch</strong> و <strong>stream</strong></h4>
<p>
        کار اخیرتر به این امکان رسیده است که از مزایای معماری <strong>lambda</strong>
        بدون معایب آن بهره‌مند شوید، با اجازه دادن به محاسبات <strong>batch</strong>
        (پردازش مجدد داده‌های تاریخی) و محاسبات <strong>stream</strong> (پردازش
        رویدادها در حین رسیدن) تا در یک سیستم واحد پیاده‌سازی شوند [15].
    </p>
<p>
        یکپارچه‌سازی پردازش <strong>batch</strong> و <strong>stream</strong> در یک سیستم
        واحد نیازمند <strong>features</strong> زیر است، که به‌طور فزاینده‌ای در
        دسترس هستند:
    </p>
<ul>
<li>
            توانایی پخش مجدد رویدادهای تاریخی از طریق همان موتور پردازشی
            که <strong>stream</strong> رویدادهای اخیر را مدیریت می‌کند. به عنوان
            مثال، <strong>message brokers</strong> مبتنی بر <strong>log</strong>، توانایی پخش
            مجدد پیام‌ها را دارند (نگاه کنید به "پخش مجدد پیام‌های قدیمی" در
            صفحه 451)، و برخی از پردازنده‌های <strong>stream</strong> می‌توانند
            ورودی را از یک سیستم فایل توزیع شده مانند <strong>HDFS</strong>
            بخوانند.
        </li>
<li>
<strong>Exactly-once semantics</strong> برای پردازنده‌های <strong>stream</strong>
            —یعنی، اطمینان از این‌که خروجی یکسان است گویی هیچ <strong>faults</strong>
            رخ نداده است، حتی اگر در واقع <strong>faults</strong> رخ داده
            باشند (نگاه کنید به "تحمل خطا" در صفحه 476). مانند پردازش
            <strong>batch</strong>، این امر مستلزم دور ریختن خروجی جزئی هر
            <strong>tasks</strong> شکست‌خورده است.
        </li>
<li>
            ابزارهایی برای <strong>windowing</strong> بر اساس زمان رویداد، نه بر اساس
            زمان پردازش، از آن‌جایی‌که زمان پردازش هنگام پردازش مجدد
            رویدادهای تاریخی بی‌معنی است (نگاه کنید به "استدلال در مورد
            زمان" در صفحه 468). به عنوان مثال، <strong>Apache Beam</strong> یک
            <strong>API</strong> برای بیان چنین محاسباتی ارائه می‌دهد، که سپس
            می‌تواند با استفاده از <strong>Apache Flink</strong> یا <strong>Google Cloud
            Dataflow</strong> اجرا شود.
            498
            |
            فصل 12: آینده‌ی سیستم‌های داده
        </li>
</ul>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0520</div>
            </div>
        </div>
        <!-- Page 0521 -->
        <div class="chapter" id="page-0521">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<h4><strong>Unbundling Databases</strong></h4>
<p>
        در یک سطح انتزاعی، پایگاه‌های داده، <strong>Hadoop</strong> و سیستم‌های عامل
        همگی عملکردهای یکسانی را انجام می‌دهند: آن‌ها مقداری داده را
        ذخیره می‌کنند، و به شما اجازه می‌دهند که آن داده‌ها را پردازش
        و <strong>query</strong> کنید [16]. یک پایگاه داده داده‌ها را در رکوردهایی از
        برخی از مدل‌های داده (سطرهای جدول، اسناد، <strong>vertices</strong> در یک
        گراف، و غیره) ذخیره می‌کند، در حالی که سیستم فایل یک سیستم عامل
        داده‌ها را در فایل‌ها ذخیره می‌کند—اما در هسته‌ی خود، هر دو
        سیستم‌های "مدیریت اطلاعات" هستند [17]. همان‌طور که در فصل 10
        دیدیم، اکوسیستم <strong>Hadoop</strong> تا حدودی شبیه یک نسخه‌ی توزیع
        شده از <strong>Unix</strong> است.
    </p>
<p>
        البته، تفاوت‌های عملی زیادی وجود دارد. به عنوان مثال، بسیاری از
        سیستم‌های فایل با یک دایرکتوری حاوی 10 میلیون فایل کوچک،
        عملکرد خوبی ندارند، در حالی که یک پایگاه داده حاوی 10 میلیون
        رکورد کوچک کاملاً عادی و بی‌اهمیت است. با این وجود، شباهت‌ها و
        تفاوت‌های بین سیستم‌های عامل و پایگاه‌های داده ارزش بررسی را
        دارند.
    </p>
<p>
<strong>Unix</strong> و پایگاه‌های داده‌ی رابطه‌ای، به مشکل مدیریت اطلاعات با
        فلسفه‌های بسیار متفاوتی نزدیک شده‌اند. <strong>Unix</strong> هدف خود را
        ارائه یک <strong>abstraction</strong> سخت‌افزاری منطقی اما نسبتاً سطح
        پایین به برنامه‌نویسان می‌دید، در حالی که پایگاه‌های داده‌ی رابطه‌ای
        می‌خواستند یک <strong>abstraction</strong> سطح بالا به برنامه‌نویسان
        برنامه ارائه دهند که پیچیدگی‌های ساختارهای داده‌ها روی دیسک،
        <strong>concurrency</strong>، <strong>crash recovery</strong> و غیره را پنهان
        کند. <strong>Unix</strong>، <strong>pipes</strong> و فایل‌هایی را توسعه داد که فقط
        دنباله‌ای از بایت‌ها هستند، در حالی که پایگاه‌های داده <strong>SQL</strong>
        و تراکنش‌ها را توسعه دادند.
    </p>
<p>
        کدام رویکرد بهتر است؟ البته، بستگی به این دارد که چه می‌خواهید.
        <strong>Unix</strong> در این معنا "ساده‌تر" است که یک <em>wrapper</em> نسبتاً
        نازک در اطراف منابع سخت‌افزاری است؛ پایگاه‌های داده‌ی رابطه‌ای در
        این معنا "ساده‌تر" هستند که یک <strong>query</strong> اعلانی کوتاه می‌تواند
        از مقدار زیادی زیرساخت قدرتمند (بهینه‌سازی <strong>query</strong>،
        <strong>indexes</strong>، روش‌های <strong>join</strong>، کنترل <strong>concurrency</strong>،
        <strong>replication</strong> و غیره) استفاده کند، بدون این‌که نویسنده
        <strong>query</strong> نیاز به درک جزئیات پیاده‌سازی داشته باشد.
    </p>
<p>
        تنش بین این فلسفه‌ها دهه‌ها ادامه داشته است (هم <strong>Unix</strong> و هم
        مدل رابطه‌ای در اوایل دهه‌ی 1970 ظهور کردند) و هنوز هم حل
        نشده است. به عنوان مثال، من جنبش <strong>NoSQL</strong> را این‌طور
        تفسیر می‌کنم که می‌خواهد یک رویکرد <strong>Unix-esque</strong> از
        <strong>abstractions</strong> سطح پایین را در حوزه‌ی ذخیره‌سازی داده‌های
        <strong>OLTP</strong> توزیع شده اعمال کند.
    </p>
<p>
        در این بخش من سعی خواهم کرد که این دو فلسفه را با هم آشتی دهم، به
        این امید که بتوانیم بهترین‌های هر دو جهان را با هم ترکیب کنیم.
    </p>
<h4>ترکیب فناوری‌های ذخیره‌سازی داده‌ها</h4>
<p>
        در طول این کتاب، ما در مورد ویژگی‌های مختلفی که توسط پایگاه‌های
        داده ارائه می‌شوند و نحوه‌ی عملکرد آن‌ها بحث کرده‌ایم، از جمله:
    </p>
<ul>
<li>
<strong>Indexes</strong> ثانویه، که به شما اجازه می‌دهند که به‌طور کارآمد
            برای رکوردها بر اساس مقدار یک <strong>field</strong> جستجو کنید (نگاه
            کنید به "ساختارهای <strong>Indexing</strong> دیگر" در صفحه 85)
            <strong>Unbundling Databases</strong>
            |
            499
        </li>
</ul>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0521</div>
            </div>
        </div>
        <!-- Page 0522 -->
        <div class="chapter" id="page-0522">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<ul>
<li>
<strong>Materialized views</strong>، که نوعی <strong>cache</strong> از قبل
            محاسبه‌شده از نتایج <strong>query</strong> هستند (نگاه کنید به "تجمیع:
            <strong>Data Cubes</strong> و <strong>Materialized Views</strong>" در صفحه 101)
        </li>
<li>
<strong>Replication logs</strong>، که کپی‌هایی از داده‌ها را در <strong>nodes</strong>
            دیگر به‌روز نگه می‌دارند (نگاه کنید به "پیاده‌سازی <strong>Replication
            Logs</strong>" در صفحه 158)
        </li>
<li>
<strong>Indexes</strong> جستجوی متن کامل، که امکان جستجوی کلمات کلیدی
            را در متن فراهم می‌کنند (نگاه کنید به "جستجوی متن کامل و
            <strong>indexes</strong> فازی" در صفحه 88) و در برخی پایگاه‌های داده‌ی
            رابطه‌ای ساخته شده‌اند [1]
        </li>
</ul>
<p>
        در فصل‌های 10 و 11، مضامین مشابهی ظاهر شدند. ما در مورد ساختن
        <strong>indexes</strong> جستجوی متن کامل (نگاه کنید به "خروجی جریان‌های
        کاری <strong>Batch</strong>" در صفحه 411)، در مورد نگهداری
        <strong>materialized view</strong> (نگاه کنید به "حفظ <strong>materialized views</strong>"
        در صفحه 467)، و در مورد <strong>replicating</strong> تغییرات از یک
        پایگاه داده به سیستم‌های داده‌ی مشتق شده (نگاه کنید به "<strong>Change
        Data Capture</strong>" در صفحه 454) صحبت کردیم.
    </p>
<p>
        به نظر می‌رسد که بین <strong>features</strong> که در پایگاه‌های داده ساخته
        شده‌اند و سیستم‌های داده‌ی مشتق شده که مردم با پردازنده‌های <strong>batch</strong>
        و <strong>stream</strong> می‌سازند، موازی‌هایی وجود دارد.
    </p>
<h4>ایجاد یک index</h4>
<p>
        به این فکر کنید که وقتی شما <strong>CREATE INDEX</strong> را برای ایجاد یک
        index جدید در یک پایگاه داده‌ی رابطه‌ای اجرا می‌کنید، چه اتفاقی
        می‌افتد. پایگاه داده باید یک <strong>snapshot</strong> <em>consistent</em> از یک
        جدول را اسکن کند، تمام مقادیر <strong>field</strong> که در حال <strong>indexing</strong>
        هستند را انتخاب کند، آن‌ها را مرتب کند، و index را
        نوشته و خارج کند. سپس باید <strong>backlog</strong> از نوشته‌هایی را که از
        زمانی‌که <strong>snapshot</strong> <em>consistent</em> گرفته شد، انجام
        شده‌اند، پردازش کند (با فرض این‌که جدول در حین ایجاد index قفل
        نشده است، بنابراین <strong>writes</strong> می‌توانند ادامه یابند). هنگامی که
        این کار انجام شد، پایگاه داده باید <strong>index</strong> را هر زمان که یک
        تراکنش در جدول می‌نویسد، به‌روز نگه دارد.
    </p>
<p>
        این فرآیند به‌طور چشمگیری شبیه راه‌اندازی یک <strong>replica</strong>
<strong>follower</strong> جدید است (نگاه کنید به "راه‌اندازی <strong>Followers</strong>
        جدید" در صفحه 155)، و همچنین بسیار شبیه به <strong>bootstrapping</strong>
<strong>change data capture</strong> در یک سیستم <strong>streaming</strong> است (نگاه
        کنید به "<strong>Initial snapshot</strong>" در صفحه 455).
    </p>
<p>
        هر زمان که شما <strong>CREATE INDEX</strong> را اجرا می‌کنید، پایگاه داده
        اساساً مجموعه‌داده موجود را دوباره پردازش می‌کند (همان‌طور که در
        "پردازش مجدد داده‌ها برای تکامل برنامه" در صفحه 496 بحث شد) و
        index را به‌عنوان یک <strong>view</strong> جدید بر روی داده‌های موجود
        استخراج می‌کند. داده‌های موجود ممکن است یک <strong>snapshot</strong> از
        <strong>state</strong> باشد تا یک <strong>log</strong> از تمام تغییراتی که تا به حال رخ
        داده است، اما این دو به‌همدیگر نزدیک هستند (نگاه کنید به "<strong>State</strong>،
        <strong>Streams</strong>، و <strong>Immutability</strong>" در صفحه 459).
    </p>
<p>
        در این نور، من فکر می‌کنم که <strong>dataflow</strong> در سراسر یک سازمان
        کامل شروع به شباهت به یک پایگاه داده‌ی عظیم می‌کند [7]. هر زمان
        که یک فرآیند <strong>batch</strong>، <strong>stream</strong> یا <strong>ETL</strong>، داده‌ها را
        از یک مکان و فرم به مکان و فرم دیگری منتقل می‌کند، مانند
        زیرسیستم پایگاه داده‌ای عمل می‌کند که <strong>indexes</strong> یا
        <strong>materialized views</strong> را به‌روز نگه می‌دارد.
        500
        |
        فصل 12: آینده‌ی سیستم‌های داده
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0522</div>
            </div>
        </div>
        <!-- Page 0523 -->
        <div class="chapter" id="page-0523">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        به این ترتیب، پردازنده‌های <strong>batch</strong> و <strong>stream</strong>
        مانند پیاده‌سازی‌های پیچیده‌ی <strong>triggers</strong>، <strong>stored
        procedures</strong>، و روال‌های نگهداری <strong>materialized view</strong>
        هستند. سیستم‌های داده‌ی مشتق شده که آن‌ها نگه‌داری می‌کنند، مانند
        انواع مختلف <strong>index</strong> هستند. به عنوان مثال، یک پایگاه داده‌ی
        رابطه‌ای ممکن است از <strong>indexes</strong> <strong>B-tree</strong>، <strong>hash
        indexes</strong>، <strong>spatial indexes</strong> (نگاه کنید به "<strong>Multi-column
        indexes</strong>" در صفحه 87)، و سایر انواع <strong>indexes</strong> پشتیبانی
        کند. در معماری در حال ظهور سیستم‌های داده‌ی مشتق شده، به‌جای
        پیاده‌سازی این <strong>facilities</strong> به عنوان <strong>features</strong> از یک
        محصول پایگاه داده‌ی یکپارچه، آن‌ها توسط قطعات نرم‌افزاری مختلف
        ارائه می‌شوند که بر روی ماشین‌های مختلف اجرا می‌شوند، و توسط تیم‌های
        مختلف مدیریت می‌شوند.
    </p>
<p>
        این پیشرفت‌ها در آینده ما را به کجا می‌برند؟ اگر ما از این فرض شروع
        کنیم که هیچ مدل داده یا فرمت ذخیره‌سازی واحدی وجود ندارد که برای
        همه‌ی الگوهای دسترسی مناسب باشد، من حدس می‌زنم که دو مسیر وجود
        دارد که از طریق آن‌ها ابزارهای ذخیره‌سازی و پردازش مختلف با این
        وجود می‌توانند به یک سیستم منسجم ترکیب شوند:
    </p>
<ul>
<li>
            پایگاه‌های داده‌ی فدرال: متحد کردن <strong>reads</strong>
</li>
<p>
            امکان ارائه‌ی یک رابط <strong>query</strong> یکپارچه به طیف گسترده‌ای
            از <strong>storage engines</strong> و روش‌های پردازش اساسی وجود
            دارد—رویکردی که به‌عنوان پایگاه داده‌ی فدرال یا <strong>polystore</strong>
            شناخته می‌شود [18، 19]. به عنوان مثال، <strong>feature</strong>
<strong>foreign data wrapper</strong> از <strong>PostgreSQL</strong> با این الگو
            مطابقت دارد [20]. برنامه‌هایی که به یک مدل داده‌ی تخصصی یا
            رابط <strong>query</strong> نیاز دارند، همچنان می‌توانند به‌طور مستقیم به
            <strong>storage engines</strong> اساسی دسترسی پیدا کنند، در حالی‌که
            کاربرانی که می‌خواهند داده‌ها را از مکان‌های مختلف ترکیب
            کنند، می‌توانند این کار را به راحتی از طریق رابط فدرال انجام
            دهند.
        </p>
<p>
            یک رابط <strong>query</strong> فدرال از سنت رابطه‌ای یک سیستم
            یکپارچه‌ی واحد با یک زبان <strong>query</strong> سطح بالا و
            <strong>semantics</strong> های ظریف پیروی می‌کند، اما یک پیاده‌سازی
            پیچیده دارد.
        </p>
<li>
            پایگاه‌های داده‌ی <strong>Unbundled</strong>: متحد کردن <strong>writes</strong>
</li>
<p>
            در حالی که <strong>federation</strong>، <strong>querying</strong> <em>read-only</em>
            را در سراسر چندین سیستم مختلف انجام می‌دهد، یک پاسخ خوب
            برای همگام‌سازی <strong>writes</strong> در سراسر آن سیستم‌ها ندارد. ما
            گفتیم که در داخل یک پایگاه داده واحد، ایجاد یک index
            <em>consistent</em> یک <strong>feature</strong> داخلی است.
            هنگامی‌که ما چندین سیستم ذخیره‌سازی را ترکیب می‌کنیم، به‌طور
            مشابه نیاز داریم که اطمینان حاصل کنیم که تمام تغییرات داده‌ها در
            تمام مکان‌های مناسب قرار می‌گیرند، حتی در مواجهه با
            <strong>faults</strong>. آسان‌تر کردن اتصال قابل اعتماد سیستم‌های
            ذخیره‌سازی با هم (به عنوان مثال، از طریق <strong>change data
            capture</strong> و <strong>event logs</strong>) مانند <strong>unbundling</strong>
<strong>features</strong> از یک پایگاه داده است که می‌تواند <strong>writes</strong>
            را در فناوری‌های مختلف همگام‌سازی کند [7، 21].
        </p>
<p>
            رویکرد <strong>unbundled</strong> از سنت <strong>Unix</strong> از ابزارهای کوچک
            که یک کار را خوب انجام می‌دهند [22] پیروی می‌کند، که از طریق
            یک <strong>API</strong> سطح پایین یکنواخت (<strong>pipes</strong>) ارتباط
            برقرار می‌کنند، و می‌تواند با استفاده از یک زبان سطح بالاتر (<strong>shell</strong>)
            ترکیب شود [16].
        </p>
</ul>
<p>
        به‌کار انداختن <strong>unbundling</strong>
</p>
<p>
<strong>Federation</strong> و <strong>unbundling</strong> دو روی یک سکه هستند: ترکیب
        یک سیستم قابل اعتماد، مقیاس‌پذیر و قابل نگهداری از اجزای
        مختلف. <em>Federated read-only</em>
<strong>Unbundling Databases</strong>
        |
        499
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0523</div>
            </div>
        </div>
        <!-- Page 0524 -->
        <div class="chapter" id="page-0524">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
<strong>querying</strong>، نیاز به <strong>mapping</strong> یک مدل داده به دیگری
        دارد، که نیاز به مقداری تفکر دارد اما در نهایت یک مشکل کاملاً قابل
        مدیریت است. من فکر می‌کنم که همگام نگه داشتن <strong>writes</strong> در
        سیستم‌های ذخیره‌سازی مختلف، مشکل مهندسی سخت‌تری است، و بنابراین
        من روی آن تمرکز خواهم کرد.
    </p>
<p>
        رویکرد سنتی برای همگام‌سازی <strong>writes</strong>، به تراکنش‌های توزیع شده
        در سراسر سیستم‌های ذخیره‌سازی ناهمگن نیاز دارد [18]، که من فکر
        می‌کنم راه‌حل اشتباهی است (نگاه کنید به "داده‌های مشتق شده در
        مقابل تراکنش‌های توزیع شده" در صفحه 492). تراکنش‌ها در یک
        سیستم ذخیره‌سازی یا پردازش <strong>stream</strong> واحد امکان‌پذیر هستند،
        اما وقتی داده‌ها از مرز بین فناوری‌های مختلف عبور می‌کنند، من
        معتقدم که یک <strong>event log</strong> <em>asynchronous</em> با <strong>writes</strong>
<em>idempotent</em> یک رویکرد بسیار قوی‌تر و عملی‌تر است.
    </p>
<p>
        به عنوان مثال، تراکنش‌های توزیع شده در برخی از پردازنده‌های
        <strong>stream</strong> برای دستیابی به <strong>exactly-once semantics</strong>
        استفاده می‌شوند (نگاه کنید به "<strong>Atomic commit</strong> بازبینی شده"
        در صفحه 477)، و این می‌تواند کاملاً خوب کار کند. با این حال،
        وقتی یک تراکنش نیاز به درگیر کردن سیستم‌هایی دارد که توسط
        گروه‌های مختلفی از افراد نوشته شده‌اند (به عنوان مثال، زمانی که
        داده‌ها از یک پردازنده <strong>stream</strong> به یک ذخیره‌سازی <strong>key-value</strong>
        توزیع شده یا index جستجو نوشته می‌شود)، فقدان یک پروتکل تراکنش
        استاندارد، ادغام را بسیار سخت‌تر می‌کند. یک <strong>log</strong> مرتب شده
        از رویدادها با <strong>consumers</strong> <em>idempotent</em> (نگاه کنید به
        "<strong>Idempotence</strong>" در صفحه 478) یک انتزاع بسیار ساده‌تر است، و
        بنابراین پیاده‌سازی آن در سراسر سیستم‌های ناهمگن بسیار
        امکان‌پذیرتر است [7].
    </p>
<p>
        مزیت بزرگ ادغام مبتنی بر <strong>log</strong>، <strong>loose coupling</strong> بین
        اجزای مختلف است، که خود را به دو روش نشان می‌دهد:
    </p>
<ul>
<li>
            در سطح سیستم، <strong>event streams</strong> <em>asynchronous</em>
            سیستم را به‌عنوان یک کل، در برابر قطعی‌ها یا کاهش عملکرد
            اجزای جداگانه، <strong>robust</strong> تر می‌کند. اگر یک
            <strong>consumer</strong> کند اجرا شود یا شکست بخورد، <strong>event log</strong>
            می‌تواند پیام‌ها را <strong>buffer</strong> کند (نگاه کنید به "استفاده از
            فضای دیسک" در صفحه 450)، که به <strong>producer</strong> و هر
            <strong>consumers</strong> دیگر اجازه می‌دهد که بدون تأثیر به اجرا
            ادامه دهند. <strong>Consumer</strong> معیوب می‌تواند در زمانی که
            تعمیر شد، خود را بازیابی کند، بنابراین هیچ داده‌ای را از دست
            نمی‌دهد، و <strong>fault</strong> در آن محدود می‌شود. در مقابل،
            تعامل <em>synchronous</em> از تراکنش‌های توزیع شده تمایل دارد که
            <strong>faults</strong> محلی را به شکست‌های در مقیاس بزرگ تبدیل
            کند (نگاه کنید به "محدودیت‌های تراکنش‌های توزیع شده" در
            صفحه 363).
        </li>
<li>
            در سطح انسانی، <strong>unbundling</strong> سیستم‌های داده به اجزای
            نرم‌افزاری و <strong>services</strong> مختلف اجازه می‌دهد که به‌طور
            مستقل از یکدیگر توسط تیم‌های مختلف توسعه، بهبود و
            نگهداری شوند. <strong>Specialization</strong> به هر تیم اجازه می‌دهد که
            روی انجام یک کار به‌خوبی تمرکز کند، با <strong>interfaces</strong>
            خوب تعریف شده برای سیستم‌های تیم‌های دیگر. <strong>Event logs</strong>
            یک <strong>interface</strong> ارائه می‌دهند که به اندازه‌ی کافی قدرتمند
            است تا ویژگی‌های <em>consistency</em> نسبتاً قوی را ثبت کند (به
            دلیل <em>durability</em> و <strong>ordering</strong> رویدادها)، اما همچنین
            به اندازه‌ی کافی کلی است تا برای تقریباً هر نوع داده قابل
            اجرا باشد.
        </li>
</ul>
<h4>سیستم‌های <strong>Unbundled</strong> در مقابل سیستم‌های یکپارچه</h4>
<p>
        اگر <strong>unbundling</strong> در واقع به راه آینده تبدیل شود، پایگاه‌های
        داده را در شکل فعلی خود جایگزین نخواهد کرد—آن‌ها همچنان بیش از
        همیشه مورد نیاز خواهند بود. پایگاه‌های داده هنوز هم
        502
        |
        فصل 12: آینده‌ی سیستم‌های داده
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0524</div>
            </div>
        </div>
        <!-- Page 0525 -->
        <div class="chapter" id="page-0525">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        لازم است برای حفظ <strong>state</strong> در پردازنده‌های <strong>stream</strong>، و
        به‌منظور <strong>queries</strong> برای خروجی پردازنده‌های <strong>batch</strong> و
        <strong>stream</strong> (نگاه کنید به "خروجی جریان‌های کاری <strong>Batch</strong>" در
        صفحه 411 و "پردازش <strong>Streams</strong>" در صفحه 464). موتورهای
        <strong>query</strong> تخصصی همچنان برای <strong>workloads</strong> خاص مهم
        خواهند بود: به عنوان مثال، موتورهای <strong>query</strong> در انبارهای داده‌ی
        <strong>MPP</strong> برای <strong>queries</strong> تحلیلی اکتشافی بهینه شده‌اند و این
        نوع <strong>workload</strong> را بسیار خوب مدیریت می‌کنند (نگاه کنید به
        "مقایسه‌ی <strong>Hadoop</strong> با پایگاه‌های داده‌ی توزیع شده" در صفحه
        414).
    </p>
<p>
        پیچیدگی اجرای چندین بخش مختلف از زیرساخت‌ها می‌تواند یک
        مشکل باشد: هر قطعه نرم‌افزار یک منحنی یادگیری، مسائل
        پیکربندی، و <em>quirks</em> عملیاتی دارد، و بنابراین ارزش دارد که تا
        حد امکان قطعات متحرک کمی را مستقر کنید. یک محصول نرم‌افزاری
        یکپارچه واحد نیز ممکن است قادر به دستیابی به عملکرد بهتر و قابل
        پیش‌بینی‌تری در مورد انواع <strong>workloads</strong> که برای آن‌ها طراحی شده
        است، در مقایسه با سیستمی که از چندین ابزار تشکیل شده است که
        شما با کد برنامه آن‌ها را ترکیب کرده‌اید [23]. همان‌طور که در
        پیشگفتار گفتم، ساختن برای مقیاسی که به آن نیاز ندارید، یک تلاش
        هدر رفته است و ممکن است شما را در یک طراحی غیرقابل انعطاف
        حبس کند. در واقع، این نوعی بهینه‌سازی زودرس است.
    </p>
<p>
        هدف از <strong>unbundling</strong> این نیست که با پایگاه‌های داده‌ی جداگانه در
        مورد عملکرد برای <strong>workloads</strong> خاص رقابت کنید؛ هدف این است
        که به شما اجازه دهد چندین پایگاه داده‌ی مختلف را با هم ترکیب
        کنید تا عملکرد خوبی را برای طیف وسیع‌تری از <strong>workloads</strong>
        نسبت به آن‌چه که با یک قطعه نرم‌افزار واحد امکان‌پذیر است، به
        دست آورید. این در مورد وسعت است، نه عمق—در همان راستای
        تنوع مدل‌های ذخیره‌سازی و پردازشی است که ما در "مقایسه‌ی
        <strong>Hadoop</strong> با پایگاه‌های داده‌ی توزیع شده" در صفحه 414 مورد
        بحث قرار دادیم.
    </p>
<p>
        بنابراین، اگر یک فناوری واحد وجود دارد که هرآن‌چه را که نیاز دارید
        انجام می‌دهد، احتمالاً بهترین کار این است که به‌سادگی از آن
        محصول استفاده کنید تا این‌که سعی کنید خودتان آن را از اجزای
        سطح پایین‌تر دوباره پیاده‌سازی کنید. مزایای <strong>unbundling</strong>
        و ترکیب، تنها زمانی وارد تصویر می‌شوند که هیچ قطعه نرم‌افزار
        واحدی وجود نداشته باشد که تمام نیازهای شما را برآورده
        کند.
    </p>
<h4>چه چیزی کم است؟</h4>
<p>
        ابزارهایی برای ترکیب سیستم‌های داده در حال بهتر شدن هستند، اما
        من فکر می‌کنم که یک بخش اصلی کم است: ما هنوز معادل <strong>Unix
        shell</strong> (یعنی یک زبان سطح بالا برای ترکیب سیستم‌های
        ذخیره‌سازی و پردازش به روشی ساده و اعلانی) از پایگاه داده‌ی
        <strong>unbundled</strong> را نداریم.
    </p>
<p>
        به عنوان مثال، من دوست دارم اگر ما می‌توانستیم به‌سادگی اعلام
        کنیم <strong>mysql | elasticsearch</strong>، که با قیاس با <strong>Unix
        pipes</strong> [22]، معادل <strong>unbundled</strong> از <strong>CREATE
        INDEX</strong> خواهد بود: تمام اسناد را در یک پایگاه داده‌ی <strong>MySQL</strong>
        می‌گرفت و آن‌ها را در یک <strong>cluster Elasticsearch</strong>
<strong>index</strong> می‌کرد. سپس به‌طور مداوم تمام تغییرات ایجاد شده در
        پایگاه داده را ثبت می‌کرد و به‌طور خودکار آن‌ها را در index جستجو
        اعمال می‌کرد، بدون این‌که ما مجبور باشیم کد برنامه سفارشی
        بنویسیم. این نوع ادغام باید با تقریباً هر نوع سیستم ذخیره‌سازی
        یا <strong>indexing</strong> امکان‌پذیر باشد.
        <strong>Unbundling Databases</strong>
        |
        503
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0525</div>
            </div>
        </div>
        <!-- Page 0526 -->
        <div class="chapter" id="page-0526">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        به همین ترتیب، عالی خواهد بود که بتوانیم <strong>caches</strong> را آسان‌تر
        از قبل محاسبه و به‌روزرسانی کنیم.
    </p>
<p>
        به یاد بیاورید که یک <strong>materialized view</strong> اساساً یک
        <strong>cache</strong> از قبل محاسبه شده است، بنابراین شما می‌توانید
        تصور کنید که یک <strong>cache</strong> را با تعیین اعلانی <strong>views</strong>
<strong>materialized</strong> برای <strong>queries</strong> پیچیده، از جمله
        <strong>queries</strong> بازگشتی در گراف‌ها (نگاه کنید به "مدل‌های داده
        شبیه گراف" در صفحه 49) و منطق برنامه، ایجاد کنید. تحقیقات
        اولیه جالبی در این زمینه وجود دارد، مانند <strong>differential
        dataflow</strong> [24، 25]، و من امیدوارم که این ایده‌ها راه خود را به
        سیستم‌های <strong>production</strong> پیدا کنند.
    </p>
<h4>طراحی برنامه‌ها حول <strong>Dataflow</strong></h4>
<p>
        رویکرد <strong>unbundling</strong> پایگاه‌های داده با ترکیب سیستم‌های
        ذخیره‌سازی و پردازش تخصصی با کد برنامه نیز به‌عنوان رویکرد
        "پایگاه داده درون به بیرون" [26]، پس از عنوان یک سخنرانی
        کنفرانسی که من در سال 2014 ارائه دادم، شناخته می‌شود [27].
        با این حال، نامیدن آن به‌عنوان یک "معماری جدید" بیش از حد
        <em>grandiose</em> است. من آن را بیشتر به عنوان یک الگوی طراحی، یک
        نقطه‌ی شروع برای بحث، می‌بینم، و ما به سادگی به آن نام می‌دهیم تا
        بتوانیم بهتر در مورد آن صحبت کنیم.
    </p>
<p>
        این ایده‌ها مال من نیستند؛ آن‌ها به‌سادگی ترکیبی از ایده‌های
        افراد دیگر هستند که من فکر می‌کنم باید از آن‌ها بیاموزیم. به‌طور
        خاص، هم‌پوشانی زیادی با زبان‌های <strong>dataflow</strong> مانند <strong>Oz</strong>
        [28] و <strong>Juttle</strong> [29]، زبان‌های برنامه‌نویسی <em>functional
        reactive</em> (<strong>FRP</strong>) مانند <strong>Elm</strong> [30، 31]، و زبان‌های
        برنامه‌نویسی منطقی مانند <strong>Bloom</strong> [32] وجود دارد.
    </p>
<p>
        اصطلاح <strong>unbundling</strong> در این <strong>context</strong> توسط <strong>Jay
        Kreps</strong> [7] پیشنهاد شد.
    </p>
<p>
        حتی <strong>spreadsheets</strong> ها دارای قابلیت‌های برنامه‌نویسی
        <strong>dataflow</strong> هستند که سال‌ها جلوتر از اکثر زبان‌های
        برنامه‌نویسی <em>mainstream</em> هستند [33]. در یک <strong>spreadsheet</strong>،
        شما می‌توانید یک فرمول را در یک سلول قرار دهید (به عنوان مثال،
        مجموع سلول‌ها در یک ستون دیگر)، و هر زمان که هر ورودی به
        فرمول تغییر کند، نتیجه‌ی فرمول به‌طور خودکار دوباره محاسبه
        می‌شود.
    </p>
<p>
        این دقیقاً همان چیزی است که ما در سطح یک سیستم داده می‌خواهیم:
        هنگامی که یک رکورد در یک پایگاه داده تغییر می‌کند، ما می‌خواهیم
        هر <strong>index</strong> برای آن رکورد به‌طور خودکار به‌روز شود، و
        هر <strong>cached views</strong> یا <strong>aggregations</strong> که به
        رکورد وابسته هستند به‌طور خودکار <strong>refreshed</strong> شوند. شما
        نباید نگران جزئیات فنی چگونگی وقوع این <strong>refresh</strong> باشید،
        بلکه باید بتوانید به‌سادگی اعتماد کنید که به‌درستی کار می‌کند.
    </p>
<p>
        بنابراین، من فکر می‌کنم که اکثر سیستم‌های داده هنوز هم چیزی
        برای یادگیری از <strong>features</strong> که <strong>VisiCalc</strong> در سال 1979
        داشت، دارند [34]. تفاوت با <strong>spreadsheets</strong> این است که
        سیستم‌های داده امروزی نیاز دارند که تحمل خطا، مقیاس‌پذیر
        باشند، و داده‌ها را به‌طور <em>durably</em> ذخیره کنند. آن‌ها همچنین
        باید قادر به ادغام فناوری‌های ناهمگون که در طول زمان توسط
        گروه‌های مختلفی از افراد نوشته شده‌اند، باشند، و کتابخانه‌ها و
        خدمات موجود را دوباره استفاده کنند: انتظار این‌که همه‌ی نرم‌افزارها
        با استفاده از یک زبان، فریم‌ورک یا ابزار خاص توسعه داده شوند،
        غیرواقعی است.
    </p>
<p>
        در این بخش من این ایده‌ها را گسترش خواهم داد و برخی از راه‌های
        ایجاد برنامه‌ها حول ایده‌های پایگاه‌های داده‌ی <strong>unbundled</strong> و
        <strong>dataflow</strong> را بررسی خواهم کرد.
        504
        |
        فصل 12: آینده‌ی سیستم‌های داده
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0526</div>
            </div>
        </div>
        <!-- Page 0527 -->
        <div class="chapter" id="page-0527">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        کد برنامه به عنوان یک تابع مشتق شده
    </p>
<p>
        وقتی یک مجموعه‌داده از دیگری مشتق می‌شود، از طریق نوعی تابع
        تبدیل کننده می‌گذرد. به عنوان مثال:
    </p>
<ul>
<li>
            یک <strong>secondary index</strong>، نوعی مجموعه‌داده‌ی مشتق شده
            با یک تابع تبدیل مستقیم است: برای هر سطر یا سند در جدول
            پایه، مقادیر را در ستون‌ها یا <strong>fields</strong> که <strong>indexed</strong>
            می‌شوند، انتخاب می‌کند، و بر اساس آن مقادیر مرتب
            می‌کند (با فرض یک <strong>index B-tree</strong> یا <strong>SSTable</strong>،
            که بر اساس <strong>key</strong> مرتب شده‌اند، همان‌طور که در فصل 3 بحث
            شد).
        </li>
<li>
            یک index جستجوی متن کامل با اعمال توابع مختلف پردازش زبان
            طبیعی مانند تشخیص زبان، <strong>word segmentation</strong>،
            <strong>stemming</strong> یا <strong>lemmatization</strong>، تصحیح
            املایی، و شناسایی مترادف‌ها، ایجاد می‌شود، و پس از آن یک
            ساختار داده برای <strong>lookups</strong> کارآمد ساخته می‌شود (مانند یک
            index معکوس).
        </li>
<li>
            در یک سیستم <strong>machine learning</strong>، ما می‌توانیم مدل را در نظر
            بگیریم که با اعمال توابع مختلف <strong>feature extraction</strong> و
            تجزیه و تحلیل آماری از داده‌های آموزشی مشتق شده است.
            هنگامی‌که مدل برای داده‌های ورودی جدید اعمال می‌شود، خروجی
            مدل از ورودی و مدل (و از این رو، به‌طور غیرمستقیم، از داده‌های
            آموزشی) مشتق می‌شود.
        </li>
<li>
            یک <strong>cache</strong> اغلب حاوی یک تجمیع از داده‌ها به شکلی است
            که در یک <strong>user interface (UI)</strong> نمایش داده می‌شود. بنابراین
            <em>Populating</em> <strong>cache</strong> نیاز به دانش این دارد که چه
            <strong>fields</strong> در <strong>UI</strong> ارجاع داده می‌شوند؛ تغییرات در
            <strong>UI</strong> ممکن است نیاز به به‌روزرسانی تعریف این‌که چگونه
            <strong>cache</strong> <em>populated</em> شده است و بازسازی
            <strong>cache</strong> داشته باشد.
        </li>
</ul>
<p>
        تابع مشتق شده برای یک <strong>secondary index</strong> آن‌قدر معمولاً مورد
        نیاز است که در بسیاری از پایگاه‌های داده به‌عنوان یک
        <strong>feature</strong> اصلی ساخته شده است، و شما می‌توانید آن را با
        گفتن <strong>CREATE INDEX</strong> فراخوانی کنید. برای <strong>full-text
        indexing</strong>، ویژگی‌های زبانی پایه برای زبان‌های رایج ممکن است
        در یک پایگاه داده ساخته شوند، اما <strong>features</strong> پیچیده‌تر
        اغلب نیاز به تنظیم خاص <strong>domain</strong> دارند. در <strong>machine
        learning</strong>، <strong>feature engineering</strong> به‌طور مشهور
        مختص برنامه است، و اغلب باید دانش دقیقی در مورد تعامل
        کاربر و استقرار یک برنامه را در بر گیرد [35].
    </p>
<p>
        وقتی تابعی که یک مجموعه‌داده مشتق شده را ایجاد می‌کند، یک تابع
        استاندارد مانند ایجاد یک <strong>secondary index</strong> نیست، کد سفارشی
        برای رسیدگی به جنبه‌های خاص برنامه مورد نیاز است. و این کد
        سفارشی جایی است که بسیاری از پایگاه‌های داده با مشکل مواجه
        هستند. اگرچه پایگاه‌های داده‌ی رابطه‌ای معمولاً از <strong>triggers</strong>،
        <strong>stored procedures</strong> و توابع تعریف شده توسط کاربر
        پشتیبانی می‌کنند، که می‌توان از آن‌ها برای اجرای کد برنامه در
        پایگاه داده استفاده کرد، اما آن‌ها تا حدودی یک تفکر ثانویه در طراحی
        پایگاه داده بوده‌اند (نگاه کنید به "انتقال جریان‌های رویداد" در صفحه
        440).
    </p>
<h4>جداسازی کد برنامه و <strong>state</strong></h4>
<p>
        از نظر تئوری، پایگاه‌های داده می‌توانند محیط‌های استقراری برای کد
        برنامه دلخواه باشند، مانند یک سیستم عامل. با این حال، در عمل آن‌ها
        تبدیل به
        <strong>Unbundling Databases</strong>
        |
        505
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0527</div>
            </div>
        </div>
        <!-- Page 0528 -->
        <div class="chapter" id="page-0528">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        i. توضیح دادن یک <strong>joke</strong> به‌ندرت آن را بهبود می‌بخشد، اما من
        نمی‌خواهم هیچ‌کس احساس بی‌اطلاعی کند. در اینجا، <strong>Church</strong>
        اشاره‌ای است به ریاضیدان <strong>Alonzo Church</strong>، که
        <strong>lambda calculus</strong> را ایجاد کرد، یک شکل اولیه از محاسبه که
        اساس اکثر زبان‌های برنامه‌نویسی <em>functional</em> است. <strong>Lambda
        calculus</strong> هیچ <strong>state</strong> <em>mutable</em> ندارد (یعنی، هیچ
        متغیری که بتواند بازنویسی شود)، بنابراین می‌توان گفت که
        <strong>mutable state</strong> از کار <strong>Church</strong> جدا است.
    </p>
<p>
        برای این منظور مناسب نیستند. آن‌ها با الزامات توسعه‌ی برنامه
        امروزی، مانند مدیریت وابستگی و بسته، کنترل نسخه،
        <strong>rolling upgrades</strong>، تکامل‌پذیری، <strong>monitoring</strong>،
        معیارها، فراخوانی <strong>network services</strong>، و ادغام با سیستم‌های
        خارجی، سازگار نیستند.
    </p>
<p>
        از سوی دیگر، ابزارهای استقرار و مدیریت <strong>cluster</strong> مانند
        <strong>Mesos</strong>، <strong>YARN</strong>، <strong>Docker</strong>، <strong>Kubernetes</strong>
        و سایرین به‌طور خاص برای هدف اجرای کد برنامه طراحی شده‌اند.
        با تمرکز بر انجام یک کار به‌خوبی، آن‌ها می‌توانند این کار را
        بسیار بهتر از یک پایگاه داده انجام دهند که اجرای توابع تعریف
        شده توسط کاربر را به‌عنوان یکی از <strong>features</strong> متعدد خود
        فراهم می‌کند.
    </p>
<p>
        من فکر می‌کنم که این منطقی است که برخی از بخش‌های یک سیستم
        در ذخیره‌سازی داده‌های <em>durable</em> تخصص داشته باشند، و بخش‌های
        دیگر در اجرای کد برنامه تخصص داشته باشند. این دو می‌توانند
        تعامل داشته باشند در حالی‌که هنوز هم مستقل هستند.
    </p>
<p>
        امروزه اکثر برنامه‌های وب به‌عنوان <strong>services</strong> <em>stateless</em>
        مستقر می‌شوند، که در آن هر درخواست کاربر می‌تواند به هر
        <strong>application server</strong> هدایت شود، و سرور پس از ارسال
        پاسخ، همه‌چیز را در مورد درخواست فراموش می‌کند. این سبک
        از استقرار راحت است، زیرا سرورها را می‌توان به‌دلخواه اضافه
        یا حذف کرد، اما <strong>state</strong> باید به جایی برود: معمولاً، یک
        پایگاه داده. روند این بوده است که منطق برنامه <em>stateless</em> را از
        مدیریت <strong>state</strong> (پایگاه‌های داده) جدا نگه داریم: قرار ندادن
        منطق برنامه در پایگاه داده و قرار ندادن <strong>state</strong> <em>persistent</em>
        در برنامه [36]. همان‌طور که مردم در جامعه‌ی برنامه‌نویسی
        <em>functional</em> دوست دارند <strong>joke</strong> کنند، "ما به جدایی
        <strong>Church</strong> و <strong>state</strong> اعتقاد داریم" [37].i
    </p>
<p>
        در این مدل برنامه وب معمول، پایگاه داده به‌عنوان نوعی متغیر
        مشترک <em>mutable</em> عمل می‌کند که می‌توان به‌طور <em>synchronously</em>
        از طریق شبکه به آن دسترسی داشت. برنامه می‌تواند متغیر را
        بخواند و به‌روزرسانی کند، و پایگاه داده مراقب است تا آن را
        <em>durable</em> کند، مقداری کنترل <strong>concurrency</strong> و تحمل
        خطا را فراهم می‌کند.
    </p>
<p>
        با این حال، در اکثر زبان‌های برنامه‌نویسی شما نمی‌توانید به
        تغییرات در یک متغیر <em>mutable</em> <strong>subscribe</strong> کنید—شما
        فقط می‌توانید آن را به‌طور دوره‌ای بخوانید. برخلاف یک
        <strong>spreadsheet</strong>، خوانندگان متغیر مطلع نمی‌شوند اگر مقدار
        متغیر تغییر کند. (شما می‌توانید چنین اعلان‌هایی را در کد
        خودتان پیاده‌سازی کنید—این به‌عنوان الگوی <strong>observer</strong>
        شناخته می‌شود—اما اکثر زبان‌ها این الگو را به‌عنوان یک
        <strong>feature</strong> داخلی ندارند.)
    </p>
<p>
        پایگاه‌های داده این رویکرد <strong>passive</strong> به داده‌های <em>mutable</em>
        را به ارث برده‌اند: اگر شما می‌خواهید بدانید آیا محتویات پایگاه
        داده تغییر کرده است، اغلب تنها گزینه‌ی شما <strong>poll</strong>
        کردن است (یعنی، تکرار <strong>query</strong> خود به‌طور دوره‌ای).
        <strong>Subscribing</strong> به تغییرات، تنها در حال شروع به‌عنوان یک
        <strong>feature</strong> است (نگاه کنید به "پشتیبانی <strong>API</strong> برای
        جریان‌های تغییر" در صفحه 456).
        506
        |
        فصل 12: آینده‌ی سیستم‌های داده
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0528</div>
            </div>
        </div>
        <!-- Page 0529 -->
        <div class="chapter" id="page-0529">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
<strong>Dataflow</strong>: تعامل بین تغییرات <strong>state</strong> و کد
        برنامه
    </p>
<p>
        تفکر در مورد برنامه‌ها از نظر <strong>dataflow</strong>، مستلزم
        بازنگری در رابطه‌ی بین کد برنامه و مدیریت <strong>state</strong>
        است. به‌جای این‌که یک پایگاه داده را به‌عنوان یک متغیر
        <em>passive</em> در نظر بگیریم که توسط برنامه دستکاری
        می‌شود، ما بیشتر در مورد تعامل و همکاری بین <strong>state</strong>،
        تغییرات <strong>state</strong>، و کدی که آن‌ها را پردازش می‌کند، فکر
        می‌کنیم. کد برنامه به تغییرات <strong>state</strong> در یک مکان پاسخ
        می‌دهد با راه‌اندازی تغییرات <strong>state</strong> در مکان دیگر.
    </p>
<p>
        ما این خط فکری را در "پایگاه‌های داده و جریان‌ها" در صفحه 451
        دیدیم، که در آن ما در مورد برخورد با <strong>log</strong> از تغییرات در یک
        پایگاه داده به‌عنوان یک <strong>stream</strong> از رویدادها که می‌توانیم
        به آن‌ها <strong>subscribe</strong> کنیم، بحث کردیم. سیستم‌های
        پیام‌رسانی مانند <strong>actors</strong> (نگاه کنید به "<strong>Message-Passing
        Dataflow</strong>" در صفحه 136) نیز این مفهوم را از پاسخ به
        رویدادها دارند. قبلاً در دهه 1980، مدل فضاهای <strong>tuple</strong> به
        بررسی بیان محاسبات توزیع شده از نظر فرآیندهایی که تغییرات
        <strong>state</strong> را مشاهده می‌کنند و به آن‌ها واکنش نشان می‌دهند،
        پرداخت [38، 39].
    </p>
<p>
        همان‌طور که بحث شد، موارد مشابهی در داخل یک پایگاه داده هنگامی
        که یک <strong>trigger</strong> به دلیل یک تغییر داده آتش می‌گیرد، یا
        هنگامی‌که یک <strong>secondary index</strong> به‌روز می‌شود تا
        تغییری را در جدول در حال <strong>indexing</strong> منعکس کند، رخ
        می‌دهد. <strong>Unbundling</strong> پایگاه داده به این معنی است که این
        ایده را بگیرید و آن را در ایجاد مجموعه‌داده‌های مشتق شده خارج از
        پایگاه داده‌ی اولیه اعمال کنید: <strong>caches</strong>، <strong>indexes</strong>
        جستجوی متن کامل، یادگیری ماشین، یا سیستم‌های تجزیه و تحلیل. ما
        می‌توانیم از پردازش <strong>stream</strong> و سیستم‌های پیام‌رسانی
        برای این منظور استفاده کنیم.
    </p>
<p>
        نکته‌ی مهمی که باید به خاطر داشت این است که نگه‌داری داده‌های
        مشتق شده با اجرای <em>asynchronous</em> <strong>job</strong> یکسان
        نیست، که سیستم‌های پیام‌رسانی به‌طور سنتی برای آن طراحی
        شده‌اند (نگاه کنید به "<strong>Logs</strong> در مقایسه با پیام‌رسانی سنتی"
        در صفحه 448):
    </p>
<ul>
<li>
            هنگام نگه‌داری داده‌های مشتق شده، ترتیب تغییرات <strong>state</strong> اغلب
            مهم است (اگر چندین <strong>views</strong> از یک <strong>event log</strong> مشتق
            شده باشند، آن‌ها باید رویدادها را به همان ترتیب پردازش کنند
            تا با یکدیگر سازگار بمانند). همان‌طور که در "تأییدیه‌ها و
            <strong>redelivery</strong>" در صفحه 445 بحث شد، بسیاری از
            <strong>message brokers</strong> این ویژگی را هنگام <strong>redelivering</strong>
            پیام‌های تأیید نشده ندارند. <strong>Dual writes</strong> نیز رد
            می‌شوند (نگاه کنید به "همگام‌سازی سیستم‌ها" در صفحه 452).
        </li>
<li>
            تحمل خطا برای داده‌های مشتق شده کلیدی است: از دست دادن فقط
            یک پیام باعث می‌شود که مجموعه‌داده‌ی مشتق شده به‌طور دائم
            از منبع داده‌های خود خارج شود. تحویل پیام و به‌روزرسانی‌های
            <strong>state</strong> مشتق شده باید قابل اعتماد باشند. به عنوان مثال،
            بسیاری از سیستم‌های <strong>actor</strong> به‌طور پیش‌فرض <strong>state</strong>
            و پیام‌ها را در حافظه حفظ می‌کنند، بنابراین اگر دستگاهی که
            <strong>actor</strong> را اجرا می‌کند، از کار بیفتد، آن‌ها از بین
            می‌روند.
        </li>
</ul>
<p>
        ترتیب <strong>ordering</strong> پیام‌های ثابت و پردازش پیام تحمل‌کننده‌ی
        خطا، الزامات بسیار سختی هستند، اما به‌مراتب کمتر پرهزینه و از
        نظر عملیاتی مستحکم‌تر از تراکنش‌های توزیع شده هستند. پردازنده‌های
        <strong>stream</strong> مدرن می‌توانند این تضمین‌های <strong>ordering</strong> و
        قابلیت اطمینان را در مقیاس ارائه دهند، و آن‌ها به کد برنامه اجازه
        می‌دهند که به عنوان <strong>stream operators</strong> اجرا شود.
        <strong>Unbundling Databases</strong>
        |
        507
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0529</div>
            </div>
        </div>
        <!-- Page 0530 -->
        <div class="chapter" id="page-0530">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        ii. در رویکرد <strong>microservices</strong>، شما می‌توانید از درخواست شبکه‌ی
        <em>synchronous</em> با <strong>caching</strong> کردن نرخ ارز به‌صورت محلی در
        <strong>service</strong> که خرید را پردازش می‌کند، اجتناب کنید. با این حال، به
        منظور تازه نگه داشتن آن <strong>cache</strong>، شما نیاز دارید که به‌طور دوره‌ای
        برای نرخ‌های ارز به‌روز شده <strong>poll</strong> کنید، یا به یک جریان از
        تغییرات <strong>subscribe</strong> کنید—که دقیقاً همان چیزی است که در
        رویکرد <strong>dataflow</strong> رخ می‌دهد.
    </p>
<p>
        این کد برنامه می‌تواند پردازش دلخواه را انجام دهد که توابع مشتق شده
        در پایگاه‌های داده به‌طور کلی ارائه نمی‌دهند. مانند ابزارهای <strong>Unix</strong>
        که توسط <strong>pipes</strong> زنجیر شده‌اند، <strong>stream operators</strong> می‌توانند
        برای ساخت سیستم‌های بزرگ حول <strong>dataflow</strong>، ترکیب شوند. هر
        <strong>operator</strong>، <strong>streams</strong> از تغییرات <strong>state</strong> را به
        عنوان ورودی می‌گیرد، و <strong>streams</strong> دیگری از تغییرات
        <strong>state</strong> را به‌عنوان خروجی تولید می‌کند.
    </p>
<h4>پردازنده‌های <strong>Stream</strong> و <strong>services</strong></h4>
<p>
        سبک فعلی توسعه برنامه شامل تجزیه‌ی عملکرد به مجموعه‌ای از
        <strong>services</strong> است که از طریق درخواست‌های شبکه <em>synchronous</em>
        مانند <strong>REST APIs</strong> ارتباط برقرار می‌کنند (نگاه کنید به "<strong>Dataflow</strong>
        از طریق <strong>Services</strong>: <strong>REST</strong> و <strong>RPC</strong>" در صفحه 131).
    </p>
<p>
        مزیت این <strong>service-oriented architecture</strong> نسبت به یک
        برنامه <em>monolithic</em> واحد، در درجه‌ی اول مقیاس‌پذیری سازمانی
        از طریق <strong>loose coupling</strong> است: تیم‌های مختلف می‌توانند روی
        <strong>services</strong> مختلف کار کنند، که تلاش هماهنگی بین تیم‌ها را
        کاهش می‌دهد (تا زمانی‌که <strong>services</strong> بتوانند به‌طور مستقل
        مستقر و به‌روز شوند).
    </p>
<p>
        ترکیب <strong>stream operators</strong> در سیستم‌های <strong>dataflow</strong>،
        ویژگی‌های مشابه زیادی با رویکرد <strong>microservices</strong> دارد [40]. با
        این حال، مکانیسم ارتباطی اساسی بسیار متفاوت است: جریان‌های پیام
        <em>one-directional</em>، <em>asynchronous</em> به‌جای تعاملات
        <em>request/response synchronous</em>.
    </p>
<p>
        علاوه بر مزایای ذکر شده در "<strong>Message-Passing Dataflow</strong>" در
        صفحه 136، مانند تحمل خطای بهتر، سیستم‌های <strong>dataflow</strong>
        همچنین می‌توانند عملکرد بهتری داشته باشند. به عنوان مثال، فرض
        کنید یک مشتری در حال خرید یک مورد است که با یک ارز قیمت‌گذاری
        شده است اما با ارز دیگری پرداخت می‌شود. به منظور انجام تبدیل
        ارز، شما نیاز دارید که نرخ ارز فعلی را بدانید. این عملیات را می‌توان
        به دو روش پیاده‌سازی کرد [40، 41]:
    </p>
<ol>
<li>
            در رویکرد <strong>microservices</strong>، کدی که خرید را پردازش
            می‌کند، احتمالاً یک <strong>service</strong> یا پایگاه داده نرخ ارز را
            <strong>query</strong> می‌کند تا نرخ فعلی را برای یک ارز خاص به‌دست
            آورد.
        </li>
<li>
            در رویکرد <strong>dataflow</strong>، کدی که خریدها را پردازش
            می‌کند، از قبل به یک جریان از به‌روزرسانی‌های نرخ ارز
            <strong>subscribe</strong> می‌شود، و نرخ فعلی را در یک پایگاه
            داده‌ی محلی ثبت می‌کند، هر زمان که تغییر کند. هنگامی که
            نوبت به پردازش خرید می‌رسد، فقط نیاز دارد که پایگاه داده
            محلی را <strong>query</strong> کند.
        </li>
</ol>
<p>
        رویکرد دوم جایگزین یک درخواست شبکه <em>synchronous</em> به یک
        <strong>service</strong> دیگر با یک <strong>query</strong> به یک پایگاه داده‌ی
        محلی (که ممکن است روی همان ماشین، حتی در همان فرآیند باشد)
        شده است.ii نه‌تنها رویکرد <strong>dataflow</strong> سریع‌تر است، بلکه
        برای
        508
        |
        فصل 12: آینده‌ی سیستم‌های داده
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0530</div>
            </div>
        </div>
        <!-- Page 0531 -->
        <div class="chapter" id="page-0531">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        از کار افتادن <strong>service</strong> دیگر. سریع‌ترین و مطمئن‌ترین درخواست
        شبکه اصلاً هیچ درخواست شبکه‌ای نیست! به‌جای <strong>RPC</strong>، ما اکنون
        یک <strong>stream join</strong> بین رویدادهای خرید و رویدادهای
        به‌روزرسانی نرخ ارز داریم (نگاه کنید به "<strong>Stream-table join (stream
        enrichment)</strong>" در صفحه 473).
    </p>
<p>
<strong>Join</strong>، وابسته به زمان است: اگر رویدادهای خرید در یک نقطه‌ی
        زمانی بعد دوباره پردازش شوند، نرخ ارز تغییر خواهد کرد. اگر شما
        می‌خواهید خروجی اصلی را بازسازی کنید، شما نیاز دارید که نرخ ارز
        تاریخی را در زمان اصلی خرید به‌دست آورید. مهم نیست که آیا شما یک
        <strong>service</strong> را <strong>query</strong> می‌کنید یا به یک جریان
        به‌روزرسانی‌های نرخ ارز <strong>subscribe</strong> می‌کنید، شما نیاز دارید
        که این وابستگی به زمان را مدیریت کنید (نگاه کنید به "وابستگی به
        زمان <strong>joins</strong>" در صفحه 475).
    </p>
<p>
        اشتراک در یک <strong>stream</strong> از تغییرات، به‌جای <strong>querying</strong>
<strong>state</strong> فعلی در صورت نیاز، ما را به یک مدل محاسباتی
        شبیه <strong>spreadsheet</strong> نزدیک‌تر می‌کند: هنگامی که یک
        قطعه داده تغییر می‌کند، هر داده‌ی مشتق شده‌ای که به آن وابسته
        است، می‌تواند به‌سرعت به‌روز شود.
    </p>
<p>
        هنوز سؤالات باز زیادی وجود دارد، به عنوان مثال در مورد مسائلی مانند
        <strong>time-dependent joins</strong>، اما من معتقدم که ساختن
        برنامه‌ها حول ایده‌های <strong>dataflow</strong> یک جهت بسیار امیدوار
        کننده است.
    </p>
<h4>مشاهده‌ی <strong>Derived State</strong></h4>
<p>
        در یک سطح انتزاعی، سیستم‌های <strong>dataflow</strong> که در بخش قبل
        مورد بحث قرار گرفتند، یک فرآیند برای ایجاد مجموعه‌داده‌های
        مشتق شده (مانند <strong>search indexes</strong>، <strong>materialized views</strong>،
        و مدل‌های پیش‌بینی‌کننده) و به‌روز نگه داشتن آن‌ها به شما
        ارائه می‌دهند. بیایید این فرآیند را <em>write path</em> بنامیم: هر زمان
        که مقداری اطلاعات در سیستم نوشته می‌شود، ممکن است از چندین
        مرحله از پردازش <strong>batch</strong> و <strong>stream</strong> عبور کند، و در
        نهایت هر مجموعه‌داده مشتق شده به‌روز می‌شود تا داده‌هایی را که
        نوشته شده‌اند، در خود جای دهد. شکل 12-1 یک نمونه از
        به‌روزرسانی یک index جستجو را نشان می‌دهد.
    </p>
<p>
        شکل 12-1. در یک <strong>search index</strong>، نوشتن‌ها (به‌روزرسانی‌های
        سند) با <strong>reads</strong> (queries) ملاقات می‌کنند.
    </p>
<p>
        اما چرا شما در وهله‌ی اول مجموعه‌داده‌ی مشتق شده را ایجاد
        می‌کنید؟ به احتمال زیاد به این دلیل که شما می‌خواهید دوباره در
        زمان بعدی آن را <strong>query</strong> کنید. این <em>read path</em> است: هنگام
        سرویس‌دهی به یک کاربر
        <strong>Unbundling Databases</strong>
        |
        509
    </p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 531" src="page_0531/image_1.png"/></div>
</div>
                <div class="page-number">صفحه 0531</div>
            </div>
        </div>
        <!-- Page 0532 -->
        <div class="chapter" id="page-0532">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        iii. با مزاح، مجموعه‌ی <strong>queries</strong> جستجوی متمایز با
        نتایج جستجوی غیرتهی، محدود است، با فرض یک <strong>corpus</strong> محدود.
        با این حال، در تعداد <strong>terms</strong> در <strong>corpus</strong>، که همچنان
        خبر بدی است، نمایی خواهد بود.
    </p>
<p>
        درخواست شما از مجموعه‌داده‌ی مشتق شده می‌خوانید، شاید
        پردازش بیشتری را روی نتایج انجام می‌دهید، و پاسخ به کاربر را
        می‌سازید.
    </p>
<p>
        در کنار هم، <em>write path</em> و <em>read path</em> کل سفر داده‌ها را
        در بر می‌گیرند، از نقطه‌ای که جمع‌آوری می‌شود تا نقطه‌ای که
        مصرف می‌شود (احتمالاً توسط انسان دیگر). <em>Write path</em> بخشی از
        سفر است که از قبل محاسبه شده است—یعنی، به محض ورود داده‌ها
        انجام می‌شود، صرف نظر از این‌که کسی از شما خواسته باشد آن
        را ببیند یا خیر. <em>Read path</em> بخشی از سفر است که فقط
        زمانی اتفاق می‌افتد که کسی آن را درخواست کند. اگر با زبان‌های
        برنامه‌نویسی <em>functional</em> آشنا هستید، ممکن است متوجه شوید که
        <em>write path</em> شبیه به ارزیابی <em>eager</em>، و <em>read path</em> شبیه
        به ارزیابی <em>lazy</em> است.
    </p>
<p>
        مجموعه‌داده‌ی مشتق شده، مکانی است که <em>write path</em> و <em>read
        path</em> به هم می‌رسند، همان‌طور که در شکل 12-1 نشان داده شده
        است. این نشان‌دهنده‌ی یک <strong>trade-off</strong> بین مقدار کاری است که
        باید در زمان <strong>write</strong> انجام شود و مقداری که باید در زمان
        <strong>read</strong> انجام شود.
    </p>
<h4><strong>Materialized views</strong> و <strong>caching</strong></h4>
<p>
        یک index جستجوی متن کامل، یک مثال خوب است: <em>write path</em> index
        را به‌روزرسانی می‌کند، و <em>read path</em>، index را برای <strong>keywords</strong>
        جستجو می‌کند. هم <strong>reads</strong> و هم <strong>writes</strong> نیاز دارند که
        کارهایی را انجام دهند. <strong>Writes</strong> نیاز دارند که ورودی‌های
        index را برای همه‌ی <strong>terms</strong> که در سند ظاهر می‌شوند،
        به‌روزرسانی کنند. <strong>Reads</strong> نیاز دارند که هر یک از کلمات را
        در <strong>query</strong> جستجو کنند، و منطق بولی را برای یافتن
        اسنادی که شامل همه‌ی کلمات در <strong>query</strong> (یک <strong>AND operator</strong>)
        هستند، یا هر مترادفی از هر یک از کلمات (یک <strong>OR operator</strong>)
        اعمال کنند.
    </p>
<p>
        اگر شما index نداشتید، یک <strong>search query</strong> باید تمام اسناد را
        (مانند <strong>grep</strong>) اسکن می‌کرد، که اگر تعداد زیادی سند
        داشتید، بسیار پرهزینه می‌شد. بدون index، کار کمتری در
        <em>write path</em> (بدون index برای به‌روزرسانی) وجود دارد، اما
        کار بسیار بیشتری در <em>read path</em> وجود دارد.
    </p>
<p>
        از سوی دیگر، شما می‌توانید نتیجه‌ی جستجو را برای همه‌ی
        <strong>queries</strong> ممکن از قبل محاسبه کنید. در این حالت، شما کار
        کمتری را در <em>read path</em> خواهید داشت: بدون منطق بولی، فقط نتایج
        را برای <strong>query</strong> خود پیدا کنید و آن‌ها را برگردانید. با این حال،
        <em>write path</em> بسیار گران‌تر خواهد بود: مجموعه <strong>queries</strong>
        جستجوی ممکن که می‌توان درخواست کرد، بی‌نهایت است، و بنابراین
        محاسبه‌ی قبلی تمام نتایج جستجوی ممکن به زمان و فضای
        ذخیره‌سازی بی‌نهایت نیاز دارد. این خیلی خوب کار نخواهد
        کرد.iii
    </p>
<p>
        یک گزینه دیگر این است که نتایج جستجو را فقط برای یک مجموعه‌ی
        ثابت از رایج‌ترین <strong>queries</strong> از قبل محاسبه کنید، به‌طوری
        که بتوان آن‌ها را سریعاً بدون نیاز به مراجعه به index سرویس
        داد.
        <strong>Queries</strong> غیرمعمول همچنان می‌توانند از index سرویس داده
        شوند. این معمولاً یک <strong>cache</strong> از <strong>queries</strong> های رایج نامیده
        می‌شود، اگرچه ما می‌توانیم آن را نیز یک <strong>materialized</strong>
        510
        |
        فصل 12: آینده‌ی سیستم‌های داده
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0532</div>
            </div>
        </div>
        <!-- Page 0533 -->
        <div class="chapter" id="page-0533">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
<strong>view</strong>، زیرا باید زمانی که اسناد جدیدی ظاهر می‌شوند که
        باید در نتایج یکی از <strong>queries</strong> های رایج گنجانده شوند،
        به‌روزرسانی شود.
    </p>
<p>
        از این مثال ما می‌توانیم ببینیم که یک index تنها مرز ممکن بین
        <em>write path</em> و <em>read path</em> نیست. <strong>Caching</strong> از
        نتایج جستجوی رایج امکان‌پذیر است، و <strong>scanning</strong> شبیه به
        <strong>grep</strong> بدون index نیز در تعداد کمی از اسناد امکان‌پذیر است.
        به این ترتیب، نقش <strong>caches</strong>، <strong>indexes</strong>، و
        <strong>materialized views</strong> ساده است: آن‌ها مرز بین
        <em>read path</em> و <em>write path</em> را جابه‌جا می‌کنند. آن‌ها به ما
        اجازه می‌دهند که با پیش‌محاسبه‌ی نتایج، کار بیشتری را در <em>write
        path</em> انجام دهیم، تا در <em>read path</em> در تلاش صرفه‌جویی
        کنیم.
    </p>
<p>
        جابه‌جایی مرز بین کارهای انجام شده در <em>write path</em> و <em>read path</em>
        در واقع موضوع مثال <strong>Twitter</strong> در ابتدای این کتاب بود، در
        "شرح <strong>Load</strong>" در صفحه 11. در آن مثال، ما همچنین دیدیم که
        چگونه مرز بین <em>write path</em> و <em>read path</em> ممکن است برای
        افراد مشهور در مقایسه با کاربران معمولی متفاوت ترسیم شود.
        پس از 500 صفحه، ما یک دور کامل زده‌ایم!
    </p>
<h4><strong>Clients</strong> <em>stateful</em> و با قابلیت <em>offline</em></h4>
<p>
        من فکر می‌کنم ایده‌ی یک مرز بین <em>write path</em> و <em>read path</em> جالب
        است زیرا ما می‌توانیم در مورد جابه‌جایی آن مرز بحث کنیم و بررسی
        کنیم که این تغییر در اصطلاحات عملی به چه معناست.
    </p>
<p>
        اجازه دهید به این ایده در یک <strong>context</strong> متفاوت نگاه کنیم.
    </p>
<p>
        محبوبیت عظیم برنامه‌های وب در دو دهه‌ی گذشته، ما را به سمت
        فرضیات خاصی در مورد توسعه برنامه هدایت کرده است که در
        نظر گرفتن آن‌ها آسان است. به‌طور خاص، مدل <strong>client/server</strong>—
        که در آن <strong>clients</strong> تا حد زیادی <em>stateless</em> هستند و
        سرورها بر داده‌ها <strong>authority</strong> دارند—آن‌قدر رایج است که
        تقریباً فراموش می‌کنیم که چیز دیگری وجود دارد. با این حال،
        فناوری به حرکت خود ادامه می‌دهد، و من فکر می‌کنم مهم است که
        وضعیت موجود را هر از چند گاهی زیر سوال ببریم.
    </p>
<p>
        به‌طور سنتی، مرورگرهای وب، <strong>clients</strong> <em>stateless</em> بوده‌اند
        که تنها زمانی می‌توانند کارهای مفیدی انجام دهند که شما اتصال به
        اینترنت داشته باشید (تقریباً تنها کاری که شما می‌توانید <em>offline</em>
        انجام دهید، پیمایش در یک صفحه است که قبلاً در حالت <em>online</em>
        بارگذاری کرده‌اید). با این حال، برنامه‌های وب <strong>JavaScript</strong>
        "تک صفحه‌ای" اخیر، قابلیت‌های <em>stateful</em> زیادی را به‌دست
        آورده‌اند، از جمله تعامل <strong>user interface</strong> سمت <strong>client</strong>
        و ذخیره‌سازی محلی <em>persistent</em> در مرورگر وب. برنامه‌های
        تلفن همراه به‌طور مشابه می‌توانند مقدار زیادی از <strong>state</strong> را روی
        دستگاه ذخیره کنند و برای اکثر تعاملات کاربر، نیازی به <em>round-
        trip</em> به سرور ندارند.
    </p>
<p>
        این قابلیت‌های در حال تغییر منجر به علاقه‌ی تجدید شده به
        برنامه‌های <em>offline-first</em> شده است که تا حد امکان با استفاده
        از یک پایگاه داده‌ی محلی روی همان دستگاه، بدون نیاز به اتصال
        به اینترنت، انجام می‌شوند و در پس‌زمینه هنگام در دسترس بودن
        اتصال شبکه، <strong>sync</strong> می‌شوند [42]. از آن‌جایی‌که
        دستگاه‌های تلفن همراه اغلب دارای اتصالات اینترنتی <em>cellular</em>
        کند و غیرقابل اعتماد هستند، اگر <strong>user interface</strong> آن‌ها نیازی به
        انتظار برای درخواست‌های شبکه <em>synchronous</em> نداشته باشد، و
        اگر برنامه‌ها بیشتر به‌صورت <em>offline</em> کار کنند، یک مزیت بزرگ
        برای کاربران دارد (نگاه کنید به "<strong>Clients</strong> با عملیات
        <em>offline</em>" در صفحه 170).
        <strong>Unbundling Databases</strong>
        |
        511
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0533</div>
            </div>
        </div>
        <!-- Page 0534 -->
        <div class="chapter" id="page-0534">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        زمانی که ما از فرض <strong>clients</strong> <em>stateless</em> که با یک
        پایگاه داده‌ی مرکزی صحبت می‌کنند دور می‌شویم و به سمت <strong>state</strong>
        ای که روی دستگاه‌های کاربر نهایی نگه‌داری می‌شود، حرکت
        می‌کنیم، دنیایی از فرصت‌های جدید باز می‌شود. به‌طور خاص، ما
        می‌توانیم به <strong>state</strong> روی دستگاه به‌عنوان یک <strong>cache</strong> از
        <strong>state</strong> در سرور فکر کنیم. پیکسل‌ها روی صفحه نمایش یک
        <strong>materialized view</strong> بر روی اشیاء مدل در برنامه
        <strong>client</strong> هستند؛ اشیاء مدل یک <strong>replica</strong> محلی از
        <strong>state</strong> در یک <strong>datacenter</strong> راه دور هستند [27].
    </p>
<h4>فشار دادن تغییرات <strong>state</strong> به <strong>clients</strong></h4>
<p>
        در یک صفحه‌ی وب معمولی، اگر شما صفحه را در یک مرورگر وب بارگذاری
        کنید و داده‌ها متعاقباً روی سرور تغییر کنند، مرورگر از تغییر
        مطلع نمی‌شود تا زمانی که شما صفحه را دوباره بارگذاری کنید.
        مرورگر فقط داده‌ها را در یک نقطه زمانی می‌خواند، با فرض این‌که
        ایستا هستند—به <strong>updates</strong> از سرور <strong>subscribe</strong>
        نمی‌شود. بنابراین، <strong>state</strong> روی دستگاه یک <strong>cache</strong> کهنه
        است که به‌روزرسانی نمی‌شود مگر این‌که شما صریحاً برای تغییرات
        <strong>poll</strong> کنید. (پروتکل‌های <strong>feed subscription</strong> مبتنی بر
        <strong>HTTP</strong> مانند <strong>RSS</strong> واقعاً فقط یک فرم اساسی از
        <strong>polling</strong> هستند.)
    </p>
<p>
        پروتکل‌های جدیدتر از الگوی <em>request/response</em> اساسی <strong>HTTP</strong>
        فراتر رفته‌اند: رویدادهای ارسال شده توسط سرور (<strong>API</strong>
<strong>EventSource</strong>) و <strong>WebSockets</strong>، کانال‌های
        ارتباطی را فراهم می‌کنند که از طریق آن‌ها یک مرورگر وب می‌تواند
        یک اتصال <strong>TCP</strong> باز را به یک سرور حفظ کند، و سرور می‌تواند
        به‌طور فعال پیام‌ها را به مرورگر <em>push</em> کند تا زمانی که متصل
        باقی بماند. این، فرصتی را برای سرور فراهم می‌کند تا به‌طور فعال
        به <strong>client</strong> کاربر نهایی در مورد هرگونه تغییر در <strong>state</strong> که
        به‌صورت محلی ذخیره کرده است، اطلاع دهد، و از کهنگی
        <strong>state</strong> <em>client-side</em> می‌کاهد.
    </p>
<p>
        از نظر مدل ما از <em>write path</em> و <em>read path</em>، به‌طور فعال
        فشار دادن تغییرات <strong>state</strong> تا تمام راه‌های دستگاه‌های
        <strong>client</strong> به‌معنای گسترش <em>write path</em> تا کاربر نهایی است.
        هنگامی که یک <strong>client</strong> برای اولین بار <em>initialized</em> می‌شود،
        هنوز هم نیاز دارد که از یک <em>read path</em> برای دریافت <strong>state</strong>
        اولیه خود استفاده کند، اما پس از آن می‌تواند به یک <strong>stream</strong> از
        تغییرات <strong>state</strong> که توسط سرور ارسال می‌شود، متکی
        باشد. ایده‌هایی که ما در مورد پردازش <strong>stream</strong> و
        پیام‌رسانی بحث کردیم، به اجرا فقط در یک <strong>datacenter</strong>
        محدود نمی‌شوند: ما می‌توانیم ایده‌ها را بیشتر پیش ببریم، و آن‌ها
        را تا تمام راه‌های دستگاه‌های کاربر نهایی گسترش دهیم [43].
    </p>
<p>
        دستگاه‌ها برخی از زمان‌ها <em>offline</em> خواهند بود، و در طول آن
        مدت قادر به دریافت هیچ‌گونه اعلانی از تغییرات <strong>state</strong> از
        سرور نخواهند بود. اما ما قبلاً این مشکل را حل کرده‌ایم: در
        "<strong>Consumer offsets</strong>" در صفحه 449، ما بحث کردیم که چگونه
        یک <strong>consumer</strong> از یک <strong>message broker</strong> مبتنی بر
        <strong>log</strong> می‌تواند پس از شکست یا قطع اتصال، دوباره
        متصل شود، و اطمینان حاصل کند که هیچ پیامی را که در
        هنگام قطع اتصال، دریافت کرده است، از دست نمی‌دهد. همان
        تکنیک برای کاربران مجزا کار می‌کند، که در آن هر دستگاه یک
        <strong>subscriber</strong> کوچک به یک <strong>stream</strong> کوچک از رویدادها
        است.
    </p>
<h4><strong>End-to-end event streams</strong></h4>
<p>
        ابزارهای اخیر برای توسعه‌ی <strong>clients</strong> <em>stateful</em> و
        <strong>user interfaces</strong>، مانند زبان <strong>Elm</strong> [30] و زنجیره‌ی
        ابزار <strong>Facebook</strong> از <strong>React</strong>، <strong>Flux</strong>، و
        <strong>Redux</strong> [44]، در حال حاضر مدیریت
        512
        |
        فصل 12: آینده‌ی سیستم‌های داده
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0534</div>
            </div>
        </div>
        <!-- Page 0535 -->
        <div class="chapter" id="page-0535">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
<strong>state</strong> <em>client-side</em> داخلی با <strong>subscribing</strong>
        به یک <strong>stream</strong> از رویدادها که نشان‌دهنده‌ی ورودی کاربر
        یا پاسخ‌ها از یک سرور هستند، ساختاریافته مشابه <strong>event
        sourcing</strong> (نگاه کنید به "<strong>Event Sourcing</strong>" در صفحه
        457).
    </p>
<p>
        این بسیار طبیعی خواهد بود که این مدل برنامه‌نویسی را گسترش دهیم تا به
        سرور نیز اجازه دهیم که رویدادهای تغییر <strong>state</strong> را در
        <strong>pipeline</strong> رویداد <strong>client-side</strong> <em>push</em> کند. بنابراین،
        تغییرات <strong>state</strong> می‌تواند از طریق یک <em>end-to-end</em> <em>write
        path</em> جریان یابد: از تعامل روی یک دستگاه که یک تغییر
        <strong>state</strong> را راه‌اندازی می‌کند، از طریق <strong>event logs</strong> و
        از طریق چندین سیستم داده‌ی مشتق شده و پردازنده‌های <strong>stream</strong>،
        تا تمام راه‌های <strong>user interface</strong> از یک فرد که <strong>state</strong> را روی
        دستگاه دیگری مشاهده می‌کند. این تغییرات <strong>state</strong> می‌توانند با
        تأخیر نسبتاً کم منتشر شوند—به عنوان مثال، کمتر از یک ثانیه
        <em>end to end</em>.
    </p>
<p>
        برخی از برنامه‌ها، مانند پیام‌رسانی فوری و بازی‌های آنلاین، در حال
        حاضر دارای چنین معماری "<em>real-time</em>" هستند (از نظر
        تعاملات با تأخیر کم، نه از نظر "تضمین‌های زمان پاسخگویی" در
        صفحه 298). اما چرا ما همه‌ی برنامه‌ها را به این روش نمی‌سازیم؟
    </p>
<p>
        چالش این است که فرض <strong>clients</strong> <em>stateless</em> و
        تعاملات <em>request/response</em>، بسیار عمیقاً در پایگاه‌های داده،
        کتابخانه‌ها، فریم‌ورک‌ها، و پروتکل‌های ما ریشه دوانده است.
    </p>
<p>
        بسیاری از <strong>datastores</strong> از عملیات <strong>read</strong> و <strong>write</strong>
        پشتیبانی می‌کنند که در آن یک درخواست یک پاسخ را برمی‌گرداند،
        اما تعداد بسیار کمتری توانایی <strong>subscribe</strong> شدن به
        تغییرات را فراهم می‌کنند—یعنی، یک درخواست که یک <strong>stream</strong>
        از پاسخ‌ها را در طول زمان برمی‌گرداند (نگاه کنید به "پشتیبانی
        <strong>API</strong> برای جریان‌های تغییر" در صفحه 456).
    </p>
<p>
        به منظور گسترش <em>write path</em> تا تمام راه‌های کاربر نهایی، ما نیاز
        خواهیم داشت که اساساً روشی را که بسیاری از این سیستم‌ها را
        می‌سازیم، دوباره بررسی کنیم: دور شدن از تعامل <em>request/response</em>
        و حرکت به سمت <strong>dataflow publish/subscribe</strong> [27]. من
        فکر می‌کنم که مزایای <strong>user interfaces</strong> پاسخگوتر و پشتیبانی
        <em>offline</em> بهتر، ارزش تلاش را دارد. اگر شما در حال طراحی
        سیستم‌های داده هستید، امیدوارم که شما این گزینه را در نظر داشته
        باشید که به تغییرات <strong>subscribe</strong> شوید، نه فقط <strong>querying</strong>
<strong>state</strong> فعلی.
    </p>
<h4><strong>Reads</strong> هم رویداد هستند</h4>
<p>
        ما بحث کردیم که وقتی یک پردازنده <strong>stream</strong> داده‌های مشتق شده
        را در یک فروشگاه (پایگاه داده، <strong>cache</strong>، یا index) می‌نویسد،
        و وقتی درخواست‌های کاربر آن فروشگاه را <strong>query</strong> می‌کنند،
        فروشگاه به‌عنوان مرز بین <em>write path</em> و <em>read path</em> عمل
        می‌کند. فروشگاه به <strong>queries</strong> <strong>read</strong> با دسترسی
        تصادفی به داده‌ها اجازه می‌دهد که در غیر این صورت به اسکن کل
        <strong>event log</strong> نیاز داشتند.
    </p>
<p>
        در بسیاری از موارد، ذخیره‌سازی داده‌ها از سیستم <strong>streaming</strong> جدا
        است. اما به یاد داشته باشید که پردازنده‌های <strong>stream</strong> نیز
        نیاز به حفظ <strong>state</strong> برای انجام تجمیع‌ها و <strong>joins</strong>
        دارند (نگاه کنید به "<strong>Stream Joins</strong>" در صفحه 472). این
        <strong>state</strong> معمولاً در داخل پردازنده <strong>stream</strong> پنهان
        می‌شود، اما برخی از فریم‌ورک‌ها به آن اجازه می‌دهند که
        توسط <strong>clients</strong> خارجی نیز <strong>queried</strong> شود [45]، و
        پردازنده <strong>stream</strong> خود را به نوعی پایگاه داده‌ی ساده
        تبدیل می‌کند.
        <strong>Unbundling Databases</strong>
        |
        513
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0535</div>
            </div>
        </div>
        <!-- Page 0536 -->
        <div class="chapter" id="page-0536">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
<strong>Nodes</strong> که داده‌های <strong>queried</strong> شده را ذخیره می‌کنند.
        این یک طراحی منطقی است، اما تنها طراحی ممکن نیست. همچنین
        امکان‌پذیر است که درخواست‌های <strong>read</strong> را به‌عنوان جریان‌هایی از
        رویدادها نشان دهیم، و هر دو رویداد <strong>read</strong> و رویدادهای <strong>write</strong> را
        از طریق یک پردازنده <strong>stream</strong> ارسال کنیم؛ پردازنده به رویدادهای
        <strong>read</strong> با انتشار نتیجه <strong>read</strong> به یک <strong>stream</strong> خروجی پاسخ
        می‌دهد [46].
    </p>
<p>
        هنگامی که هر دو <strong>writes</strong> و <strong>reads</strong> به‌عنوان رویدادها نشان
        داده می‌شوند، و برای مدیریت شدن به یک <strong>stream operator</strong> یکسان
        هدایت می‌شوند، ما در واقع یک <strong>stream-table join</strong> را بین
        جریان <strong>read queries</strong> و پایگاه داده انجام می‌دهیم. رویداد
        <strong>read</strong> باید به <strong>partition</strong> پایگاه داده‌ای که داده‌ها
        را در خود نگه می‌دارد، ارسال شود (نگاه کنید به "<strong>Request
        Routing</strong>" در صفحه 214)، درست مانند پردازنده‌های <strong>batch</strong>
        و <strong>stream</strong> نیاز به <strong>copartition</strong> ورودی‌ها بر روی
        <strong>key</strong> یکسان هنگام <strong>joining</strong> دارند (نگاه کنید به "<strong>Reduce-
        Side Joins and Grouping</strong>" در صفحه 403).
    </p>
<p>
        این مطابقت بین سرویس‌دهی به درخواست‌ها و انجام <strong>joins</strong> کاملاً
        اساسی است [47]. یک درخواست <strong>read</strong> یک‌باره، فقط درخواست را
        از طریق <strong>join operator</strong> منتقل می‌کند و سپس بلافاصله آن را
        فراموش می‌کند؛ یک درخواست <strong>subscribe</strong> یک <strong>join</strong>
<em>persistent</em> با رویدادهای گذشته و آینده در طرف دیگر
        <strong>join</strong> است.
    </p>
<p>
        ثبت یک <strong>log</strong> از رویدادهای <strong>read</strong> به‌طور بالقوه مزایایی
        نیز در رابطه با پیگیری وابستگی‌های علّی و <strong>data provenance</strong>
        در سراسر یک سیستم دارد: این به شما اجازه می‌دهد که آن‌چه را که
        کاربر قبل از تصمیم‌گیری خاصی مشاهده کرد، بازسازی کنید. به عنوان
        مثال، در یک فروشگاه آنلاین، احتمالاً تاریخ حمل و نقل پیش‌بینی شده
        و وضعیت موجودی که به یک مشتری نشان داده می‌شود، بر این‌که آیا
        آن‌ها تصمیم به خرید یک مورد می‌گیرند تأثیر می‌گذارد [4]. برای
        تجزیه و تحلیل این ارتباط، شما نیاز دارید که نتیجه <strong>query</strong>
        کاربر از وضعیت حمل و نقل و موجودی را ثبت کنید.
    </p>
<p>
        بنابراین، نوشتن رویدادهای <strong>read</strong> در ذخیره‌سازی <em>durable</em>،
        بهتر کردن ردیابی وابستگی‌های علّی را ممکن می‌کند (نگاه کنید به
        "ترتیب دادن رویدادها برای ثبت <strong>causality</strong>" در صفحه 493)،
        اما هزینه‌ی ذخیره‌سازی و <strong>I/O</strong> اضافی را متحمل می‌شود.
        بهینه‌سازی چنین سیستم‌هایی برای کاهش <strong>overhead</strong>، هنوز هم یک
        مشکل تحقیقاتی باز است [2]. اما اگر شما در حال حاضر درخواست‌های
        <strong>read</strong> را برای اهداف عملیاتی <strong>log</strong> می‌کنید، به‌عنوان
        یک اثر جانبی از پردازش درخواست، تغییر زیادی را برای این‌که
        <strong>log</strong> را به عنوان منبع درخواست‌ها در نظر بگیرید، ایجاد
        نمی‌کند.
    </p>
<h4>پردازش داده‌های چند <strong>partition</strong></h4>
<p>
        برای <strong>queries</strong> که فقط یک <strong>partition</strong> واحد را لمس
        می‌کنند، تلاش برای ارسال <strong>queries</strong> از طریق یک
        <strong>stream</strong> و جمع‌آوری یک <strong>stream</strong> از پاسخ‌ها،
        شاید زیاد باشد. با این حال، این ایده امکان اجرای توزیع شده
        <strong>queries</strong> پیچیده‌ای را باز می‌کند که نیاز به ترکیب داده‌ها
        از چندین <strong>partition</strong> دارند، که از زیرساخت برای مسیریابی
        پیام‌ها، تقسیم‌بندی، و <strong>joining</strong> که قبلاً توسط پردازنده‌های
        <strong>stream</strong> ارائه شده است، استفاده می‌کند.
    </p>
<p>
<strong>feature</strong> <strong>distributed RPC</strong> از <strong>Storm</strong> از این
        الگوی استفاده پشتیبانی می‌کند (نگاه کنید به "پیام‌رسانی و
        <strong>RPC</strong>" در صفحه 468). به عنوان مثال، از آن برای محاسبه‌ی
        تعداد افرادی که یک <strong>URL</strong> را در <strong>Twitter</strong> دیده‌اند—یعنی،
        اجتماع مجموعه‌های دنبال‌کننده از همه‌ی کسانی که آن <strong>URL</strong>
        را توییت کرده‌اند، استفاده شده است [48]. از آن‌جایی‌که مجموعه‌ی
        کاربران <strong>Twitter</strong> تقسیم‌بندی شده است، این محاسبه نیاز
        دارد که نتایج را از <strong>partitions</strong> زیادی ترکیب کند.
        494
        |
        فصل 12: آینده‌ی سیستم‌های داده
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0536</div>
            </div>
        </div>
        <!-- Page 0537 -->
        <div class="chapter" id="page-0537">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        یک مثال دیگر از این الگو در پیشگیری از کلاهبرداری رخ می‌دهد: به منظور
        ارزیابی ریسک این‌که آیا یک رویداد خرید خاص، کلاهبرداری است، شما
        می‌توانید امتیازات شهرت آدرس <strong>IP</strong> کاربر، آدرس <strong>email</strong>،
        آدرس صورت‌حساب، آدرس حمل‌ونقل و غیره را بررسی
        کنید. هر یک از این پایگاه‌های داده‌ی شهرت، خودشان تقسیم‌بندی
        شده‌اند، و بنابراین جمع‌آوری امتیازات برای یک رویداد خرید خاص
        نیازمند یک توالی از <strong>joins</strong> با مجموعه‌داده‌های مختلف
        تقسیم‌بندی شده است [49].
    </p>
<p>
        گراف‌های اجرای <strong>query</strong> داخلی از پایگاه‌های داده‌ی <strong>MPP</strong>،
        ویژگی‌های مشابهی دارند (نگاه کنید به "مقایسه‌ی <strong>Hadoop</strong> با
        پایگاه‌های داده‌ی توزیع شده" در صفحه 414). اگر شما نیاز به انجام
        این نوع <strong>join</strong> چند <strong>partition</strong> را دارید، احتمالاً استفاده از
        پایگاه داده‌ای که این <strong>feature</strong> را فراهم می‌کند، ساده‌تر است
        تا این‌که آن را با استفاده از یک پردازنده <strong>stream</strong> پیاده‌سازی
        کنید. با این حال، در نظر گرفتن <strong>queries</strong> به‌عنوان <strong>streams</strong>
        یک گزینه برای پیاده‌سازی برنامه‌هایی در مقیاس بزرگ فراهم می‌کند
        که در برابر محدودیت‌های راه‌حل‌های <em>off-the-shelf</em> متعارف اجرا
        می‌شوند.
    </p>
<h4>هدف قرار دادن درستی</h4>
<p>
        با <strong>services</strong> <em>stateless</em> که فقط داده‌ها را می‌خوانند، اگر
        چیزی اشتباه پیش برود، مسئله‌ی بزرگی نیست: شما می‌توانید
        <strong>bug</strong> را برطرف کنید و <strong>service</strong> را راه‌اندازی مجدد
        کنید، و همه‌چیز به حالت عادی برمی‌گردد. سیستم‌های <em>stateful</em>
        مانند پایگاه‌های داده این‌طور ساده نیستند: آن‌ها برای به یاد
        سپردن چیزها برای همیشه (کم و بیش) طراحی شده‌اند، بنابراین اگر
        چیزی اشتباه پیش برود، اثرات نیز به‌طور بالقوه برای همیشه باقی
        می‌ماند—که به این معنی است که آن‌ها نیاز به تفکر دقیق‌تری دارند
        [50].
    </p>
<p>
        ما می‌خواهیم برنامه‌هایی بسازیم که قابل اعتماد و درست هستند (یعنی،
        برنامه‌هایی که <strong>semantics</strong> آن‌ها به‌خوبی تعریف و درک
        شده‌اند، حتی در مواجهه با <strong>faults</strong> مختلف). برای تقریباً
        چهار دهه، ویژگی‌های تراکنش <em>atomicity</em>، <em>isolation</em>، و
        <em>durability</em> (فصل 7) ابزارهای انتخابی برای ساخت برنامه‌های
        درست بوده‌اند. با این حال، آن مبانی ضعیف‌تر از آن‌چه به‌نظر
        می‌رسند، هستند: شاهد به عنوان مثال، سردرگمی سطوح <em>weak
        isolation</em> باشید (نگاه کنید به "سطوح <strong>Weak Isolation</strong>" در
        صفحه 233).
    </p>
<p>
        در برخی از حوزه‌ها، تراکنش‌ها به‌طور کامل کنار گذاشته می‌شوند و با
        مدل‌هایی جایگزین می‌شوند که عملکرد و مقیاس‌پذیری بهتری را ارائه
        می‌دهند، اما <strong>semantics</strong> بسیار <em>messier</em> را ارائه
        می‌دهند (به عنوان مثال، "<strong>Leaderless Replication</strong>" در صفحه
        177 را ببینید). اغلب در مورد <strong>consistency</strong> صحبت می‌شود،
        اما به‌خوبی تعریف نشده است (نگاه کنید به "<strong>Consistency</strong>" در
        صفحه 224 و فصل 9). برخی از افراد ادعا می‌کنند که ما باید
        "<strong>consistency</strong> ضعیف را بپذیریم" به خاطر در دسترس
        بودن بهتر، در حالی‌که یک ایده‌ی روشن در مورد این‌که این در عمل
        به‌راستی چه معنایی دارد، ندارند.
    </p>
<p>
        برای یک موضوع که بسیار مهم است، درک و روش‌های مهندسی ما به‌طور
        شگفت‌انگیزی سست هستند. به عنوان مثال، تعیین این‌که آیا اجرای یک
        برنامه خاص در یک سطح <strong>isolation</strong> تراکنش خاص یا
        پیکربندی <strong>replication</strong>، ایمن است، بسیار دشوار است [51، 52].
        اغلب راه‌حل‌های ساده زمانی که <strong>concurrency</strong> کم باشد و هیچ
        <strong>faults</strong> وجود نداشته باشد، به‌درستی کار می‌کنند، اما در
        شرایط سخت‌تر، <strong>bugs</strong> ظریف زیادی دارند.
    </p>
<p>
        به عنوان مثال، آزمایش‌های <strong>Jepsen</strong> از <strong>Kyle Kingsbury</strong>
        [53]، تفاوت‌های آشکار بین تضمین‌های ایمنی ادعایی برخی از
        محصولات و عملکرد واقعی آن‌ها را برجسته کرده است.
        هدف قرار دادن درستی
        |
        515
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0537</div>
            </div>
        </div>
        <!-- Page 0538 -->
        <div class="chapter" id="page-0538">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        رفتار در حضور مشکلات شبکه و <strong>crashes</strong>. حتی اگر
        محصولات زیرساختی مانند پایگاه‌های داده از مشکلات عاری
        باشند، کد برنامه همچنان باید از <strong>features</strong> که ارائه
        می‌دهند به‌درستی استفاده کند، که اگر <strong>configuration</strong>
        درکش سخت باشد (که این مورد در سطوح <em>weak isolation</em>،
        پیکربندی <strong>quorum</strong> و غیره صدق می‌کند)، مستعد خطا
        است.
    </p>
<p>
        اگر برنامه شما می‌تواند گاهی اوقات داده‌ها را به روش‌های
        غیرقابل پیش‌بینی خراب یا از دست بدهد، زندگی بسیار ساده‌تر
        می‌شود، و شما ممکن است بتوانید صرفاً با آرزوی بهترین‌ها از
        این قضیه عبور کنید. از سوی دیگر، اگر شما به اطمینان‌های
        بیشتری از درستی نیاز دارید، سپس <em>serializability</em> و <strong>atomic
        commit</strong> رویکردهای تثبیت‌شده هستند، اما آن‌ها هزینه‌ای
        دارند: آن‌ها معمولاً فقط در یک <strong>datacenter</strong> واحد کار
        می‌کنند (منجر به رد معماری‌های توزیع شده‌ی جغرافیایی می‌شوند)،
        و آن‌ها مقیاس و ویژگی‌های تحمل خطا را که می‌توانید به‌دست
        آورید، محدود می‌کنند.
    </p>
<p>
        در حالی‌که رویکرد تراکنش سنتی از بین نمی‌رود، من همچنین
        معتقدم که این آخرین کلمه در درست و مقاوم کردن برنامه‌ها در برابر
        خطاها نیست. در این بخش من راه‌هایی را برای فکر کردن در مورد
        درستی در <strong>context</strong> از معماری‌های <strong>dataflow</strong>
        پیشنهاد خواهم کرد.
    </p>
<h4>استدلال <strong>End-to-End</strong> برای پایگاه‌های داده</h4>
<p>
        فقط به این دلیل که یک برنامه از یک سیستم داده استفاده می‌کند که
        ویژگی‌های ایمنی نسبتاً قوی را ارائه می‌دهد، مانند تراکنش‌های
        <em>serializable</em>، به این معنی نیست که تضمین می‌شود که
        برنامه از از دست رفتن یا خراب شدن داده‌ها عاری است. به عنوان
        مثال، اگر یک برنامه دارای یک <strong>bug</strong> باشد که باعث
        می‌شود داده‌های نادرستی را بنویسد، یا داده‌ها را از یک پایگاه
        داده حذف کند، تراکنش‌های <em>serializable</em> شما را نجات
        نمی‌دهند.
    </p>
<p>
        این مثال ممکن است بی‌اهمیت به‌نظر برسد، اما ارزش دارد که آن را
        جدی بگیریم: <strong>application bugs</strong> رخ می‌دهند، و افراد
        مرتکب اشتباه می‌شوند. من از این مثال در "<strong>State</strong>،
        <strong>Streams</strong>، و <strong>Immutability</strong>" در صفحه 459 برای
        بحث در مورد <em>immutable</em> و داده‌های <em>append-only</em> استفاده
        کردم، زیرا بازیابی از چنین اشتباهاتی آسان‌تر است اگر شما
        توانایی کد معیوب را برای از بین بردن داده‌های خوب حذف کنید.
    </p>
<p>
        اگرچه <em>immutability</em> مفید است، اما به‌خودی خود یک راه‌حل
        کامل نیست. بیایید به یک مثال ظریف‌تر از فساد داده‌ها که می‌تواند
        رخ دهد، نگاهی بیندازیم.
    </p>
<h4>اجرای <strong>exactly-once</strong> از یک عملیات</h4>
<p>
        در "تحمل خطا" در صفحه 476، ما به یک ایده به نام <strong>exactly-once</strong>
        (یا <em>effectively-once</em>) <strong>semantics</strong> برخورد کردیم. اگر
        چیزی در حین پردازش یک پیام اشتباه پیش برود، شما می‌توانید
        یا تسلیم شوید (پیام را <em>drop</em> کنید—یعنی، متحمل از دست
        دادن داده‌ها شوید) یا دوباره امتحان کنید. اگر شما دوباره
        امتحان کنید، خطر این وجود دارد که در واقع بار اول موفق شده
        باشد، اما شما فقط از موفقیت آن مطلع نشدید، و بنابراین پیام
        در نهایت دو بار پردازش می‌شود.
    </p>
<p>
        پردازش دوبار یک نوع از فساد داده‌ها است: شارژ کردن دو برابری
        یک مشتری برای یک سرویس یکسان (صورت‌حساب بیش از حد برای
        آن‌ها) یا افزایش یک <strong>counter</strong> دو بار ناخواسته است.
        516
        |
        فصل 12: آینده‌ی سیستم‌های داده
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0538</div>
            </div>
        </div>
        <!-- Page 0539 -->
        <div class="chapter" id="page-0539">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        (<em>overstating</em> یک معیار). در این <strong>context</strong>،
        <strong>exactly-once</strong> به‌معنای تنظیم محاسبه به‌گونه‌ای است
        که اثر نهایی یکسان است گویی هیچ <strong>faults</strong> رخ نداده است،
        حتی اگر عملیات واقعاً به‌دلیل برخی از <strong>faults</strong> دوباره
        تلاش شده باشد. ما قبلاً در مورد چند رویکرد برای دستیابی به این
        هدف بحث کردیم.
    </p>
<p>
        یکی از مؤثرترین رویکردها این است که عملیات را <em>idempotent</em>
        (نگاه کنید به "<strong>Idempotence</strong>" در صفحه 478) کنید؛ یعنی،
        اطمینان حاصل کنید که بدون در نظر گرفتن این‌که یک یا چند بار اجرا
        شود، همان اثر را دارد. با این حال، انجام یک عملیات که ذاتاً
        <em>idempotent</em> نیست و <em>idempotent</em> کردن آن، مستلزم مقداری
        تلاش و مراقبت است: شما ممکن است نیاز داشته باشید که برخی
        <strong>metadata</strong>های اضافی را حفظ کنید (مانند مجموعه‌ی
        <strong>operation IDs</strong> که یک مقدار را به‌روزرسانی کرده‌اند)، و
        در صورت <em>failing over</em> از یک <strong>node</strong> به دیگری،
        <strong>fencing</strong> را تضمین کنید (نگاه کنید به "رهبر و قفل" در
        صفحه 301).
    </p>
<h4>سرکوب تکراری</h4>
<p>
        همان الگوی نیاز به سرکوب تکراری در بسیاری از مکان‌های دیگر
        علاوه بر پردازش <strong>stream</strong> رخ می‌دهد. به عنوان مثال،
        <strong>TCP</strong> از شماره‌های توالی روی بسته‌ها برای قرار دادن
        آن‌ها در ترتیب صحیح در <strong>recipient</strong> استفاده می‌کند، و
        برای تعیین این‌که آیا هر بسته‌ای در شبکه از بین رفته یا تکراری
        شده است. هر بسته‌ای که از دست رفته باشد دوباره ارسال می‌شود
        و هر تکراری توسط <strong>TCP stack</strong> حذف می‌شود قبل از این‌که
        داده‌ها را به یک برنامه تحویل دهد.
    </p>
<p>
        با این حال، این سرکوب تکراری فقط در <strong>context</strong> یک اتصال
        <strong>TCP</strong> واحد کار می‌کند. تصور کنید اتصال <strong>TCP</strong> یک
        <strong>client</strong> به یک پایگاه داده است، و در حال حاضر تراکنش را
        در مثال 12-1 اجرا می‌کند. در بسیاری از پایگاه‌های داده، یک
        تراکنش به یک اتصال <strong>client</strong> گره خورده است (اگر <strong>client</strong>
        چندین <strong>query</strong> را ارسال کند، پایگاه داده می‌داند که آن‌ها به
        یک تراکنش یکسان تعلق دارند زیرا آن‌ها از طریق همان اتصال
        <strong>TCP</strong> ارسال می‌شوند). اگر <strong>client</strong> دچار یک
        <em>network interruption</em> و <strong>connection timeout</strong> پس از
        ارسال <strong>COMMIT</strong> شود، اما قبل از دریافت پاسخ از سرور
        پایگاه داده، نمی‌داند که آیا تراکنش <strong>committed</strong> شده
        است یا خیر (شکل 8-1).
    </p>
<p>
        مثال 12-1. انتقال غیر <em>idempotent</em> پول از یک حساب به حساب
        دیگر
    </p>
<pre><code class="language-sql">BEGIN TRANSACTION;
UPDATE accounts SET balance = balance + 11.00 WHERE account_id = 1234;
UPDATE accounts SET balance = balance - 11.00 WHERE account_id = 4321;
COMMIT;
</code></pre>
<p>
<strong>Client</strong> می‌تواند دوباره به پایگاه داده متصل شود و تراکنش را
        دوباره امتحان کند، اما اکنون خارج از محدوده‌ی سرکوب تکراری
        <strong>TCP</strong> است. از آن‌جایی‌که تراکنش در مثال 12-1 <em>idempotent</em>
        نیست، ممکن است 22 دلار به‌جای 11 دلار مورد نظر، منتقل
        شود.
    </p>
<p>
        بنابراین، حتی اگر مثال 12-1 یک مثال استاندارد برای <em>atomicity</em>
        تراکنش باشد، در واقع درست نیست، و بانک‌های واقعی این‌طور
        عمل نمی‌کنند [3].
    </p>
<p>
        پروتکل‌های <strong>Two-phase commit (2PC)</strong> (نگاه کنید به
        "<strong>Atomic Commit</strong> و <strong>Two-Phase Commit (2PC)</strong>" در
        صفحه 354)، نگاشت 1:1 بین یک اتصال <strong>TCP</strong> و یک
        تراکنش را می‌شکنند، زیرا آن‌ها باید به یک هماهنگ‌کننده‌ی
        تراکنش اجازه دهند تا پس از یک <em>network failure</em> دوباره به
        یک پایگاه داده متصل شود—
        هدف قرار دادن درستی
        |
        517
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0539</div>
            </div>
        </div>
        <!-- Page 0540 -->
        <div class="chapter" id="page-0540">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        عملیات درگیر در کار <strong>fault</strong>، و به آن بگویید که آیا تراکنش در
        شک را <strong>commit</strong> کند یا <strong>abort</strong> کند. آیا این برای اطمینان از
        این‌که تراکنش فقط یک بار اجرا خواهد شد، کافی است؟ متأسفانه، نه.
    </p>
<p>
        حتی اگر ما بتوانیم تراکنش‌های تکراری بین <strong>database client</strong> و
        سرور را سرکوب کنیم، ما هنوز نیاز داریم که نگران شبکه بین دستگاه
        کاربر نهایی و <strong>application server</strong> باشیم. به عنوان مثال، اگر
        <strong>client</strong> کاربر نهایی یک مرورگر وب باشد، احتمالاً از یک درخواست
        <strong>HTTP POST</strong> برای ارسال یک دستور به سرور استفاده
        می‌کند. شاید کاربر در یک اتصال داده‌ی تلفن همراه ضعیف باشد، و
        آن‌ها در ارسال <strong>POST</strong> موفق می‌شوند، اما سیگنال قبل از
        این‌که بتوانند پاسخ را از سرور دریافت کنند، خیلی ضعیف می‌شود.
    </p>
<p>
        در این حالت، احتمالاً به کاربر یک پیام خطا نشان داده می‌شود، و آن‌ها
        ممکن است به‌صورت دستی دوباره امتحان کنند. مرورگرهای وب هشدار
        می‌دهند، "آیا مطمئن هستید که می‌خواهید این فرم را دوباره ارسال
        کنید؟"—و کاربر بله می‌گوید، زیرا آن‌ها می‌خواستند عملیات اتفاق
        بیفتد. (الگوی <strong>Post/Redirect/Get</strong> [54] از این پیام هشدار
        در عملیات عادی اجتناب می‌کند، اما اگر درخواست <strong>POST</strong> <em>timeout</em>
        شود، کمکی نمی‌کند.) از نظر <strong>web server</strong>، تکرار یک
        درخواست جداگانه است، و از نظر پایگاه داده یک تراکنش
        جداگانه است.
    </p>
<p>
        مکانیسم‌های معمول <strong>deduplication</strong> کمکی نمی‌کنند.
    </p>
<h4>شناسه‌های عملیات</h4>
<p>
        برای <em>idempotent</em> کردن عملیات از طریق چندین <strong>hops</strong> از
        ارتباط شبکه، متکی بودن فقط بر یک مکانیسم تراکنش که توسط یک
        پایگاه داده ارائه شده است، کافی نیست—شما نیاز دارید که جریان
        <em>end-to-end</em> از درخواست را در نظر بگیرید.
    </p>
<p>
        به عنوان مثال، شما می‌توانید یک شناسه منحصربه‌فرد برای یک
        عملیات تولید کنید (مانند یک <strong>UUID</strong>) و آن را به‌عنوان یک
        فیلد فرم مخفی در برنامه <strong>client</strong> قرار دهید، یا یک
        <strong>hash</strong> از تمام <strong>fields</strong> فرم مرتبط برای
        استخراج <strong>operation ID</strong> را محاسبه کنید [3]. اگر مرورگر
        وب، درخواست <strong>POST</strong> را دو بار ارسال کند، دو درخواست
        دارای <strong>operation ID</strong> یکسان خواهند بود.
    </p>
<p>
        سپس شما می‌توانید آن <strong>operation ID</strong> را تا پایگاه داده
        منتقل کنید و بررسی کنید که شما فقط یک عملیات را با یک <strong>ID</strong>
        داده شده اجرا می‌کنید، همان‌طور که در مثال 12-2 نشان داده شده
        است.
    </p>
<p>
        مثال 12-2. سرکوب درخواست‌های تکراری با استفاده از یک <strong>ID</strong>
        منحصربه‌فرد
    </p>
<pre><code class="language-sql">ALTER TABLE requests ADD UNIQUE (request_id);
BEGIN TRANSACTION;
INSERT INTO requests
  (request_id, from_account, to_account, amount)
  VALUES('0286FDB8-D7E1-423F-B40B-792B3608036C', 4321, 1234, 11.00);
UPDATE accounts SET balance = balance + 11.00 WHERE account_id = 1234;
UPDATE accounts SET balance = balance - 11.00 WHERE account_id = 4321;
COMMIT;
</code></pre>
<p>
        518
        |
        فصل 12: آینده‌ی سیستم‌های داده
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0540</div>
            </div>
        </div>
        <!-- Page 0541 -->
        <div class="chapter" id="page-0541">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        مثال 12-2 به یک <strong>uniqueness constraint</strong> در ستون
        <strong>request_id</strong> متکی است. اگر یک تراکنش تلاش کند <strong>ID</strong>
        ای را درج کند که از قبل وجود دارد، <strong>INSERT</strong> شکست می‌خورد و
        تراکنش <strong>aborted</strong> می‌شود، و از این‌که دو بار تأثیر بگذارد،
        جلوگیری می‌کند. پایگاه‌های داده‌ی رابطه‌ای به‌طور کلی می‌توانند یک
        <strong>uniqueness constraint</strong> را به‌درستی حفظ کنند، حتی در سطوح
        <em>weak isolation</em> (در حالی‌که یک <strong>check-then-insert</strong> در
        سطح برنامه ممکن است تحت <em>nonserializable isolation</em> شکست
        بخورد، همان‌طور که در "<strong>Write Skew</strong> و <strong>Phantoms</strong>"
        در صفحه 246 بحث شد).
    </p>
<p>
        علاوه بر سرکوب درخواست‌های تکراری، جدول درخواست‌ها در مثال 12-2
        به عنوان نوعی <strong>event log</strong> عمل می‌کند، که در جهت
        <strong>event sourcing</strong> اشاره دارد (نگاه کنید به "<strong>Event
        Sourcing</strong>" در صفحه 457). به‌روزرسانی‌های ترازهای حساب
        واقعاً نیازی به رخ دادن در همان تراکنش به‌عنوان درج رویداد ندارند،
        زیرا آن‌ها <em>redundant</em> هستند و می‌توانند از رویداد درخواست در
        یک <strong>consumer</strong> <em>downstream</em> استخراج شوند—تا
        زمانی‌که رویداد دقیقاً یک بار پردازش شود، که می‌تواند دوباره با
        استفاده از <strong>request ID</strong> اعمال شود.
    </p>
<h4>استدلال <strong>End-to-End</strong></h4>
<p>
        این سناریو از سرکوب تراکنش‌های تکراری، تنها یک نمونه از یک اصل
        کلی‌تر به نام استدلال <strong>end-to-end</strong> است، که توسط
        <strong>Saltzer</strong>، <strong>Reed</strong>، و <strong>Clark</strong> در سال 1984
        بیان شد [55]:
    </p>
<p>
        عملکرد مورد نظر می‌تواند به‌طور کامل و صحیح فقط با دانش و
        کمک برنامه که در <strong>endpoints</strong> از سیستم ارتباطی قرار دارد،
        پیاده‌سازی شود. بنابراین، ارائه آن <strong>function</strong> مورد نظر
        به عنوان یک <strong>feature</strong> از خود سیستم ارتباطی،
        امکان‌پذیر نیست. (گاهی اوقات یک نسخه ناقص از <strong>function</strong>
        ارائه شده توسط سیستم ارتباطی ممکن است به‌عنوان یک بهبود
        عملکرد مفید باشد.)
    </p>
<p>
        در مثال ما، <strong>function</strong> مورد نظر سرکوب تکراری بود. ما دیدیم
        که <strong>TCP</strong> بسته‌های تکراری را در سطح اتصال <strong>TCP</strong>
        سرکوب می‌کند، و برخی از پردازنده‌های <strong>stream</strong>
<em>exactly-once semantics</em> را در سطح پردازش پیام ارائه
        می‌دهند، اما این برای جلوگیری از این‌که یک کاربر یک درخواست
        تکراری را ارسال کند، کافی نیست اگر اولی <em>timeout</em> شود.
        به‌خودی خود، <strong>TCP</strong>، تراکنش‌های پایگاه داده، و پردازنده‌های
        <strong>stream</strong> نمی‌توانند به‌طور کامل این موارد تکراری را
        حذف کنند. حل این مشکل نیازمند یک راه‌حل <strong>end-to-end</strong>
        است: یک شناسه تراکنش که از <strong>client</strong> کاربر نهایی تا پایگاه
        داده منتقل می‌شود.
    </p>
<p>
        استدلال <strong>end-to-end</strong> همچنین برای بررسی یکپارچگی داده‌ها
        اعمال می‌شود: <strong>checksums</strong> ساخته شده در <strong>Ethernet</strong>،
        <strong>TCP</strong>، و <strong>TLS</strong> می‌توانند خراب شدن بسته‌ها در
        شبکه را تشخیص دهند، اما آن‌ها نمی‌توانند خراب شدن را به‌دلیل
        <strong>bugs</strong> در نرم‌افزار در پایان‌های ارسال و دریافت اتصال
        شبکه، یا خراب شدن روی دیسک‌ها که داده‌ها در آن‌ها ذخیره شده‌اند،
        تشخیص دهند. اگر شما می‌خواهید همه‌ی منابع ممکن فساد داده‌ها را
        شناسایی کنید، شما همچنین به <strong>checksums</strong> های <em>end-to-end</em>
        نیاز دارید.
    </p>
<p>
        یک استدلال مشابه در مورد رمزگذاری اعمال می‌شود [55]: رمز عبور در
        شبکه‌ی <strong>WiFi</strong> خانگی شما در برابر افرادی که در ترافیک
        <strong>WiFi</strong> شما <em>snooping</em> می‌کنند، محافظت می‌کند، اما
        در برابر مهاجمان در جای دیگری در اینترنت محافظت
        نمی‌کند؛ <strong>TLS/SSL</strong> بین <strong>client</strong> شما و سرور از
        نگاه‌کردن به
        هدف قرار دادن درستی
        |
        519
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0541</div>
            </div>
        </div>
        <!-- Page 0542 -->
        <div class="chapter" id="page-0542">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        در برابر حمله‌کنندگان شبکه محافظت می‌کند، اما در برابر <strong>compromises</strong>
        سرور محافظت نمی‌کند. فقط رمزگذاری و <strong>authentication</strong> <em>end-to-
        end</em> می‌تواند در برابر همه‌ی این موارد محافظت کند.
    </p>
<p>
        اگرچه <strong>features</strong> سطح پایین (سرکوب تکراری <strong>TCP</strong>،
        <strong>checksums Ethernet</strong>، رمزگذاری <strong>WiFi</strong>) نمی‌توانند
        به‌تنهایی <strong>features end-to-end</strong> مورد نظر را ارائه
        دهند، آن‌ها هنوز هم مفید هستند، زیرا احتمال بروز مشکلات را در
        سطوح بالاتر کاهش می‌دهند. به عنوان مثال، درخواست‌های <strong>HTTP</strong>
        اغلب اگر <strong>TCP</strong> بسته‌ها را به ترتیب صحیح قرار ندهد،
        <em>mangled</em> خواهند شد. ما فقط نیاز داریم که به یاد داشته
        باشیم که <strong>features</strong> قابلیت اطمینان سطح پایین، به‌خودی خود
        برای اطمینان از درستی <em>end-to-end</em> کافی نیستند.
    </p>
<h4>اعمال استدلال <strong>end-to-end</strong> در سیستم‌های داده</h4>
<p>
        این موضوع من را به پایان‌نامه‌ی اصلی‌ام برمی‌گرداند: فقط به این
        دلیل که یک برنامه از یک سیستم داده استفاده می‌کند که
        ویژگی‌های ایمنی نسبتاً قوی را ارائه می‌دهد، مانند تراکنش‌های
        <em>serializable</em>، به این معنی نیست که تضمین می‌شود که برنامه
        از از دست رفتن یا خراب شدن داده‌ها عاری است. خود برنامه
        نیاز دارد که اقدامات <em>end-to-end</em> را انجام دهد، مانند
        سرکوب تکراری، نیز.
    </p>
<p>
        این یک <em>shame</em> است، زیرا مکانیسم‌های تحمل خطا به‌درستی
        عمل کردن، سخت هستند. مکانیسم‌های قابلیت اطمینان سطح پایین،
        مانند آن‌هایی که در <strong>TCP</strong> وجود دارند، کاملاً خوب عمل
        می‌کنند، و بنابراین <strong>faults</strong> سطح بالاتر با نسبتاً به‌ندرت
        رخ می‌دهند. واقعاً خوب خواهد بود که ماشین‌آلات تحمل خطای
        باقی‌مانده سطح بالا را در یک <strong>abstraction</strong> جمع کنیم تا
        کد برنامه نیازی به نگرانی در مورد آن نداشته باشد—اما من
        می‌ترسم که هنوز <strong>abstraction</strong> مناسب را پیدا نکرده
        باشیم.
    </p>
<p>
        تراکنش‌ها مدت‌هاست که به‌عنوان یک <strong>abstraction</strong> خوب دیده
        می‌شوند، و من معتقدم که آن‌ها مفید هستند. همان‌طور که در
        مقدمه فصل 7 بحث شد، آن‌ها طیف گسترده‌ای از مسائل
        احتمالی (<strong>writes</strong> همزمان، نقض محدودیت‌ها، <strong>crashes</strong>،
        <em>network interruptions</em>، <strong>disk failures</strong>) را می‌گیرند
        و آن‌ها را به دو نتیجه‌ی ممکن تبدیل می‌کنند: <strong>commit</strong> یا
        <strong>abort</strong>.
    </p>
<p>
        این یک ساده‌سازی بزرگ از مدل برنامه‌نویسی است، اما من می‌ترسم
        که کافی نباشد.
    </p>
<p>
        تراکنش‌ها پرهزینه هستند، به‌ویژه زمانی که شامل فناوری‌های
        ذخیره‌سازی ناهمگن می‌شوند (نگاه کنید به "تراکنش‌های توزیع شده
        در عمل" در صفحه 360). وقتی ما از استفاده از تراکنش‌های
        توزیع شده به این دلیل که خیلی گران هستند خودداری
        می‌کنیم، در نهایت باید مکانیسم‌های تحمل خطا را در کد
        برنامه دوباره پیاده‌سازی کنیم. همان‌طور که نمونه‌های متعددی
        در سراسر این کتاب نشان داده شده است، استدلال در مورد
        <strong>concurrency</strong> و <strong>partial failure</strong> دشوار و
        <em>counterintuitive</em> است، و بنابراین من مشکوک هستم که اکثر
        مکانیسم‌های سطح برنامه به‌درستی کار نمی‌کنند. نتیجه، از
        دست رفتن یا خراب شدن داده‌ها است.
    </p>
<p>
        به همین دلایل، من فکر می‌کنم ارزش دارد که <strong>abstractions</strong>
        های تحمل خطا را بررسی کنیم که درک درستی از
        ویژگی‌های <em>application-specific end-to-end</em> را آسان می‌کنند،
        اما همچنین عملکرد خوب و ویژگی‌های عملیاتی خوب را در یک
        محیط توزیع شده در مقیاس بزرگ حفظ می‌کنند.
        520
        |
        فصل 12: آینده‌ی سیستم‌های داده
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0542</div>
            </div>
        </div>
        <!-- Page 0543 -->
        <div class="chapter" id="page-0543">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        اعمال محدودیت‌ها
    </p>
<p>
        بیایید در مورد درستی در <strong>context</strong> از ایده‌های اطراف
        <strong>unbundling databases</strong> فکر کنیم ("<strong>Unbundling Databases</strong>"
        در صفحه 499). ما دیدیم که سرکوب تکراری <em>end-to-end</em> را می‌توان
        با یک <strong>request ID</strong> که از <strong>client</strong> تا پایگاه داده که
        <strong>write</strong> را ثبت می‌کند، منتقل می‌شود، به‌دست
        آورد. در مورد انواع دیگر محدودیت‌ها چطور؟
    </p>
<p>
        به‌طور خاص، بیایید روی <strong>uniqueness constraints</strong> تمرکز
        کنیم—مانند موردی که ما در مثال 12-2 به آن متکی بودیم. در
        "محدودیت‌ها و تضمین‌های منحصربه‌فرد بودن" در صفحه 330 ما
        چندین مثال دیگر از <strong>features</strong> برنامه را دیدیم که نیاز به
        اعمال <strong>uniqueness</strong> دارند: یک نام کاربری یا آدرس <strong>email</strong>
        باید به‌طور منحصربه‌فرد یک کاربر را شناسایی کند، یک
        <strong>service</strong> ذخیره‌سازی فایل نمی‌تواند بیش از یک فایل با
        نام یکسان داشته باشد، و دو نفر نمی‌توانند یک صندلی را در یک
        پرواز یا در یک تئاتر رزرو کنند.
    </p>
<p>
        سایر انواع محدودیت‌ها بسیار شبیه هستند: به عنوان مثال، اطمینان از
        این‌که موجودی حساب هرگز منفی نمی‌شود، این‌که شما بیش از آن
        مقدار آیتم موجود در انبار را نمی‌فروشید، یا این‌که یک سالن
        اجتماعات، رزروهای همپوشانی ندارد. تکنیک‌هایی که <strong>uniqueness</strong>
        را اعمال می‌کنند، اغلب برای این نوع محدودیت‌ها نیز استفاده
        می‌شوند.
    </p>
<h4><strong>Uniqueness constraints</strong> نیاز به اجماع دارند</h4>
<p>
        در فصل 9 ما دیدیم که در یک محیط توزیع شده، اعمال یک
        <strong>uniqueness constraint</strong> به <strong>consensus</strong> نیاز
        دارد: اگر چندین درخواست همزمان با مقدار یکسان وجود داشته
        باشد، سیستم به‌نوعی نیاز دارد که تصمیم بگیرد کدام‌یک از
        عملیات متناقض پذیرفته می‌شود، و موارد دیگر را به‌عنوان
        نقض محدودیت رد کند.
    </p>
<p>
        رایج‌ترین راه برای دستیابی به این <strong>consensus</strong> این است که یک
        <strong>node</strong> واحد را <strong>leader</strong> قرار دهیم، و آن را مسئول
        تصمیم‌گیری‌ها کنیم. این کار تا زمانی خوب است که شما
        مخالف هدایت تمام درخواست‌ها از طریق یک <strong>node</strong> واحد
        نباشید (حتی اگر <strong>client</strong> در طرف دیگر دنیا باشد)، و تا زمانی
        که آن <strong>node</strong> شکست نخورد. اگر شما نیاز دارید که شکست
        <strong>leader</strong> را تحمل کنید، شما دوباره به مشکل <strong>consensus</strong>
        برمی‌گردید (نگاه کنید به "<strong>Single-leader replication</strong> و
        <strong>consensus</strong>" در صفحه 367).
    </p>
<p>
        بررسی <strong>uniqueness</strong> را می‌توان با <strong>partitioning</strong> بر
        اساس مقداری که نیاز به <strong>unique</strong> بودن دارد، <em>scaled out</em>
        کرد. به عنوان مثال، اگر شما نیاز دارید که <strong>uniqueness</strong>
        را بر اساس <strong>request ID</strong> تضمین کنید، همان‌طور که در مثال
        12-2 نشان داده شده است، شما می‌توانید اطمینان حاصل کنید که
        تمام درخواست‌ها با <strong>request ID</strong> یکسان به یک
        <strong>partition</strong> یکسان هدایت می‌شوند (نگاه کنید به فصل 6). اگر شما
        نیاز دارید که نام‌های کاربری <strong>unique</strong> باشند، شما
        می‌توانید بر اساس <strong>hash</strong> از نام کاربری، <strong>partition</strong>
        کنید.
    </p>
<p>
        با این حال، <strong>replication</strong> <em>asynchronous multi-master</em>
        منتفی است، زیرا ممکن است رخ دهد که <strong>masters</strong>
        مختلف، به‌طور هم‌زمان <strong>writes</strong> متناقضی را بپذیرند، و
        بنابراین مقادیر دیگر <strong>unique</strong> نیستند (نگاه کنید به
        "پیاده‌سازی سیستم‌های <strong>Linearizable</strong>" در صفحه 332). اگر
        شما می‌خواهید بلافاصله هر <strong>writes</strong> را که محدودیت را نقض
        می‌کند، رد کنید، هماهنگی <em>synchronous</em> اجتناب‌ناپذیر است
        [56].
        هدف قرار دادن درستی
        |
        521
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0543</div>
            </div>
        </div>
        <!-- Page 0544 -->
        <div class="chapter" id="page-0544">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
<strong>Uniqueness</strong> در پیام‌رسانی مبتنی بر <strong>log</strong>
</p>
<p>
<strong>Log</strong> تضمین می‌کند که تمام <strong>consumers</strong> پیام‌ها را
        به همان ترتیب می‌بینند—تضمینی که به‌طور رسمی به‌عنوان <strong>total
        order broadcast</strong> شناخته می‌شود و معادل <strong>consensus</strong>
        است (نگاه کنید به "<strong>Total Order Broadcast</strong>" در صفحه 348). در
        رویکرد پایگاه داده‌ی <strong>unbundled</strong> با پیام‌رسانی مبتنی بر <strong>log</strong>،
        ما می‌توانیم از یک رویکرد بسیار مشابه برای اعمال
        <strong>uniqueness constraints</strong> استفاده کنیم.
    </p>
<p>
        یک پردازنده <strong>stream</strong> تمام پیام‌ها را در یک <strong>log
        partition</strong> به‌صورت متوالی در یک <strong>thread</strong> واحد مصرف
        می‌کند (نگاه کنید به "<strong>Logs</strong> در مقایسه با پیام‌رسانی سنتی"
        در صفحه 448). بنابراین، اگر <strong>log</strong> بر اساس مقداری که
        نیاز به <strong>unique</strong> بودن دارد، <strong>partitioned</strong> شده
        باشد، یک پردازنده <strong>stream</strong> می‌تواند به‌طور صریح و
        <em>deterministic</em> تصمیم بگیرد که کدام‌یک از چندین عملیات
        متناقض، اول آمده است. به عنوان مثال، در مورد چندین کاربر که
        سعی می‌کنند همان نام کاربری را ادعا کنند [57]:
    </p>
<ol>
<li>
            هر درخواست برای یک نام کاربری به عنوان یک پیام رمزگذاری
            شده است، و به یک <strong>partition</strong> اضافه می‌شود که توسط
            <strong>hash</strong> از نام کاربری تعیین می‌شود.
        </li>
<li>
            یک پردازنده <strong>stream</strong> به‌طور متوالی درخواست‌ها را در
            <strong>log</strong> می‌خواند، و از یک پایگاه داده‌ی محلی برای
            پیگیری این‌که کدام نام‌های کاربری گرفته شده‌اند، استفاده
            می‌کند. برای هر درخواست برای یک نام کاربری که در دسترس
            است، نام را به‌عنوان گرفته شده ثبت می‌کند و یک پیام
            موفقیت را به یک <strong>stream</strong> خروجی منتشر می‌کند. برای
            هر درخواست برای یک نام کاربری که قبلاً گرفته شده است،
            یک پیام رد را به یک <strong>stream</strong> خروجی منتشر می‌کند.
        </li>
<li>
<strong>Client</strong> که نام کاربری را درخواست کرده است، <strong>stream</strong>
            خروجی را تماشا می‌کند و منتظر یک پیام موفقیت یا رد
            متناظر با درخواست خود می‌ماند.
        </li>
</ol>
<p>
        این الگوریتم اساساً با الگوریتم موجود در "پیاده‌سازی
        ذخیره‌سازی <em>linearizable</em> با استفاده از <strong>total order broadcast</strong>"
        در صفحه 350 یکسان است. این کار با افزایش تعداد
        <strong>partitions</strong> به‌راحتی به یک توان عملیاتی زیاد درخواست
        می‌رسد، زیرا هر <strong>partition</strong> می‌تواند به‌طور مستقل پردازش
        شود.
    </p>
<p>
        این رویکرد، نه‌تنها برای <strong>uniqueness constraints</strong>، بلکه
        برای بسیاری از انواع دیگر محدودیت‌ها نیز کار می‌کند. اصل
        اساسی آن این است که هر <strong>writes</strong> که ممکن است متناقض
        باشند، به همان <strong>partition</strong> هدایت می‌شوند و به‌طور
        متوالی پردازش می‌شوند. همان‌طور که در "<strong>What is a conflict</strong>"
        در صفحه 174 و "<strong>Write Skew</strong> و <strong>Phantoms</strong>" در
        صفحه 246 بحث شد، تعریف یک <em>conflict</em> ممکن است به برنامه
        بستگی داشته باشد، اما پردازنده <strong>stream</strong> می‌تواند از
        منطق دلخواه برای تأیید یک درخواست استفاده کند. این ایده
        مشابه رویکردی است که توسط <strong>Bayou</strong> در دهه‌ی 1990 پیشگام
        شد [58].
    </p>
<h4>پردازش درخواست چند <strong>partition</strong></h4>
<p>
        اطمینان از این‌که یک عملیات به‌صورت <em>atomically</em> اجرا می‌شود،
        در حالی‌که محدودیت‌ها را برآورده می‌کند، زمانی جالب‌تر می‌شود
        که چندین <strong>partitions</strong> درگیر باشند. در مثال 12-2،
        به‌طور بالقوه سه <strong>partition</strong> وجود دارد: یکی حاوی
        <strong>request ID</strong>، یکی حاوی حساب <strong>payee</strong>، و یکی
        حاوی حساب <strong>payer</strong>. هیچ دلیلی وجود ندارد که
        522
        |
        فصل 12: آینده‌ی سیستم‌های داده
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0544</div>
            </div>
        </div>
        <!-- Page 0545 -->
        <div class="chapter" id="page-0545">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        به این دلیل که چرا آن سه مورد باید در یک <strong>partition</strong> یکسان باشند،
        از آن‌جایی‌که همه‌ی آن‌ها مستقل از یکدیگر هستند.
    </p>
<p>
        در رویکرد سنتی به پایگاه‌های داده، اجرای این تراکنش به یک <strong>atomic
        commit</strong> در سراسر هر سه <strong>partitions</strong> نیاز دارد، که
        اساساً آن را به یک <strong>total order</strong> با توجه به همه‌ی تراکنش‌های
        دیگر در هر یک از آن <strong>partitions</strong> مجبور می‌کند. از آن‌جایی
        که اکنون هماهنگی <em>cross-partition</em> وجود دارد، <strong>partitions</strong>
        مختلف دیگر نمی‌توانند به‌طور مستقل پردازش شوند، بنابراین احتمالاً
        توان عملیاتی تحت تأثیر قرار می‌گیرد.
    </p>
<p>
        با این حال، مشخص شد که می‌توان با <strong>partitioned logs</strong>، درستی
        معادل را به‌دست آورد، و بدون یک <strong>atomic commit</strong>:
    </p>
<ol>
<li>
            به درخواست انتقال پول از حساب A به حساب B یک <strong>request ID</strong>
            منحصربه‌فرد توسط <strong>client</strong> داده می‌شود، و به یک <strong>log
            partition</strong> بر اساس <strong>request ID</strong> اضافه می‌شود.
        </li>
<li>
            یک پردازنده <strong>stream</strong>، <strong>log</strong> درخواست‌ها را
            می‌خواند. برای هر پیام درخواست، دو پیام به جریان‌های خروجی
            منتشر می‌کند: یک دستور بدهی به حساب پرداخت‌کننده A
            (<strong>partitioned</strong> شده توسط A)، و یک دستور اعتبار به حساب
            دریافت‌کننده B (<strong>partitioned</strong> شده توسط B). <strong>Request
            ID</strong> اصلی در آن پیام‌های منتشر شده گنجانده شده است.
        </li>
<li>
            پردازنده‌های بیشتر، جریان‌های دستورالعمل‌های اعتبار و بدهی را مصرف
            می‌کنند، با <strong>request ID</strong> حذف تکراری انجام می‌دهند، و
            تغییرات را در ترازهای حساب اعمال می‌کنند.
        </li>
</ol>
<p>
        مراحل 1 و 2 ضروری هستند زیرا اگر <strong>client</strong> مستقیماً
        دستورالعمل‌های اعتبار و بدهی را ارسال می‌کرد، نیاز به یک
        <strong>atomic commit</strong> در سراسر آن دو <strong>partitions</strong> برای
        اطمینان از این‌که هر دو یا هیچ‌کدام رخ می‌دهند. برای جلوگیری از
        نیاز به یک تراکنش توزیع شده، ما ابتدا درخواست را به‌صورت
        <em>durably</em> به‌عنوان یک پیام واحد <strong>log</strong> می‌کنیم، و سپس
        دستورالعمل‌های اعتبار و بدهی را از آن پیام اول استخراج می‌کنیم.
        <strong>Writes</strong> تک شیء در تقریباً تمام سیستم‌های داده <em>atomic</em>
        هستند (نگاه کنید به "<strong>Single-object writes</strong>" در صفحه 230)،
        و بنابراین درخواست یا در <strong>log</strong> ظاهر می‌شود یا نمی‌شود،
        بدون هیچ نیازی به یک <strong>atomic commit</strong> چند <strong>partition</strong>.
    </p>
<p>
        اگر پردازنده <strong>stream</strong> در مرحله‌ی 2 شکست بخورد، پردازش را از
        آخرین <strong>checkpoint</strong> خود از سر می‌گیرد. با انجام این کار،
        هیچ پیام درخواستی را رد نمی‌کند، اما ممکن است درخواست‌ها را
        چندین بار پردازش کند و دستورالعمل‌های اعتبار و بدهی تکراری
        تولید کند. با این حال، از آن‌جایی‌که <em>deterministic</em> است، فقط
        همان دستورالعمل‌ها را دوباره تولید می‌کند، و پردازنده‌ها در
        مرحله‌ی 3 می‌توانند به‌راحتی با استفاده از <strong>end-to-end request
        ID</strong>، آن‌ها را حذف تکراری کنند.
    </p>
<p>
        اگر شما می‌خواهید اطمینان حاصل کنید که حساب پرداخت‌کننده با این
        انتقال <em>overdrawn</em> نشده است، شما می‌توانید به‌طور اضافی یک
        پردازنده <strong>stream</strong> (<strong>partitioned</strong> شده توسط شماره
        حساب پرداخت‌کننده) داشته باشید که ترازهای حساب را حفظ و
        تراکنش‌ها را تأیید می‌کند. فقط تراکنش‌های معتبر سپس در <strong>log</strong>
        درخواست در مرحله 1 قرار می‌گیرند.
    </p>
<p>
        با شکستن تراکنش چند <strong>partition</strong> به دو مرحله‌ی
        <strong>partitioned</strong> شده‌ی مختلف و استفاده از <strong>end-to-end request
        ID</strong>، ما به همان ویژگی درستی (هر درخواست دقیقاً یک بار برای
        هر دو حساب پرداخت‌کننده و دریافت‌کننده اعمال می‌شود) دست یافته‌ایم،
        حتی در حضور <strong>faults</strong>، و بدون استفاده از یک پروتکل
        <strong>atomic commit</strong>.
        هدف قرار دادن درستی
        |
        523
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0545</div>
            </div>
        </div>
        <!-- Page 0546 -->
        <div class="chapter" id="page-0546">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        ایده‌ی استفاده از مراحل <strong>partitioned</strong> شده‌ی مختلف مشابه
        چیزی است که ما در "پردازش داده‌های چند <strong>partition</strong>" در
        صفحه 514 بحث کردیم (همچنین به "کنترل <strong>Concurrency</strong>" در
        صفحه 462 مراجعه کنید).
    </p>
<h4>به‌موقع بودن و یکپارچگی</h4>
<p>
        یک ویژگی مناسب از تراکنش‌ها این است که آن‌ها معمولاً
        <em>linearizable</em> هستند (نگاه کنید به "<strong>Linearizability</strong>" در
        صفحه 324): یعنی، یک <strong>writer</strong> صبر می‌کند تا زمانی که یک
        تراکنش <strong>committed</strong> شود، و پس از آن، <strong>writes</strong>
        آن‌ها بلافاصله برای تمام <strong>readers</strong> قابل مشاهده
        است.
    </p>
<p>
        این مورد زمانی وجود ندارد که یک عملیات در سراسر مراحل متعدد
        از پردازنده‌های <strong>stream</strong> <strong>unbundle</strong> می‌شود:
        <strong>consumers</strong> از یک <strong>log</strong> به‌طور پیش‌فرض
        <em>asynchronous</em> هستند، بنابراین یک فرستنده منتظر نمی‌ماند
        تا زمانی که پیامش توسط <strong>consumers</strong> پردازش شود. با این
        حال، برای یک <strong>client</strong> ممکن است منتظر بماند تا یک
        پیام در یک <strong>stream</strong> خروجی ظاهر شود. این همان چیزی
        است که ما در "<strong>Uniqueness</strong> در پیام‌رسانی مبتنی بر
        <strong>log</strong>" در صفحه 522 هنگام بررسی این‌که آیا یک
        <strong>uniqueness constraint</strong> برآورده شده است، انجام
        دادیم.
    </p>
<p>
        در این مثال، درستی بررسی <strong>uniqueness</strong>، به این بستگی
        ندارد که آیا فرستنده‌ی پیام، منتظر نتیجه است یا خیر. انتظار
        کشیدن فقط این هدف را دارد که به‌طور <em>synchronously</em> به
        فرستنده اطلاع دهد که آیا بررسی <strong>uniqueness</strong> موفقیت‌آمیز
        بوده است یا خیر، اما این اعلان را می‌توان از اثرات پردازش
        پیام جدا کرد.
    </p>
<p>
        به‌طور کلی‌تر، من فکر می‌کنم اصطلاح <strong>consistency</strong>، دو
        نیاز مختلف را که ارزش بررسی جداگانه را دارند، با هم
        ادغام می‌کند:
    </p>
<ul>
<li>
            به‌موقع بودن
        </li>
<p>
            به‌موقع بودن به معنای اطمینان از این است که کاربران سیستم را
            در یک وضعیت به‌روز مشاهده می‌کنند.
        </p>
<p>
            ما قبلاً دیدیم که اگر یک کاربر از یک کپی کهنه از داده‌ها
            بخواند، ممکن است آن را در یک وضعیت ناسازگار مشاهده کند
            (نگاه کنید به "مشکلات با <strong>Replication Lag</strong>" در صفحه
            161). با این حال، آن ناسازگاری موقتی است، و در نهایت با
            انتظار و تلاش دوباره برطرف خواهد شد.
        </p>
<p>
            قضیه‌ی <strong>CAP</strong> (نگاه کنید به "هزینه‌ی
            <strong>Linearizability</strong>" در صفحه 335) از
            <strong>consistency</strong> در معنای <strong>linearizability</strong>
            استفاده می‌کند، که یک راه قوی برای دستیابی به به‌موقع
            بودن است. ویژگی‌های به‌موقع بودن ضعیف‌تر مانند <strong>read-
            after-write consistency</strong> (نگاه کنید به "خواندن
            نوشتن‌های خودتان" در صفحه 162) نیز می‌تواند مفید
            باشد.
        </p>
<li>
            یکپارچگی
        </li>
<p>
            یکپارچگی به‌معنای فقدان فساد است؛ یعنی، عدم از دست
            دادن داده‌ها، و عدم داده‌های متناقض یا نادرست. به‌طور
            خاص، اگر برخی از مجموعه‌داده‌های مشتق شده به‌عنوان یک
            <strong>view</strong> بر روی برخی از داده‌های اساسی حفظ می‌شوند
            (نگاه کنید به "استخراج <strong>state</strong> فعلی از <strong>event log</strong>"
            در صفحه 458)، استخراج باید صحیح باشد. به عنوان
            مثال، یک index پایگاه داده باید محتویات پایگاه داده را
            به‌درستی منعکس کند—یک index که در آن برخی از
            رکوردها از دست رفته‌اند، چندان مفید نیست.
            524
            |
            فصل 12: آینده‌ی سیستم‌های داده
        
</p></ul>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0546</div>
            </div>
        </div>
        <!-- Page 0547 -->
        <div class="chapter" id="page-0547">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        اگر <strong>integrity</strong> نقض شود، ناسازگاری دائمی است: انتظار
        کشیدن و دوباره تلاش کردن در اکثر موارد، فساد پایگاه داده را برطرف
        نمی‌کند. در عوض، بررسی و تعمیر صریح مورد نیاز است. در
        <strong>context</strong> از تراکنش‌های <strong>ACID</strong> (نگاه کنید به "معنی
        <strong>ACID</strong>" در صفحه 223)، <strong>consistency</strong> معمولاً به عنوان
        نوعی مفهوم <em>application-specific</em> از <strong>integrity</strong> درک
        می‌شود. <em>Atomicity</em> و <em>durability</em> ابزارهای مهمی برای
        حفظ <strong>integrity</strong> هستند.
    </p>
<p>
        به‌صورت شعار: نقض <strong>timeliness</strong> "<strong>eventual
        consistency</strong>" است، در حالی که نقض <strong>integrity</strong>،
        "<strong>perpetual inconsistency</strong>" است.
    </p>
<p>
        من قصد دارم این ادعا را مطرح کنم که در اکثر برنامه‌ها، <strong>integrity</strong>
        بسیار مهم‌تر از <strong>timeliness</strong> است. نقض <strong>timeliness</strong>
        می‌تواند آزاردهنده و گیج‌کننده باشد، اما نقض
        <strong>integrity</strong> می‌تواند فاجعه‌آمیز باشد.
    </p>
<p>
        به عنوان مثال، در بیانیه‌ی کارت اعتباری شما، این‌که یک تراکنش که
        شما در 24 ساعت گذشته انجام داده‌اید، هنوز ظاهر نشده است،
        تعجب‌آور نیست—این طبیعی است که این سیستم‌ها دارای یک
        <em>lag</em> خاصی باشند. ما می‌دانیم که بانک‌ها تراکنش‌ها را به‌صورت
        <em>asynchronously</em> <em>reconcile</em> و <em>settle</em> می‌کنند، و
        <strong>timeliness</strong> در اینجا چندان مهم نیست [3]. با این حال، اگر
        موجودی بیانیه برابر با مجموع تراکنش‌ها به‌علاوه موجودی
        بیانیه‌ی قبلی نباشد (یک خطا در مجموع)، یا اگر یک تراکنش به
        شما شارژ شده باشد اما به تاجر پرداخت نشده باشد (ناپدید شدن
        پول)، بسیار بد خواهد بود. چنین مشکلاتی نقض <strong>integrity</strong>
        سیستم خواهد بود.
    </p>
<h4>درستی سیستم‌های <strong>Dataflow</strong></h4>
<p>
        تراکنش‌های <strong>ACID</strong> معمولاً هر دو <strong>timeliness</strong> (به
        عنوان مثال، <em>linearizability</em>) و <strong>integrity</strong> (به
        عنوان مثال، <strong>atomic commit</strong>) را تضمین می‌کنند.
        بنابراین، اگر شما به درستی برنامه از دیدگاه تراکنش‌های <strong>ACID</strong>
        نزدیک شوید، تمایز بین <strong>timeliness</strong> و <strong>integrity</strong>
        تقریباً بی‌اهمیت است.
    </p>
<p>
        از سوی دیگر، یک ویژگی جالب از سیستم‌های <strong>dataflow</strong> مبتنی بر
        رویداد که ما در این فصل مورد بحث قرار دادیم این است که آن‌ها
        <strong>timeliness</strong> و <strong>integrity</strong> را از هم جدا می‌کنند.
        هنگام پردازش جریان‌های رویداد به‌صورت <em>asynchronously</em>،
        هیچ تضمینی برای <strong>timeliness</strong> وجود ندارد، مگر این‌که
        شما صریحاً <strong>consumers</strong> بسازید که منتظر رسیدن یک پیام
        باشند قبل از بازگشت. اما <strong>integrity</strong> در واقع برای
        سیستم‌های <strong>streaming</strong> اساسی است.
    </p>
<p>
<strong>Exactly-once</strong> یا <em>effectively-once semantics</em> (نگاه کنید
        به "تحمل خطا" در صفحه 476) یک مکانیسم برای حفظ
        <strong>integrity</strong> است. اگر یک رویداد از دست برود، یا اگر یک رویداد
        دو بار تأثیر بگذارد، <strong>integrity</strong> از یک سیستم داده ممکن
        است نقض شود. بنابراین، تحویل پیام تحمل‌کننده‌ی خطا و سرکوب
        تکراری (به عنوان مثال، عملیات <em>idempotent</em>) برای حفظ
        <strong>integrity</strong> از یک سیستم داده در مواجهه با <strong>faults</strong>
        مهم هستند.
    </p>
<p>
        همان‌طور که در بخش آخر دیدیم، سیستم‌های پردازش <strong>stream</strong>
        قابل اعتماد می‌توانند <strong>integrity</strong> را بدون نیاز به تراکنش‌های
        توزیع شده و یک پروتکل <strong>atomic commit</strong> حفظ کنند، که
        به این معنی است که آن‌ها به‌طور بالقوه می‌توانند درستی قابل
        مقایسه‌ای را با عملکرد بسیار بهتری به‌دست آورند
        هدف قرار دادن درستی
        |
        525
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0547</div>
            </div>
        </div>
        <!-- Page 0548 -->
        <div class="chapter" id="page-0548">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        عملکرد و استحکام عملیاتی. ما این <strong>integrity</strong> را از طریق ترکیبی
        از مکانیسم‌ها به‌دست آوردیم:
    </p>
<ul>
<li>
            نشان دادن محتوای عملیات <strong>write</strong> به عنوان یک پیام واحد،
            که به‌راحتی می‌تواند به‌صورت <em>atomically</em> نوشته شود—رویکردی
            که با <strong>event sourcing</strong> بسیار خوب مطابقت دارد
            (نگاه کنید به "<strong>Event Sourcing</strong>" در صفحه 457)
        </li>
<li>
            استخراج تمام به‌روزرسانی‌های <strong>state</strong> دیگر از آن پیام
            واحد با استفاده از توابع استخراج <em>deterministic</em>، مشابه
            <strong>stored procedures</strong> (نگاه کنید به "اجرای سریال
            واقعی" در صفحه 252 و "کد برنامه به عنوان یک تابع مشتق شده"
            در صفحه 505)
        </li>
<li>
            ارسال یک <strong>request ID</strong> تولید شده توسط <strong>client</strong> از
            طریق تمام این سطوح پردازش، که امکان سرکوب تکراری و
            <strong>idempotence</strong> <em>end-to-end</em> را فراهم
            می‌کند
        </li>
<li>
            ساختن پیام‌ها <em>immutable</em> و اجازه دادن به <strong>data</strong> مشتق
            شده تا هر از چند گاهی دوباره پردازش شود، که بازیابی از
            <strong>bugs</strong> را آسان‌تر می‌کند (نگاه کنید به "مزایای رویدادهای
            <em>immutable</em>" در صفحه 460)
        </li>
</ul>
<p>
        به نظر من این ترکیب از مکانیسم‌ها، یک جهت بسیار امیدوارکننده
        برای ساخت برنامه‌های تحمل‌کننده‌ی خطا در آینده است.
    </p>
<h4>محدودیت‌های تفسیر شده‌ی آزاد</h4>
<p>
        همان‌طور که قبلاً بحث شد، اعمال یک <strong>uniqueness constraint</strong>
        نیازمند <strong>consensus</strong> است، که معمولاً با انتقال تمام
        رویدادها در یک <strong>partition</strong> خاص از طریق یک <strong>node</strong>
        واحد پیاده‌سازی می‌شود. این محدودیت اجتناب‌ناپذیر است اگر ما
        شکل سنتی <strong>uniqueness constraint</strong> را بخواهیم، و پردازش
        <strong>stream</strong> نمی‌تواند از آن اجتناب کند.
    </p>
<p>
        با این حال، نکته‌ی دیگری که باید متوجه شد این است که بسیاری از
        برنامه‌های واقعی می‌توانند در واقع از مفاهیم ضعیف‌تری از
        <strong>uniqueness</strong> استفاده کنند:
    </p>
<ul>
<li>
            اگر دو نفر به‌طور همزمان همان نام کاربری را ثبت کنند یا همان
            صندلی را رزرو کنند، شما می‌توانید به یکی از آن‌ها پیامی برای
            عذرخواهی ارسال کنید، و از آن‌ها بخواهید که یکی دیگر را انتخاب
            کنند. این نوع تغییر برای اصلاح یک اشتباه، یک تراکنش
            <em>compensating</em> نامیده می‌شود [59، 60].
        </li>
<li>
            اگر مشتریان بیش از آن‌چه در انبار دارید، کالا سفارش دهند،
            شما می‌توانید موجودی بیشتری را سفارش دهید، از مشتریان به‌دلیل
            تأخیر عذرخواهی کنید، و به آن‌ها تخفیف ارائه دهید. این در واقع
            مشابه کاری است که شما باید انجام دهید اگر، به عنوان مثال، یک
            لیفتراک از روی برخی از اقلام موجود در انبار شما عبور کرد، و
            باعث شد که شما اقلام کمتری را نسبت به آن‌چه فکر می‌کردید
            داشته باشید [61]. بنابراین، گردش کار عذرخواهی در هر صورت
            باید بخشی از فرآیندهای تجاری شما باشد، و بنابراین ممکن است
            نیازی به یک <strong>constraint</strong> <em>linearizable</em> در
            تعداد اقلام موجود در انبار نباشد.
        </li>
<li>
            به‌طور مشابه، بسیاری از خطوط هوایی، هواپیماها را بیش از حد
            رزرو می‌کنند با این انتظار که برخی از مسافران پرواز خود را از
            دست بدهند، و بسیاری از هتل‌ها، اتاق‌ها را بیش از حد رزرو
            می‌کنند، با این انتظار که برخی از مهمانان لغو کنند. در این
            موارد، <strong>constraint</strong> از "یک نفر در هر صندلی"
            عمدتاً
            526
            |
            فصل 12: آینده‌ی سیستم‌های داده
        </li>
</ul>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0548</div>
            </div>
        </div>
        <!-- Page 0549 -->
        <div class="chapter" id="page-0549">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        عمداً به‌دلیل دلایل تجاری نقض شده‌اند، و فرآیندهای جبران (بازپرداخت‌ها،
        <strong>upgrades</strong>، ارائه یک اتاق رایگان در یک هتل همسایه) برای
        مدیریت موقعیت‌هایی که در آن‌ها تقاضا از عرضه بیشتر می‌شود، در
        نظر گرفته شده‌اند. حتی اگر هیچ <em>overbooking</em> وجود نداشت،
        فرآیندهای عذرخواهی و جبران باید برای رسیدگی به پروازهایی که به‌دلیل
        هوای بد یا اعتصاب کارکنان لغو شده‌اند—بازیابی از چنین مسائلی
        فقط یک بخش عادی از تجارت است [3].
    </p>
<ul>
<li>
            اگر شخصی بیش از آن‌چه در حسابش دارد، پول برداشت کند، بانک
            می‌تواند از آن‌ها یک کارمزد <strong>overdraft</strong> دریافت کند و از
            آن‌ها بخواهد که آن‌چه را که بدهکار هستند، پس دهند. با محدود
            کردن کل برداشت‌ها در روز، ریسک برای بانک محدود می‌شود.
        </li>
</ul>
<p>
        در بسیاری از زمینه‌های تجاری، در واقع پذیرفته شده است که
        محدودیت را موقتاً نقض کنید و بعداً آن را اصلاح کنید با عذرخواهی
        کردن. هزینه عذرخواهی (از نظر پول یا شهرت) متفاوت است، اما
        اغلب کاملاً کم است: شما نمی‌توانید یک <strong>email</strong> را <em>unsend</em>
        کنید، اما شما می‌توانید یک <strong>email</strong> پیگیری را با یک
        اصلاحیه ارسال کنید. اگر شما به‌طور تصادفی یک کارت اعتباری را دو
        بار شارژ کنید، شما می‌توانید یکی از هزینه‌ها را بازپرداخت کنید، و
        هزینه‌ای که برای شما دارد فقط کارمزد پردازش و شاید یک شکایت
        مشتری است. هنگامی‌که پول از یک <strong>ATM</strong> پرداخت شده است، شما
        نمی‌توانید مستقیماً آن را پس بگیرید، اگرچه در اصل شما می‌توانید
        ماموران جمع‌آوری بدهی را برای بازیابی پول ارسال کنید اگر حساب
        <em>overdrawn</em> بوده باشد و مشتری حاضر به بازپرداخت آن
        نباشد.
    </p>
<p>
        این‌که آیا هزینه‌ی عذرخواهی قابل قبول است، یک تصمیم تجاری
        است. اگر قابل قبول باشد، مدل سنتی بررسی همه‌ی محدودیت‌ها قبل
        از این‌که داده‌ها را بنویسید، به‌طور غیرضروری محدودکننده است،
        و یک <strong>linearizable constraint</strong> مورد نیاز نیست. ممکن
        است یک انتخاب منطقی باشد که با یک <strong>write</strong> <em>optimistically</em>
        ادامه دهیم، و <strong>constraint</strong> را پس از واقعیت بررسی
        کنیم. شما همچنان می‌توانید اطمینان حاصل کنید که <strong>validation</strong>
        قبل از انجام کارهایی که بازیابی از آن‌ها پرهزینه خواهد بود، رخ
        می‌دهد، اما این بدان معنا نیست که شما باید <strong>validation</strong> را
        قبل از این‌که حتی داده‌ها را بنویسید، انجام دهید.
    </p>
<p>
        این برنامه‌ها، درستی را طلب می‌کنند: شما نمی‌خواهید یک رزرو را از
        دست بدهید، یا این‌که پول به‌دلیل بدهی‌ها و اعتبارات <em>mismatched</em>،
        ناپدید شود. اما آن‌ها <strong>timeliness</strong> را در اجرای <strong>constraint</strong>
        نمی‌خواهند: اگر شما بیش از آن‌چه که در انبار دارید، کالا فروخته
        باشید، شما می‌توانید مشکل را پس از واقعیت با عذرخواهی برطرف
        کنید.
    </p>
<p>
        انجام این کار شبیه به رویکردهای <strong>conflict resolution</strong> است که
        ما در "مدیریت تضادهای <strong>Write</strong>" در صفحه 171 بحث
        کردیم.
    </p>
<h4>سیستم‌های داده‌ای که از هماهنگی اجتناب می‌کنند</h4>
<p>
        ما اکنون دو مشاهده‌ی جالب را انجام داده‌ایم:
    </p>
<ol>
<li>
            سیستم‌های <strong>dataflow</strong> می‌توانند تضمین‌های <strong>integrity</strong>
            را در مورد داده‌های مشتق شده بدون <strong>atomic commit</strong>،
            <strong>linearizability</strong>، یا هماهنگی <em>cross-partition
            synchronous</em> حفظ کنند.
        </li>
<li>
            اگرچه <strong>uniqueness constraints</strong> دقیق نیازمند
            <strong>timeliness</strong> و هماهنگی هستند، بسیاری از
            برنامه‌ها در واقع با محدودیت‌های آزاد که ممکن است موقتاً
            نقض شوند و بعداً اصلاح شوند، خوب هستند، تا زمانی‌که
            <strong>integrity</strong> در سراسر حفظ شود.
            هدف قرار دادن درستی
            |
            527
        </li>
</ol>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0549</div>
            </div>
        </div>
        <!-- Page 0550 -->
        <div class="chapter" id="page-0550">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        در کنار هم، این مشاهدات به این معنی است که سیستم‌های <strong>dataflow</strong>
        می‌توانند خدمات مدیریت داده را برای بسیاری از برنامه‌ها بدون نیاز
        به هماهنگی، ارائه دهند، در حالی‌که همچنان تضمین‌های <strong>integrity</strong>
        قوی را ارائه می‌دهند. چنین سیستم‌های داده‌ای که از هماهنگی اجتناب
        می‌کنند، جذابیت زیادی دارند: آن‌ها می‌توانند عملکرد و تحمل خطای
        بهتری نسبت به سیستم‌هایی که نیاز به انجام هماهنگی <em>synchronous</em>
        دارند، به‌دست آورند [56].
    </p>
<p>
        به عنوان مثال، چنین سیستمی می‌تواند به‌صورت توزیع شده در
        چندین <strong>datacenter</strong> در یک پیکربندی چند <strong>leader</strong>
        عمل کند، که به‌صورت <em>asynchronously</em> بین مناطق <strong>replicating</strong>
        می‌کند. هر <strong>datacenter</strong> می‌تواند به‌طور مستقل از سایرین
        به‌عملکرد خود ادامه دهد، زیرا هیچ هماهنگی <em>cross-region
        synchronous</em> مورد نیاز نیست. چنین سیستمی تضمین‌های
        <strong>timeliness</strong> ضعیفی خواهد داشت—نمی‌توانست بدون
        معرفی هماهنگی <em>linearizable</em> باشد—اما همچنان می‌تواند
        تضمین‌های <strong>integrity</strong> قوی داشته باشد.
    </p>
<p>
        در این <strong>context</strong>، تراکنش‌های <em>serializable</em> همچنان به‌عنوان
        بخشی از حفظ <strong>state</strong> مشتق شده، مفید هستند، اما آن‌ها
        می‌توانند در یک محدوده‌ی کوچک اجرا شوند که در آن خوب عمل
        می‌کنند [8]. تراکنش‌های توزیع شده ناهمگن مانند تراکنش‌های <strong>XA</strong>
        (نگاه کنید به "تراکنش‌های توزیع شده در عمل" در صفحه 360) مورد
        نیاز نیستند. هماهنگی <em>synchronous</em> همچنان می‌تواند در مکان‌هایی
        که مورد نیاز است معرفی شود (به عنوان مثال، برای اعمال
        محدودیت‌های سخت قبل از یک عملیات که بازیابی از آن امکان‌پذیر
        نیست)، اما نیازی نیست که همه‌چیز هزینه‌ی هماهنگی را پرداخت
        کند اگر تنها بخش کوچکی از یک برنامه به آن نیاز داشته باشد [43].
    </p>
<p>
        یک راه دیگر برای نگاه کردن به هماهنگی و محدودیت‌ها: آن‌ها تعداد
        عذرخواهی‌هایی را که شما باید به‌دلیل ناسازگاری‌ها انجام دهید را
        کاهش می‌دهند، اما به‌طور بالقوه عملکرد و در دسترس بودن سیستم
        شما را نیز کاهش می‌دهند، و بنابراین به‌طور بالقوه تعداد
        عذرخواهی‌هایی که شما باید به‌دلیل قطعی‌ها انجام دهید را
        افزایش می‌دهند. شما نمی‌توانید تعداد عذرخواهی‌ها را به صفر
        برسانید، اما شما می‌توانید هدف خود را پیدا کردن بهترین
        <strong>trade-off</strong> برای نیازهای خود قرار دهید—نقطه‌ی مطلوب
        که در آن نه ناسازگاری‌های زیادی وجود دارد و نه مشکلات در
        دسترسی.
    </p>
<h4>اعتماد کنید، اما تأیید کنید</h4>
<p>
        تمام بحث‌های ما در مورد درستی، <strong>integrity</strong>، و تحمل خطا
        تحت این فرض بوده است که چیزهای خاصی ممکن است اشتباه
        پیش بروند، اما چیزهای دیگر این‌طور نخواهند بود. ما این
        فرضیات را مدل سیستم خود می‌نامیم (نگاه کنید به "<strong>Mapping</strong>
        مدل‌های سیستم به دنیای واقعی" در صفحه 309): به عنوان مثال،
        ما باید فرض کنیم که فرآیندها می‌توانند <strong>crash</strong> کنند،
        ماشین‌ها می‌توانند ناگهان برق خود را از دست بدهند، و شبکه
        می‌تواند پیام‌ها را به‌طور دلخواه به تأخیر بیندازد یا <em>drop</em>
        کند. اما ما همچنین ممکن است فرض کنیم که داده‌هایی که روی
        دیسک نوشته می‌شوند، پس از <strong>fsync</strong> از دست نمی‌روند، که
        داده‌ها در حافظه خراب نمی‌شوند، و دستورالعمل ضرب <strong>CPU</strong>
        ما همیشه نتیجه‌ی درستی را برمی‌گرداند.
    </p>
<p>
        این فرضیات کاملاً منطقی هستند، زیرا آن‌ها بیشتر مواقع درست
        هستند، و اگر ما مجبور بودیم که دائماً نگران اشتباهات کامپیوترهای
        خود باشیم، انجام هر کاری دشوار می‌شد. به‌طور سنتی، مدل‌های
        سیستم یک رویکرد باینری به سمت <strong>faults</strong> در پیش
        می‌گیرند: ما فرض می‌کنیم که برخی از چیزها می‌توانند اتفاق
        بیفتند، و چیزهای دیگر هرگز نمی‌توانند اتفاق بیفتند.
    </p>
<p>
        در واقعیت، این بیشتر یک مسئله‌ی احتمالات است: برخی از
        چیزها محتمل‌تر هستند، دیگر
        528
        |
        فصل 12: آینده‌ی سیستم‌های داده
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0550</div>
            </div>
        </div>
        <!-- Page 0551 -->
        <div class="chapter" id="page-0551">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
        چیزهایی کمتر محتمل هستند. این سوال پیش می‌آید که آیا نقض
        فرضیات ما به‌اندازه‌ی کافی اتفاق می‌افتد که ما ممکن است در عمل با
        آن‌ها مواجه شویم.
    </p>
<p>
        ما دیده‌ایم که داده‌ها می‌توانند در حالی‌که روی دیسک‌ها دست
        نخورده هستند، خراب شوند (نگاه کنید به "<strong>Replication</strong> و
        <strong>Durability</strong>" در صفحه 227)، و فساد داده‌ها در شبکه
        گاهی اوقات می‌تواند از <strong>checksums TCP</strong> فرار کند (نگاه کنید
        به "اشکال‌های ضعیف دروغ" در صفحه 306).
        شاید این چیزی است که ما باید توجه بیشتری به آن داشته باشیم؟
    </p>
<p>
        یک برنامه که من در گذشته روی آن کار می‌کردم، گزارش‌های <strong>crash</strong>
        را از <strong>clients</strong> جمع‌آوری می‌کرد، و برخی از گزارش‌هایی که
        ما دریافت کردیم، فقط با <em>bit-flips</em> تصادفی در حافظه‌ی آن
        دستگاه‌ها قابل توضیح بودند. این غیرمحتمل به‌نظر می‌رسد، اما اگر
        شما دستگاه‌های کافی برای اجرای نرم‌افزار خود داشته باشید، حتی
        چیزهای بسیار بعید نیز اتفاق می‌افتند. علاوه بر فساد حافظه‌ی
        تصادفی به‌دلیل خطاهای سخت‌افزاری یا تشعشعات، الگوهای دسترسی
        به حافظه خاصی می‌توانند بیت‌ها را حتی در حافظه‌ای که هیچ <strong>fault</strong>
        ای ندارد، تغییر دهند [62]—اثری که می‌تواند برای شکستن
        مکانیسم‌های امنیتی در سیستم‌های عامل استفاده شود [63] (این
        تکنیک به‌عنوان <strong>rowhammer</strong> شناخته می‌شود). هنگامی که شما
        از نزدیک نگاه می‌کنید، سخت‌افزار یک <strong>abstraction</strong> کاملاً
        بی‌نقص نیست که ممکن است به‌نظر برسد.
    </p>
<p>
        واضح بگویم، <em>bit-flips</em> تصادفی همچنان در سخت‌افزار مدرن بسیار
        نادر هستند [64]. من فقط می‌خواهم اشاره کنم که آن‌ها خارج از
        قلمرو امکان نیستند، و بنابراین سزاوار توجه هستند.
    </p>
<h4>حفظ <strong>integrity</strong> در مواجهه با <strong>software bugs</strong></h4>
<p>
        علاوه بر چنین مسائل سخت‌افزاری، همیشه خطر <strong>software bugs</strong>
        وجود دارد، که توسط <strong>checksums</strong> سطح پایین‌تر شبکه، حافظه،
        یا سیستم فایل‌ها، شناسایی نمی‌شوند. حتی نرم‌افزارهای پایگاه
        داده‌ی پرکاربرد نیز <strong>bugs</strong> دارند: من شخصاً مواردی از <strong>MySQL</strong>
        را دیده‌ام که در حفظ صحیح یک <strong>uniqueness constraint</strong> شکست
        می‌خورد [65] و سطح <em>isolation</em> <em>serializable</em> از
        <strong>PostgreSQL</strong>، <em>anomalies write skew</em> را نشان می‌دهد [66]،
        حتی اگر <strong>MySQL</strong> و <strong>PostgreSQL</strong> پایگاه‌های داده‌ای
        <strong>robust</strong> و مورد احترام هستند که توسط افراد زیادی برای
        سال‌های زیادی مورد آزمایش قرار گرفته‌اند. در نرم‌افزارهای کم‌تر
        بالغ، وضعیت احتمالاً بسیار بدتر است.
    </p>
<p>
        با وجود تلاش‌های قابل توجه در طراحی دقیق، آزمایش و بررسی،
        <strong>bugs</strong> همچنان رخ می‌دهند. اگرچه آن‌ها نادر هستند، و در
        نهایت پیدا و اصلاح می‌شوند، هنوز یک دوره‌ای وجود دارد که در
        طول آن چنین <strong>bugs</strong> می‌توانند داده‌ها را خراب
        کنند.
    </p>
<p>
        وقتی نوبت به کد برنامه می‌رسد، ما باید <strong>bugs</strong> های بیشتری را
        فرض کنیم، از آن‌جایی‌که اکثر برنامه‌ها به اندازه‌ی کافی نزدیک به
        مقدار بررسی و آزمایشی که کد پایگاه داده دریافت می‌کند، دریافت
        نمی‌کنند. بسیاری از برنامه‌ها حتی از <strong>features</strong> که پایگاه‌های
        داده برای حفظ <strong>integrity</strong> ارائه می‌دهند، مانند محدودیت‌های
        کلید خارجی یا <strong>uniqueness</strong> به‌درستی استفاده نمی‌کنند
        [36].
    </p>
<p>
<strong>Consistency</strong> در معنای <strong>ACID</strong> (نگاه کنید به
        "<strong>Consistency</strong>" در صفحه 224) بر اساس این ایده است
        که پایگاه داده از یک <strong>state</strong> <em>consistent</em> شروع می‌شود،
        و یک تراکنش آن را از یک <strong>state</strong> <em>consistent</em> به
        دیگری تبدیل می‌کند. بنابراین، ما انتظار داریم که پایگاه داده
        همیشه در یک وضعیت <em>consistent</em> باشد. با این حال، این مفهوم
        تنها در صورتی منطقی است که شما فرض کنید که تراکنش از
        <strong>bugs</strong> عاری است. اگر برنامه، پایگاه داده را به‌درستی
        استفاده نکند
        هدف قرار دادن درستی
        |
        529
    </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0551</div>
            </div>
        </div>
        <!-- Page 0552 -->
        <div class="chapter" id="page-0552">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<h3>فرهنگ بررسی و اعتبار سنجی</h3>
<p>به نحوی، برای مثال با استفاده از یک سطح ایزوله‌سازی ضعیف به صورت ناامن، یکپارچگی 
   <strong>database</strong>
   را نمی‌توان تضمین کرد.</p>
<p>فقط کورکورانه به آنچه قول می‌دهند اعتماد نکنید.</p>
<p>با توجه به اینکه هم <strong>hardware</strong> و هم <strong>software</strong> همیشه در حد ایده‌آلی که می‌خواهیم نیستند، به نظر می‌رسد که 
   <strong>data corruption</strong>
   دیر یا زود اجتناب‌ناپذیر است. بنابراین، ما باید حداقل راهی برای فهمیدن اینکه آیا 
   <strong>data</strong>
   خراب شده است یا خیر، داشته باشیم تا بتوانیم آن را تعمیر کرده و منبع خطا را ردیابی کنیم. بررسی یکپارچگی 
   <strong>data</strong>
   به عنوان <strong>auditing</strong> شناخته می‌شود.</p>
<p>همانطور که در صفحه 460 در مورد "مزایای رویدادهای تغییرناپذیر" بحث شد، <strong>auditing</strong> فقط برای برنامه‌های مالی نیست. با این حال، <strong>auditability</strong> در امور مالی بسیار مهم است، دقیقاً به این دلیل که همه می‌دانند اشتباهات رخ می‌دهد و همه ما نیاز به توانایی تشخیص و رفع مشکلات را می‌شناسیم.</p>
<p>سیستم‌های بالغ نیز به طور مشابه تمایل دارند احتمال وقوع اتفاقات بعید را در نظر بگیرند و آن ریسک را مدیریت کنند. به عنوان مثال، سیستم‌های ذخیره‌سازی در مقیاس بزرگ مانند <strong>HDFS</strong> و <strong>Amazon S3</strong> به طور کامل به دیسک‌ها اعتماد ندارند: آنها فرآیندهای پس‌زمینه‌ای را اجرا می‌کنند که به طور مداوم فایل‌ها را دوباره می‌خوانند، آنها را با سایر نسخه‌ها مقایسه می‌کنند و فایل‌ها را از یک دیسک به دیسک دیگر منتقل می‌کنند تا خطر خراب شدن بی‌صدا را کاهش دهند [67].</p>
<p>اگر می‌خواهید مطمئن شوید که 
   <strong>data</strong>
   شما هنوز وجود دارد، باید واقعاً آن را بخوانید و بررسی کنید. بیشتر اوقات هنوز آنجا خواهد بود، اما اگر اینطور نیست، واقعاً می‌خواهید زودتر از دیرتر متوجه شوید. با همین استدلال، مهم است که گهگاه از 
   <strong>backups</strong>
   خود بازیابی کنید - در غیر این صورت ممکن است متوجه شوید که 
   <strong>backup</strong>
   شما خراب شده است، زمانی که خیلی دیر شده و شما قبلاً 
   <strong>data</strong>
   را از دست داده‌اید. فقط کورکورانه اعتماد نکنید که همه چیز درست کار می‌کند.</p>
<h4>یک فرهنگ بررسی و اعتبار سنجی</h4>
<p>سیستم‌هایی مانند 
   <strong>HDFS</strong> و <strong>S3</strong> هنوز هم باید فرض کنند که دیسک‌ها در بیشتر مواقع به درستی کار می‌کنند - که یک فرض منطقی است، اما به معنای فرض اینکه آنها همیشه به درستی کار می‌کنند، نیست. با این حال، در حال حاضر سیستم‌های زیادی این رویکرد "اعتماد کن، اما بررسی کن" خود-
   <strong>auditing</strong>
   را ندارند. بسیاری فرض می‌کنند که تضمین‌های درستی مطلق هستند و هیچ تمهیدی برای احتمال خراب شدن نادر 
   <strong>data</strong>
   در نظر نمی‌گیرند. من امیدوارم که در آینده سیستم‌های خود-اعتبارسنجی یا خود-
   <strong>auditing</strong>
   بیشتری را ببینیم که به طور مداوم یکپارچگی خود را بررسی می‌کنند، به جای اینکه به اعتماد کورکورانه متکی باشند [68].</p>
<p>من می‌ترسم که فرهنگ <strong>ACID databases</strong> ما را به سمت توسعه برنامه‌ها بر اساس اعتماد کورکورانه به فناوری (مانند یک مکانیزم 
   <strong>transaction</strong>
   ) سوق داده باشد و هر نوع <strong>auditability</strong> را در این فرآیند نادیده گرفته باشیم. از آنجایی که فناوری که به آن اعتماد داشتیم در بیشتر مواقع به اندازه کافی خوب کار می‌کرد، مکانیزم‌های 
   <strong>auditing</strong>
   ارزش سرمایه‌گذاری را نداشتند.</p>
<p>530 | فصل 12: آینده سیستم‌های 
   <strong>Data</strong>
</p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0552</div>
            </div>
        </div>
        <!-- Page 0553 -->
        <div class="chapter" id="page-0553">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>اما سپس چشم‌انداز 
   <strong>database</strong>
   تغییر کرد: تضمین‌های 
   <strong>consistency</strong>
   ضعیف‌تر تحت عنوان 
   <strong>NoSQL</strong>
   به یک هنجار تبدیل شدند و تکنولوژی‌های ذخیره‌سازی کم‌تجربه‌تر به طور گسترده مورد استفاده قرار گرفتند. با این حال، از آنجایی که مکانیزم‌های 
   <strong>audit</strong>
   توسعه نیافته بودند، ما به ساختن برنامه‌ها بر اساس اعتماد کورکورانه ادامه دادیم، حتی اگر این رویکرد اکنون خطرناک‌تر شده باشد. بیایید لحظه‌ای در مورد طراحی برای 
   <strong>auditability</strong>
   فکر کنیم.</p>
<h4>طراحی برای <strong>auditability</strong></h4>
<p>اگر یک 
   <strong>transaction</strong>
   چندین 
   <strong>object</strong>
   را در یک 
   <strong>database</strong>
   تغییر دهد، پس از آن دشوار است که بگوییم آن 
   <strong>transaction</strong>
   چه معنایی دارد. حتی اگر لاگ‌های 
   <strong>transaction</strong>
   را ثبت کنید (به "
   <strong>Change Data Capture</strong>
   " در صفحه 454 مراجعه کنید)، درج‌ها، به‌روزرسانی‌ها و حذف‌ها در جداول مختلف لزوماً تصویر روشنی از دلیل انجام این تغییرات ارائه نمی‌دهند. فراخوانی منطق برنامه که در مورد این تغییرات تصمیم گرفته است، گذرا است و نمی‌توان آن را بازتولید کرد.</p>
<p>در مقابل، سیستم‌های مبتنی بر 
   <strong>event</strong>
   می‌توانند 
   <strong>auditability</strong>
   بهتری ارائه دهند. در رویکرد 
   <strong>event sourcing</strong>
   ، ورودی کاربر به سیستم به عنوان یک 
   <strong>event</strong>
   تغییرناپذیر واحد نمایش داده می‌شود و هر به‌روزرسانی حالت حاصل از آن 
   <strong>event</strong>
   مشتق می‌شود. این اشتقاق می‌تواند قطعی و تکرارپذیر باشد، به طوری که اجرای همان لاگ 
   <strong>event</strong>
   ها از طریق همان نسخه از کد اشتقاق منجر به به‌روزرسانی‌های حالت یکسان می‌شود.</p>
<p>صریح بودن در مورد 
   <strong>dataflow</strong>
   (به "فلسفه خروجی‌های فرآیند 
   <strong>batch</strong>
   " در صفحه 413 مراجعه کنید) منشأ 
   <strong>data</strong>
   را بسیار واضح‌تر می‌کند، که بررسی یکپارچگی را بسیار راحت‌تر می‌کند. برای لاگ 
   <strong>event</strong>
   ، می‌توانیم از 
   <strong>hash</strong>
   ها برای بررسی اینکه آیا ذخیره‌سازی 
   <strong>event</strong>
   خراب نشده است، استفاده کنیم. برای هر حالت مشتق‌شده، می‌توانیم فرآیندهای 
   <strong>batch</strong>
   و 
   <strong>stream</strong>
   را که آن را از لاگ 
   <strong>event</strong>
   مشتق کرده‌اند، دوباره اجرا کنیم تا بررسی کنیم آیا به نتیجه یکسانی می‌رسیم یا حتی یک اشتقاق افزونه را به موازات اجرا کنیم.</p>
<p>یک 
   <strong>dataflow</strong>
   قطعی و خوش‌تعریف همچنین اشکال‌زدایی و ردیابی اجرای یک سیستم را آسان‌تر می‌کند تا تعیین کنیم چرا کاری انجام داده است [4، 69]. اگر اتفاق غیرمنتظره‌ای رخ داد، داشتن قابلیت تشخیصی برای بازتولید شرایط دقیقی که منجر به 
   <strong>event</strong>
   غیرمنتظره شد - نوعی قابلیت اشکال‌زدایی سفر در زمان - ارزشمند است.</p>
<h4>استدلال <strong>end-to-end</strong> دوباره</h4>
<p>اگر نتوانیم به طور کامل اعتماد کنیم که هر جزء جداگانه سیستم از خراب شدن مصون خواهد بود - اینکه هر قطعه از 
   <strong>hardware</strong>
   بدون نقص است و هر قطعه از 
   <strong>software</strong>
   بدون 
   <strong>bug</strong>
   است - پس باید حداقل به‌طور دوره‌ای یکپارچگی 
   <strong>data</strong>
   خود را بررسی کنیم. اگر بررسی نکنیم، در مورد خراب شدن چیزی متوجه نخواهیم شد تا زمانی که خیلی دیر شده باشد و باعث آسیب‌های بعدی شده باشد، که در این صورت ردیابی مشکل بسیار دشوارتر و پرهزینه‌تر خواهد بود.</p>
<p>بررسی یکپارچگی سیستم‌های 
   <strong>data</strong>
   بهترین شکل در روش 
   <strong>end-to-end</strong>
   انجام می‌شود (به "استدلال 
   <strong>End-to-End</strong>
   برای 
   <strong>Database</strong>
   " در صفحه 516 مراجعه کنید): هر چه سیستم‌های بیشتری بتوانیم ...</p>
<p><strong>Aiming for Correctness</strong> | 531</p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0553</div>
            </div>
        </div>
        <!-- Page 0554 -->
        <div class="chapter" id="page-0554">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>هرچه سیستم‌های بیشتری را بتوانیم در بررسی یکپارچگی لحاظ کنیم، فرصت‌های کمتری برای نادیده گرفتن فساد در مرحله‌ای از فرآیند وجود دارد. اگر بتوانیم بررسی کنیم که کل 
   <strong>data pipeline</strong>
   مشتق‌شده از ابتدا تا انتها درست است، در این صورت هر دیسک، شبکه، 
   <strong>service</strong>
   و الگوریتم در طول مسیر، به‌طور ضمنی در بررسی لحاظ می‌شوند.</p>
<p>داشتن بررسی‌های یکپارچگی 
   <strong>end-to-end</strong>
   مداوم، اعتماد شما را نسبت به درستی سیستم‌هایتان افزایش می‌دهد، که به نوبه خود به شما امکان می‌دهد سریع‌تر حرکت کنید [70]. مانند تست خودکار، 
   <strong>auditing</strong>
   شانس یافتن سریع 
   <strong>bug</strong>
   ها را افزایش می‌دهد و در نتیجه خطر آسیب دیدن به دلیل تغییر در سیستم یا فناوری ذخیره‌سازی جدید را کاهش می‌دهد. اگر از ایجاد تغییرات نمی‌ترسید، می‌توانید یک 
   <strong>application</strong>
   را بسیار بهتر برای پاسخگویی به نیازهای در حال تغییر، تکامل دهید.</p>
<h4>ابزارهایی برای سیستم‌های <strong>data</strong> قابل <strong>audit</strong></h4>
<p>در حال حاضر، سیستم‌های 
   <strong>data</strong>
   زیادی، 
   <strong>auditability</strong>
   را به عنوان یک نگرانی در سطح بالا در نظر نمی‌گیرند. برخی از برنامه‌ها، مکانیزم‌های 
   <strong>audit</strong>
   خود را پیاده‌سازی می‌کنند، به عنوان مثال با ثبت تمام تغییرات در یک جدول 
   <strong>audit</strong>
   جداگانه، اما تضمین یکپارچگی لاگ 
   <strong>audit</strong>
   و وضعیت 
   <strong>database</strong>
   هنوز دشوار است. یک لاگ 
   <strong>transaction</strong>
   را می‌توان با امضای دوره‌ای آن با یک 
   <strong>hardware security module</strong>
   ، غیرقابل دستکاری کرد، اما این تضمین نمی‌کند که 
   <strong>transaction</strong>
   های صحیح در وهله اول وارد لاگ شده باشند.</p>
<p>استفاده از ابزارهای رمزنگاری برای اثبات یکپارچگی یک سیستم به گونه‌ای که در برابر طیف وسیعی از مسائل 
   <strong>hardware</strong>
   و 
   <strong>software</strong>
   مقاوم باشد و حتی اقدامات بالقوه مخرب جالب خواهد بود. ارزهای رمزنگاری شده، 
   <strong>blockchains</strong>
   و فناوری‌های دفتر کل توزیع‌شده مانند 
   <strong>Bitcoin, Ethereum, Ripple, Stellar</strong>
   و موارد دیگر [71, 72, 73] برای بررسی این حوزه ظهور کرده‌اند.</p>
<p>من صلاحیت اظهار نظر در مورد مزایای این فناوری‌ها به عنوان ارز یا مکانیزم‌هایی برای توافق‌نامه‌ها را ندارم. با این حال، از دیدگاه سیستم‌های 
   <strong>data</strong>
   ، آنها حاوی ایده‌های جالبی هستند. اساساً، آنها 
   <strong>databases</strong>
   توزیع‌شده‌ای هستند، با یک مدل 
   <strong>data</strong>
   و مکانیزم 
   <strong>transaction</strong>
   ، که در آن 
   <strong>replica</strong>
   های مختلف می‌توانند توسط سازمان‌های غیرقابل اعتماد متقابل میزبانی شوند. 
   <strong>replica</strong>
   ها به‌طور مداوم یکپارچگی یکدیگر را بررسی می‌کنند و از یک پروتکل 
   <strong>consensus</strong>
   برای توافق بر روی 
   <strong>transaction</strong>
   هایی که باید اجرا شوند، استفاده می‌کنند.</p>
<p>من تا حدودی نسبت به جنبه‌های تحمل خطای 
   <strong>Byzantine</strong>
   این فناوری‌ها شک دارم (به "خطاهای 
   <strong>Byzantine</strong>
   " در صفحه 304 مراجعه کنید)، و تکنیک اثبات کار (به عنوان مثال، 
   <strong>Bitcoin mining</strong>
   ) را فوق‌العاده اتلاف‌آمیز می‌دانم. توان عملیاتی 
   <strong>transaction</strong>
   بیت کوین نسبتاً کم است، اگرچه به دلایل سیاسی و اقتصادی بیشتر از دلایل فنی. با این حال، جنبه‌های بررسی یکپارچگی جالب هستند.</p>
<p>
<strong>Auditing</strong>
   رمزنگاری و بررسی یکپارچگی اغلب به 
   <strong>Merkle trees</strong>
   [74] متکی است، که درختانی از 
   <strong>hash</strong>
   ها هستند که می‌توان از آنها برای اثبات کارآمد این که یک رکورد در برخی از مجموعه داده‌ها ظاهر می‌شود (و چند چیز دیگر) استفاده کرد. در خارج از هیاهوی ارزهای رمزنگاری شده، شفافیت گواهی یک فناوری امنیتی است که برای بررسی اعتبار گواهی‌های 
   <strong>TLS/SSL</strong>
   به 
   <strong>Merkle trees</strong>
   متکی است [75, 76].</p>
<p>532 | فصل 12: آینده سیستم‌های 
   <strong>Data</strong>
</p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0554</div>
            </div>
        </div>
        <!-- Page 0555 -->
        <div class="chapter" id="page-0555">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>من می‌توانم تصور کنم که الگوریتم‌های بررسی و 
   <strong>auditing</strong>
   یکپارچگی، مانند موارد شفافیت گواهی و دفاتر کل توزیع‌شده، به طور کلی در سیستم‌های 
   <strong>data</strong>
   بیشتر مورد استفاده قرار می‌گیرند. مقداری کار برای مقیاس‌پذیری یکسان آنها با سیستم‌های بدون 
   <strong>auditing</strong>
   رمزنگاری و پایین نگه داشتن جریمه عملکرد مورد نیاز است. اما من فکر می‌کنم این یک حوزه جالب برای پیگیری در آینده است.</p>
<h4>انجام کار درست</h4>
<p>در بخش پایانی این کتاب، می‌خواهم یک قدم به عقب بردارم. در طول این کتاب، ما طیف گسترده‌ای از معماری‌های مختلف برای سیستم‌های 
   <strong>data</strong>
   را بررسی کرده‌ایم، مزایا و معایب آنها را ارزیابی کرده‌ایم و تکنیک‌هایی را برای ساخت برنامه‌های قابل اعتماد، مقیاس‌پذیر و قابل نگهداری بررسی کرده‌ایم. با این حال، ما یک بخش مهم و اساسی از بحث را حذف کرده‌ایم، که اکنون می‌خواهم آن را پر کنم.</p>
<p>هر سیستم برای هدفی ساخته شده است؛ هر اقدامی که انجام می‌دهیم، عواقب مورد نظر و ناخواسته را دارد. هدف ممکن است به سادگی کسب درآمد باشد، اما عواقب آن برای جهان ممکن است فراتر از آن هدف اصلی باشد. ما، مهندسانی که این سیستم‌ها را می‌سازیم، وظیفه داریم این عواقب را با دقت در نظر بگیریم و آگاهانه تصمیم بگیریم که می‌خواهیم در چه نوع دنیایی زندگی کنیم.</p>
<p>ما در مورد 
   <strong>data</strong>
   به عنوان یک چیز انتزاعی صحبت می‌کنیم، اما به یاد داشته باشید که بسیاری از مجموعه داده‌ها در مورد مردم هستند: رفتار، علایق و هویت آنها. ما باید با چنین 
   <strong>data</strong>
   ای با انسانیت و احترام رفتار کنیم. کاربران نیز انسان هستند و کرامت انسانی از اهمیت بالایی برخوردار است.</p>
<p>توسعه 
   <strong>software</strong>
   به طور فزاینده‌ای شامل اتخاذ انتخاب‌های اخلاقی مهم است. دستورالعمل‌هایی برای کمک به مهندسان 
   <strong>software</strong>
   در پیمایش این مسائل وجود دارد، مانند 
   <strong>Software Engineering Code of Ethics and Professional Practice</strong>
   از 
   <strong>ACM</strong>
   [77]، اما آنها به ندرت مورد بحث، اجرا و اعمال قرار می‌گیرند. در نتیجه، مهندسان و مدیران محصول گاهی اوقات نگرش بسیار بی‌احتیاطی نسبت به حریم خصوصی و عواقب منفی احتمالی محصولات خود دارند [78, 79, 80].</p>
<p>یک فناوری فی نفسه خوب یا بد نیست - آنچه مهم است نحوه استفاده از آن و تأثیر آن بر مردم است. این در مورد یک سیستم 
   <strong>software</strong>
   مانند یک موتور جستجو به همان روشی صادق است که در مورد یک سلاح مانند اسلحه. من فکر می‌کنم برای مهندسان 
   <strong>software</strong>
   کافی نیست که منحصراً بر فناوری تمرکز کنند و عواقب آن را نادیده بگیرند: مسئولیت اخلاقی نیز بر عهده ماست. استدلال در مورد اخلاقیات دشوار است، اما نادیده گرفتن آن بسیار مهم است.</p>
<h4>تجزیه و تحلیل پیش‌بینی‌کننده</h4>
<p>به عنوان مثال، 
   <strong>predictive analytics</strong>
   بخش عمده‌ای از تبلیغات "
   <strong>Big Data</strong>
   " است. استفاده از تجزیه و تحلیل 
   <strong>data</strong>
   برای پیش‌بینی آب و هوا یا شیوع بیماری‌ها یک چیز است [81]؛ پیش‌بینی اینکه آیا یک مجرم احتمالاً دوباره مرتکب جرم می‌شود، آیا یک متقاضی وام احتمالاً 
   <strong>default</strong>
   می‌کند، یا اینکه آیا یک مشتری بیمه احتمالاً ادعاهای پرهزینه‌ای را مطرح می‌کند، موضوع دیگری است. دومی تأثیر مستقیمی بر زندگی افراد دارد.</p>
<p>
<strong>Doing the Right Thing</strong> | 533
  </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0555</div>
            </div>
        </div>
        <!-- Page 0556 -->
        <div class="chapter" id="page-0556">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>به طور طبیعی، شبکه‌های پرداخت می‌خواهند از تراکنش‌های تقلبی جلوگیری کنند، بانک‌ها می‌خواهند از وام‌های بد اجتناب کنند، خطوط هوایی می‌خواهند از هواپیماربایی جلوگیری کنند و شرکت‌ها می‌خواهند از استخدام افراد بی‌اثر یا غیرقابل اعتماد جلوگیری کنند. از دیدگاه آنها، هزینه یک فرصت تجاری از دست رفته کم است، اما هزینه یک وام بد یا یک کارمند مسئله‌دار بسیار بیشتر است، بنابراین برای سازمان‌ها طبیعی است که بخواهند محتاط باشند. در صورت تردید، بهتر است بگویند نه.</p>
<p>با این حال، با گسترش تصمیم‌گیری الگوریتمی، فردی که (به‌درستی یا نادرست) توسط برخی از الگوریتم‌ها به عنوان خطرناک برچسب‌گذاری شده است، ممکن است از تعداد زیادی از آن تصمیمات "نه" رنج ببرد. حذف سیستماتیک از مشاغل، سفرهای هوایی، پوشش بیمه، اجاره املاک، خدمات مالی و سایر جنبه‌های کلیدی جامعه، محدودیتی بزرگ برای آزادی فرد است که "زندان الگوریتمی" [82] نامیده شده است. در کشورهایی که به حقوق بشر احترام می‌گذارند، سیستم عدالت کیفری بی‌گناهی را تا زمان اثبات جرم فرض می‌کند. از سوی دیگر، سیستم‌های خودکار می‌توانند یک فرد را بدون هیچ مدرکی دال بر گناه و با فرصت کمی برای تجدید نظر، به‌طور سیستماتیک و خودسرانه از مشارکت در جامعه محروم کنند.</p>
<h4>سوگیری و تبعیض</h4>
<p>تصمیمات اتخاذ شده توسط یک الگوریتم لزوماً بهتر یا بدتر از تصمیمات اتخاذ شده توسط یک انسان نیست. هر فرد احتمالاً دارای سوگیری‌هایی است، حتی اگر فعالانه سعی در مقابله با آنها داشته باشد، و اقدامات تبعیض‌آمیز می‌تواند به طور فرهنگی نهادینه شود. این امید وجود دارد که تصمیم‌گیری بر اساس داده‌ها، به جای ارزیابی‌های ذهنی و غریزی توسط مردم، می‌تواند منصفانه‌تر باشد و شانس بهتری را به افرادی بدهد که اغلب در سیستم سنتی نادیده گرفته می‌شوند [83].</p>
<p>هنگامی که ما سیستم‌های 
   <strong>predictive analytics</strong>
   را توسعه می‌دهیم، ما صرفاً در حال خودکارسازی تصمیم یک انسان با استفاده از 
   <strong>software</strong>
   برای تعیین قوانینی برای زمان گفتن بله یا نه نیستیم. ما حتی قوانین را به خودی خود واگذار می‌کنیم تا از 
   <strong>data</strong>
   استنباط شوند. با این حال، الگوهای آموخته شده توسط این سیستم‌ها مبهم هستند: حتی اگر همبستگی‌هایی در 
   <strong>data</strong>
   وجود داشته باشد، ممکن است ندانیم چرا. اگر در ورودی یک الگوریتم سوگیری سیستماتیک وجود داشته باشد، به احتمال زیاد سیستم آن سوگیری را در خروجی خود یاد می‌گیرد و تقویت می‌کند [84].</p>
<p>در بسیاری از کشورها، قوانین ضد تبعیض، رفتار متفاوت با مردم را بسته به ویژگی‌های محافظت‌شده مانند قومیت، سن، جنسیت، گرایش جنسی، ناتوانی یا عقاید ممنوع می‌کند. ویژگی‌های دیگر 
   <strong>data</strong>
   یک فرد ممکن است تجزیه و تحلیل شود، اما اگر با ویژگی‌های محافظت‌شده مرتبط شوند، چه اتفاقی می‌افتد؟ به عنوان مثال، در محله‌های جدا شده نژادی، کد پستی یا حتی آدرس 
   <strong>IP</strong>
   یک فرد، پیش‌بینی‌کننده قوی نژاد است.</p>
<p>با این حال، این باور اغلب توسط طرفداران تصمیم‌گیری مبتنی بر 
   <strong>data</strong>
   به نظر می‌رسد، نگرشی که به عنوان "یادگیری ماشینی مانند پول‌شویی برای سوگیری است" [86] هجو شده است. سیستم‌های 
   <strong>predictive analytics</strong>
   صرفاً از گذشته برون‌یابی می‌کنند؛ اگر گذشته تبعیض‌آمیز باشد، آن تبعیض را کدگذاری می‌کنند. اگر می‌خواهیم آینده بهتر از ...</p>
<p>534 | فصل 12: آینده سیستم‌های 
   <strong>Data</strong>
</p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0556</div>
            </div>
        </div>
        <!-- Page 0557 -->
        <div class="chapter" id="page-0557">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>گذشته، تخیل اخلاقی مورد نیاز است، و این چیزی است که فقط انسان‌ها می‌توانند ارائه دهند [87]. داده‌ها و مدل‌ها باید ابزارهای ما باشند، نه اربابان ما.</p>
<h4>مسئولیت و پاسخگویی</h4>
<p>تصمیم‌گیری خودکار، سوال مسئولیت و پاسخگویی را مطرح می‌کند [87]. اگر یک انسان اشتباه کند، می‌توان او را پاسخگو دانست و فردی که تحت تأثیر تصمیم قرار گرفته است می‌تواند درخواست تجدید نظر کند. الگوریتم‌ها نیز اشتباه می‌کنند، اما اگر اشتباه پیش بروند، چه کسی پاسخگو است [88]؟ وقتی یک خودروی خودران باعث تصادف می‌شود، چه کسی مسئول است؟ اگر یک الگوریتم امتیازدهی اعتباری خودکار به‌طور سیستماتیک علیه مردم یک نژاد یا مذهب خاص تبعیض قائل شود، آیا هیچ راه حلی وجود دارد؟ اگر تصمیمی توسط سیستم یادگیری ماشینی شما مورد بررسی قضایی قرار گرفت، آیا می‌توانید به قاضی توضیح دهید که چگونه الگوریتم تصمیم خود را گرفته است؟</p>
<p>آژانس‌های رتبه‌بندی اعتباری یک مثال قدیمی از جمع‌آوری 
   <strong>data</strong>
   برای تصمیم‌گیری در مورد مردم هستند. یک امتیاز اعتباری بد، زندگی را دشوار می‌کند، اما حداقل یک امتیاز اعتباری معمولاً بر اساس حقایق مربوط به سابقه وام‌گیری واقعی یک فرد است و هرگونه خطایی در سوابق می‌تواند اصلاح شود (اگرچه آژانس‌ها معمولاً این کار را آسان نمی‌کنند). با این حال، الگوریتم‌های امتیازدهی مبتنی بر یادگیری ماشینی به‌طور معمول از طیف وسیع‌تری از ورودی‌ها استفاده می‌کنند و بسیار مبهم‌تر هستند و درک چگونگی اتخاذ یک تصمیم خاص و اینکه آیا با کسی به روشی ناعادلانه یا تبعیض‌آمیز رفتار می‌شود یا خیر را دشوارتر می‌کند [89].</p>
<p>یک امتیاز اعتباری خلاصه می‌کند "شما در گذشته چگونه رفتار کردید؟" در حالی که 
   <strong>predictive analytics</strong>
   معمولاً بر اساس "چه کسی شبیه شما است، و افرادی مانند شما در گذشته چگونه رفتار کردند؟" کار می‌کند. ترسیم موازی با رفتار دیگران، به معنای کلیشه‌ای کردن مردم است، به عنوان مثال بر اساس جایی که زندگی می‌کنند (یک پراکسی نزدیک برای نژاد و طبقه اجتماعی-اقتصادی). در مورد افرادی که در سطل اشتباه قرار می‌گیرند، چه می‌شود؟ علاوه بر این، اگر تصمیمی به دلیل 
   <strong>data</strong>
   نادرست نادرست باشد، راه حل تقریباً غیرممکن است [87].</p>
<p>بسیاری از 
   <strong>data</strong>
   ها ماهیت آماری دارند، به این معنی که حتی اگر توزیع احتمال در کل درست باشد، موارد فردی ممکن است اشتباه باشند. به عنوان مثال، اگر میانگین امید به زندگی در کشور شما 80 سال است، این بدان معنا نیست که انتظار می‌رود در تولد 80 سالگی خود به ناگاه بمیرید. از میانگین و توزیع احتمال، نمی‌توانید چیز زیادی در مورد سنی که یک فرد خاص در آن زندگی خواهد کرد، بگویید. به طور مشابه، خروجی یک سیستم پیش‌بینی احتمالی است و ممکن است در موارد فردی اشتباه باشد.</p>
<p>یک باور کورکورانه به برتری 
   <strong>data</strong>
   برای تصمیم‌گیری نه تنها توهم‌آمیز است، بلکه به طور مثبت خطرناک است. با گسترش تصمیم‌گیری مبتنی بر 
   <strong>data</strong>
   ، باید دریابیم که چگونه الگوریتم‌ها را پاسخگو و شفاف کنیم، چگونه از تقویت سوگیری‌های موجود اجتناب کنیم و چگونه آنها را هنگامی که اجتناب‌ناپذیر مرتکب اشتباه می‌شوند، برطرف کنیم.</p>
<p>همچنین باید دریابیم که چگونه از 
   <strong>data</strong>
   برای آسیب رساندن به مردم جلوگیری کنیم و در عوض، پتانسیل مثبت آن را محقق کنیم. به عنوان مثال، 
   <strong>analytics</strong>
   می‌تواند مالی و ... را نشان دهد.</p>
<p>
<strong>Doing the Right Thing</strong> | 535
  </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0557</div>
            </div>
        </div>
        <!-- Page 0558 -->
        <div class="chapter" id="page-0558">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>ویژگی‌های اجتماعی زندگی مردم. از یک سو، این قدرت می‌تواند برای متمرکز کردن کمک‌ها و حمایت‌ها برای کمک به افرادی که بیشتر به آن نیاز دارند، استفاده شود. از سوی دیگر، گاهی اوقات توسط مشاغل سودجو برای شناسایی افراد آسیب‌پذیر و فروش محصولات پرخطر مانند وام‌های پرهزینه و مدارک دانشگاهی بی‌ارزش استفاده می‌شود [87، 90].</p>
<h4>حلقه‌های بازخورد</h4>
<p>حتی با برنامه‌های پیش‌بینی‌کننده‌ای که تأثیرات کمتری بر مردم دارند، مانند سیستم‌های توصیه‌گر، مسائل دشواری وجود دارد که باید با آنها مقابله کنیم. وقتی خدمات در پیش‌بینی محتوایی که کاربران می‌خواهند ببینند، خوب می‌شوند، ممکن است فقط نظراتی را به مردم نشان دهند که قبلاً با آنها موافق هستند، که منجر به اتاق‌های تکراری می‌شود که در آنها کلیشه‌ها، اطلاعات نادرست و قطبی شدن می‌تواند تکثیر شود. ما در حال حاضر تأثیر اتاق‌های تکراری رسانه‌های اجتماعی را بر کمپین‌های انتخاباتی می‌بینیم [91].</p>
<p>وقتی 
   <strong>predictive analytics</strong>
   بر زندگی مردم تأثیر می‌گذارد، مشکلات به‌ویژه مخربی به دلیل حلقه‌های بازخورد خودتقویت‌کننده ایجاد می‌شود. به عنوان مثال، مورد کارفرمایانی را در نظر بگیرید که از امتیازات اعتباری برای ارزیابی استخدام‌های بالقوه استفاده می‌کنند. ممکن است شما یک کارگر خوب با یک امتیاز اعتباری خوب باشید، اما ناگهان خود را به دلیل یک بدبختی خارج از کنترل خود در مشکلات مالی می‌یابید. همانطور که پرداخت‌های خود را در قبوض از دست می‌دهید، امتیاز اعتباری شما آسیب می‌بیند و احتمال کمتری وجود دارد که کار پیدا کنید. بی‌کاری شما را به سمت فقر سوق می‌دهد، که بیشتر امتیازات شما را بدتر می‌کند، و یافتن اشتغال را دشوارتر می‌کند [87]. این یک مارپیچ نزولی است که به دلیل فرض‌های سمی، در پشت یک استتار از دقت ریاضی و 
   <strong>data</strong>
   پنهان شده است.</p>
<p>ما همیشه نمی‌توانیم پیش‌بینی کنیم که چه زمانی چنین حلقه‌های بازخوردی رخ می‌دهد. با این حال، بسیاری از عواقب را می‌توان با تفکر در مورد کل سیستم (نه فقط قسمت‌های رایانه‌ای، بلکه افرادی که با آن تعامل دارند) پیش‌بینی کرد - رویکردی که به عنوان تفکر سیستمی شناخته می‌شود [92]. ما می‌توانیم سعی کنیم بفهمیم که چگونه یک سیستم تجزیه و تحلیل 
   <strong>data</strong>
   به رفتارهای، ساختارها یا ویژگی‌های مختلف پاسخ می‌دهد. آیا سیستم تفاوت‌های موجود بین مردم را تقویت و بزرگ می‌کند (به عنوان مثال، ثروتمندان را ثروتمندتر یا فقرا را فقیرتر می‌کند)، یا سعی می‌کند با بی‌عدالتی مبارزه کند؟ و حتی با بهترین نیات، باید از عواقب ناخواسته بر حذر باشیم.</p>
<h4>حریم خصوصی و ردیابی</h4>
<p>علاوه بر مشکلات 
   <strong>predictive analytics</strong>
   - یعنی استفاده از 
   <strong>data</strong>
   برای تصمیم‌گیری خودکار در مورد مردم - مشکلات اخلاقی با جمع‌آوری 
   <strong>data</strong>
   خود وجود دارد. رابطه بین سازمان‌هایی که 
   <strong>data</strong>
   را جمع‌آوری می‌کنند و مردمی که 
   <strong>data</strong>
   آنها جمع‌آوری می‌شود، چیست؟</p>
<p>وقتی سیستمی فقط 
   <strong>data</strong>
   ای را ذخیره می‌کند که یک کاربر صراحتاً وارد کرده است، زیرا آنها می‌خواهند سیستم آن را به روشی خاص ذخیره و پردازش کند، سیستم در حال انجام یک 
   <strong>service</strong>
   برای کاربر است: کاربر، مشتری است. اما هنگامی که فعالیت کاربر به عنوان یک عارضه جانبی از کارهای دیگری که انجام می‌دهند ردیابی و ثبت می‌شود، رابطه کمتر مشخص است. این 
   <strong>service</strong>
   ...</p>
<p>536 | فصل 12: آینده سیستم‌های 
   <strong>Data</strong>
</p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0558</div>
            </div>
        </div>
        <!-- Page 0559 -->
        <div class="chapter" id="page-0559">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>دیگر فقط آنچه کاربر به آن می‌گوید را انجام نمی‌دهد، بلکه منافع خاص خود را در پیش می‌گیرد، که ممکن است با منافع کاربر در تضاد باشد.</p>
<p>ردیابی 
   <strong>behavioral data</strong>
   برای ویژگی‌های 
   <strong>user-facing</strong>
   بسیاری از 
   <strong>online services</strong>
   اهمیت فزاینده‌ای پیدا کرده است: ردیابی نتایج جستجویی که روی آنها کلیک می‌شود به بهبود رتبه‌بندی نتایج جستجو کمک می‌کند. توصیه "افرادی که 
   <strong>X</strong>
   را دوست داشتند، 
   <strong>Y</strong>
   را هم دوست داشتند" به کاربران کمک می‌کند تا چیزهای جالب و مفیدی را کشف کنند. تست‌های 
   <strong>A/B</strong>
   و تجزیه و تحلیل 
   <strong>user flow</strong>
   می‌تواند به نشان دادن چگونگی بهبود رابط کاربری کمک کند. این ویژگی‌ها به مقداری ردیابی رفتار کاربر نیاز دارند و کاربران از آنها بهره‌مند می‌شوند.</p>
<p>با این حال، بسته به مدل کسب‌وکار یک شرکت، ردیابی اغلب در اینجا متوقف نمی‌شود. اگر این 
   <strong>service</strong>
   از طریق تبلیغات تأمین می‌شود، تبلیغ‌کنندگان، مشتریان واقعی هستند و منافع کاربران در رتبه دوم قرار می‌گیرند. ردیابی 
   <strong>data</strong>
   جزئی‌تر می‌شود، تجزیه و تحلیل‌ها گسترده‌تر می‌شوند و 
   <strong>data</strong>
   برای مدت طولانی برای ایجاد پروفایل‌های دقیق از هر فرد برای اهداف بازاریابی حفظ می‌شود.</p>
<p>اکنون رابطه بین شرکت و کاربری که 
   <strong>data</strong>
   آن جمع‌آوری می‌شود، کاملاً متفاوت به نظر می‌رسد. به کاربر یک 
   <strong>free service</strong>
   داده می‌شود و تشویق می‌شود تا تا حد امکان با آن درگیر شود. ردیابی کاربر در درجه اول نه به نفع آن فرد، بلکه به نیازهای تبلیغ‌کنندگانی که این 
   <strong>service</strong>
   را تأمین می‌کنند، خدمت می‌کند. من فکر می‌کنم این رابطه را می‌توان با کلمه‌ای که مفاهیم شوم‌تری دارد، به درستی توصیف کرد: نظارت.</p>
<h4>نظارت</h4>
<p>به عنوان یک آزمایش فکری، سعی کنید کلمه 
   <strong>data</strong>
   را با نظارت جایگزین کنید و مشاهده کنید که آیا عبارات رایج هنوز هم خوب به نظر می‌رسند [93]. در مورد این چطور: "در سازمان نظارت‌محور ما، جریان‌های نظارتی بی‌درنگ را جمع‌آوری می‌کنیم و آنها را در انبار نظارت خود ذخیره می‌کنیم. دانشمندان نظارت ما از تجزیه و تحلیل پیشرفته و پردازش نظارت برای به دست آوردن بینش‌های جدید استفاده می‌کنند."</p>
<p>این آزمایش فکری برای این کتاب، 
   <strong>Designing Surveillance-Intensive Applications</strong>
   ، به طور غیرعادی بحث‌انگیز است، اما من فکر می‌کنم که برای تأکید بر این نکته به کلمات قوی نیاز است. در تلاش‌هایمان برای اینکه 
   <strong>software</strong>
   "جهان را بخورد" [94]، ما بزرگترین زیرساخت نظارت جمعی را که جهان تاکنون دیده است، ساخته‌ایم. با عجله به سمت یک 
   <strong>Internet of Things</strong>
   ، ما به سرعت به جهانی نزدیک می‌شویم که در آن هر فضای مسکونی حاوی حداقل یک میکروفون متصل به اینترنت، در قالب گوشی‌های هوشمند، تلویزیون‌های هوشمند، دستگاه‌های دستیار کنترل‌شده با صدا، مانیتورهای کودک، و حتی اسباب‌بازی‌های کودکان است که از تشخیص گفتار مبتنی بر ابر استفاده می‌کنند. بسیاری از این دستگاه‌ها سابقه امنیتی وحشتناکی دارند [95].</p>
<p>حتی استبدادی‌ترین و سرکوب‌کننده‌ترین رژیم‌ها نیز فقط می‌توانند آرزوی قرار دادن یک میکروفون در هر اتاق و مجبور کردن هر فرد به حمل مداوم دستگاهی را داشته باشند که قادر به ردیابی مکان و حرکات آنها باشد. با این حال، ما ظاهراً داوطلبانه، حتی مشتاقانه، خود را به این دنیای نظارت کامل پرتاب می‌کنیم. این تفاوت...</p>
<p>
<strong>Doing the Right Thing</strong> | 537
  </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0559</div>
            </div>
        </div>
        <!-- Page 0560 -->
        <div class="chapter" id="page-0560">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>تفاوت این است که 
   <strong>data</strong>
   توسط شرکت‌ها جمع‌آوری می‌شود تا آژانس‌های دولتی [96].</p>
<p>جمع‌آوری 
   <strong>data</strong>
   لزوماً به عنوان نظارت واجد شرایط نیست، اما بررسی آن به این ترتیب می‌تواند به ما در درک رابطه خود با جمع‌کننده 
   <strong>data</strong>
   کمک کند. چرا ما ظاهراً از نظارت توسط شرکت‌ها خوشحالیم؟ شاید احساس می‌کنید چیزی برای پنهان کردن ندارید - به عبارت دیگر، شما کاملاً با ساختارهای قدرت موجود هماهنگ هستید، یک اقلیت حاشیه‌ای نیستید و نیازی به ترس از آزار و اذیت ندارید [97]. همه اینقدر خوش شانس نیستند. یا شاید به این دلیل باشد که هدف بی‌ضرر به نظر می‌رسد - این اجبار و انطباق آشکار نیست، بلکه صرفاً توصیه‌های بهتر و بازاریابی شخصی‌تر است. با این حال، با ترکیب بحث 
   <strong>predictive analytics</strong>
   از بخش قبل، این تمایز کمتر واضح به نظر می‌رسد.</p>
<p>ما در حال حاضر شاهد مرتبط شدن حق بیمه خودرو با دستگاه‌های ردیاب در خودروها و پوشش بیمه درمانی هستیم که به پوشیدن یک دستگاه ردیابی تناسب اندام توسط مردم بستگی دارد. وقتی از نظارت برای تعیین چیزهایی استفاده می‌شود که بر جنبه‌های مهم زندگی، مانند پوشش بیمه یا اشتغال، حاکم هستند، کمتر بی‌ضرر به نظر می‌رسد. علاوه بر این، تجزیه و تحلیل 
   <strong>data</strong>
   می‌تواند چیزهای شگفت‌آوری مزاحم را نشان دهد: به عنوان مثال، حسگر حرکت در یک ساعت هوشمند یا ردیاب تناسب اندام می‌تواند برای تشخیص آنچه شما تایپ می‌کنید (به عنوان مثال، رمزهای عبور) با دقت نسبتاً خوبی استفاده شود [98]. و الگوریتم‌های تجزیه و تحلیل فقط قرار است بهتر شوند.</p>
<h4>رضایت و آزادی انتخاب</h4>
<p>ممکن است ادعا کنیم که کاربران داوطلبانه استفاده از 
   <strong>service</strong>
   ای را انتخاب می‌کنند که فعالیت آنها را ردیابی می‌کند، و آنها با شرایط 
   <strong>service</strong>
   و سیاست حفظ حریم خصوصی موافقت کرده‌اند، بنابراین به جمع‌آوری 
   <strong>data</strong>
   رضایت می‌دهند. ما حتی ممکن است ادعا کنیم که کاربران در ازای 
   <strong>data</strong>
   ای که ارائه می‌دهند، 
   <strong>service</strong>
   ارزشمندی دریافت می‌کنند و ردیابی برای ارائه 
   <strong>service</strong>
   لازم است. بدون شک، شبکه‌های اجتماعی، موتورهای جستجو و سایر خدمات 
   <strong>online</strong>
   رایگان برای کاربران ارزشمند هستند - اما مشکلاتی در این استدلال وجود دارد.</p>
<p>کاربران دانش کمی در مورد 
   <strong>data</strong>
   ای که وارد 
   <strong>databases</strong>
   ما می‌کنند، یا نحوه حفظ و پردازش آن دارند - و اکثر سیاست‌های حفظ حریم خصوصی، بیشتر از روشن کردن، مبهم می‌کنند. بدون درک آنچه برای 
   <strong>data</strong>
   آنها اتفاق می‌افتد، کاربران نمی‌توانند رضایت معناداری بدهند. اغلب، 
   <strong>data</strong>
   از یک کاربر نیز در مورد افراد دیگری که کاربر 
   <strong>service</strong>
   نیستند و با هیچ شرایطی موافقت نکرده‌اند، چیزهایی را بیان می‌کند. مجموعه داده‌های مشتق شده‌ای که ما در این قسمت از کتاب مورد بحث قرار دادیم - که در آن 
   <strong>data</strong>
   از کل پایگاه کاربری ممکن است با ردیابی رفتاری و منابع 
   <strong>data</strong>
   خارجی ترکیب شده باشد - دقیقاً از انواع 
   <strong>data</strong>
   هستند که کاربران نمی‌توانند درک معناداری از آن داشته باشند.</p>
<p>علاوه بر این، 
   <strong>data</strong>
   از کاربران از طریق یک فرآیند یک‌طرفه استخراج می‌شود، نه یک رابطه با رفتار متقابل واقعی، و نه یک تبادل ارزش منصفانه. هیچ گفتگویی وجود ندارد، هیچ گزینه‌ای برای کاربران وجود ندارد تا در مورد میزان 
   <strong>data</strong>
   ای که ارائه می‌دهند و چه 
   <strong>service</strong>
   ای دریافت می‌کنند، مذاکره کنند.</p>
<p>538 | فصل 12: آینده سیستم‌های 
   <strong>Data</strong>
</p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0560</div>
            </div>
        </div>
        <!-- Page 0561 -->
        <div class="chapter" id="page-0561">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>بازگشت: رابطه بین 
   <strong>service</strong>
   و کاربر بسیار نامتقارن و یک‌طرفه است. شرایط توسط 
   <strong>service</strong>
   تعیین می‌شود، نه توسط کاربر [99].</p>
<p>برای کاربری که به نظارت رضایت نمی‌دهد، تنها جایگزین واقعی این است که به سادگی از یک 
   <strong>service</strong>
   استفاده نکند. اما این انتخاب هم آزاد نیست: اگر یک 
   <strong>service</strong>
   آنقدر محبوب باشد که "توسط اکثر مردم به عنوان ضروری برای مشارکت اجتماعی اساسی در نظر گرفته شود" [99]، پس انتظار نمی‌رود مردم از این 
   <strong>service</strong>
   انصراف دهند - استفاده از آن عملاً اجباری است.</p>
<p>به عنوان مثال، در اکثر جوامع اجتماعی غربی، حمل گوشی هوشمند، استفاده از 
   <strong>Facebook</strong>
   برای معاشرت، و استفاده از 
   <strong>Google</strong>
   برای یافتن اطلاعات به یک هنجار تبدیل شده است. به خصوص زمانی که یک 
   <strong>service</strong>
   اثرات شبکه‌ای دارد، یک هزینه اجتماعی برای افرادی وجود دارد که تصمیم می‌گیرند از آن استفاده نکنند.</p>
<p>خودداری از استفاده از یک 
   <strong>service</strong>
   به دلیل ردیابی کاربران، تنها یک گزینه برای تعداد کمی از افرادی است که به اندازه کافی امتیاز دارند تا وقت و دانش لازم برای درک سیاست حفظ حریم خصوصی آن را داشته باشند، و می‌توانند از مشارکت اجتماعی یا فرصت‌های حرفه‌ای که ممکن است در صورت مشارکت در 
   <strong>service</strong>
   ایجاد شده باشد، چشم‌پوشی کنند. برای افرادی که در موقعیت‌های کم‌امتیازتری قرار دارند، هیچ آزادی انتخاب معناداری وجود ندارد: نظارت اجتناب‌ناپذیر می‌شود.</p>
<h4>حریم خصوصی و استفاده از <strong>data</strong></h4>
<p>گاهی اوقات مردم ادعا می‌کنند که "حریم خصوصی مرده است" به این دلیل که برخی از کاربران مایلند انواع مختلفی از چیزها را در مورد زندگی خود در رسانه‌های اجتماعی پست کنند، گاهی اوقات پیش پا افتاده و گاهی عمیقاً شخصی. با این حال، این ادعا نادرست است و بر اساس سوء تفاهم از کلمه حریم خصوصی است.</p>
<p>داشتن حریم خصوصی به معنای پنهان نگه داشتن همه چیز نیست؛ این به معنای داشتن آزادی انتخاب است که چه چیزهایی را به چه کسی فاش کنیم، چه چیزی را عمومی کنیم و چه چیزی را محرمانه نگه داریم. حق حریم خصوصی یک حق تصمیم‌گیری است: این حق به هر فرد این امکان را می‌دهد که در هر موقعیتی تصمیم بگیرد که می‌خواهد در طیف بین محرمانه بودن و شفافیت کجا باشد [99]. این یک جنبه مهم از آزادی و استقلال یک فرد است.</p>
<p>وقتی 
   <strong>data</strong>
   از طریق زیرساخت‌های نظارتی از افراد استخراج می‌شود، حقوق حریم خصوصی لزوماً از بین نمی‌روند، بلکه به جمع‌کننده 
   <strong>data</strong>
   منتقل می‌شوند. شرکت‌هایی که 
   <strong>data</strong>
   را به دست می‌آورند اساساً می‌گویند "به ما اعتماد کنید تا با 
   <strong>data</strong>
   شما کار درست را انجام دهیم"، به این معنی که حق تصمیم‌گیری در مورد آنچه باید فاش شود و آنچه باید محرمانه نگه داشته شود، از فرد به شرکت منتقل می‌شود.</p>
<p>شرکت‌ها به نوبه خود تصمیم می‌گیرند که بخش زیادی از نتیجه این نظارت را محرمانه نگه دارند، زیرا فاش کردن آن به عنوان خزنده تلقی می‌شود و به مدل کسب‌وکار آنها آسیب می‌رساند (که به دانستن اطلاعات بیشتر در مورد مردم نسبت به سایر شرکت‌ها متکی است). اطلاعات صمیمی در مورد کاربران فقط به طور غیرمستقیم فاش می‌شود، به عنوان مثال در قالب ابزارهایی برای هدف قرار دادن تبلیغات به گروه‌های خاصی از افراد (مانند کسانی که از یک بیماری خاص رنج می‌برند).</p>
<p>
<strong>Doing the Right Thing</strong> | 539
  </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0561</div>
            </div>
        </div>
        <!-- Page 0562 -->
        <div class="chapter" id="page-0562">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>حتی اگر کاربران خاصی نتوانند شخصاً از سطل افرادی که توسط یک تبلیغ خاص هدف قرار گرفته‌اند، دوباره شناسایی شوند، آنها اختیار خود را در مورد افشای برخی از اطلاعات صمیمی، مانند اینکه آیا از یک بیماری رنج می‌برند یا خیر، از دست داده‌اند. این کاربر نیست که بر اساس ترجیحات شخصی خود تصمیم می‌گیرد چه چیزی به چه کسی فاش شود - این شرکت است که حق حریم خصوصی را با هدف به حداکثر رساندن سود خود اعمال می‌کند.</p>
<p>بسیاری از شرکت‌ها این هدف را دارند که به عنوان خزنده تلقی نشوند - اجتناب از سوال در مورد میزان تهاجمی جمع‌آوری 
   <strong>data</strong>
   آنها در واقع چقدر است، و در عوض بر مدیریت درک کاربران تمرکز می‌کنند. و حتی این درک‌ها اغلب ضعیف مدیریت می‌شوند: به عنوان مثال، ممکن است چیزی از نظر واقعیت درست باشد، اما اگر خاطرات دردناکی را ایجاد کند، ممکن است کاربر نخواهد که به آن یادآوری شود [100]. با هر نوع 
   <strong>data</strong>
   باید انتظار این احتمال را داشته باشیم که به نوعی اشتباه، ناخواسته یا نامناسب باشد، و ما باید مکانیسم‌هایی برای رسیدگی به آن شکست‌ها ایجاد کنیم. اینکه آیا چیزی "ناخواسته" یا "نامناسب" است، البته به قضاوت انسانی بستگی دارد. الگوریتم‌ها از این مفاهیم بی‌خبرند مگر اینکه ما صریحاً آنها را برنامه‌ریزی کنیم تا به نیازهای انسانی احترام بگذارند. ما به عنوان مهندسان این سیستم‌ها باید متواضع باشیم، چنین شکست‌هایی را بپذیریم و برای آنها برنامه‌ریزی کنیم.</p>
<p>تنظیمات حریم خصوصی که به کاربر یک 
   <strong>online service</strong>
   اجازه می‌دهد تا جنبه‌های 
   <strong>data</strong>
   خود را که سایر کاربران می‌توانند ببینند کنترل کنند، یک نقطه شروع برای بازگرداندن مقداری کنترل به کاربران است. با این حال، صرف نظر از تنظیمات، خود 
   <strong>service</strong>
   هنوز به 
   <strong>data</strong>
   دسترسی نامحدود دارد و می‌تواند از آن به هر نحوی که توسط سیاست حفظ حریم خصوصی مجاز است، استفاده کند. حتی اگر 
   <strong>service</strong>
   قول می‌دهد که 
   <strong>data</strong>
   را به اشخاص ثالث نفروشد، معمولاً حقوق نامحدودی برای پردازش و تجزیه و تحلیل 
   <strong>data</strong>
   در داخل به خود می‌دهد، که اغلب بسیار فراتر از آنچه برای کاربران آشکارا قابل مشاهده است، می‌رود.</p>
<p>این نوع انتقال در مقیاس بزرگ حقوق حریم خصوصی از افراد به شرکت‌ها از نظر تاریخی بی‌سابقه است [99]. نظارت همیشه وجود داشته است، اما قبلاً گران و دستی بود، نه مقیاس‌پذیر و خودکار. روابط اعتماد همیشه وجود داشته است، به عنوان مثال بین یک بیمار و پزشک خود، یا بین یک متهم و وکیل خود - اما در این موارد استفاده از 
   <strong>data</strong>
   به شدت توسط محدودیت‌های اخلاقی، قانونی و نظارتی اداره می‌شد. خدمات اینترنتی جمع‌آوری مقادیر زیادی از اطلاعات حساس را بدون رضایت معنادار، و استفاده از آن در مقیاس وسیع بدون اینکه کاربران بفهمند چه اتفاقی برای 
   <strong>data</strong>
   خصوصی آنها می‌افتد، بسیار آسان‌تر کرده است.</p>
<h4>
<strong>Data</strong>
   به عنوان دارایی و قدرت</h4>
<p>از آنجایی که 
   <strong>behavioral data</strong>
   یک محصول جانبی از تعامل کاربران با یک 
   <strong>service</strong>
   است، گاهی اوقات "
   <strong>data exhaust</strong>
   " نامیده می‌شود - که نشان می‌دهد 
   <strong>data</strong>
   ، مواد زائد بی‌ارزش است. با این دید، تجزیه و تحلیل رفتاری و پیش‌بینی‌کننده را می‌توان به عنوان شکلی از بازیافت در نظر گرفت که از 
   <strong>data</strong>
   ای که در غیر این صورت دور ریخته می‌شد، ارزش استخراج می‌کند.</p>
<p>درست‌تر این است که آن را به روش دیگری مشاهده کنید: از دیدگاه اقتصادی، اگر تبلیغات هدفمند چیزی است که هزینه یک 
   <strong>service</strong>
   را پرداخت می‌کند، در این صورت 
   <strong>behavioral data</strong>
   در مورد مردم، دارایی اصلی 
   <strong>service</strong>
   است. در این حالت، برنامه‌ای که کاربر با آن تعامل دارد، صرفاً وسیله‌ای برای جذب کاربران به تغذیه اطلاعات شخصی بیشتر و بیشتر است.</p>
<p>540 | فصل 12: آینده سیستم‌های 
   <strong>Data</strong>
</p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0562</div>
            </div>
        </div>
        <!-- Page 0563 -->
        <div class="chapter" id="page-0563">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>اطلاعات به زیرساخت نظارتی [99]. خلاقیت انسانی لذت‌بخش و روابط اجتماعی که اغلب در 
   <strong>online services</strong>
   ابراز می‌شوند، به طور بدبینانه‌ای توسط دستگاه استخراج 
   <strong>data</strong>
   استفاده می‌شوند.</p>
<p>این ادعا که 
   <strong>data</strong>
   شخصی یک دارایی ارزشمند است، با وجود واسطه‌های 
   <strong>data</strong>
   ، یک صنعت بدنام که در خفا فعالیت می‌کند، خرید، تجمیع، تجزیه و تحلیل، استنباط، و فروش مجدد 
   <strong>data</strong>
   شخصی مزاحم در مورد مردم، بیشتر برای اهداف بازاریابی، پشتیبانی می‌شود [90]. استارتاپ‌ها بر اساس تعداد کاربران، "
   <strong>eyeballs</strong>
   " - یعنی بر اساس قابلیت‌های نظارتی خود - ارزش‌گذاری می‌شوند.</p>
<p>از آنجایی که 
   <strong>data</strong>
   ارزشمند است، بسیاری از مردم آن را می‌خواهند. البته شرکت‌ها آن را می‌خواهند - به همین دلیل است که در وهله اول آن را جمع‌آوری می‌کنند. اما دولت‌ها نیز می‌خواهند آن را به دست آورند: از طریق معاملات محرمانه، اجبار، اجبار قانونی یا به سادگی سرقت آن [101]. وقتی یک شرکت ورشکسته می‌شود، 
   <strong>data</strong>
   شخصی که جمع‌آوری کرده است یکی از دارایی‌هایی است که فروخته می‌شود. علاوه بر این، ایمن‌سازی 
   <strong>data</strong>
   دشوار است، بنابراین نقض‌ها به‌طور نگران‌کننده‌ای اغلب اتفاق می‌افتند [102].</p>
<p>این مشاهدات منتقدان را بر آن داشته است تا بگویند که 
   <strong>data</strong>
   فقط یک دارایی نیست، بلکه یک "دارایی سمی" [101]، یا حداقل "مواد خطرناک" [103] است. حتی اگر فکر می‌کنیم که قادر به جلوگیری از سوء استفاده از 
   <strong>data</strong>
   هستیم، هر زمان که 
   <strong>data</strong>
   را جمع‌آوری می‌کنیم، باید مزایا را با خطر افتادن آن به دست افراد اشتباهی متعادل کنیم: سیستم‌های کامپیوتری ممکن است توسط مجرمان یا سرویس‌های اطلاعاتی خارجی متخاصم به خطر بیفتند، 
   <strong>data</strong>
   ممکن است توسط افراد داخلی درز پیدا کند، شرکت ممکن است به دست مدیریت بی‌وجدان بیفتد که ارزش‌های ما را به اشتراک نمی‌گذارد، یا کشور ممکن است توسط رژیمی که هیچ تردیدی در مجبور کردن ما به تحویل 
   <strong>data</strong>
   ندارد، تصرف شود.</p>
<p>هنگام جمع‌آوری 
   <strong>data</strong>
   ، ما باید نه تنها محیط سیاسی امروز، بلکه تمام دولت‌های آینده ممکن را نیز در نظر بگیریم. هیچ تضمینی وجود ندارد که هر دولتی که در آینده انتخاب می‌شود، به حقوق بشر و آزادی‌های مدنی احترام بگذارد، بنابراین "نصب فناوری‌هایی که روزی می‌تواند یک دولت پلیسی را تسهیل کند، بهداشت مدنی ضعیفی است" [104].</p>
<p>"دانش قدرت است"، همانطور که ضرب‌المثل قدیمی می‌گوید. و علاوه بر این، "بازرسی دیگران در حالی که از بازرسی خودداری می‌کنید، یکی از مهم‌ترین اشکال قدرت است" [105]. به همین دلیل است که دولت‌های توتالیتر خواهان نظارت هستند: این به آنها قدرت کنترل جمعیت را می‌دهد. اگرچه شرکت‌های فناوری امروزی آشکارا به دنبال قدرت سیاسی نیستند، اما 
   <strong>data</strong>
   و دانشی که جمع‌آوری کرده‌اند، با وجود این، قدرت زیادی بر زندگی ما به آنها می‌دهد، که بخش زیادی از آن پنهانی و خارج از نظارت عمومی است [106].</p>
<h4>به یاد آوردن انقلاب صنعتی</h4>
<p>
<strong>Data</strong>
   ویژگی تعیین‌کننده عصر اطلاعات است. اینترنت، ذخیره‌سازی 
   <strong>data</strong>
   ، پردازش، و اتوماسیون مبتنی بر 
   <strong>software</strong>
   تأثیر عمده‌ای بر اقتصاد جهانی و جامعه بشری دارد. از آنجایی که زندگی روزمره و سازمان اجتماعی ما در دهه گذشته تغییر کرده است و احتمالاً در دهه‌های آینده نیز به‌طور اساسی تغییر خواهد کرد، مقایسه‌ها با انقلاب صنعتی به ذهن خطور می‌کند [87، 96].</p>
<p>
<strong>Doing the Right Thing</strong> | 541
  </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0563</div>
            </div>
        </div>
        <!-- Page 0564 -->
        <div class="chapter" id="page-0564">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>انقلاب صنعتی از طریق پیشرفت‌های عمده تکنولوژیکی و کشاورزی به وجود آمد و رشد اقتصادی پایدار و استانداردهای زندگی را در درازمدت به‌طور قابل توجهی بهبود بخشید. با این حال، این انقلاب با مشکلات عمده‌ای نیز همراه بود: آلودگی هوا (به دلیل دود و فرآیندهای شیمیایی) و آب (از زباله‌های صنعتی و انسانی) وحشتناک بود. صاحبان کارخانه‌ها در تجمل زندگی می‌کردند، در حالی که کارگران شهری اغلب در مسکن بسیار نامناسب زندگی می‌کردند و ساعت‌های طولانی در شرایط سخت کار می‌کردند. کار کودکان رایج بود، از جمله کار خطرناک و کم‌درآمد در معادن.</p>
<p>مدت زیادی طول کشید تا محافظت‌هایی مانند مقررات حفاظت از محیط زیست، پروتکل‌های ایمنی برای محیط‌های کاری، غیرقانونی کردن کار کودکان و بازرسی‌های بهداشتی برای غذا ایجاد شود. بدون شک هزینه انجام تجارت زمانی افزایش یافت که کارخانه‌ها دیگر نمی‌توانستند زباله‌های خود را در رودخانه‌ها بریزند، غذاهای آلوده را بفروشند یا از کارگران سوء استفاده کنند. اما جامعه به عنوان یک کل از این امر بسیار بهره‌مند شد و تعداد کمی از ما می‌خواهیم به زمانی قبل از آن مقررات برگردیم [87].</p>
<p>همانطور که انقلاب صنعتی یک جنبه تاریک داشت که باید مدیریت می‌شد، گذار ما به عصر اطلاعات مشکلات عمده‌ای دارد که باید با آنها مقابله کرده و حل کنیم. من معتقدم که جمع‌آوری و استفاده از 
   <strong>data</strong>
   یکی از این مشکلات است. به گفته بروس اشنایر [96]:</p>
<p>
<strong>Data</strong>
   مشکل آلودگی عصر اطلاعات است، و محافظت از حریم خصوصی چالش زیست‌محیطی است. تقریباً همه کامپیوترها اطلاعات تولید می‌کنند. این اطلاعات باقی می‌مانند و ریشه می‌دوانند. نحوه برخورد ما با آن - نحوه مهار و نحوه دور انداختن آن - برای سلامت اقتصاد اطلاعات ما حیاتی است. همانطور که امروزه به دهه‌های اولیه عصر صنعتی نگاه می‌کنیم و تعجب می‌کنیم که چگونه اجداد ما می‌توانستند آلودگی را در عجله خود برای ساختن یک دنیای صنعتی نادیده بگیرند، نوه‌های ما در این دهه‌های اولیه عصر اطلاعات به ما نگاه خواهند کرد و ما را بر اساس نحوه پرداختن ما به چالش جمع‌آوری و سوء استفاده از 
   <strong>data</strong>
   قضاوت خواهند کرد.</p>
<p>ما باید سعی کنیم آنها را مفتخر کنیم.</p>
<h4>قانون‌گذاری و خودتنظیمی</h4>
<p>قوانین حفاظت از 
   <strong>data</strong>
   ممکن است بتوانند به حفظ حقوق افراد کمک کنند. به عنوان مثال، دستورالعمل حفاظت از 
   <strong>Data</strong>
   اروپا در سال 1995 بیان می‌کند که 
   <strong>data</strong>
   شخصی باید "برای اهداف مشخص، صریح و مشروع جمع‌آوری شود و به روشی که با آن اهداف ناسازگار است، بیشتر پردازش نشود" و علاوه بر این که 
   <strong>data</strong>
   باید "کافی، مرتبط و بیش از حد نباشد" با توجه به اهدافی که برای آنها جمع‌آوری می‌شوند [107].</p>
<p>با این حال، شک‌برانگیز است که آیا این قانون‌گذاری در بستر اینترنت امروزی مؤثر است [108]. این قوانین مستقیماً با فلسفه 
   <strong>Big Data</strong>
   مغایرت دارند، که عبارت است از به حداکثر رساندن جمع‌آوری 
   <strong>data</strong>
   ، ترکیب آن با سایر مجموعه‌داده‌ها، آزمایش و کاوش برای تولید بینش‌های جدید. کاوش به معنای استفاده از 
   <strong>data</strong>
   برای اهداف پیش‌بینی‌نشده است، که متضاد با اهداف "مشخص و صریح" است که کاربر رضایت خود را داده است (اگر اصلاً بتوانیم به معنای واقعی از رضایت صحبت کنیم [109]). اکنون مقررات به‌روزرسانی‌شده در حال توسعه است [89].</p>
<p>542 | فصل 12: آینده سیستم‌های 
   <strong>Data</strong>
</p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0564</div>
            </div>
        </div>
        <!-- Page 0565 -->
        <div class="chapter" id="page-0565">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>شرکت‌هایی که 
   <strong>data</strong>
   زیادی در مورد مردم جمع‌آوری می‌کنند، با مقررات به عنوان یک بار و مانعی برای نوآوری مخالفت می‌کنند. تا حدی این مخالفت موجه است. به عنوان مثال، هنگام به اشتراک گذاشتن 
   <strong>data</strong>
   پزشکی، خطرات روشنی برای حریم خصوصی وجود دارد، اما فرصت‌های بالقوه‌ای نیز وجود دارد: اگر تجزیه و تحلیل 
   <strong>data</strong>
   بتواند به ما در دستیابی به تشخیص بهتر یا یافتن درمان‌های بهتر کمک کند، چند مرگ می‌تواند پیشگیری شود [110]؟ مقررات‌گذاری بیش از حد ممکن است از چنین پیشرفت‌هایی جلوگیری کند. متعادل کردن چنین فرصت‌های بالقوه‌ای با خطرات دشوار است [105].</p>
<p>در اصل، من فکر می‌کنم ما به یک تغییر فرهنگی در صنعت فناوری در مورد 
   <strong>data</strong>
   شخصی نیاز داریم. ما باید کاربران را به عنوان معیارهایی که باید بهینه شوند، در نظر گرفتن را متوقف کنیم، و به یاد داشته باشیم که آنها انسان‌هایی هستند که شایسته احترام، کرامت و اختیار هستند. ما باید شیوه‌های جمع‌آوری و پردازش 
   <strong>data</strong>
   خود را خودتنظیمی کنیم تا اعتماد افرادی را که به 
   <strong>software</strong>
   ما متکی هستند، ایجاد و حفظ کنیم [111]. و ما باید خودمان را متعهد کنیم که به کاربران نهایی در مورد نحوه استفاده از 
   <strong>data</strong>
   آنها آموزش دهیم، به جای اینکه آنها را در تاریکی نگه داریم.</p>
<p>ما باید به هر فرد اجازه دهیم حریم خصوصی خود را حفظ کند - یعنی کنترل خود بر 
   <strong>data</strong>
   خود - و این کنترل را از طریق نظارت از آنها ندزدیم. حق فردی ما برای کنترل 
   <strong>data</strong>
   مانند محیط طبیعی یک پارک ملی است: اگر ما صریحاً از آن محافظت و مراقبت نکنیم، نابود خواهد شد. این تراژدی مشترکات خواهد بود، و ما همه به خاطر آن بدتر خواهیم شد. نظارت همه‌جا حاضر اجتناب‌ناپذیر نیست - ما هنوز هم می‌توانیم آن را متوقف کنیم.</p>
<p>اینکه دقیقاً چگونه می‌توانیم به این هدف برسیم، یک سوال باز است. در ابتدا، ما نباید 
   <strong>data</strong>
   را برای همیشه حفظ کنیم، بلکه باید آن را به محض اینکه دیگر مورد نیاز نیست، حذف کنیم [111، 112]. پاکسازی 
   <strong>data</strong>
   با ایده تغییرناپذیری مغایرت دارد (به "محدودیت‌های تغییرناپذیری" در صفحه 463 مراجعه کنید)، اما آن مسئله قابل حل است. یک رویکرد امیدوارکننده‌ای که می‌بینم، اعمال کنترل دسترسی از طریق پروتکل‌های رمزنگاری است، نه صرفاً با سیاست [113، 114]. در مجموع، تغییرات فرهنگی و نگرشی ضروری خواهد بود.</p>
<h4>خلاصه</h4>
<p>در این فصل، ما رویکردهای جدیدی را برای طراحی سیستم‌های 
   <strong>data</strong>
   مورد بحث قرار دادیم، و من نظرات و گمانه‌زنی‌های شخصی خود را در مورد آینده گنجاندم. ما با این مشاهده شروع کردیم که هیچ ابزار واحدی وجود ندارد که بتواند به طور موثر به تمام موارد استفاده ممکن خدمت کند، و بنابراین برنامه‌ها لزوماً نیاز به ترکیب چندین قطعه مختلف از 
   <strong>software</strong>
   برای دستیابی به اهداف خود دارند. ما در مورد نحوه حل این مشکل ادغام 
   <strong>data</strong>
   با استفاده از پردازش 
   <strong>batch</strong>
   و جریان‌های 
   <strong>event</strong>
   برای اجازه دادن به تغییرات 
   <strong>data</strong>
   در بین سیستم‌های مختلف بحث کردیم.</p>
<p>در این رویکرد، سیستم‌های خاصی به عنوان سیستم‌های ثبت تعیین می‌شوند، و سایر 
   <strong>data</strong>
   از طریق تحولات از آنها مشتق می‌شوند. به این ترتیب، ما می‌توانیم فهرست‌ها، 
   <strong>materialized views</strong>
   ، مدل‌های یادگیری ماشینی، خلاصه‌های آماری و موارد دیگر را حفظ کنیم. با ایجاد این اشتقاقات و تحولات ناهمزمان و سست‌شده، ...</p>
<p>
<strong>Summary</strong> | 543
  </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0565</div>
            </div>
        </div>
        <!-- Page 0566 -->
        <div class="chapter" id="page-0566">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>مشکل در یک ناحیه از گسترش به قسمت‌های نامرتبط سیستم جلوگیری می‌شود، که باعث افزایش استحکام و تحمل خطای سیستم به عنوان یک کل می‌شود.</p>
<p>بیان 
   <strong>dataflows</strong>
   به عنوان تبدیل از یک مجموعه داده به مجموعه داده دیگر نیز به تکامل برنامه‌ها کمک می‌کند: اگر می‌خواهید یکی از مراحل پردازش را تغییر دهید، به عنوان مثال برای تغییر ساختار یک شاخص یا 
   <strong>cache</strong>
   ، می‌توانید فقط کد تبدیل جدید را روی کل مجموعه داده ورودی دوباره اجرا کنید تا خروجی را دوباره استنتاج کنید. به طور مشابه، اگر مشکلی پیش آمد، می‌توانید کد را اصلاح کرده و 
   <strong>data</strong>
   را دوباره پردازش کنید تا بازیابی شود.</p>
<p>این فرآیندها کاملاً شبیه به کارهایی هستند که 
   <strong>databases</strong>
   از قبل در داخل انجام می‌دهند، بنابراین ما ایده برنامه‌های 
   <strong>dataflow</strong>
   را به عنوان از بین بردن اجزای یک 
   <strong>database</strong>
   ، و ساختن یک برنامه با ترکیب این اجزای سست‌شده، بازسازی می‌کنیم.</p>
<p>حالت مشتق‌شده را می‌توان با مشاهده تغییرات در 
   <strong>data</strong>
   اساسی به‌روزرسانی کرد. علاوه بر این، خود حالت مشتق‌شده می‌تواند توسط مصرف‌کنندگان 
   <strong>downstream</strong>
   بیشتر مشاهده شود. ما حتی می‌توانیم این 
   <strong>dataflow</strong>
   را تا دستگاه کاربر نهایی که 
   <strong>data</strong>
   را نمایش می‌دهد، ادامه دهیم، و در نتیجه رابط‌های کاربری را بسازیم که به‌طور پویا به‌روزرسانی می‌شوند تا تغییرات 
   <strong>data</strong>
   را منعکس کنند و به کار خود به صورت 
   <strong>offline</strong>
   ادامه دهند.</p>
<p>در مرحله بعد، ما در مورد چگونگی اطمینان از اینکه همه این پردازش‌ها در حضور خطاها درست باقی می‌مانند، بحث کردیم. ما دیدیم که تضمین‌های یکپارچگی قوی را می‌توان با پردازش رویداد ناهمزمان، با استفاده از شناسه‌های عملیات 
   <strong>end-to-end</strong>
   برای ایجاد عملیات هم‌ارز و با بررسی محدودیت‌ها به‌صورت ناهمزمان، به طور مقیاس‌پذیر پیاده‌سازی کرد. کلاینت‌ها می‌توانند منتظر بمانند تا بررسی انجام شود، یا بدون انتظار به کار خود ادامه دهند، اما خطر نقض محدودیت را دارند. این رویکرد بسیار مقیاس‌پذیرتر و قوی‌تر از رویکرد سنتی استفاده از تراکنش‌های توزیع‌شده است و با نحوه عملکرد بسیاری از فرآیندهای تجاری در عمل مطابقت دارد.</p>
<p>با ساختار دادن به برنامه‌ها حول 
   <strong>dataflow</strong>
   و بررسی محدودیت‌ها به‌صورت ناهمزمان، می‌توانیم از بیشتر هماهنگی‌ها اجتناب کنیم و سیستم‌هایی ایجاد کنیم که یکپارچگی را حفظ کنند، اما همچنان عملکرد خوبی داشته باشند، حتی در سناریوهای توزیع‌شده جغرافیایی و در حضور خطاها. سپس کمی در مورد استفاده از 
   <strong>audits</strong>
   برای تأیید یکپارچگی 
   <strong>data</strong>
   و تشخیص فساد صحبت کردیم.</p>
<p>در نهایت، ما یک قدم به عقب برداشتیم و برخی از جنبه‌های اخلاقی ساخت برنامه‌های 
   <strong>data</strong>
   فشرده را بررسی کردیم. ما دیدیم که اگرچه 
   <strong>data</strong>
   می‌تواند برای انجام کارهای خوب استفاده شود، اما می‌تواند آسیب قابل توجهی نیز وارد کند: اتخاذ تصمیماتی که به‌طور جدی بر زندگی مردم تأثیر می‌گذارد و مقابله با آنها دشوار است، منجر به تبعیض و استثمار می‌شود، نظارت را عادی می‌کند، و اطلاعات صمیمی را آشکار می‌کند. ما همچنین در معرض خطر نقض 
   <strong>data</strong>
   قرار داریم، و ممکن است متوجه شویم که استفاده‌ای که با حسن نیت از 
   <strong>data</strong>
   شده است، عواقب ناخواسته‌ای داشته است.</p>
<p>از آنجایی که 
   <strong>software</strong>
   و 
   <strong>data</strong>
   تأثیر زیادی بر جهان دارند، ما مهندسان باید به یاد داشته باشیم که ما مسئولیت داریم تا برای دنیایی که می‌خواهیم در آن زندگی کنیم، کار کنیم: دنیایی که با مردم با انسانیت و احترام رفتار می‌کند. من امیدوارم که بتوانیم با هم به سمت این هدف تلاش کنیم.</p>
<p>544 | فصل 12: آینده سیستم‌های 
   <strong>Data</strong>
</p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0566</div>
            </div>
        </div>
        <!-- Page 0567 -->
        <div class="chapter" id="page-0567">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<h4>مراجع</h4>
<p>[1] Rachid Belaid: “
   <strong>Postgres Full-Text Search is Good Enough!</strong>
   ،” rachbelaid.com, July 13, 2015.</p>
<p>[2] Philippe Ajoux, Nathan Bronson, Sanjeev Kumar, et al.: “
   <strong>Challenges to Adopting Stronger Consistency at Scale</strong>
   ،” at 15th 
   <strong>USENIX Workshop on Hot Topics in Operating Systems (HotOS)</strong>
   , May 2015.</p>
<p>[3] Pat Helland and Dave Campbell: “
   <strong>Building on Quicksand</strong>
   ،” at 4th 
   <strong>Biennial Conference on Innovative Data Systems Research (CIDR)</strong>
   , January 2009.</p>
<p>[4] Jessica Kerr: “
   <strong>Provenance and Causality in Distributed Systems</strong>
   ،” blog.jessitron.com, September 25, 2016.</p>
<p>[5] Kostas Tzoumas: “
   <strong>Batch Is a Special Case of Streaming</strong>
   ،” data-artisans.com, September 15, 2015.</p>
<p>[6] Shinji Kim and Robert Blafford: “
   <strong>Stream Windowing Performance Analysis: Concord and Spark Streaming</strong>
   ،” concord.io, July 6, 2016.</p>
<p>[7] Jay Kreps: “
   <strong>The Log: What Every Software Engineer Should Know About Real-Time Data’s Unifying Abstraction</strong>
   ،” engineering.linkedin.com, December 16, 2013.</p>
<p>[8] Pat Helland: “
   <strong>Life Beyond Distributed Transactions: An Apostate’s Opinion</strong>
   ،” at 3rd 
   <strong>Biennial Conference on Innovative Data Systems Research (CIDR)</strong>
   , January 2007.</p>
<p>[9] “
   <strong>Great Western Railway (1835–1948)</strong>
   ،” 
   <strong>Network Rail Virtual Archive</strong>
   , networkrail.co.uk.</p>
<p>[10] Jacqueline Xu: “
   <strong>Online Migrations at Scale</strong>
   ،” stripe.com, February 2, 2017.</p>
<p>[11] Molly Bartlett Dishman and Martin Fowler: “
   <strong>Agile Architecture</strong>
   ،” at 
   <strong>O’Reilly Software Architecture Conference</strong>
   , March 2015.</p>
<p>[12] Nathan Marz and James Warren: 
   <strong>Big Data: Principles and Best Practices of Scalable Real-Time Data Systems</strong>
   . Manning, 2015. 
   <strong>ISBN</strong>: 978-1-617-29034-3</p>
<p>[13] Oscar Boykin, Sam Ritchie, Ian O’Connell, and Jimmy Lin: “
   <strong>Summingbird: A Framework for Integrating Batch and Online MapReduce Computations</strong>
   ،” at 40th 
   <strong>International Conference on Very Large Data Bases (VLDB)</strong>
   , September 2014.</p>
<p>[14] Jay Kreps: “
   <strong>Questioning the Lambda Architecture</strong>
   ،” oreilly.com, July 2, 2014.</p>
<p>[15] Raul Castro Fernandez, Peter Pietzuch, Jay Kreps, et al.: “
   <strong>Liquid: Unifying Nearline and Offline Big Data Integration</strong>
   ،” at 7th 
   <strong>Biennial Conference on Innovative Data Systems Research (CIDR)</strong>
   , January 2015.</p>
<p>
<strong>Summary</strong> | 545
  </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0567</div>
            </div>
        </div>
        <!-- Page 0568 -->
        <div class="chapter" id="page-0568">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>[16] Dennis M. Ritchie and Ken Thompson: “
   <strong>The UNIX Time-Sharing System</strong>
   ،” 
   <strong>Communications of the ACM</strong>
   , volume 17, number 7, pages 365–375, July 1974. 
   <strong>doi</strong>
   : 10.1145/361011.361061</p>
<p>[17] Eric A. Brewer and Joseph M. Hellerstein: “
   <strong>CS262a: Advanced Topics in Computer Systems</strong>
   ،” lecture notes, 
   <strong>University of California, Berkeley</strong>
   , cs.berkeley.edu, August 2011.</p>
<p>[18] Michael Stonebraker: “
   <strong>The Case for Polystores</strong>
   ،” wp.sigmod.org, July 13, 2015.</p>
<p>[19] Jennie Duggan, Aaron J. Elmore, Michael Stonebraker, et al.: “
   <strong>The BigDAWG Polystore System</strong>
   ،” 
   <strong>ACM SIGMOD Record</strong>
   , volume 44, number 2, pages 11–16, June 2015. 
   <strong>doi</strong>
   :10.1145/2814710.2814713</p>
<p>[20] Patrycja Dybka: “
   <strong>Foreign Data Wrappers for PostgreSQL</strong>
   ،” vertabelo.com, March 24, 2015.</p>
<p>[21] David B. Lomet, Alan Fekete, Gerhard Weikum, and Mike Zwilling: “
   <strong>Unbundling Transaction Services in the Cloud</strong>
   ،” at 4th 
   <strong>Biennial Conference on Innovative Data Systems Research (CIDR)</strong>
   , January 2009.</p>
<p>[22] Martin Kleppmann and Jay Kreps: “
   <strong>Kafka, Samza and the Unix Philosophy of Distributed Data</strong>
   ،” 
   <strong>IEEE Data Engineering Bulletin</strong>
   , volume 38, number 4, pages 4–14, December 2015.</p>
<p>[23] John Hugg: “
   <strong>Winning Now and in the Future: Where VoltDB Shines</strong>
   ،” voltdb.com, March 23, 2016.</p>
<p>[24] Frank McSherry, Derek G. Murray, Rebecca Isaacs, and Michael Isard: “
   <strong>Differential Dataflow</strong>
   ،” at 6th 
   <strong>Biennial Conference on Innovative Data Systems Research (CIDR)</strong>
   , January 2013.</p>
<p>[25] Derek G Murray, Frank McSherry, Rebecca Isaacs, et al.: “
   <strong>Naiad: A Timely Dataflow System</strong>
   ،” at 24th 
   <strong>ACM Symposium on Operating Systems Principles (SOSP)</strong>
   , pages 439–455, November 2013. 
   <strong>doi</strong>
   :10.1145/2517349.2522738</p>
<p>[26] Gwen Shapira: “
   <strong>We have a bunch of customers who are implementing ‘database inside-out’ concept and they all ask ‘is anyone else doing it? are we crazy?</strong>
   ،” twitter.com, July 28, 2016.</p>
<p>[27] Martin Kleppmann: “
   <strong>Turning the Database Inside-out with Apache Samza</strong>
   ،” at 
   <strong>Strange Loop</strong>
   , September 2014.</p>
<p>[28] Peter Van Roy and Seif Haridi: 
   <strong>Concepts, Techniques, and Models of Computer Programming</strong>
   . 
   <strong>MIT Press</strong>
   , 2004. 
   <strong>ISBN</strong>: 978-0-262-22069-9</p>
<p>[29] “
   <strong>Juttle Documentation</strong>
   ،” juttle.github.io, 2016.</p>
<p>
<strong>Summary</strong> | 546
  </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0568</div>
            </div>
        </div>
        <!-- Page 0569 -->
        <div class="chapter" id="page-0569">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>[30] Evan Czaplicki and Stephen Chong: “
   <strong>Asynchronous Functional Reactive Programming for GUIs</strong>
   ،” at 34th 
   <strong>ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI)</strong>
   , June 2013. 
   <strong>doi</strong>
   :10.1145/2491956.2462161</p>
<p>[31] Engineer Bainomugisha, Andoni Lombide Carreton, Tom van Cutsem, Stijn
   Mostinckx, and Wolfgang de Meuter: “
   <strong>A Survey on Reactive Programming</strong>
   ،” 
   <strong>ACM Computing Surveys</strong>
   , volume 45, number 4, pages 1–34, August 2013. 
   <strong>doi</strong>
   :10.1145/2501654.2501666</p>
<p>[32] Peter Alvaro, Neil Conway, Joseph M. Hellerstein, and William R. Marczak:
   “
   <strong>Consistency Analysis in Bloom: A CALM and Collected Approach</strong>
   ،” at 5th 
   <strong>Biennial Conference on Innovative Data Systems Research (CIDR)</strong>
   , January 2011.</p>
<p>[33] Felienne Hermans: “
   <strong>Spreadsheets Are Code</strong>
   ،” at 
   <strong>Code Mesh</strong>
   , November 2015.</p>
<p>[34] Dan Bricklin and Bob Frankston: “
   <strong>VisiCalc: Information from Its Creators</strong>
   ،” danbricklin.com.</p>
<p>[35] D. Sculley, Gary Holt, Daniel Golovin, et al.: “
   <strong>Machine Learning: The High-Interest Credit Card of Technical Debt</strong>
   ،” at 
   <strong>NIPS Workshop on Software Engineering for Machine Learning (SE4ML)</strong>
   , December 2014.</p>
<p>[36] Peter Bailis, Alan Fekete, Michael J Franklin, et al.: “
   <strong>Feral Concurrency Control: An Empirical Investigation of Modern Application Integrity</strong>
   ،” at 
   <strong>ACM International Conference on Management of Data (SIGMOD)</strong>
   , June 2015. 
   <strong>doi</strong>
   :10.1145/2723372.2737784</p>
<p>[37] Guy Steele: “
   <strong>Re: Need for Macros (Was Re: Icon)</strong>
   ،” email to ll1-discuss mailing list, people.csail.mit.edu, December 24, 2001.</p>
<p>[38] David Gelernter: “
   <strong>Generative Communication in Linda</strong>
   ،” 
   <strong>ACM Transactions on Programming Languages and Systems (TOPLAS)</strong>
   , volume 7, number 1, pages 80–112, January 1985. 
   <strong>doi</strong>
   :10.1145/2363.2433</p>
<p>[39] Patrick Th. Eugster, Pascal A. Felber, Rachid Guerraoui, and Anne-Marie Ker‐
   marrec: “
   <strong>The Many Faces of Publish/Subscribe</strong>
   ،” 
   <strong>ACM Computing Surveys</strong>
   , volume 35, number 2, pages 114–131, June 2003. 
   <strong>doi</strong>
   :10.1145/857076.857078</p>
<p>[40] Ben Stopford: “
   <strong>Microservices in a Streaming World</strong>
   ،” at 
   <strong>QCon London</strong>
   , March 2016.</p>
<p>[41] Christian Posta: “
   <strong>Why Microservices Should Be Event Driven: Autonomy vs Authority</strong>
   ،” blog.christianposta.com, May 27, 2016.</p>
<p>[42] Alex Feyerke: “
   <strong>Say Hello to Offline First</strong>
   ،” hood.ie, November 5, 2013.</p>
<p>[43] Sebastian Burckhardt, Daan Leijen, Jonathan Protzenko, and Manuel Fähndrich:
   “
   <strong>Global Sequence Protocol: A Robust Abstraction for Replicated Shared State</strong>
   ،” at ...</p>
<p>
<strong>Summary</strong> | 547
  </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0569</div>
            </div>
        </div>
        <!-- Page 0570 -->
        <div class="chapter" id="page-0570">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>[44] Mark Soper: “
   <strong>Clearing Up React Data Management Confusion with Flux, Redux, and Relay</strong>
   ،” medium.com, December 3, 2015.</p>
<p>[45] Eno Thereska, Damian Guy, Michael Noll, and Neha Narkhede: “
   <strong>Unifying Stream Processing and Interactive Queries in Apache Kafka</strong>
   ،” confluent.io, October 26, 2016.</p>
<p>[46] Frank McSherry: “
   <strong>Dataflow as Database</strong>
   ،” github.com, July 17, 2016.</p>
<p>[47] Peter Alvaro: “
   <strong>I See What You Mean</strong>
   ،” at 
   <strong>Strange Loop</strong>
   , September 2015.</p>
<p>[48] Nathan Marz: “
   <strong>Trident: A High-Level Abstraction for Realtime Computation</strong>
   ،” blog.twitter.com, August 2, 2012.</p>
<p>[49] Edi Bice: “
   <strong>Low Latency Web Scale Fraud Prevention with Apache Samza, Kafka and Friends</strong>
   ،” at 
   <strong>Merchant Risk Council MRC Vegas Conference</strong>
   , March 2016.</p>
<p>[50] Charity Majors: “
   <strong>The Accidental DBA</strong>
   ،” charity.wtf, October 2, 2016.</p>
<p>[51] Arthur J. Bernstein, Philip M. Lewis, and Shiyong Lu: “
   <strong>Semantic Conditions for Correctness at Different Isolation Levels</strong>
   ،” at 16th 
   <strong>International Conference on Data Engineering (ICDE)</strong>
   , February 2000. 
   <strong>doi</strong>
   :10.1109/ICDE.2000.839387</p>
<p>[52] Sudhir Jorwekar, Alan Fekete, Krithi Ramamritham, and S. Sudarshan: “
   <strong>Automating the Detection of Snapshot Isolation Anomalies</strong>
   ،” at 33rd 
   <strong>International Conference on Very Large Data Bases (VLDB)</strong>
   , September 2007.</p>
<p>[53] Kyle Kingsbury: 
   <strong>Jepsen blog post series</strong>
   , aphyr.com, 2013–2016.</p>
<p>[54] Michael Jouravlev: “
   <strong>Redirect After Post</strong>
   ،” theserverside.com, August 1, 2004.</p>
<p>[55] Jerome H. Saltzer, David P. Reed, and David D. Clark: “
   <strong>End-to-End Arguments in System Design</strong>
   ،” 
   <strong>ACM Transactions on Computer Systems</strong>
   , volume 2, number 4, pages 277–288, November 1984. 
   <strong>doi</strong>
   :10.1145/357401.357402</p>
<p>[56] Peter Bailis, Alan Fekete, Michael J. Franklin, et al.: “
   <strong>Coordination-Avoiding Database Systems</strong>
   ،” 
   <strong>Proceedings of the VLDB Endowment</strong>
   , volume 8, number 3, pages 185–196, November 2014.</p>
<p>[57] Alex Yarmula: “
   <strong>Strong Consistency in Manhattan</strong>
   ،” blog.twitter.com, March 17, 2016.</p>
<p>[58] Douglas B Terry, Marvin M Theimer, Karin Petersen, et al.: “
   <strong>Managing Update Conflicts in Bayou, a Weakly Connected Replicated Storage System</strong>
   ،” at 15th 
   <strong>ACM Symposium on Operating Systems Principles (SOSP)</strong>
   , pages 172–182, December 1995. 
   <strong>doi</strong>
   :10.1145/224056.224070</p>
<p>548 | فصل 12: آینده سیستم‌های 
   <strong>Data</strong>
</p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0570</div>
            </div>
        </div>
        <!-- Page 0571 -->
        <div class="chapter" id="page-0571">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>[59] Jim Gray: “
   <strong>The Transaction Concept: Virtues and Limitations</strong>
   ،” at 7th 
   <strong>International Conference on Very Large Data Bases (VLDB)</strong>
   , September 1981.</p>
<p>[60] Hector Garcia-Molina and Kenneth Salem: “
   <strong>Sagas</strong>
   ،” at 
   <strong>ACM International Conference on Management of Data (SIGMOD)</strong>
   , May 1987. 
   <strong>doi</strong>
   :10.1145/38713.38742</p>
<p>[61] Pat Helland: “
   <strong>Memories, Guesses, and Apologies</strong>
   ،” blogs.msdn.com, May 15, 2007.</p>
<p>[62] Yoongu Kim, Ross Daly, Jeremie Kim, et al.: “
   <strong>Flipping Bits in Memory Without Accessing Them: An Experimental Study of DRAM Disturbance Errors</strong>
   ،” at 41st 
   <strong>Annual International Symposium on Computer Architecture (ISCA)</strong>
   , June 2014. 
   <strong>doi</strong>
   :10.1145/2678373.2665726</p>
<p>[63] Mark Seaborn and Thomas Dullien: “
   <strong>Exploiting the DRAM Rowhammer Bug to Gain Kernel Privileges</strong>
   ،” googleprojectzero.blogspot.co.uk, March 9, 2015.</p>
<p>[64] Jim N. Gray and Catharine van Ingen: “
   <strong>Empirical Measurements of Disk Failure Rates and Error Rates</strong>
   ،” 
   <strong>Microsoft Research</strong>
   , 
   <strong>MSR-TR-2005-166</strong>
   , December 2005.</p>
<p>[65] Annamalai Gurusami and Daniel Price: “
   <strong>Bug #73170: Duplicates in Unique Secondary Index Because of Fix of Bug#68021</strong>
   ،” bugs.mysql.com, July 2014.</p>
<p>[66] Gary Fredericks: “
   <strong>Postgres Serializability Bug</strong>
   ،” github.com, September 2015.</p>
<p>[67] Xiao Chen: “
   <strong>HDFS DataNode Scanners and Disk Checker Explained</strong>
   ،” blog.cloudera.com, December 20, 2016.</p>
<p>[68] Jay Kreps: “
   <strong>Getting Real About Distributed System Reliability</strong>
   ،” blog.empathybox.com, March 19, 2012.</p>
<p>[69] Martin Fowler: “
   <strong>The LMAX Architecture</strong>
   ،” martinfowler.com, July 12, 2011.</p>
<p>[70] Sam Stokes: “
   <strong>Move Fast with Confidence</strong>
   ،” blog.samstokes.co.uk, July 11, 2016.</p>
<p>[71] “
   <strong>Sawtooth Lake Documentation</strong>
   ،” 
   <strong>Intel Corporation</strong>
   , intelledger.github.io, 2016.</p>
<p>[72] Richard Gendal Brown: “
   <strong>Introducing R3 Corda™: A Distributed Ledger Designed for Financial Services</strong>
   ،” gendal.me, April 5, 2016.</p>
<p>[73] Trent McConaghy, Rodolphe Marques, Andreas Müller, et al.: “
   <strong>BigchainDB: A Scalable Blockchain Database</strong>
   ،” bigchaindb.com, June 8, 2016.</p>
<p>[74] Ralph C. Merkle: “
   <strong>A Digital Signature Based on a Conventional Encryption Function</strong>
   ،” at 
   <strong>CRYPTO ’87</strong>
   , August 1987. 
   <strong>doi</strong>
   :10.1007/3-540-48184-2_32</p>
<p>[75] Ben Laurie: “
   <strong>Certificate Transparency</strong>
   ،” 
   <strong>ACM Queue</strong>
   , volume 12, number 8, pages 10-19, August 2014. 
   <strong>doi</strong>
   :10.1145/2668152.2668154</p>
<p>
<strong>Summary</strong> | 549
  </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0571</div>
            </div>
        </div>
        <!-- Page 0572 -->
        <div class="chapter" id="page-0572">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>[76] Mark D. Ryan: “
   <strong>Enhanced Certificate Transparency and End-to-End Encrypted Mail</strong>
   ،” at 
   <strong>Network and Distributed System Security Symposium (NDSS)</strong>
   , February 2014. 
   <strong>doi</strong>
   :10.14722/ndss.2014.23379</p>
<p>[77] “
   <strong>Software Engineering Code of Ethics and Professional Practice</strong>
   ،” 
   <strong>Association for Computing Machinery</strong>
   , acm.org, 1999.</p>
<p>[78] François Chollet: “
   <strong>Software development is starting to involve important ethical choices</strong>
   ،” twitter.com, October 30, 2016.</p>
<p>[79] Igor Perisic: “
   <strong>Making Hard Choices: The Quest for Ethics in Machine Learning</strong>
   ،” engineering.linkedin.com, November 2016.</p>
<p>[80] John Naughton: “
   <strong>Algorithm Writers Need a Code of Conduct</strong>
   ،” theguardian.com, December 6, 2015.</p>
<p>[81] Logan Kugler: “
   <strong>What Happens When Big Data Blunders?</strong>
   ،” 
   <strong>Communications of the ACM</strong>
   , volume 59, number 6, pages 15–16, June 2016. 
   <strong>doi</strong>
   :10.1145/2911975</p>
<p>[82] Bill Davidow: “
   <strong>Welcome to Algorithmic Prison</strong>
   ،” theatlantic.com, February 20, 2014.</p>
<p>[83] Don Peck: “
   <strong>They’re Watching You at Work</strong>
   ،” theatlantic.com, December 2013.</p>
<p>[84] Leigh Alexander: “
   <strong>Is an Algorithm Any Less Racist Than a Human?</strong>
   ،” theguardian.com, August 3, 2016.</p>
<p>[85] Jesse Emspak: “
   <strong>How a Machine Learns Prejudice</strong>
   ،” scientificamerican.com, December 29, 2016.</p>
<p>[86] Maciej Cegłowski: “
   <strong>The Moral Economy of Tech</strong>
   ،” idlewords.com, June 2016.</p>
<p>[87] Cathy O’Neil: 
   <strong>Weapons of Math Destruction: How Big Data Increases Inequality and Threatens Democracy</strong>
   . 
   <strong>Crown Publishing</strong>
   , 2016. 
   <strong>ISBN</strong>: 978-0-553-41881-1</p>
<p>[88] Julia Angwin: “
   <strong>Make Algorithms Accountable</strong>
   ،” nytimes.com, August 1, 2016.</p>
<p>[89] Bryce Goodman and Seth Flaxman: “
   <strong>European Union Regulations on Algorithmic Decision-Making and a ‘Right to Explanation’</strong>
   ،” 
   <strong>arXiv</strong>
   :1606.08813, August 31, 2016.</p>
<p>[90] “
   <strong>A Review of the Data Broker Industry: Collection, Use, and Sale of Consumer Data for Marketing Purposes</strong>
   ،” 
   <strong>Staff Report</strong>
   , 
   <strong>United States Senate Committee on Commerce, Science, and Transportation</strong>
   , commerce.senate.gov, December 2013.</p>
<p>[91] Olivia Solon: “
   <strong>Facebook’s Failure: Did Fake News and Polarized Politics Get Trump Elected?</strong>
   ،” theguardian.com, November 10, 2016.</p>
<p>[92] Donella H. Meadows and Diana Wright: 
   <strong>Thinking in Systems: A Primer</strong>
   . 
   <strong>Chelsea Green Publishing</strong>
   , 2008. 
   <strong>ISBN</strong>: 978-1-603-58055-7</p>
<p>550 | فصل 12: آینده سیستم‌های 
   <strong>Data</strong>
</p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0572</div>
            </div>
        </div>
        <!-- Page 0573 -->
        <div class="chapter" id="page-0573">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>[93] Daniel J. Bernstein: “
   <strong>Listening to a ‘big data’/‘data science’ talk</strong>
   ،” twitter.com, May 12, 2015.</p>
<p>[94] Marc Andreessen: “
   <strong>Why Software Is Eating the World</strong>
   ،” 
   <strong>The Wall Street Journal</strong>
   , 20 August 2011.</p>
<p>[95] J. M. Porup: “‘
   <strong>Internet of Things’ Security Is Hilariously Broken and Getting Worse</strong>
   ،” arstechnica.com, January 23, 2016.</p>
<p>[96] Bruce Schneier: 
   <strong>Data and Goliath: The Hidden Battles to Collect Your Data and Control Your World</strong>
   . 
   <strong>W. W. Norton</strong>
   , 2015. 
   <strong>ISBN</strong>: 978-0-393-35217-7</p>
<p>[97] 
   <strong>The Grugq</strong>
   : “
   <strong>Nothing to Hide</strong>
   ،” grugq.tumblr.com, April 15, 2016.</p>
<p>[98] Tony Beltramelli: “
   <strong>Deep-Spying: Spying Using Smartwatch and Deep Learning</strong>
   ،” 
   <strong>Masters Thesis</strong>
   , 
   <strong>IT University of Copenhagen</strong>
   , December 2015. Available at arxiv.org/abs/1512.05616</p>
<p>[99] Shoshana Zuboff: “
   <strong>Big Other: Surveillance Capitalism and the Prospects of an Information Civilization</strong>
   ،” 
   <strong>Journal of Information Technology</strong>
   , volume 30, number 1, pages 75–89, April 2015. 
   <strong>doi</strong>
   :10.1057/jit.2015.5</p>
<p>[100] Carina C. Zona: “
   <strong>Consequences of an Insightful Algorithm</strong>
   ،” at 
   <strong>GOTO Berlin</strong>
   , November 2016.</p>
<p>[101] Bruce Schneier: “
   <strong>Data Is a Toxic Asset, So Why Not Throw It Out?</strong>
   ،” schneier.com, March 1, 2016.</p>
<p>[102] John E. Dunn: “
   <strong>The UK’s 15 Most Infamous Data Breaches</strong>
   ،” techworld.com, November 18, 2016.</p>
<p>[103] Cory Scott: “
   <strong>Data is not toxic - which implies no benefit - but rather hazardous material, where we must balance need vs. want</strong>
   ،” twitter.com, March 6, 2016.</p>
<p>[104] Bruce Schneier: “
   <strong>Mission Creep: When Everything Is Terrorism</strong>
   ،” schneier.com, July 16, 2013.</p>
<p>[105] Lena Ulbricht and Maximilian von Grafenstein: “
   <strong>Big Data: Big Power Shifts?</strong>
   ،” 
   <strong>Internet Policy Review</strong>
   , volume 5, number 1, March 2016. 
   <strong>doi</strong>
   :10.14763/2016.1.406</p>
<p>[106] Ellen P. Goodman and Julia Powles: “
   <strong>Facebook and Google: Most Powerful and Secretive Empires We’ve Ever Known</strong>
   ،” theguardian.com, September 28, 2016.</p>
<p>[107] 
   <strong>Directive 95/46/EC on the protection of individuals with regard to the processing of personal data and on the free movement of such data</strong>
   , 
   <strong>Official Journal of the European Communities No. L 281/31</strong>
   , eur-lex.europa.eu, November 1995.</p>
<p>[108] Brendan Van Alsenoy: “
   <strong>Regulating Data Protection: The Allocation of Responsibility and Risk Among Actors Involved in Personal Data Processing</strong>
   ،” 
   <strong>Thesis</strong>
   , 
   <strong>KU Leuven Centre for IT and IP Law</strong>
   , August 2016.</p>
<p>
<strong>Summary</strong> | 551
  </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0573</div>
            </div>
        </div>
        <!-- Page 0574 -->
        <div class="chapter" id="page-0574">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>[109] Michiel Rhoen: “
   <strong>Beyond Consent: Improving Data Protection Through Consumer Protection Law</strong>
   ،” 
   <strong>Internet Policy Review</strong>
   , volume 5, number 1, March 2016. 
   <strong>doi</strong>
   :10.14763/2016.1.404</p>
<p>[110] Jessica Leber: “
   <strong>Your Data Footprint Is Affecting Your Life in Ways You Can’t Even Imagine</strong>
   ،” fastcoexist.com, March 15, 2016.</p>
<p>[111] Maciej Cegłowski: “
   <strong>Haunted by Data</strong>
   ،” idlewords.com, October 2015.</p>
<p>[112] Sam Thielman: “
   <strong>You Are Not What You Read: Librarians Purge User Data to Protect Privacy</strong>
   ،” theguardian.com, January 13, 2016.</p>
<p>[113] Conor Friedersdorf: “
   <strong>Edward Snowden’s Other Motive for Leaking</strong>
   ،” theatlantic.com, May 13, 2014.</p>
<p>[114] Phillip Rogaway: “
   <strong>The Moral Character of Cryptographic Work</strong>
   ،” 
   <strong>Cryptology ePrint</strong>
   2015/1162, December 2015.</p>
<p>552 | فصل 12: آینده سیستم‌های 
   <strong>Data</strong>
</p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0574</div>
            </div>
        </div>
        <!-- Page 0575 -->
        <div class="chapter" id="page-0575">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<h4>واژه‌نامه</h4>
<p>لطفاً توجه داشته باشید که تعاریف موجود در این واژه‌نامه کوتاه و ساده هستند، و هدف از آن انتقال ایده اصلی است، نه ظرافت‌های کامل یک اصطلاح. برای اطلاعات بیشتر، لطفاً مراجع را در متن اصلی دنبال کنید.</p>
<p>
<strong>asynchronous</strong>
</p>
<p>منتظر کامل شدن چیزی نیست</p>
<p>(به عنوان مثال، ارسال 
   <strong>data</strong>
   از طریق شبکه به</p>
<p>یک گره دیگر)، و هیچ فرضی در مورد اینکه</p>
<p>چقدر طول می‌کشد تا انجام شود، ندارد.</p>
<p>به "
   <strong>Synchronous Versus Asynchronous Replication</strong>
   " در صفحه 153، "
   <strong>Synchronous Versus Asynchronous Networks</strong>
   " در</p>
<p>صفحه 284، و "
   <strong>System Model and Reality</strong>
   " در</p>
<p>صفحه 306 مراجعه کنید.</p>
<p>
<strong>atomic</strong>
</p>
<p>1. در زمینه عملیات همزمان: توصیف یک عملیات که به نظر می‌رسد</p>
<p>در یک نقطه واحد در زمان اثر می‌گذارد، بنابراین</p>
<p>یک فرآیند همزمان دیگر هرگز نمی‌تواند</p>
<p>عملیات را در حالت "نیمه‌تمام" مشاهده کند.</p>
<p>همچنین به 
   <strong>isolation</strong>
   مراجعه کنید.</p>
<p>2. در زمینه تراکنش‌ها: گروه‌بندی</p>
<p>مجموعه‌ای از نوشته‌ها که یا همه آنها باید</p>
<p>تعهد داده شوند یا همه آنها باید بازگردانده شوند، حتی اگر</p>
<p>خطاها رخ دهند. به "
   <strong>Atomicity</strong>
   " در صفحه 223</p>
<p>و "
   <strong>Atomic Commit and Two-Phase Commit (2PC)</strong>
   " در</p>
<p>صفحه 354 مراجعه کنید.</p>
<p>
<strong>backpressure</strong>
</p>
<p>وادار کردن فرستنده برخی از 
   <strong>data</strong>
   ها به کاهش سرعت</p>
<p>به این دلیل که گیرنده نمی‌تواند با آن هماهنگ باشد. همچنین به عنوان کنترل جریان شناخته می‌شود. به</p>
<p>"
   <strong>Messaging Systems</strong>
   " در صفحه 441 مراجعه کنید.</p>
<p>
<strong>batch process</strong>
</p>
<p>محاسباتی که مجموعه‌ای ثابت (و</p>
<p>معمولاً بزرگ) از 
   <strong>data</strong>
   را به عنوان ورودی دریافت می‌کند و</p>
<p>برخی دیگر از 
   <strong>data</strong>
   ها را به عنوان خروجی تولید می‌کند، بدون</p>
<p>تغییر ورودی. به فصل 10 مراجعه کنید.</p>
<p>
<strong>bounded</strong>
</p>
<p>داشتن برخی از محدودیت‌های بالایی یا اندازه مشخص. به عنوان مثال، در زمینه</p>
<p>تاخیر شبکه استفاده می‌شود (به "
   <strong>Timeouts and Unbounded Delays</strong>
   " در صفحه 281 مراجعه کنید) و مجموعه‌داده‌ها</p>
<p>(به مقدمه فصل 11 مراجعه کنید).</p>
<p>
<strong>Byzantine fault</strong>
</p>
<p>یک گره که به روشی نادرست رفتار می‌کند، به عنوان مثال با ارسال</p>
<p>پیام‌های متناقض یا مخرب به</p>
<p>سایر گره‌ها. به "
   <strong>Byzantine Faults</strong>
   " در</p>
<p>صفحه 304 مراجعه کنید.</p>
<p>
<strong>cache</strong>
</p>
<p>مؤلفه‌ای که 
   <strong>data</strong>
   های اخیراً استفاده شده را به خاطر می‌آورد تا خوانش‌های آینده از همان</p>
<p>
<strong>data</strong>
   را سرعت بخشد. به طور کلی کامل نیست: بنابراین، اگر 
   <strong>data</strong>
   ای در 
   <strong>cache</strong>
   وجود نداشته باشد، باید از</p>
<p>برخی از ذخیره‌سازی 
   <strong>data</strong>
   اساسی و کندتر</p>
<p>واکشی شود.</p>
<p>
<strong>Glossary</strong> | 553
  </p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 575" src="page_0575/image_1.png"/></div>
</div>
                <div class="page-number">صفحه 0575</div>
            </div>
        </div>
        <!-- Page 0576 -->
        <div class="chapter" id="page-0576">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>سیستمی که یک کپی کامل از</p>
<p>
<strong>data</strong>
   را دارد.</p>
<p>
<strong>CAP theorem</strong>
</p>
<p>یک نتیجه نظری که به طور گسترده اشتباه فهمیده شده است</p>
<p>که در عمل مفید نیست. به "
   <strong>The CAP theorem</strong>
   " در صفحه 336 مراجعه کنید.</p>
<p>
<strong>causality</strong>
</p>
<p>وابستگی بین رویدادهایی که به وجود می‌آیند زمانی که یک</p>
<p>چیز "قبل از" چیز دیگری در یک سیستم "اتفاق می‌افتد". به عنوان مثال، یک</p>
<p>رویداد بعدی که در پاسخ به یک رویداد قبلی است، یا بر اساس یک رویداد قبلی ساخته می‌شود، یا</p>
<p>باید در پرتو یک</p>
<p>رویداد قبلی درک شود. به "رابطه "
   <strong>happens-before</strong>
   " و همزمانی" در صفحه</p>
<p>186 و "
   <strong>Ordering and Causality</strong>
   " در صفحه</p>
<p>339 مراجعه کنید.</p>
<p>
<strong>consensus</strong>
</p>
<p>یک مشکل اساسی در محاسبات توزیع‌شده، مربوط به گرفتن چندین</p>
<p>گره برای توافق بر سر چیزی (به عنوان مثال، کدام گره باید سرپرست برای یک</p>
<p>خوشه 
   <strong>database</strong>
   باشد). این مشکل بسیار بیشتر است</p>
<p>از آنچه در نگاه اول به نظر می‌رسد. به</p>
<p>"
   <strong>Fault-Tolerant Consensus</strong>
   " در صفحه 364 مراجعه کنید.</p>
<p>
<strong>data warehouse</strong>
</p>
<p>یک 
   <strong>database</strong>
   که در آن 
   <strong>data</strong>
   از چندین 
   <strong>system</strong>
   های مختلف 
   <strong>OLTP</strong>
   ترکیب شده است</p>
<p>و برای استفاده در اهداف تحلیلی آماده شده است. به "
   <strong>Data Warehousing</strong>
   " در صفحه</p>
<p>91 مراجعه کنید.</p>
<p>
<strong>declarative</strong>
</p>
<p>توصیف ویژگی‌هایی که یک چیز باید داشته باشد، اما نه مراحل دقیق برای</p>
<p>چگونگی دستیابی به آن. در زمینه پرسش‌ها، یک بهینه‌ساز پرس و جو یک</p>
<p>پرس و جوی اعلانی را دریافت می‌کند و تصمیم می‌گیرد که چگونه باید به بهترین شکل اجرا شود. به "
   <strong>Query Languages for Data</strong>
   " در</p>
<p>صفحه 42 مراجعه کنید.</p>
<p>
<strong>denormalize</strong>
</p>
<p>برای معرفی مقداری افزونگی یا تکرار در یک</p>
<p>مجموعه داده نرمال شده، معمولاً در قالب یک 
   <strong>cache</strong>
   یا</p>
<p>شاخص، به منظور سرعت بخشیدن به خواندن. A</p>
<p>مقدار 
   <strong>denormalized</strong>
   نوعی نتیجه 
   <strong>query</strong>
   از پیش محاسبه شده است، شبیه به یک</p>
<p>
<strong>view</strong>
   مادی‌شده. به "
   <strong>Single-Object and Multi-Object Operations</strong>
   " در صفحه 228 و</p>
<p>"
   <strong>Deriving several views from the same event log</strong>
   " در صفحه 461 مراجعه کنید.</p>
<p>
<strong>derived data</strong>
</p>
<p>یک مجموعه داده که از برخی دیگر ایجاد شده است</p>
<p>
<strong>data</strong>
   از طریق یک فرآیند تکرارپذیر، که</p>
<p>در صورت لزوم می‌توانید دوباره اجرا کنید. معمولاً،</p>
<p>
<strong>derived data</strong>
   برای سرعت بخشیدن به یک قسمت خاص نیاز است</p>
<p>از دسترسی خواندن به 
   <strong>data</strong>
   . شاخص‌ها، 
   <strong>caches</strong>
   ، و 
   <strong>views</strong>
   مادی شده</p>
<p>نمونه‌هایی از 
   <strong>derived data</strong>
   هستند. به</p>
<p>مقدمه قسمت سوم مراجعه کنید.</p>
<p>
<strong>deterministic</strong>
</p>
<p>توصیف یک تابع که همیشه</p>
<p>در صورت ارائه ورودی یکسان، خروجی یکسانی تولید می‌کند. این بدان معناست که نمی‌تواند وابسته باشد</p>
<p>به اعداد تصادفی، زمان روز، شبکه</p>
<p>ارتباطات، یا موارد غیرقابل پیش‌بینی دیگر.</p>
<p>
<strong>distributed</strong>
</p>
<p>اجرا در چندین گره متصل شده توسط یک</p>
<p>شبکه. با شکست‌های جزئی مشخص می‌شود:</p>
<p>ممکن است بخشی از سیستم خراب شود</p>
<p>در حالی که سایر قسمت‌ها هنوز در حال کار هستند، و آن</p>
<p>اغلب برای 
   <strong>software</strong>
   غیرممکن است که بداند</p>
<p>دقیقاً چه چیزی خراب شده است. به "
   <strong>Faults and Partial Failures</strong>
   " در صفحه 274 مراجعه کنید.</p>
<p>
<strong>durable</strong>
</p>
<p>ذخیره 
   <strong>data</strong>
   به گونه‌ای که</p>
<p>اعتقاد دارید که از دست نخواهد رفت، حتی اگر موارد مختلف</p>
<p>خطا رخ دهد. به "
   <strong>Durability</strong>
   " در صفحه 226 مراجعه کنید.</p>
<p>
<strong>ETL</strong>
</p>
<p>
<strong>Extract–Transform–Load</strong>
   . فرآیند</p>
<p>استخراج 
   <strong>data</strong>
   از یک 
   <strong>source database</strong>
   ،</p>
<p>تبدیل آن به شکلی که بیشتر است</p>
<p>مناسب برای پرس و جوهای تحلیلی، و بارگذاری آن است</p>
<p>به یک 
   <strong>data warehouse</strong>
   یا سیستم پردازش 
   <strong>batch</strong>
   . به "
   <strong>Data Warehousing</strong>
   " در صفحه</p>
<p>91 مراجعه کنید.</p>
<p>
<strong>failover</strong>
</p>
<p>در سیستم‌هایی که یک سرپرست دارند، 
   <strong>failover</strong>
   فرآیند انتقال است</p>
<p>نقش سرپرستی از یک گره به گره دیگر. به</p>
<p>"
   <strong>Handling Node Outages</strong>
   " در صفحه 156 مراجعه کنید.</p>
<p>
<strong>CAP theorem</strong>
</p>
<p>554 | واژه نامه</p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0576</div>
            </div>
        </div>
        <!-- Page 0577 -->
        <div class="chapter" id="page-0577">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
<strong>fault-tolerant</strong>
</p>
<p>قادر به بازیابی خودکار در صورت بروز مشکل</p>
<p>(به عنوان مثال، اگر یک ماشین</p>
<p>خراب شود یا یک اتصال شبکه از کار بیفتد). به "
   <strong>Reli-</strong>
</p>
<p>
<strong>ability</strong>
   " در صفحه 6 مراجعه کنید.</p>
<p>
<strong>flow control</strong>
</p>
<p>به 
   <strong>backpressure</strong>
   مراجعه کنید.</p>
<p>
<strong>follower</strong>
</p>
<p>یک 
   <strong>replica</strong>
   که مستقیماً هیچ</p>
<p>نوشته‌ای را از کلاینت‌ها نمی‌پذیرد، بلکه فقط</p>
<p>تغییرات 
   <strong>data</strong>
   را که از یک 
   <strong>leader</strong>
   دریافت می‌کند، پردازش می‌کند.</p>
<p>همچنین به عنوان یک 
   <strong>secondary, slave, read</strong>
</p>
<p>
<strong>replica</strong>
   ، یا 
   <strong>hot standby</strong>
   شناخته می‌شود. به "
   <strong>Leaders and</strong>
</p>
<p>
<strong>Followers</strong>
   " در صفحه 152 مراجعه کنید.</p>
<p>
<strong>full-text search</strong>
</p>
<p>جستجوی متن با کلمات کلیدی دلخواه،</p>
<p>اغلب با ویژگی‌های اضافی مانند</p>
<p>مطابقت با کلمات یا مترادف‌های مشابه. یک شاخص متن کامل نوعی شاخص است.</p>
<p>شاخص ثانویه است که از چنین پرس و جوهایی پشتیبانی می‌کند. به</p>
<p>"
   <strong>Full-text search and fuzzy indexes</strong>
   " در</p>
<p>صفحه 88 مراجعه کنید.</p>
<p>
<strong>graph</strong>
</p>
<p>یک ساختار 
   <strong>data</strong>
   که از راس تشکیل شده است</p>
<p>(چیزهایی که می‌توانید به آنها ارجاع دهید، که همچنین</p>
<p>به عنوان گره یا موجودیت شناخته می‌شوند) و لبه‌ها (اتصالات</p>
<p>از یک راس به دیگری، همچنین</p>
<p>به عنوان روابط یا کمان‌ها شناخته می‌شوند). ببینید</p>
<p>"
   <strong>Graph-Like Data Models</strong>
   " در صفحه 49.</p>
<p>
<strong>hash</strong>
</p>
<p>تابعی که یک ورودی را به یک</p>
<p>عدد با ظاهر تصادفی تبدیل می‌کند. همان ورودی</p>
<p>همیشه همان عدد را به عنوان خروجی برمی‌گرداند.</p>
<p>دو ورودی مختلف احتمالاً دو عدد مختلف را به عنوان خروجی دارند،</p>
<p>اگرچه این امکان وجود دارد که دو ورودی مختلف خروجی یکسانی تولید کنند (این است</p>
<p>یک برخورد نامیده می‌شود). به "
   <strong>Partitioning by</strong>
</p>
<p>
<strong>Hash of Key</strong>
   " در صفحه 203 مراجعه کنید.</p>
<p>
<strong>idempotent</strong>
</p>
<p>توصیف یک عملیات که می‌تواند با خیال راحت دوباره امتحان شود. اگر بیش از یک بار اجرا شود، این</p>
<p>همان اثر را دارد که گویی فقط اجرا شده است</p>
<p>یک بار. به "
   <strong>Idempotence</strong>
   " در صفحه</p>
<p>478 مراجعه کنید.</p>
<p>
<strong>index</strong>
</p>
<p>یک ساختار 
   <strong>data</strong>
   که به شما امکان می‌دهد به طور موثر</p>
<p>برای همه رکوردهایی که دارای یک رکورد هستند، جستجو کنید</p>
<p>مقدار خاصی در یک فیلد خاص. به "
   <strong>Data</strong>
</p>
<p>
<strong>Structures That Power Your Database</strong>
   " در</p>
<p>صفحه 70 مراجعه کنید.</p>
<p>
<strong>isolation</strong>
</p>
<p>در زمینه تراکنش‌ها، توصیف</p>
<p>درجه‌ای که تراکنش‌های همزمان اجرا می‌شوند</p>
<p>می‌توانند با یکدیگر تداخل داشته باشند. 
   <strong>isolation</strong>
   قابل سریال‌سازی تضمین‌های قوی‌تری را ارائه می‌دهد، اما 
   <strong>isolation</strong>
   ضعیف‌تر</p>
<p>سطوح نیز استفاده می‌شود. به "
   <strong>Isolation</strong>
   " در</p>
<p>صفحه 225 مراجعه کنید.</p>
<p>
<strong>join</strong>
</p>
<p>برای جمع‌آوری رکوردهایی که چیزی دارند</p>
<p>مشترک است. معمولاً در مواردی استفاده می‌شود که یک رکورد دارای یک</p>
<p>ارجاع به دیگری (یک کلید خارجی، یک سند)</p>
<p>ارجاع، یک لبه در یک 
   <strong>graph</strong>
   ) و a</p>
<p>پرس و جو باید رکوردی را که به آن اشاره می‌کند دریافت کند. به "
   <strong>Many-to-One and</strong>
</p>
<p>
<strong>Many-to-Many Relationships</strong>
   " در صفحه 33</p>
<p>و "
   <strong>Reduce-Side Joins and Grouping</strong>
   " در</p>
<p>صفحه 403 مراجعه کنید.</p>
<p>
<strong>leader</strong>
</p>
<p>وقتی 
   <strong>data</strong>
   یا سرویسی در گره‌های مختلف تکرار می‌شود، 
   <strong>leader</strong>
   . 
   <strong>replica</strong>
   مقرر است که مجاز به ایجاد تغییرات است. آ</p>
<p>
<strong>leader</strong>
   ممکن است از طریق یک پروتکل انتخاب شود، یا</p>
<p>به صورت دستی توسط یک 
   <strong>administrator</strong>
   انتخاب شود. همچنین به عنوان 
   <strong>primary</strong>
   یا</p>
<p>
<strong>master</strong>
   شناخته می‌شود. به "
   <strong>Leaders and Followers</strong>
   " در</p>
<p>صفحه 152 مراجعه کنید.</p>
<p>
<strong>linearizable</strong>
</p>
<p>مانند این است که تنها یک کپی از</p>
<p>
<strong>data</strong>
   در سیستم وجود دارد، که توسط</p>
<p>عملیات اتمی به‌روزرسانی می‌شود. به "
   <strong>Linearizability</strong>
   " در</p>
<p>صفحه 324 مراجعه کنید.</p>
<p>
<strong>locality</strong>
</p>
<p>بهینه‌سازی عملکرد: قرار دادن چند</p>
<p>قطعه 
   <strong>data</strong>
   در یک مکان اگر آنها اغلب مورد نیاز هستند</p>
<p>در همان زمان. به "
   <strong>Data locality for queries</strong>
   " در صفحه 41 مراجعه کنید.</p>
<p>
<strong>locality</strong>
</p>
<p>
<strong>Glossary</strong> | 555
  </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0577</div>
            </div>
        </div>
        <!-- Page 0578 -->
        <div class="chapter" id="page-0578">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
<strong>lock</strong>
</p>
<p>مکانیسمی برای اطمینان از اینکه فقط یک</p>
<p>
<strong>thread</strong>
   ، گره یا تراکنش می‌تواند به</p>
<p>چیزی دسترسی داشته باشد، و هر کس دیگری که می‌خواهد</p>
<p>به همان چیز دسترسی داشته باشد، باید تا زمانی که</p>
<p>
<strong>lock</strong>
   آزاد شود، صبر کند. به "
   <strong>Two-Phase Locking</strong>
   (2PL)" در صفحه 257 و "
   <strong>The leader and</strong>
</p>
<p>
<strong>the lock</strong>
   " در صفحه 301 مراجعه کنید.</p>
<p>
<strong>log</strong>
</p>
<p>یک فایل 
   <strong>append-only</strong>
   برای ذخیره 
   <strong>data</strong>
   . آ</p>
<p>
<strong>write-ahead log</strong>
   برای مقاوم کردن یک موتور ذخیره‌سازی در برابر خرابی‌ها استفاده می‌شود (به "
   <strong>Mak-</strong>
</p>
<p>
<strong>ing B-trees reliable</strong>
   " در صفحه 82 مراجعه کنید)، یک موتور ذخیره‌سازی 
   <strong>log-structured</strong>
   از 
   <strong>logs</strong>
   به عنوان</p>
<p>فرمت ذخیره‌سازی اولیه خود استفاده می‌کند (به "
   <strong>SSTables</strong>
   و 
   <strong>LSM-Trees</strong>
   " در صفحه 76 مراجعه کنید)، یک کپی‌برداری</p>
<p>
<strong>log</strong>
   برای کپی کردن نوشته‌ها از یک 
   <strong>leader</strong>
   به</p>
<p>
<strong>followers</strong>
   استفاده می‌شود (به "
   <strong>Leaders and Followers</strong>
   " در</p>
<p>صفحه 152 مراجعه کنید)، و یک 
   <strong>event log</strong>
   می‌تواند</p>
<p>یک جریان 
   <strong>data</strong>
   را نشان دهد (به "
   <strong>Partitioned Logs</strong>
   " در</p>
<p>صفحه 446 مراجعه کنید).</p>
<p>
<strong>materialize</strong>
</p>
<p>برای انجام یک محاسبه مشتاقانه و</p>
<p>نوشتن نتیجه آن، بر خلاف محاسبه آن</p>
<p>در صورت درخواست. به</p>
<p>"
   <strong>Aggregation: Data Cubes and Material-</strong>
</p>
<p>
<strong>ized Views</strong>
   " در صفحه 101 و "
   <strong>Materializa-</strong>
</p>
<p>
<strong>tion of Intermediate State</strong>
   " در صفحه 419 مراجعه کنید.</p>
<p>
<strong>node</strong>
</p>
<p>نمونه‌ای از یک 
   <strong>software</strong>
   که در حال اجرا است</p>
<p>بر روی یک کامپیوتر، که با</p>
<p>
<strong>nodes</strong>
   دیگر از طریق یک شبکه برای</p>
<p>انجام برخی از کارها ارتباط برقرار می‌کند.</p>
<p>
<strong>normalized</strong>
</p>
<p>به گونه‌ای ساختار یافته که</p>
<p>هیچ افزونگی یا تکراری وجود ندارد. در یک نرمال</p>
<p>
<strong>database</strong>
   ized، هنگامی که برخی از 
   <strong>data</strong>
   ها</p>
<p>تغییر می‌کند، فقط باید آن را در یک</p>
<p>مکان تغییر دهید، نه کپی‌های زیاد در مکان‌های مختلف. به "
   <strong>Many-to-One and Many-to-</strong>
</p>
<p>
<strong>Many Relationships</strong>
   " در صفحه 33 مراجعه کنید.</p>
<p>
<strong>OLAP</strong>
</p>
<p>پردازش تحلیلی آنلاین. الگوی دسترسی</p>
<p>مشخص‌شده با تجمیع (به عنوان مثال، شمارش،</p>
<p>جمع، میانگین) روی تعداد زیادی از</p>
<p>رکوردها. به "
   <strong>Transaction Processing or</strong>
</p>
<p>
<strong>Analytics?</strong>
   " در صفحه 90 مراجعه کنید.</p>
<p>
<strong>OLTP</strong>
</p>
<p>پردازش تراکنش‌های آنلاین. دسترسی</p>
<p>الگوی مشخص شده با پرس و جوهای سریع که</p>
<p>تعداد کمی از رکوردها را می‌خواند یا می‌نویسد،</p>
<p>معمولاً با کلید فهرست‌بندی می‌شود. به "
   <strong>Transaction</strong>
</p>
<p>
<strong>Processing or Analytics?</strong>
   " در صفحه 90 مراجعه کنید.</p>
<p>
<strong>partitioning</strong>
</p>
<p>تقسیم یک مجموعه داده یا محاسبه بزرگ</p>
<p>که برای یک ماشین واحد خیلی بزرگ است به</p>
<p>بخش‌های کوچکتر و پخش آنها در</p>
<p>چندین ماشین. همچنین به عنوان شناخته می‌شود</p>
<p>
<strong>sharding</strong>
   . به فصل 6 مراجعه کنید.</p>
<p>
<strong>percentile</strong>
</p>
<p>راهی برای اندازه‌گیری توزیع</p>
<p>مقادیر با شمارش تعداد مقادیری که هستند</p>
<p>بالاتر یا پایین‌تر از یک آستانه. برای</p>
<p>به عنوان مثال، صدک 95ام زمان پاسخ</p>
<p>در طول یک دوره، زمانی است که</p>
<p>95٪ از درخواست‌ها در آن دوره</p>
<p>در کمتر از 
   <strong>t</strong>
   تکمیل می‌شوند، و 5٪ بیشتر طول می‌کشد</p>
<p>از 
   <strong>t</strong>
   . به "
   <strong>Describing Performance</strong>
   " در</p>
<p>صفحه 13 مراجعه کنید.</p>
<p>
<strong>primary key</strong>
</p>
<p>مقدار (معمولاً یک عدد یا یک رشته)</p>
<p>که یک رکورد را منحصراً شناسایی می‌کند. در بسیاری از</p>
<p>برنامه‌ها، کلیدهای اصلی توسط سیستم تولید می‌شوند</p>
<p>هنگامی که یک رکورد ایجاد می‌شود (به عنوان مثال، متوالی یا تصادفی)؛ آنها هستند</p>
<p>معمولاً توسط کاربران تنظیم نمی‌شوند. همچنین به 
   <strong>secondary</strong>
</p>
<p>
<strong>index</strong>
   مراجعه کنید.</p>
<p>
<strong>quorum</strong>
</p>
<p>حداقل تعداد 
   <strong>nodes</strong>
   که باید</p>
<p>به یک عملیات رای دهند قبل از اینکه بتوان آن را در نظر گرفت</p>
<p>موفق. به "
   <strong>Quorums for reading and writing</strong>
   " در صفحه 179 مراجعه کنید.</p>
<p>
<strong>rebalance</strong>
</p>
<p>برای انتقال 
   <strong>data</strong>
   یا خدمات از یک گره به</p>
<p>دیگری به منظور توزیع منصفانه بار. به "
   <strong>Rebalancing Partitions</strong>
   " در</p>
<p>صفحه 209 مراجعه کنید.</p>
<p>
<strong>replication</strong>
</p>
<p>نگه داشتن یک کپی از همان 
   <strong>data</strong>
   در</p>
<p>چندین 
   <strong>nodes</strong>
   (
   <strong>replicas</strong>
   ) به طوری که باقی می‌ماند</p>
<p>
<strong>lock</strong>
   556 | واژه نامه
  </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0578</div>
            </div>
        </div>
        <!-- Page 0579 -->
        <div class="chapter" id="page-0579">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>قابل دسترسی است اگر یک گره غیرقابل دسترس شود.</p>
<p>به فصل 5 مراجعه کنید.</p>
<p>
<strong>schema</strong>
</p>
<p>توصیفی از ساختار برخی از</p>
<p>
<strong>data</strong>
   ، از جمله فیلدها و انواع داده‌های آن.</p>
<p>اینکه آیا برخی از 
   <strong>data</strong>
   ها با یک 
   <strong>schema</strong>
   مطابقت دارند یا خیر</p>
<p>می‌تواند در نقاط مختلف در طول عمر 
   <strong>data</strong>
   بررسی شود (به "انعطاف‌پذیری 
   <strong>Schema</strong>
   در</p>
<p>
<strong>document model</strong>
   " در صفحه 39 مراجعه کنید)، و a</p>
<p>
<strong>schema</strong>
   می‌تواند با گذشت زمان تغییر کند (به فصل</p>
<p>4 مراجعه کنید).</p>
<p>
<strong>secondary index</strong>
</p>
<p>یک ساختار 
   <strong>data</strong>
   اضافی که در کنار ذخیره‌سازی 
   <strong>data</strong>
   اصلی نگهداری می‌شود</p>
<p>و به شما امکان می‌دهد به طور کارآمد</p>
<p>برای رکوردهایی که با یک نوع خاص مطابقت دارند، جستجو کنید</p>
<p>شرط. به "سایر ساختارهای فهرست‌بندی" در</p>
<p>صفحه 85 و "
   <strong>Partitioning and Secondary Indexes</strong>
   " در</p>
<p>صفحه 206 مراجعه کنید.</p>
<p>
<strong>serializable</strong>
</p>
<p>تضمینی که اگر چندین تراکنش</p>
<p>به طور همزمان اجرا شوند، همانطور رفتار می‌کنند</p>
<p>که اگر یک بار در یک ترتیب سریال اجرا می‌شدند.</p>
<p>به "
   <strong>Serializability</strong>
   " در صفحه 251 مراجعه کنید.</p>
<p>
<strong>shared-nothing</strong>
</p>
<p>معماری که در آن مستقل</p>
<p>
<strong>nodes</strong>
   - هر کدام با 
   <strong>CPUs</strong>
   ، حافظه و</p>
<p>دیسک‌های خود - از طریق یک</p>
<p>شبکه متعارف، برخلاف معماری‌های 
   <strong>shared-</strong>
</p>
<p>
<strong>memory</strong>
   یا 
   <strong>shared-disk</strong>
   . به</p>
<p>مقدمه قسمت دوم مراجعه کنید.</p>
<p>
<strong>skew</strong>
</p>
<p>1. بار نامتعادل در سراسر پارتیشن‌ها، به طوری که</p>
<p>برخی از پارتیشن‌ها درخواست‌ها یا 
   <strong>data</strong>
   بسیاری دارند، و</p>
<p>بقیه بسیار کمتر دارند. همچنین به عنوان نقاط داغ شناخته می‌شود. به "
   <strong>Skewed Work-</strong>
</p>
<p>
<strong>loads and Relieving Hot Spots</strong>
   " در صفحه</p>
<p>205 و "
   <strong>Handling skew</strong>
   " در صفحه 407 مراجعه کنید.</p>
<p>2. یک ناهنجاری زمان‌بندی که باعث می‌شود رویدادها</p>
<p>به ترتیب غیرمنتظره و غیر متوالی ظاهر می‌شوند.</p>
<p>به بحث‌های مربوط به 
   <strong>read skew</strong>
   در</p>
<p>"
   <strong>Snapshot Isolation and Repeatable Read</strong>
   " در</p>
<p>صفحه 237، 
   <strong>write skew</strong>
   در "
   <strong>Write Skew</strong>
</p>
<p>
<strong>and Phantoms</strong>
   " در صفحه 246، و 
   <strong>clock</strong>
   skew
  </p>
<p>در "
   <strong>Timestamps for ordering events</strong>
   " در</p>
<p>صفحه 291 مراجعه کنید.</p>
<p>
<strong>split brain</strong>
</p>
<p>سناریویی که در آن دو گره همزمان</p>
<p>معتقدند که 
   <strong>leader</strong>
   هستند، و این ممکن است باعث شود</p>
<p>تضمین‌های سیستم نقض شود. به "
   <strong>Handling Node Out-</strong>
</p>
<p>
<strong>ages</strong>
   " در صفحه 156 و "
   <strong>The Truth Is</strong>
</p>
<p>
<strong>Defined by the Majority</strong>
   " در صفحه 300 مراجعه کنید.</p>
<p>
<strong>stored procedure</strong>
</p>
<p>راهی برای رمزگذاری منطق یک 
   <strong>transaction</strong>
   به گونه‌ای که می‌تواند کاملاً اجرا شود</p>
<p>در یک 
   <strong>database server</strong>
   ، بدون ارتباط</p>
<p>با یک کلاینت در طول</p>
<p>
<strong>transaction</strong>
   . به "
   <strong>Actual Serial Execu-</strong>
</p>
<p>
<strong>tion</strong>
   " در صفحه 252 مراجعه کنید.</p>
<p>
<strong>stream process</strong>
</p>
<p>یک محاسبه که به طور مداوم در حال اجرا است</p>
<p>یک جریان بی‌پایان از رویدادها را به عنوان ورودی مصرف می‌کند، و</p>
<p>برخی خروجی‌ها را از آن می‌گیرد. به فصل 11 مراجعه کنید.</p>
<p>
<strong>synchronous</strong>
</p>
<p>متضاد 
   <strong>asynchronous</strong>
   .</p>
<p>
<strong>system of record</strong>
</p>
<p>سیستمی که نسخه اولیه و معتبر برخی از</p>
<p>
<strong>data</strong>
   را نگه می‌دارد، که همچنین به عنوان منبع حقیقت شناخته می‌شود. تغییرات ابتدا در اینجا نوشته می‌شوند، و سایر مجموعه‌های 
   <strong>data</strong>
   ممکن است</p>
<p>از 
   <strong>system of record</strong>
   مشتق شوند. به</p>
<p>مقدمه قسمت سوم مراجعه کنید.</p>
<p>
<strong>timeout</strong>
</p>
<p>یکی از ساده‌ترین راه‌ها برای تشخیص یک</p>
<p>خطا، یعنی با مشاهده عدم پاسخ در</p>
<p>مقدار مشخصی از زمان. با این حال، غیرممکن است که بدانیم</p>
<p>اینکه آیا یک 
   <strong>timeout</strong>
   به دلیل مشکلی است</p>
<p>با گره از راه دور، یا یک مسئله در</p>
<p>شبکه. به "
   <strong>Timeouts and Unbounded</strong>
</p>
<p>
<strong>Delays</strong>
   " در صفحه 281 مراجعه کنید.</p>
<p>
<strong>total order</strong>
</p>
<p>راهی برای مقایسه چیزها (به عنوان مثال، زمان</p>
<p>مهر) که به شما امکان می‌دهد همیشه بگویید</p>
<p>کدام یک از دو چیز بزرگتر است و</p>
<p>کدام یک کوچکتر است. یک سفارش که در آن</p>
<p>
<strong>total order</strong>
</p>
<p>
<strong>Glossary</strong> | 557
  </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0579</div>
            </div>
        </div>
        <!-- Page 0580 -->
        <div class="chapter" id="page-0580">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>برخی چیزها غیرقابل مقایسه هستند (شما</p>
<p>نمی‌توانید بگویید کدام بزرگتر یا کوچکتر است) به</p>
<p>یک مرتبه جزئی گفته می‌شود. به "
   <strong>The causal</strong>
</p>
<p>
<strong>order is not a total order</strong>
   " در صفحه 341 مراجعه کنید.</p>
<p>
<strong>transaction</strong>
</p>
<p>گروه‌بندی چندین عمل خواندن و</p>
<p>نوشتن در یک واحد منطقی، به منظور</p>
<p>ساده‌سازی مدیریت خطا و همزمانی</p>
<p>مسائل. به فصل 7 مراجعه کنید.</p>
<p>
<strong>two-phase commit (2PC)</strong>
</p>
<p>یک الگوریتم برای اطمینان از اینکه چندین 
   <strong>data-</strong>
</p>
<p>
<strong>base node</strong>
   یا همه متعهد می‌شوند یا همه موارد را متوقف می‌کنند</p>
<p>یک 
   <strong>transaction</strong>
   . به "
   <strong>Atomic Commit and</strong>
</p>
<p>
<strong>Two-Phase Commit (2PC)</strong>
   " در صفحه 354 مراجعه کنید.</p>
<p>
<strong>two-phase locking (2PL)</strong>
</p>
<p>یک الگوریتم برای دستیابی به 
   <strong>serializable</strong>
</p>
<p>
<strong>isolation</strong>
   که با یک 
   <strong>transaction</strong>
   کار می‌کند</p>
<p>به دست آوردن یک 
   <strong>lock</strong>
   در تمام 
   <strong>data</strong>
   هایی که می‌خواند یا</p>
<p>می‌نویسد، و نگه داشتن 
   <strong>lock</strong>
   تا انتها</p>
<p>از 
   <strong>transaction</strong>
   . به "
   <strong>Two-Phase Lock-</strong>
</p>
<p>
<strong>ing (2PL)</strong>
   " در صفحه 257 مراجعه کنید.</p>
<p>
<strong>unbounded</strong>
</p>
<p>نداشتن هیچ حد بالایی یا اندازه مشخصی. برعکس</p>
<p>
<strong>bounded</strong>
   .</p>
<p>
<strong>transaction</strong>
   558 | واژه‌نامه</p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0580</div>
            </div>
        </div>
        <!-- Page 0581 -->
        <div class="chapter" id="page-0581">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<h4>فهرست مطالب</h4>
<p>
<strong>A</strong>
</p>
<p>
<strong>aborts (transactions)</strong>
   , 222, 224</p>
<p>در 
   <strong>two-phase commit</strong>
   , 356</p>
<p>عملکرد کنترل همزمانی خوش‌بینانه، 266</p>
<p>تلاش مجدد تراکنش‌های لغو شده، 231</p>
<p>
<strong>abstraction</strong>
   , 21, 27, 222, 266, 321</p>
<p>
<strong>access path (in network model)</strong>
   , 37, 60</p>
<p>
<strong>accidental complexity</strong>
   , حذف، 21</p>
<p>
<strong>accountability</strong>
   , 535</p>
<p>ویژگی‌های 
   <strong>ACID (transactions)</strong>
   ، 90، 223</p>
<p>اتمی بودن، 223، 228</p>
<p>سازگاری، 224، 529</p>
<p>ماندگاری، 226</p>
<p>
<strong>isolation</strong>
   ، 225، 228</p>
<p>
<strong>acknowledgements (messaging)</strong>
   , 445</p>
<p>
<strong>active/active replication (see multi-leader repli-</strong>
</p>
<p>
<strong>cation)</strong>
</p>
<p>
<strong>active/passive replication (see leader-based rep-</strong>
</p>
<p>
<strong>lication)</strong>
</p>
<p>
<strong>ActiveMQ (messaging)</strong>
   , 137, 444</p>
<p>پشتیبانی از تراکنش توزیع‌شده، 361</p>
<p>
<strong>ActiveRecord (object-relational mapper)</strong>
   , 30,</p>
<p>232</p>
<p>
<strong>actor model</strong>
   , 138</p>
<p>(همچنین به 
   <strong>message-passing</strong>
   مراجعه کنید)</p>
<p>مقایسه با مدل 
   <strong>Pregel</strong>
   ، 425</p>
<p>مقایسه با پردازش جریان، 468</p>
<p>
<strong>Advanced Message Queuing Protocol (see</strong>
</p>
<p>
<strong>AMQP)</strong>
</p>
<p>سیستم‌های هوافضا، 6، 10، 305، 372</p>
<p>
<strong>aggregation</strong>
</p>
<p>مکعب‌های 
   <strong>data</strong>
   و 
   <strong>views</strong>
   مادی شده، 101</p>
<p>در فرآیندهای 
   <strong>batch</strong>
   ، 406</p>
<p>در فرآیندهای جریان، 466</p>
<p>زبان پرس و جوی خط لوله تجمیع، 48</p>
<p>
<strong>Agile</strong>
   ، 22</p>
<p>به حداقل رساندن برگشت‌ناپذیری، 414، 497</p>
<p>سریع‌تر حرکت کردن با اطمینان، 532</p>
<p>فلسفه یونیکس، 394</p>
<p>
<strong>agreement</strong>
   , 365</p>
<p>(همچنین به 
   <strong>consensus</strong>
   مراجعه کنید)</p>
<p>
<strong>Airflow (workflow scheduler)</strong>
   , 402</p>
<p>
<strong>Ajax</strong>
   , 131</p>
<p>
<strong>Akka (actor framework)</strong>
   , 139</p>
<p>الگوریتم‌ها</p>
<p>صحت الگوریتم، 308</p>
<p>
<strong>B-trees</strong>
   , 79-83</p>
<p>برای سیستم‌های توزیع‌شده، 306</p>
<p>شاخص‌های 
   <strong>hash</strong>
   ، 72-75</p>
<p>
<strong>mergesort</strong>
   ، 76، 402، 405</p>
<p>درختان 
   <strong>red-black</strong>
   ، 78</p>
<p>
<strong>SSTables</strong>
   و 
   <strong>LSM-trees</strong>
   ، 76-79</p>
<p>
<strong>all-to-all replication topologies</strong>
   , 175</p>
<p>
<strong>AllegroGraph (database)</strong>
   , 50</p>
<p>دستور 
   <strong>ALTER TABLE (SQL)</strong>
   , 40, 111</p>
<p>
<strong>Amazon</strong>
</p>
<p>
<strong>Dynamo (database)</strong>
   , 177</p>
<p>
<strong>Amazon Web Services (AWS)</strong>
   , 8</p>
<p>
<strong>Kinesis Streams (messaging)</strong>
   , 448</p>
<p>قابلیت اطمینان شبکه، 279</p>
<p>
<strong>postmortems</strong>
   ، 9</p>
<p>
<strong>RedShift (database)</strong>
   , 93</p>
<p>
<strong>S3 (object storage)</strong>
   , 398</p>
<p>بررسی یکپارچگی 
   <strong>data</strong>
   ، 530</p>
<p>تقویت</p>
<p>سوگیری، 534</p>
<p>شکست‌ها، 364، 495</p>
<p>
<strong>Index</strong>
   | 559
  </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0581</div>
            </div>
        </div>
        <!-- Page 0582 -->
        <div class="chapter" id="page-0582">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>از تاخیر دم، 16، 207</p>
<p>
<strong>write amplification</strong>
   , 84</p>
<p>
<strong>AMQP (Advanced Message Queuing Protocol)</strong>
   ,
   </p>
<p>444</p>
<p>(همچنین به سیستم‌های پیام‌رسانی مراجعه کنید)</p>
<p>مقایسه با پیام‌رسانی مبتنی بر 
   <strong>log</strong>
   ، 448،</p>
<p>451</p>
<p>ترتیب پیام‌ها، 446</p>
<p>
<strong>analytics</strong>
   , 90</p>
<p>مقایسه با پردازش تراکنش، 91</p>
<p>
<strong>data warehousing (see data warehousing)</strong>
</p>
<p>اجرای پرس و جو موازی در 
   <strong>databases MPP</strong>
   , 415</p>
<p>پیش‌بینی (به 
   <strong>predictive analytics</strong>
   مراجعه کنید)</p>
<p>ارتباط با پردازش 
   <strong>batch</strong>
   ، 411</p>
<p>
<strong>schemas</strong>
   برای، 93-95</p>
<p>
<strong>snapshot isolation</strong>
   برای پرس و جوها، 238</p>
<p>
<strong>stream analytics</strong>
   , 466</p>
<p>با استفاده از 
   <strong>MapReduce</strong>
   ، تجزیه و تحلیل رویدادهای فعالیت کاربر (مثال)، 404</p>
<p>
<strong>anti-caching (in-memory databases)</strong>
   , 89</p>
<p>
<strong>anti-entropy</strong>
   , 178</p>
<p>
<strong>Apache ActiveMQ (see ActiveMQ)</strong>
</p>
<p>
<strong>Apache Avro (see Avro)</strong>
</p>
<p>
<strong>Apache Beam (see Beam)</strong>
</p>
<p>
<strong>Apache BookKeeper (see BookKeeper)</strong>
</p>
<p>
<strong>Apache Cassandra (see Cassandra)</strong>
</p>
<p>
<strong>Apache CouchDB (see CouchDB)</strong>
</p>
<p>
<strong>Apache Curator (see Curator)</strong>
</p>
<p>
<strong>Apache Drill (see Drill)</strong>
</p>
<p>
<strong>Apache Flink (see Flink)</strong>
</p>
<p>
<strong>Apache Giraph (see Giraph)</strong>
</p>
<p>
<strong>Apache Hadoop (see Hadoop)</strong>
</p>
<p>
<strong>Apache HAWQ (see HAWQ)</strong>
</p>
<p>
<strong>Apache HBase (see HBase)</strong>
</p>
<p>
<strong>Apache Helix (see Helix)</strong>
</p>
<p>
<strong>Apache Hive (see Hive)</strong>
</p>
<p>
<strong>Apache Impala (see Impala)</strong>
</p>
<p>
<strong>Apache Jena (see Jena)</strong>
</p>
<p>
<strong>Apache Kafka (see Kafka)</strong>
</p>
<p>
<strong>Apache Lucene (see Lucene)</strong>
</p>
<p>
<strong>Apache MADlib (see MADlib)</strong>
</p>
<p>
<strong>Apache Mahout (see Mahout)</strong>
</p>
<p>
<strong>Apache Oozie (see Oozie)</strong>
</p>
<p>
<strong>Apache Parquet (see Parquet)</strong>
</p>
<p>
<strong>Apache Qpid (see Qpid)</strong>
</p>
<p>
<strong>Apache Samza (see Samza)</strong>
</p>
<p>
<strong>Apache Solr (see Solr)</strong>
</p>
<p>
<strong>Apache Spark (see Spark)</strong>
</p>
<p>
<strong>Apache Storm (see Storm)</strong>
</p>
<p>
<strong>Apache Tajo (see Tajo)</strong>
</p>
<p>
<strong>Apache Tez (see Tez)</strong>
</p>
<p>
<strong>Apache Thrift (see Thrift)</strong>
</p>
<p>
<strong>Apache ZooKeeper (see ZooKeeper)</strong>
</p>
<p>
<strong>Apama (stream analytics)</strong>
   , 466</p>
<p>
<strong>append-only B-trees</strong>
   , 82, 242</p>
<p>فایل‌های 
   <strong>append-only (see logs)</strong>
</p>
<p>
<strong>Application Programming Interfaces (APIs)</strong>
   ، 5،</p>
<p>27</p>
<p>برای پردازش 
   <strong>batch</strong>
   ، 403</p>
<p>برای جریان‌های تغییر، 456</p>
<p>برای تراکنش‌های توزیع‌شده، 361</p>
<p>برای پردازش 
   <strong>graph</strong>
   ، 425</p>
<p>برای 
   <strong>services</strong>
   ، 131-136</p>
<p>(همچنین به 
   <strong>services</strong>
   مراجعه کنید)</p>
<p>قابلیت تکامل، 136</p>
<p>
<strong>RESTful</strong>
   , 133</p>
<p>
<strong>SOAP</strong>
   , 133</p>
<p>
<strong>application state (see state)</strong>
</p>
<p>جستجوی تقریبی (به 
   <strong>similarity search</strong>
   مراجعه کنید)</p>
<p>ذخیره‌سازی آرشیوی، 
   <strong>data</strong>
   از 
   <strong>databases</strong>
   , 131</p>
<p>
<strong>arcs (see edges)</strong>
</p>
<p>میانگین حسابی، 14</p>
<p>متن 
   <strong>ASCII</strong>
   ، 119، 395</p>
<p>
<strong>ASN.1 (schema language)</strong>
   , 127</p>
<p>شبکه‌های ناهمزمان، 278، 553</p>
<p>مقایسه با شبکه‌های همزمان، 284</p>
<p>مدل رسمی، 307</p>
<p>
<strong>asynchronous replication</strong>
   , 154, 553</p>
<p>تشخیص درگیری، 172</p>
<p>از دست رفتن 
   <strong>data</strong>
   در 
   <strong>failover</strong>
   , 157</p>
<p>خوانده‌ها از 
   <strong>follower asynchronous</strong>
   , 162</p>
<p>
<strong>Asynchronous Transfer Mode (ATM)</strong>
   , 285</p>
<p>
<strong>atomic broadcast (see total order broadcast)</strong>
</p>
<p>ساعت‌های اتمی (ساعت‌های سزیم)، 294، 295</p>
<p>(همچنین به ساعت‌ها مراجعه کنید)</p>
<p>اتمی بودن (همزمانی)، 553</p>
<p>افزایش و دریافت اتمی، 351</p>
<p>مقایسه و تنظیم، 245، 327</p>
<p>(همچنین به عملیات مقایسه و تنظیم مراجعه کنید)</p>
<p>عملیات تکراری، 246</p>
<p>عملیات نوشتن، 243</p>
<p>اتمی بودن (تراکنش‌ها)، 223، 228، 553</p>
<p>تعهد اتمی، 353</p>
<p>اجتناب از، 523، 528</p>
<p>مسدود کردن و غیرمسدود کردن، 359</p>
<p>در پردازش جریان، 360، 477</p>
<p>حفظ 
   <strong>derived data</strong>
   ، 453</p>
<p>560 | 
   <strong>Index</strong>
</p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0582</div>
            </div>
        </div>
        <!-- Page 0583 -->
        <div class="chapter" id="page-0583">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>برای تراکنش‌های چند 
   <strong>object</strong>
   ، 229</p>
<p>برای نوشتن‌های 
   <strong>single-object</strong>
   ، 230</p>
<p>
<strong>auditability</strong>
   , 528-533</p>
<p>طراحی برای، 531</p>
<p>سیستم‌های خود نظارتی، 530</p>
<p>از طریق تغییرناپذیری، 460</p>
<p>ابزارهایی برای سیستم‌های 
   <strong>data</strong>
   قابل 
   <strong>audit</strong>
   ، 532</p>
<p>
<strong>availability</strong>
   , 8</p>
<p>(همچنین به تحمل خطا مراجعه کنید)</p>
<p>در قضیه 
   <strong>CAP</strong>
   ، 337</p>
<p>در توافقنامه‌های سطح 
   <strong>service (SLAs)</strong>
   ، 15</p>
<p>
<strong>Avro (data format)</strong>
   , 122-127</p>
<p>تولید کد، 127</p>
<p>
<strong>schemas</strong>
   که به صورت پویا تولید شده‌اند، 126</p>
<p>فایل‌های 
   <strong>object container</strong>
   ، 125، 131، 414</p>
<p>خواننده 
   <strong>schema</strong>
   نویسنده را تعیین می‌کند، 125</p>
<p>تکامل 
   <strong>schema</strong>
   ، 123</p>
<p>استفاده در 
   <strong>Hadoop</strong>
   ، 414</p>
<p>
<strong>awk (Unix tool)</strong>
   , 391</p>
<p>
<strong>AWS (see Amazon Web Services)</strong>
</p>
<p>
<strong>Azure (see Microsoft)</strong>
</p>
<p>
<strong>B</strong>
</p>
<p>
<strong>B-trees (indexes)</strong>
   , 79-83</p>
<p>تغییرات 
   <strong>append-only/copy-on-write</strong>
   ، 82،</p>
<p>242</p>
<p>فاکتور انشعاب، 81</p>
<p>مقایسه با 
   <strong>LSM-trees</strong>
   ، 83-85</p>
<p>بازیابی خرابی، 82</p>
<p>رشد با تقسیم یک صفحه، 81</p>
<p>بهینه‌سازی، 82</p>
<p>شباهت به پارتیشن‌بندی پویا، 212</p>
<p>
<strong>backpressure</strong>
   , 441, 553</p>
<p>در 
   <strong>TCP</strong>
   ، 282</p>
<p>
<strong>backups</strong>
</p>
<p>
<strong>snapshot</strong>
   از 
   <strong>database</strong>
   برای تکثیر، 156</p>
<p>یکپارچگی، 530</p>
<p>استفاده برای فرآیندهای 
   <strong>ETL</strong>
   ، 405</p>
<p>سازگاری به عقب، 112</p>
<p>
<strong>BASE</strong>
   ، در مقابل 
   <strong>ACID</strong>
   ، 223</p>
<p>
<strong>bash shell (Unix)</strong>
   , 70, 395, 503</p>
<p>پردازش 
   <strong>batch</strong>
   , 28, 389-431, 553</p>
<p>ترکیب با پردازش جریان</p>
<p>معماری 
   <strong>lambda</strong>
   ، 497</p>
<p>فناوری‌های متحدکننده، 498</p>
<p>مقایسه با 
   <strong>databases MPP</strong>
   ، 414-418</p>
<p>مقایسه با پردازش جریان، 464</p>
<p>مقایسه با یونیکس، 413-414</p>
<p>موتورهای 
   <strong>dataflow</strong>
   ، 421-423</p>
<p>تحمل خطا، 406، 414، 422، 442</p>
<p>برای ادغام 
   <strong>data</strong>
   ، 494-498</p>
<p>حفظ حالت مشتق شده، 495</p>
<p>
<strong>MapReduce</strong>
   و فایل‌سیستم‌های توزیع‌شده،</p>
<p>397-413</p>
<p>(همچنین به 
   <strong>MapReduce</strong>
   مراجعه کنید)</p>
<p>اندازه‌گیری عملکرد، 13، 390</p>
<p>خروجی‌ها، 411-413</p>
<p>فروشگاه‌های کلید-مقدار، 412</p>
<p>شاخص‌های جستجو، 411</p>
<p>با استفاده از ابزارهای یونیکس (مثال)، 391-394</p>
<p>
<strong>Bayou (database)</strong>
   , 522</p>
<p>
<strong>Beam (dataflow library)</strong>
   , 498</p>
<p>سوگیری، 534</p>
<p>توپ بزرگ گل‌ولای، 20</p>
<p>مدل 
   <strong>Bigtable</strong>
   , 41, 99</p>
<p>رمزگذاری 
   <strong>data</strong>
   باینری، 115-128</p>
<p>
<strong>Avro</strong>
   ، 122-127</p>
<p>
<strong>MessagePack</strong>
   , 116-117</p>
<p>
<strong>Thrift</strong>
   و 
   <strong>Protocol Buffers</strong>
   ، 117-121</p>
<p>کدگذاری باینری</p>
<p>مبتنی بر 
   <strong>schemas</strong>
   ، 127</p>
<p>توسط درایورهای شبکه، 128</p>
<p>رشته‌های باینری، عدم پشتیبانی در 
   <strong>JSON</strong>
   و</p>
<p>
<strong>XML</strong>
   ، 114</p>
<p>رمزگذاری 
   <strong>BinaryProtocol (Thrift)</strong>
   , 118</p>
<p>
<strong>Bitcask (storage engine)</strong>
   , 72</p>
<p>بازیابی خرابی، 74</p>
<p>
<strong>Bitcoin (cryptocurrency)</strong>
   , 532</p>
<p>تحمل خطای 
   <strong>Byzantine</strong>
   ، 305</p>
<p>باگ‌های همزمانی در مبادلات، 233</p>
<p>شاخص‌های 
   <strong>bitmap</strong>
   ، 97</p>
<p>
<strong>blockchains</strong>
   , 532</p>
<p>تحمل خطای 
   <strong>Byzantine</strong>
   ، 305</p>
<p>تعهد اتمی مسدود کننده، 359</p>
<p>
<strong>Bloom (programming language)</strong>
   , 504</p>
<p>فیلتر 
   <strong>Bloom (algorithm)</strong>
   ، 79، 466</p>
<p>
<strong>BookKeeper (replicated log)</strong>
   , 372</p>
<p>
<strong>Bottled Water (change data capture)</strong>
   , 455</p>
<p>مجموعه داده‌های 
   <strong>bounded</strong>
   ، 430، 439، 553</p>
<p>(همچنین به پردازش 
   <strong>batch</strong>
   مراجعه کنید)</p>
<p>تاخیرهای محدود، 553</p>
<p>در شبکه‌ها، 285</p>
<p>مکث فرآیند، 298</p>
<p>اتصال 
   <strong>hash</strong>
   ، 409</p>
<p>
<strong>Index</strong>
   | 561
  </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0583</div>
            </div>
        </div>
        <!-- Page 0584 -->
        <div class="chapter" id="page-0584">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
<strong>brokerless messaging</strong>
   , 442</p>
<p>
<strong>Brubeck (metrics aggregator)</strong>
   , 442</p>
<p>
<strong>BTM (transaction coordinator)</strong>
   , 356</p>
<p>مدل موازی همزمان انبوه (
   <strong>BSP</strong>
   )، 425</p>
<p>الگوهای ترافیک شبکه انفجاری، 285</p>
<p>پردازش 
   <strong>business data</strong>
   ، 28، 90، 390</p>
<p>توالی بایت، کدگذاری 
   <strong>data</strong>
   در، 112</p>
<p>
<strong>Byzantine faults</strong>
   , 304-306, 307, 553</p>
<p>سیستم‌های تحمل خطای 
   <strong>Byzantine</strong>
   ، 305، 532</p>
<p>مسئله ژنرال‌های 
   <strong>Byzantine</strong>
   ، 304</p>
<p>الگوریتم‌های 
   <strong>consensus</strong>
   و، 366</p>
<p>
<strong>C</strong>
</p>
<p>
<strong>caches</strong>
   , 89, 553</p>
<p>و 
   <strong>views</strong>
   مادی شده، 101</p>
<p>به عنوان 
   <strong>derived data</strong>
   ، 386، 499-504</p>
<p>
<strong>database</strong>
   به عنوان 
   <strong>cache</strong>
   از لاگ تراکنش، 460</p>
<p>در 
   <strong>CPUs</strong>
   ، 99، 338، 428</p>
<p>بی‌اعتبارسازی و نگهداری، 452، 467</p>
<p>
<strong>linearizability</strong>
   , 324</p>
<p>قضیه 
   <strong>CAP</strong>
   ، 336-338، 554</p>
<p>
<strong>Cascading (batch processing)</strong>
   , 419, 427</p>
<p>اتصالات 
   <strong>hash</strong>
   , 409</p>
<p>
<strong>workflows</strong>
   , 403</p>
<p>شکست‌های آبشاری، 9، 214، 281</p>
<p>
<strong>Cascalog (batch processing)</strong>
   , 60</p>
<p>
<strong>Cassandra (database)</strong>
</p>
<p>مدل 
   <strong>data</strong>
   خانواده-ستون، 41، 99</p>
<p>استراتژی فشرده‌سازی، 79</p>
<p>
<strong>primary key</strong>
   مرکب، 204</p>
<p>پروتکل شایعه‌پراکنی، 216</p>
<p>تقسیم‌بندی 
   <strong>hash</strong>
   ، 203-205</p>
<p>
<strong>last-write-wins</strong>
   حل تعارض، 186، 292</p>
<p>تکثیر بدون رهبر، 177</p>
<p>
<strong>linearizability</strong>
   ، کمبود، 335</p>
<p>ذخیره‌سازی مبتنی بر 
   <strong>log</strong>
   ، 78</p>
<p>پشتیبانی از چند 
   <strong>datacenter</strong>
   ، 184</p>
<p>طرح تقسیم‌بندی، 213</p>
<p>شاخص‌های ثانویه، 207</p>
<p>
<strong>sloppy quorums</strong>
   ، 184</p>
<p>
<strong>cat (Unix tool)</strong>
   , 391</p>
<p>
<strong>causal context</strong>
   , 191</p>
<p>(همچنین به وابستگی‌های علّی مراجعه کنید)</p>
<p>وابستگی‌های علّی، 186-191</p>
<p>ثبت، 191، 342، 494، 514</p>
<p>با ترتیب کل، 493</p>
<p>ترتیب علّی، 339</p>
<p>در تراکنش‌ها، 262</p>
<p>ارسال پیام به دوستان (مثال)، 494</p>
<p>
<strong>causality</strong>
   , 554</p>
<p>ترتیب علّی، 339-343</p>
<p>
<strong>linearizability</strong>
   و، 342</p>
<p>ترتیب کل با، 344، 345</p>
<p>سازگاری با، 344-347</p>
<p>
<strong>consistent snapshots</strong>
   , 340</p>
<p>رابطه 
   <strong>happens-before</strong>
   , 186</p>
<p>در تراکنش‌های 
   <strong>serializable</strong>
   ، 262-265</p>
<p>عدم تطابق با ساعت‌ها، 292</p>
<p>مرتب‌سازی رویدادها برای ثبت، 493</p>
<p>نقض، 165، 176، 292، 340</p>
<p>با ساعت‌های همزمان، 294</p>
<p>
<strong>CEP (see complex event processing)</strong>
</p>
<p>شفافیت گواهی، 532</p>
<p>تکثیر زنجیره‌ای، 155</p>
<p>خواندن‌های 
   <strong>linearizable</strong>
   ، 351</p>
<p>
<strong>change data capture</strong>
   , 160, 454</p>
<p>پشتیبانی 
   <strong>API</strong>
   برای جریان‌های تغییر، 456</p>
<p>مقایسه با 
   <strong>event sourcing</strong>
   ، 457</p>
<p>پیاده‌سازی، 454</p>
<p>
<strong>initial snapshot</strong>
   , 455</p>
<p>فشرده‌سازی 
   <strong>log</strong>
   ، 456</p>
<p>
<strong>changelogs</strong>
   , 460</p>
<p>
<strong>change data capture</strong>
   , 454</p>
<p>برای وضعیت اپراتور، 479</p>
<p>تولید با 
   <strong>triggers</strong>
   ، 455</p>
<p>در جریان 
   <strong>join</strong>
   ، 474</p>
<p>فشرده‌سازی 
   <strong>log</strong>
   ، 456</p>
<p>حفظ حالت مشتق‌شده، 452</p>
<p>
<strong>Chaos Monkey</strong>
   ، 7، 280</p>
<p>
<strong>checkpointing</strong>
</p>
<p>در پردازشگرهای 
   <strong>batch</strong>
   ، 422، 426</p>
<p>در محاسبات با کارایی بالا، 275</p>
<p>در پردازشگرهای جریان، 477، 523</p>
<p>
<strong>chronicle data model</strong>
   , 458</p>
<p>شبکه‌های 
   <strong>circuit-switched</strong>
   , 284</p>
<p>توپولوژی‌های تکثیر دایره‌ای، 175</p>
<p>داده‌های 
   <strong>clickstream</strong>
   ، تجزیه و تحلیل، 404</p>
<p>کلاینت‌ها</p>
<p>فراخوانی 
   <strong>services</strong>
   ، 131</p>
<p>فشار دادن تغییرات حالت به، 512</p>
<p>
<strong>request routing</strong>
   , 214</p>
<p>
<strong>stateful and offline-capable</strong>
   , 170, 511</p>
<p>ساعت‌ها، 287-299</p>
<p>ساعت‌های اتمی (ساعت‌های سزیم)، 294، 295</p>
<p>(همچنین به ساعت‌ها مراجعه کنید)</p>
<p>فاصله اطمینان، 293-295</p>
<p>برای 
   <strong>global snapshots</strong>
   ، 294</p>
<p>منطقی (به ساعت‌های منطقی مراجعه کنید)</p>
<p>562 | 
   <strong>Index</strong>
</p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0584</div>
            </div>
        </div>
        <!-- Page 0585 -->
        <div class="chapter" id="page-0585">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
<strong>skew</strong>
   , 291-294, 334</p>
<p>
<strong>slewing</strong>
   , 289</p>
<p>همگام‌سازی و دقت، 289-291</p>
<p>همگام‌سازی با استفاده از 
   <strong>GPS</strong>
   ، 287، 290، 294،</p>
<p>295</p>
<p>زمان روز در مقابل ساعت‌های یکنواخت، 288</p>
<p>رویدادهای 
   <strong>timestamping</strong>
   , 471</p>
<p>
<strong>cloud computing</strong>
   , 146, 275</p>
<p>نیاز به کشف 
   <strong>service</strong>
   ، 372</p>
<p>مشکلات شبکه، 279</p>
<p>منابع مشترک، 284</p>
<p>قابلیت اطمینان تک ماشینی، 8</p>
<p>
<strong>Cloudera Impala (see Impala)</strong>
</p>
<p>شاخص‌های خوشه‌ای، 86</p>
<p>مدل 
   <strong>CODASYL</strong>
   ، 36</p>
<p>(همچنین به مدل شبکه مراجعه کنید)</p>
<p>تولید کد</p>
<p>با 
   <strong>Avro</strong>
   ، 127</p>
<p>با 
   <strong>Thrift</strong>
   و 
   <strong>Protocol Buffers</strong>
   ، 118</p>
<p>با 
   <strong>WSDL</strong>
   ، 133</p>
<p>ویرایش مشارکتی</p>
<p>تکثیر چند 
   <strong>leader</strong>
   و، 170</p>
<p>ذخیره‌سازی 
   <strong>column families (Bigtable)</strong>
   , 41, 99</p>
<p>ذخیره‌سازی 
   <strong>column-oriented</strong>
   , 95-101</p>
<p>فشرده‌سازی ستون، 97</p>
<p>تفاوت بین خانواده‌های ستون و، 99</p>
<p>در پردازشگرهای 
   <strong>batch</strong>
   ، 428</p>
<p>
<strong>Parquet</strong>
   , 96, 131, 414</p>
<p>ترتیب مرتب‌سازی در، 99-100</p>
<p>پردازش برداری، 99، 428</p>
<p>نوشتن به، 101</p>
<p>مقادیر جدا شده با کاما (به 
   <strong>CSV</strong>
   مراجعه کنید)</p>
<p>مسئولیت تفکیک پرس و جوی دستور (
   <strong>CQRS</strong>
   )، 462</p>
<p>دستورات (
   <strong>event sourcing</strong>
   )، 459</p>
<p>تعهد (تراکنش‌ها)، 222</p>
<p>تعهد اتمی، 354-355</p>
<p>(همچنین به اتمی بودن; تراکنش‌ها مراجعه کنید)</p>
<p>خواندن 
   <strong>read committed isolation</strong>
   ، 234</p>
<p>تعهد سه فاز (
   <strong>3PC</strong>
   )، 359</p>
<p>تعهد دو فاز (
   <strong>2PC</strong>
   )، 355-359</p>
<p>عملیات جابجایی، 246</p>
<p>
<strong>complex event processing (CEP)</strong>
   , 465</p>
<p>پیچیدگی</p>
<p>تخلیص در مدل‌های نظری، 310</p>
<p>پنهان کردن با استفاده از 
   <strong>abstraction</strong>
   ، 27</p>
<p>از سیستم‌های 
   <strong>software</strong>
   ، مدیریت، 20</p>
<p>ترکیب سیستم‌های 
   <strong>data</strong>
   (به جدا کردن 
   <strong>data-</strong>
</p>
<p>
<strong>bases</strong>
   مراجعه کنید)</p>
<p>برنامه‌های فشرده محاسباتی، 3، 275</p>
<p>شاخص‌های پیوسته‌شده، 87</p>
<p>در 
   <strong>Cassandra</strong>
   ، 204</p>
<p>
<strong>Concord (stream processor)</strong>
   , 466</p>
<p>همزمانی</p>
<p>مدل برنامه‌نویسی 
   <strong>actor</strong>
   ، 138، 468</p>
<p>(همچنین به 
   <strong>message-passing</strong>
   مراجعه کنید)</p>
<p>خطاها از 
   <strong>isolation</strong>
   تراکنش ضعیف، 233</p>
<p>حل تعارض، 171، 174</p>
<p>تشخیص نوشتن همزمان، 184-191</p>
<p>نوشته‌های دوگانه، مشکلات با، 453</p>
<p>رابطه 
   <strong>happens-before</strong>
   ، 186</p>
<p>در سیستم‌های تکراری، 161-191، 324-338</p>
<p>از دست دادن به‌روزرسانی‌ها، 243</p>
<p>کنترل همزمانی چند نسخه</p>
<p>(
   <strong>MVCC</strong>
   )، 239</p>
<p>کنترل همزمانی خوش‌بینانه، 261</p>
<p>ترتیب عملیات، 326، 341</p>
<p>کاهش، از طریق 
   <strong>event logs</strong>
   ، 351، 462، 507</p>
<p>زمان و نسبیت، 187</p>
<p>
<strong>isolation</strong>
   تراکنش، 225</p>
<p>
<strong>write skew (transaction isolation)</strong>
   , 246-251</p>
<p>
<strong>conflict-free replicated datatypes (CRDTs)</strong>
   , 174</p>
<p>درگیری‌ها</p>
<p>تشخیص درگیری، 172</p>
<p>وابستگی‌های علّی، 186، 342</p>
<p>در الگوریتم‌های 
   <strong>consensus</strong>
   ، 368</p>
<p>در تکثیر بدون رهبر، 184</p>
<p>
<strong>Index</strong>
   | 563
  </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0585</div>
            </div>
        </div>
        <!-- Page 0586 -->
        <div class="chapter" id="page-0586">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>در سیستم‌های مبتنی بر 
   <strong>log</strong>
   ، 351، 521</p>
<p>در سیستم‌های غیر 
   <strong>linearizable</strong>
   ، 343</p>
<p>در 
   <strong>serializable snapshot isolation (SSI)</strong>
   ،</p>
<p>264</p>
<p>در 
   <strong>two-phase commit</strong>
   ، 357، 364</p>
<p>حل تعارض</p>
<p>حل تعارض خودکار، 174</p>
<p>با لغو تراکنش‌ها، 261</p>
<p>با عذرخواهی، 527</p>
<p>همگرایی، 172-174</p>
<p>در سیستم‌های بدون 
   <strong>leader</strong>
   ، 190</p>
<p>
<strong>last write wins (LWW)</strong>
   , 186, 292</p>
<p>با استفاده از عملیات اتمی، 246</p>
<p>با استفاده از منطق سفارشی، 173</p>
<p>تعیین اینکه چه چیزی یک درگیری است، 174، 522</p>
<p>در تکثیر چند 
   <strong>leader</strong>
   ، 171-175</p>
<p>اجتناب از درگیری‌ها، 172</p>
<p>از دست دادن به‌روزرسانی‌ها، 242-246</p>
<p>
<strong>materializing</strong>
   , 251</p>
<p>ارتباط با ترتیب عملیات، 339</p>
<p>
<strong>write skew (transaction isolation)</strong>
   , 246-251</p>
<p>ترافیک شبکه (شبکه‌ها)</p>
<p>اجتناب، 282</p>
<p>محدود کردن دقت ساعت‌ها، 293</p>
<p>تاخیر صف، 282</p>
<p>
<strong>consensus</strong>
   , 321, 364-375, 554</p>
<p>الگوریتم‌ها، 366-368</p>
<p>جلوگیری از 
   <strong>split brain</strong>
   ، 367</p>
<p>ویژگی‌های ایمنی و زنده بودن، 365</p>
<p>با استفاده از عملیات 
   <strong>linearizable</strong>
   ، 351</p>
<p>هزینه، 369</p>
<p>تراکنش‌های توزیع‌شده، 352-375</p>
<p>در عمل، 360-364</p>
<p>تعهد دو فاز (
   <strong>2PC</strong>
   )، 354-359</p>
<p>تراکنش‌های 
   <strong>XA</strong>
   ، 361-364</p>
<p>غیرممکن بودن، 353</p>
<p>خدمات عضویت و هماهنگی،</p>
<p>370-373</p>
<p>ارتباط با مقایسه و تنظیم، 335، 350، 352،</p>
<p>374</p>
<p>ارتباط با تکثیر، 155، 349</p>
<p>ارتباط با محدودیت‌های منحصر به فرد، 521</p>
<p>
<strong>consistency</strong>
   , 224, 524</p>
<p>در سراسر 
   <strong>databases</strong>
   مختلف، 157، 452، 462، 492</p>
<p>علّی، 339-348، 493</p>
<p>خواندن‌های پیشوند سازگار، 165-167</p>
<p>
<strong>consistent snapshots</strong>
   , 156, 237-242, 294,</p>
<p>455، 500</p>
<p>(همچنین به 
   <strong>snapshots</strong>
   مراجعه کنید)</p>
<p>بازیابی خرابی، 82</p>
<p>اعمال محدودیت‌ها (به محدودیت‌ها مراجعه کنید)</p>
<p>
<strong>eventual</strong>
   ، 162، 322</p>
<p>(همچنین به 
   <strong>eventual consistency</strong>
   مراجعه کنید)</p>
<p>در تراکنش‌های 
   <strong>ACID</strong>
   ، 224، 529</p>
<p>در قضیه 
   <strong>CAP</strong>
   ، 337</p>
<p>
<strong>linearizability</strong>
   , 324-338</p>
<p>معانی، 224</p>
<p>خواندن‌های یکنواخت، 164-165</p>
<p>شاخص‌های ثانویه، 231، 241، 354، 491،</p>
<p>500</p>
<p>ترتیب تضمین‌ها، 339-352</p>
<p>خواندن-بعد از نوشتن، 162-164</p>
<p>ترتیبی، 351</p>
<p>قوی (به 
   <strong>linearizability</strong>
   مراجعه کنید)</p>
<p>به موقع بودن و یکپارچگی، 524</p>
<p>با استفاده از 
   <strong>quorums</strong>
   ، 181، 334</p>
<p>
<strong>consistent hashing</strong>
   , 204</p>
<p>خواندن‌های پیشوند سازگار، 165</p>
<p>محدودیت‌ها (
   <strong>databases</strong>
   )، 225، 248</p>
<p>به‌صورت ناهمزمان بررسی می‌شود، 526</p>
<p>اجتناب از هماهنگی، 527</p>
<p>اطمینان از 
   <strong>idempotence</strong>
   ، 519</p>
<p>در سیستم‌های مبتنی بر 
   <strong>log</strong>
   ، 521-524</p>
<p>در سراسر چندین پارتیشن، 522</p>
<p>در تعهد دو فاز، 355، 357</p>
<p>ارتباط با ترتیب رویداد، 347</p>
<p>نیازمند 
   <strong>linearizability</strong>
   , 330</p>
<p>
<strong>Consul (service discovery)</strong>
   , 372</p>
<p>مصرف‌کنندگان (جریان‌های پیام)، 137، 440</p>
<p>
<strong>backpressure</strong>
   , 441</p>
<p>
<strong>consumer offsets in logs</strong>
   , 449</p>
<p>شکست‌ها، 445، 449</p>
<p>
<strong>fan-out</strong>
   , 11, 445, 448</p>
<p>
<strong>load balancing</strong>
   , 444, 448</p>
<p>هماهنگ نشدن با تولیدکنندگان، 441، 450،</p>
<p>502</p>
<p>تغییرات متن، 14، 297</p>
<p>همگرایی (حل تعارض)، 172-174، 322</p>
<p>هماهنگی</p>
<p>اجتناب از، 527</p>
<p>
<strong>cross-datacenter</strong>
   , 168, 493</p>
<p>ترتیب 
   <strong>cross-partition</strong>
   ، 256، 294، 348، 523</p>
<p>
<strong>services</strong>
   , 330, 370-373</p>
<p>هماهنگ‌کننده (در 
   <strong>2PC</strong>
   )، 356</p>
<p>شکست، 358</p>
<p>در تراکنش‌های 
   <strong>XA</strong>
   ، 361-364</p>
<p>بازیابی، 363</p>
<p>564 | 
   <strong>Index</strong>
</p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0586</div>
            </div>
        </div>
        <!-- Page 0587 -->
        <div class="chapter" id="page-0587">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
<strong>copy-on-write (B-trees)</strong>
   , 82, 242</p>
<p>
<strong>CORBA (Common Object Request Broker Architecture)</strong>
   , 134</p>
<p>صحت، 6</p>
<p>
<strong>auditability</strong>
   , 528-533</p>
<p>تحمل خطای 
   <strong>Byzantine</strong>
   ، 305، 532</p>
<p>مقابله با شکست‌های جزئی، 274</p>
<p>در سیستم‌های مبتنی بر 
   <strong>log</strong>
   ، 521-524</p>
<p>در مدل سیستم، 308</p>
<p>از تراکنش‌های جبرانی، 355</p>
<p>
<strong>consensus</strong>
   , 368</p>
<p>
<strong>derived data</strong>
   , 497, 531</p>
<p>
<strong>immutable data</strong>
   ، 461</p>
<p>
<strong>personal data</strong>
   ، 535، 540</p>
<p>زمان، 176، 289-295</p>
<p>تراکنش‌ها، 225، 515، 529</p>
<p>به موقع بودن و یکپارچگی، 524-528</p>
<p>فساد 
   <strong>data</strong>
</p>
<p>تشخیص، 519، 530-533</p>
<p>به دلیل دسترسی پاتولوژیک به حافظه، 529</p>
<p>به دلیل تابش، 305</p>
<p>به دلیل 
   <strong>split brain</strong>
   ، 158، 302</p>
<p>به دلیل 
   <strong>isolation</strong>
   تراکنش ضعیف، 233</p>
<p>رسمیت در اجماع، 366</p>
<p>بسته‌های شبکه، 306</p>
<p>روی دیسک‌ها، 227</p>
<p>جلوگیری با استفاده از 
   <strong>write-ahead logs</strong>
   ، 82</p>
<p>بازیابی از، 414، 460</p>
<p>
<strong>Couchbase (database)</strong>
</p>
<p>ماندگاری، 89</p>
<p>تقسیم‌بندی 
   <strong>hash</strong>
   , 203-204, 211</p>
<p>تعادل مجدد، 213</p>
<p>
<strong>request routing</strong>
   , 216</p>
<p>
<strong>CouchDB (database)</strong>
</p>
<p>ذخیره‌سازی 
   <strong>B-tree</strong>
   ، 242</p>
<p>
<strong>change feed</strong>
   , 456</p>
<p>مدل 
   <strong>data</strong>
   اسناد، 31</p>
<p>پشتیبانی از 
   <strong>join</strong>
   , 34</p>
<p>پشتیبانی از 
   <strong>MapReduce</strong>
   , 46, 400</p>
<p>تکثیر، 170، 173</p>
<p>
<strong>covering indexes</strong>
   , 86</p>
<p>
<strong>CPUs</strong>
</p>
<p>انسجام 
   <strong>cache</strong>
   و موانع حافظه، 338</p>
<p>
<strong>caching and pipelining</strong>
   , 99, 428</p>
<p>افزایش موازی‌سازی، 43</p>
<p>
<strong>CRDTs (see conflict-free replicated datatypes)</strong>
</p>
<p>دستور 
   <strong>CREATE INDEX (SQL)</strong>
   , 85, 500</p>
<p>آژانس‌های رتبه‌بندی اعتباری، 535</p>
<p>
<strong>Crunch (batch processing)</strong>
   , 419, 427</p>
<p>اتصالات 
   <strong>hash</strong>
   ، 409</p>
<p>
<strong>sharded joins</strong>
   , 408</p>
<p>
<strong>workflows</strong>
   , 403</p>
<p>رمزنگاری</p>
<p>دفاع در برابر مهاجمان، 306</p>
<p>رمزگذاری و احراز هویت 
   <strong>end-to-end</strong>
   ، 519، 543</p>
<p>اثبات یکپارچگی 
   <strong>data</strong>
   ، 532</p>
<p>
<strong>CSS (Cascading Style Sheets)</strong>
   , 44</p>
<p>
<strong>CSV (comma-separated values)</strong>
   , 70, 114, 396</p>
<p>
<strong>Curator (ZooKeeper recipes)</strong>
   , 330, 371</p>
<p>
<strong>curl (Unix tool)</strong>
   , 135, 397</p>
<p>پایداری نشانگر، 243</p>
<p>
<strong>Cypher (query language)</strong>
   , 52</p>
<p>مقایسه با 
   <strong>SPARQL</strong>
   ، 59</p>
<p>
<strong>D</strong>
</p>
<p>فساد 
   <strong>data</strong>
   (به فساد 
   <strong>data</strong>
   مراجعه کنید)</p>
<p>مکعب‌های 
   <strong>data</strong>
   ، 102</p>
<p>فرمت‌های 
   <strong>data</strong>
   (به رمزگذاری مراجعه کنید)</p>
<p>ادغام 
   <strong>data</strong>
   ، 490-498، 543</p>
<p>پردازش 
   <strong>batch</strong>
   و جریان، 494-498</p>
<p>معماری 
   <strong>lambda</strong>
   ، 497</p>
<p>حفظ حالت مشتق شده، 495</p>
<p>پردازش مجدد 
   <strong>data</strong>
   ، 496</p>
<p>اتحاد، 498</p>
<p>با از بین بردن 
   <strong>databases</strong>
   ، 499-515</p>
<p>مقایسه با 
   <strong>databases</strong>
   فدرال، 501</p>
<p>ترکیب ابزارها با مشتق کردن 
   <strong>data</strong>
   ، 490-494</p>
<p>
<strong>data</strong>
   مشتق‌شده در مقابل تراکنش‌های توزیع‌شده،</p>
<p>492</p>
<p>محدودیت‌های مرتب‌سازی کل، 493</p>
<p>مرتب‌سازی رویدادها برای ثبت علیت، 493</p>
<p>فلسفه در مورد 
   <strong>dataflows</strong>
   ، 491</p>
<p>نیاز به، 385</p>
<p>
<strong>data lakes</strong>
   , 415</p>
<p>مکان داده‌ها (به مکان مراجعه کنید)</p>
<p>مدل‌های 
   <strong>data</strong>
   ، 27-64</p>
<p>مدل‌های 
   <strong>graph-like</strong>
   ، 49-63</p>
<p>زبان 
   <strong>Datalog</strong>
   ، 60-63</p>
<p>
<strong>property graphs</strong>
   , 50</p>
<p>
<strong>RDF</strong>
   و 
   <strong>triple-stores</strong>
   ، 55-59</p>
<p>زبان‌های پرس و جو، 42-48</p>
<p>مدل رابطه‌ای در مقابل مدل سند،</p>
<p>28-42</p>
<p>مقررات حفاظت از 
   <strong>data</strong>
   ، 542</p>
<p>سیستم‌های 
   <strong>data</strong>
   , 3</p>
<p>درباره، 4</p>
<p>
<strong>Index</strong>
   | 565
  </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0587</div>
            </div>
        </div>
        <!-- Page 0588 -->
        <div class="chapter" id="page-0588">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>نگرانی‌ها هنگام طراحی، 5</p>
<p>آینده، 489-544</p>
<p>صحت، محدودیت‌ها و یکپارچگی،</p>
<p>515-533</p>
<p>ادغام 
   <strong>data</strong>
   ، 490-498</p>
<p>
<strong>unbundling databases</strong>
   , 499-515</p>
<p>ناهماهنگ، همگام‌سازی، 452</p>
<p>قابلیت نگهداری، 18-22</p>
<p>خطاهای احتمالی در، 221</p>
<p>قابلیت اطمینان، 6-10</p>
<p>خطاهای سخت‌افزاری، 7</p>
<p>خطاهای انسانی، 9</p>
<p>اهمیت، 10</p>
<p>خطاهای 
   <strong>software</strong>
   , 8</p>
<p>مقیاس‌پذیری، 10-18</p>
<p>ساعت‌های غیرقابل اعتماد، 287-299</p>
<p>
<strong>data warehousing</strong>
   , 91-95, 554</p>
<p>مقایسه با دریاچه‌های 
   <strong>data</strong>
   ، 415</p>
<p>
<strong>ETL (extract-transform-load)</strong>
   , 92, 416, 452</p>
<p>همگام‌سازی سیستم‌های 
   <strong>data</strong>
   ، 452</p>
<p>طراحی 
   <strong>schema</strong>
   , 93</p>
<p>
<strong>slowly changing dimension (SCD)</strong>
   , 476</p>
<p>
<strong>data-intensive applications</strong>
   , 3</p>
<p>
<strong>database triggers (see triggers)</strong>
</p>
<p>تراکنش‌های توزیع‌شده داخلی 
   <strong>database</strong>
   ، 360،</p>
<p>364، 477</p>
<p>
<strong>databases</strong>
</p>
<p>ذخیره‌سازی آرشیوی، 131</p>
<p>مقایسه 
   <strong>message brokers</strong>
   با، 443</p>
<p>
<strong>dataflow</strong>
   از طریق، 129</p>
<p>استدلال 
   <strong>end-to-end</strong>
   برای، 519-520</p>
<p>بررسی یکپارچگی، 531</p>
<p>از درون به بیرون، 504</p>
<p>(همچنین به 
   <strong>unbundling databases</strong>
   مراجعه کنید)</p>
<p>خروجی از 
   <strong>batch workflows</strong>
   ، 412</p>
<p>ارتباط با جریان‌های رویداد، 451-464</p>
<p>(همچنین به 
   <strong>changelogs</strong>
   مراجعه کنید)</p>
<p>پشتیبانی 
   <strong>API</strong>
   برای جریان‌های تغییر، 456،</p>
<p>506</p>
<p>
<strong>change data capture</strong>
   , 454-457</p>
<p>
<strong>event sourcing</strong>
   , 457-459</p>
<p>نگه داشتن سیستم‌ها همگام، 452-453</p>
<p>فلسفه رویدادهای تغییرناپذیر،</p>
<p>459-464</p>
<p>
<strong>unbundling</strong>
   , 499-515</p>
<p>ترکیب فناوری‌های ذخیره‌سازی 
   <strong>data</strong>
   ،</p>
<p>499-504</p>
<p>طراحی برنامه‌ها در اطراف 
   <strong>dataflow</strong>
   ،</p>
<p>504-509</p>
<p>مشاهده حالت مشتق شده، 509-515</p>
<p>
<strong>datacenters</strong>
</p>
<p>جغرافیایی توزیع‌شده، 145، 164، 278،</p>
<p>493</p>
<p>چند مستأجری و منابع مشترک، 284</p>
<p>معماری شبکه، 276</p>
<p>خطاهای شبکه، 279</p>
<p>تکثیر در سراسر، 169</p>
<p>تکثیر بدون 
   <strong>leader</strong>
   ، 184</p>
<p>تکثیر چند 
   <strong>leader</strong>
   ، 168، 335</p>
<p>
<strong>dataflow</strong>
   , 128-139, 504-509</p>
<p>صحت سیستم‌های 
   <strong>dataflow</strong>
   ، 525</p>
<p>دیفرانسیل، 504</p>
<p>
<strong>message-passing</strong>
   , 136-139</p>
<p>استدلال در مورد، 491</p>
<p>از طریق 
   <strong>databases</strong>
   ، 129</p>
<p>از طریق 
   <strong>services</strong>
   ، 131-136</p>
<p>موتورهای 
   <strong>dataflow</strong>
   ، 421-423</p>
<p>مقایسه با پردازش جریان، 464</p>
<p>
<strong>directed acyclic graphs (DAG)</strong>
   , 424</p>
<p>تقسیم‌بندی، رویکرد به، 429</p>
<p>پشتیبانی از پرس و جوهای اعلانی، 427</p>
<p>زبان 
   <strong>Datalog (query language)</strong>
   , 60-63</p>
<p>انواع 
   <strong>data</strong>
</p>
<p>رشته‌های باینری در 
   <strong>XML</strong>
   و 
   <strong>JSON</strong>
   ، 114</p>
<p>غیر 
   <strong>conflict-free</strong>
   ، 174</p>
<p>در کدگذاری‌های 
   <strong>Avro</strong>
   ، 122</p>
<p>در 
   <strong>Thrift</strong>
   و 
   <strong>Protocol Buffers</strong>
   ، 121</p>
<p>اعداد در 
   <strong>XML</strong>
   و 
   <strong>JSON</strong>
   ، 114</p>
<p>
<strong>Datomic (database)</strong>
</p>
<p>ذخیره‌سازی 
   <strong>B-tree</strong>
   ، 242</p>
<p>مدل 
   <strong>data</strong>
   ، 50، 57</p>
<p>زبان پرس و جوی 
   <strong>Datalog</strong>
   ، 60</p>
<p>حذف (حذف 
   <strong>data</strong>
   )، 463</p>
<p>زبان‌ها برای تراکنش‌ها، 255</p>
<p>اجرای سریال تراکنش‌ها، 253</p>
<p>بن‌بست</p>
<p>تشخیص، در 
   <strong>two-phase commit (2PC)</strong>
   ، 364</p>
<p>در 
   <strong>two-phase locking (2PL)</strong>
   ، 258</p>
<p>
<strong>Debezium (change data capture)</strong>
   , 455</p>
<p>زبان‌های اعلانی، 42، 554</p>
<p>
<strong>Bloom</strong>
   ، 504</p>
<p>
<strong>CSS</strong>
   و 
   <strong>XSL</strong>
   ، 44</p>
<p>
<strong>Cypher</strong>
   , 52</p>
<p>مقایسه با 
   <strong>SPARQL</strong>
   ، 59</p>
<p>566 | 
   <strong>Index</strong>
</p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0588</div>
            </div>
        </div>
        <!-- Page 0589 -->
        <div class="chapter" id="page-0589">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>تاخیرهای شبکه، 285</p>
<p>مکث‌های پردازشی محدود، 298</p>
<p>تاخیرهای شبکه نامحدود، 282</p>
<p>مکث‌های پردازشی نامحدود، 296</p>
<p>حذف 
   <strong>data</strong>
   ، 463</p>
<p>
<strong>denormalization (data representation)</strong>
   , 34, 554</p>
<p>هزینه‌ها، 39</p>
<p>در سیستم‌های 
   <strong>derived data</strong>
   ، 386</p>
<p>
<strong>materialized views</strong>
   , 101</p>
<p>به‌روزرسانی 
   <strong>derived data</strong>
   , 228, 231, 490</p>
<p>در مقابل 
   <strong>normalization</strong>
   ، 462</p>
<p>
<strong>derived data</strong>
   , 386, 439, 554</p>
<p>از 
   <strong>change data capture</strong>
   , 454</p>
<p>در 
   <strong>event sourcing</strong>
   ، 458-458</p>
<p>حفظ حالت مشتق‌شده از طریق 
   <strong>logs</strong>
   ،</p>
<p>452-457، 459-463</p>
<p>مشاهده، با مشترک شدن در جریان‌ها، 512</p>
<p>خروجی‌های پردازش 
   <strong>batch</strong>
   و جریان، 495</p>
<p>از طریق کد برنامه، 505</p>
<p>در مقابل تراکنش‌های توزیع‌شده، 492</p>
<p>عملیات قطعی، 255، 274، 554</p>
<p>عدم قطعیت تصادفی، 423</p>
<p>و تحمل خطا، 423، 426</p>
<p>و هم‌ارزی، 478، 492</p>
<p>محاسبه 
   <strong>derived data</strong>
   ، 495، 526، 531</p>
<p>در تکثیر ماشین حالت، 349، 452، 458</p>
<p>
<strong>joins</strong>
   , 476</p>
<p>
<strong>DevOps</strong>
   , 394</p>
<p>
<strong>differential dataflow</strong>
   , 504</p>
<p>جداول ابعادی، 94</p>
<p>مدل‌سازی ابعادی (به 
   <strong>star schemas</strong>
   مراجعه کنید)</p>
<p>
<strong>directed acyclic graphs (DAGs)</strong>
   , 424</p>
<p>خواندن‌های کثیف (
   <strong>transaction isolation</strong>
   )، 234</p>
<p>نوشتن‌های کثیف (
   <strong>transaction isolation</strong>
   )، 235</p>
<p>تبعیض، 534</p>
<p>دیسک‌ها (به هارد دیسک‌ها مراجعه کنید)</p>
<p>قابلیت اطمینان سیستم‌های توزیع‌شده، 138</p>
<p>
<strong>distributed filesystems</strong>
   , 398-399</p>
<p>جدا کردن از موتورهای پرس و جو، 417</p>
<p>به طور بی‌رویه 
   <strong>data</strong>
   را در، 415 می‌ریزد</p>
<p>استفاده توسط 
   <strong>MapReduce</strong>
   ، 402</p>
<p>سیستم‌های توزیع‌شده، 273-312، 554</p>
<p>خطاهای 
   <strong>Byzantine</strong>
   ، 304-306</p>
<p>ماشین حساب و ابر رایانه، 275</p>
<p>تشخیص خطاهای شبکه، 280</p>
<p>خطاها و شکست‌های جزئی، 274-277</p>
<p>رسمیت بخشیدن به اجماع، 365</p>
<p>نتایج ناممکن، 338، 353</p>
<p>مسائل مربوط به 
   <strong>failover</strong>
   , 157</p>
<p>محدودیت‌های تراکنش‌های توزیع‌شده، 363</p>
<p>چند 
   <strong>datacenter</strong>
   ، 169، 335</p>
<p>مشکلات شبکه، 277-286</p>
<p>
<strong>quorums</strong>
   ، اتکا به، 301</p>
<p>دلایل استفاده، 145، 151</p>
<p>ساعت‌های همزمان، اتکا به، 291-295</p>
<p>تراکنش‌های توزیع‌شده (به تراکنش‌ها مراجعه کنید)</p>
<p>
<strong>Django (web framework)</strong>
   , 232</p>
<p>
<strong>DNS (Domain Name System)</strong>
   , 216, 372</p>
<p>
<strong>Docker (container manager)</strong>
   , 506</p>
<p>مدل 
   <strong>data</strong>
   اسناد، 30-42</p>
<p>مقایسه با مدل رابطه‌ای، 38-42</p>
<p>
<strong>document references</strong>
   , 38, 403</p>
<p>
<strong>document-oriented databases</strong>
   , 31</p>
<p>روابط 
   <strong>many-to-many</strong>
   و 
   <strong>joins</strong>
   ، 36</p>
<p>تراکنش‌های چند 
   <strong>object</strong>
   ، نیاز به، 231</p>
<p>در مقابل مدل رابطه‌ای</p>
<p>همگرایی مدل‌ها، 41</p>
<p>جایگاه 
   <strong>data</strong>
   ، 41</p>
<p>شاخص‌های 
   <strong>document-partitioned</strong>
   ، 206، 217، 411</p>
<p>
<strong>domain-driven design (DDD)</strong>
   , 457</p>
<p>
<strong>DRBD (Distributed Replicated Block Device)</strong>
   , 153</p>
<p>خطای (ساعت‌ها)، 289</p>
<p>
<strong>Drill (query engine)</strong>
   , 93</p>
<p>
<strong>Druid (database)</strong>
   , 461</p>
<p>
<strong>Dryad (dataflow engine)</strong>
   , 421</p>
<p>
<strong>dual writes</strong>
   ، مشکلات با، 452، 507</p>
<p>تکرارها، سرکوب، 517</p>
<p>(همچنین به 
   <strong>idempotence</strong>
   مراجعه کنید)</p>
<p>با استفاده از یک 
   <strong>ID</strong>
   منحصر به فرد، 518، 522</p>
<p>ماندگاری (تراکنش‌ها)، 226، 554</p>
<p>مدت زمان (زمان)، 287</p>
<p>اندازه‌گیری با ساعت‌های یکنواخت، 288</p>
<p>پارتیشن‌بندی پویا، 212</p>
<p>
<strong>dynamically typed languages</strong>
</p>
<p>تشابه با 
   <strong>schema-on-read</strong>
   ، 40</p>
<p>تولید کد و، 127</p>
<p>پایگاه‌های داده سبک 
   <strong>Dynamo (see leaderless replica-</strong>
</p>
<p>
<strong>tion)</strong>
</p>
<p>
<strong>E</strong>
</p>
<p>
<strong>edges (in graphs)</strong>
   , 49, 403</p>
<p>مدل 
   <strong>property graph</strong>
   ، 50</p>
<p>فاصله ویرایش (جستجوی متن کامل)، 88</p>
<p>معناشناسی موثر-یک بار، 476، 516</p>
<p>
<strong>Index</strong>
   | 567
  </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0589</div>
            </div>
        </div>
        <!-- Page 0590 -->
        <div class="chapter" id="page-0590">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>(همچنین به 
   <strong>exactly-once semantics</strong>
   مراجعه کنید)</p>
<p>حفظ یکپارچگی، 525</p>
<p>سیستم‌های الاستیک، 17</p>
<p>
<strong>Elasticsearch (search server)</strong>
</p>
<p>شاخص‌های 
   <strong>document-partitioned</strong>
   ، 207</p>
<p>تعادل مجدد پارتیشن، 211</p>
<p>
<strong>percolator (stream search)</strong>
   , 467</p>
<p>مثال استفاده، 4</p>
<p>استفاده از 
   <strong>Lucene</strong>
   ، 79</p>
<p>
<strong>ElephantDB (database)</strong>
   , 413</p>
<p>
<strong>Elm (programming language)</strong>
   , 504, 512</p>
<p>رمزگذاری‌ها (فرمت‌های 
   <strong>data</strong>
   )، 111-128</p>
<p>
<strong>Avro</strong>
   , 122-127</p>
<p>انواع باینری 
   <strong>JSON</strong>
   و 
   <strong>XML</strong>
   ، 115</p>
<p>سازگاری، 112</p>
<p>فراخوانی 
   <strong>services</strong>
   ، 136</p>
<p>استفاده از 
   <strong>databases</strong>
   ، 129-131</p>
<p>استفاده از 
   <strong>message-passing</strong>
   ، 138</p>
<p>تعریف شده، 113</p>
<p>
<strong>JSON, XML, and CSV</strong>
   , 114</p>
<p>فرمت‌های مخصوص زبان، 113</p>
<p>مزایای 
   <strong>schemas</strong>
   , 127</p>
<p>نمایش 
   <strong>data</strong>
   ، 112</p>
<p>
<strong>Thrift</strong>
   و 
   <strong>Protocol Buffers</strong>
   , 117-121</p>
<p>
<strong>end-to-end argument</strong>
   , 277, 519-520</p>
<p>بررسی یکپارچگی، 531</p>
<p>جریان‌های 
   <strong>publish/subscribe</strong>
   ، 512</p>
<p>غنی‌سازی (جریان)، 473</p>
<p>
<strong>Enterprise JavaBeans (EJB)</strong>
   , 134</p>
<p>موجودیت‌ها (به راس‌ها مراجعه کنید)</p>
<p>دوره (الگوریتم‌های 
   <strong>consensus</strong>
   )، 368</p>
<p>دوره (
   <strong>Unix timestamps</strong>
   )، 288</p>
<p>اتصالات 
   <strong>equi-joins</strong>
   ، 403</p>
<p>
<strong>erasure coding (error correction)</strong>
   , 398</p>
<p>
<strong>Erlang OTP (actor framework)</strong>
   , 139</p>
<p>مدیریت خطا</p>
<p>برای خطاهای شبکه، 280</p>
<p>در تراکنش‌ها، 231</p>
<p>کدهای تصحیح خطا، 277، 398</p>
<p>
<strong>Esper (CEP engine)</strong>
   , 466</p>
<p>
<strong>etcd (coordination service)</strong>
   , 370-373</p>
<p>عملیات 
   <strong>linearizable</strong>
   ، 333</p>
<p>
<strong>locks</strong>
   و انتخاب 
   <strong>leader</strong>
   ، 330</p>
<p>خواندن‌های 
   <strong>quorum</strong>
   ، 351</p>
<p>کشف 
   <strong>service</strong>
   ، 372</p>
<p>استفاده از الگوریتم 
   <strong>Raft</strong>
   ، 349، 353</p>
<p>
<strong>Ethereum (blockchain)</strong>
   , 532</p>
<p>
<strong>Ethernet (networks)</strong>
   , 276, 278, 285</p>
<p>
<strong>packet checksums</strong>
   , 306, 519</p>
<p>
<strong>Etherpad (collaborative editor)</strong>
   , 170</p>
<p>اخلاقیات، 533-543</p>
<p>کد اخلاق و عملکرد حرفه‌ای، 533</p>
<p>قانون‌گذاری و خودتنظیمی، 542</p>
<p>
<strong>predictive analytics</strong>
   , 533-536</p>
<p>تقویت سوگیری، 534</p>
<p>حلقه‌های بازخورد، 536</p>
<p>حریم خصوصی و ردیابی، 536-543</p>
<p>رضایت و آزادی انتخاب، 538</p>
<p>
<strong>data</strong>
   به عنوان دارایی و قدرت، 540</p>
<p>معنی حریم خصوصی، 539</p>
<p>نظارت، 537</p>
<p>احترام، کرامت، و عاملیت، 543، 544</p>
<p>عواقب ناخواسته، 533، 536</p>
<p>
<strong>ETL (extract-transform-load)</strong>
   , 92, 405, 452, 554</p>
<p>استفاده از 
   <strong>Hadoop</strong>
   برای، 416</p>
<p>
<strong>event sourcing</strong>
   , 457-459</p>
<p>فرمان‌ها و رویدادها، 459</p>
<p>مقایسه با 
   <strong>change data capture</strong>
   ، 457</p>
<p>مقایسه با معماری 
   <strong>lambda</strong>
   ، 497</p>
<p>استنتاج حالت فعلی از لاگ رویداد، 458</p>
<p>تغییرناپذیری و 
   <strong>auditability</strong>
   ، 459، 531</p>
<p>
<strong>Event Store (database)</strong>
   , 458</p>
<p>جریان‌های رویداد (به جریان‌ها مراجعه کنید)</p>
<p>رویدادها، 440</p>
<p>تصمیم‌گیری در مورد ترتیب کل، 493</p>
<p>استنتاج 
   <strong>views</strong>
   از 
   <strong>event log</strong>
   ، 461</p>
<p>تفاوت با دستورات، 459</p>
<p>زمان رویداد در مقابل زمان پردازش، 469، 477،</p>
<p>498</p>
<p>تغییرناپذیر، مزایای، 460، 531</p>
<p>ترتیب برای ثبت علیت، 493</p>
<p>
<strong>reads</strong>
   به عنوان، 513</p>
<p>
<strong>stragglers</strong>
   , 470, 498</p>
<p>
<strong>timestamp</strong>
   رویداد، در پردازش جریان، 471</p>
<p>
<strong>EventSource (browser API)</strong>
   , 512</p>
<p>
<strong>eventual consistency</strong>
   , 152, 162, 308, 322</p>
<p>(همچنین به ناهمگونی نهایی مراجعه کنید)</p>
<p>و ناهمگونی دائمی، 525</p>
<p>قابلیت تکامل، 21، 111</p>
<p>فراخوانی 
   <strong>services</strong>
   ، 136</p>
<p>
<strong>data</strong>
   ساختاریافته 
   <strong>graph</strong>
   ، 52</p>
<p>از 
   <strong>databases</strong>
   ، 40، 129-131، 461، 497</p>
<p>از 
   <strong>message-passing</strong>
   ، 138</p>
<p>پردازش مجدد 
   <strong>data</strong>
   ، 496، 498</p>
<p>تکامل 
   <strong>schema</strong>
   در 
   <strong>Avro</strong>
   ، 123</p>
<p>تکامل 
   <strong>schema</strong>
   در 
   <strong>Thrift</strong>
   و 
   <strong>Protocol</strong>
</p>
<p>
<strong>Buffers</strong>
   ، 120</p>
<p>568 | 
   <strong>Index</strong>
</p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0590</div>
            </div>
        </div>
        <!-- Page 0591 -->
        <div class="chapter" id="page-0591">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
<strong>schema-on-read</strong>
   , 39, 111, 128</p>
<p>
<strong>exactly-once semantics</strong>
   , 360, 476, 516</p>
<p>برابری با پردازشگرهای 
   <strong>batch</strong>
   ، 498</p>
<p>حفظ یکپارچگی، 525</p>
<p>حالت انحصاری (
   <strong>locks</strong>
   )، 258</p>
<p>تراکنش‌های 
   <strong>eXtended Architecture (see XA</strong>
</p>
<p>
<strong>transactions)</strong>
</p>
<p>
<strong>extract-transform-load (see ETL)</strong>
</p>
<p>
<strong>F</strong>
</p>
<p>
<strong>Facebook</strong>
</p>
<p>
<strong>Presto (query engine)</strong>
   , 93</p>
<p>
<strong>React, Flux, and Redux (user interface libraries)</strong>
   , 512</p>
<p>
<strong>social graphs</strong>
   , 49</p>
<p>
<strong>Wormhole (change data capture)</strong>
   , 455</p>
<p>جداول 
   <strong>fact</strong>
   , 93</p>
<p>
<strong>failover</strong>
   , 157, 554</p>
<p>(همچنین به تکثیر مبتنی بر 
   <strong>leader</strong>
   مراجعه کنید)</p>
<p>در تکثیر بدون 
   <strong>leader</strong>
   ، عدم وجود، 178</p>
<p>انتخاب 
   <strong>leader</strong>
   ، 301، 348، 352</p>
<p>مشکلات احتمالی، 157</p>
<p>شکست‌ها</p>
<p>تقویت‌شده توسط تراکنش‌های توزیع‌شده،</p>
<p>364، 495</p>
<p>تشخیص شکست، 280</p>
<p>تعادل مجدد خودکار باعث ایجاد شکست‌های آبشاری، 214 می‌شود</p>
<p>تشخیص‌دهنده‌های شکست کامل، 359</p>
<p>زمان‌بندی و تأخیرهای نامحدود، 282،</p>
<p>284</p>
<p>با استفاده از 
   <strong>ZooKeeper</strong>
   ، 371</p>
<p>خطاها در مقابل، 7</p>
<p>شکست‌های جزئی در سیستم‌های توزیع‌شده،</p>
<p>275-277، 310</p>
<p>
<strong>fan-out (messaging systems)</strong>
   , 11, 445</p>
<p>
<strong>fault tolerance</strong>
   , 6-10, 555</p>
<p>انتزاعات برای، 321</p>
<p>رسمیت در اجماع، 365-369</p>
<p>استفاده از تکثیر، 367</p>
<p>تحمل خطای انسانی، 414</p>
<p>در پردازش 
   <strong>batch</strong>
   ، 406، 414، 422، 425</p>
<p>در سیستم‌های مبتنی بر 
   <strong>log</strong>
   ، 520، 524-526</p>
<p>در پردازش جریان، 476-479</p>
<p>تعهد اتمی، 477</p>
<p>هم‌ارزی، 478</p>
<p>حفظ حالت مشتق‌شده، 495</p>
<p>میکرو
   <strong>batching</strong>
   و 
   <strong>checkpointing</strong>
   , 477</p>
<p>بازسازی حالت پس از خرابی، 478</p>
<p>از تراکنش‌های توزیع‌شده، 362-364</p>
<p>اتمی بودن تراکنش، 223، 354-361</p>
<p>
<strong>faults</strong>
   , 6</p>
<p>خطاهای 
   <strong>Byzantine</strong>
   ، 304-306</p>
<p>شکست‌ها در مقابل، 7</p>
<p>مدیریت شده توسط تراکنش‌ها، 221</p>
<p>مدیریت در ابر رایانه و محاسبات ابری،</p>
<p>275</p>
<p>خطاهای سخت‌افزاری، 7</p>
<p>در پردازش 
   <strong>batch</strong>
   در مقابل 
   <strong>databases</strong>
   توزیع‌شده، 417</p>
<p>در سیستم‌های توزیع‌شده، 274-277</p>
<p>معرفی عمدی، 7، 280</p>
<p>خطاهای شبکه، 279-281</p>
<p>خطاهای نامتقارن، 300</p>
<p>تحمل، در تکثیر چند 
   <strong>leader</strong>
   ،</p>
<p>169</p>
<p>خطاهای 
   <strong>software</strong>
   , 8</p>
<p>تحمل (به تحمل خطا مراجعه کنید)</p>
<p>
<strong>federated databases</strong>
   , 501</p>
<p>
<strong>fence (CPU instruction)</strong>
   , 338</p>
<p>
<strong>fencing (preventing split brain)</strong>
   , 158, 302-304</p>
<p>تولید 
   <strong>fencing tokens</strong>
   ، 349، 370</p>
<p>ویژگی‌های 
   <strong>fencing tokens</strong>
   ، 308</p>
<p>پردازشگرهای جریان نوشتن به 
   <strong>databases</strong>
   ، 478،</p>
<p>517</p>
<p>
<strong>Fibre Channel (networks)</strong>
   , 398</p>
<p>
<strong>field tags (Thrift and Protocol Buffers)</strong>
   , 119-121</p>
<p>فایل دیسکریپتورها (یونیکس)، 395</p>
<p>
<strong>financial data</strong>
   , 460</p>
<p>
<strong>Firebase (database)</strong>
   , 456</p>
<p>
<strong>Flink (processing framework)</strong>
   , 421-423</p>
<p>
<strong>dataflow APIs</strong>
   , 427</p>
<p>تحمل خطا، 422، 477، 479</p>
<p>
<strong>Gelly API (graph processing)</strong>
   , 425</p>
<p>ادغام پردازش 
   <strong>batch</strong>
   و جریان،</p>
<p>495، 498</p>
<p>یادگیری ماشینی، 428</p>
<p>بهینه‌ساز 
   <strong>query</strong>
   ، 427</p>
<p>پردازش جریان، 466</p>
<p>
<strong>flow control</strong>
   , 282, 441, 555</p>
<p>نتیجه 
   <strong>FLP (on consensus)</strong>
   ، 353</p>
<p>
<strong>FlumeJava (dataflow library)</strong>
   , 403, 427</p>
<p>
<strong>followers</strong>
   , 152, 555</p>
<p>(همچنین به تکثیر مبتنی بر 
   <strong>leader</strong>
   مراجعه کنید)</p>
<p>کلیدهای خارجی، 38، 403</p>
<p>سازگاری به جلو، 112</p>
<p>
<strong>forward decay (algorithm)</strong>
   , 16</p>
<p>
<strong>Index</strong>
   | 569
  </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0591</div>
            </div>
        </div>
        <!-- Page 0592 -->
        <div class="chapter" id="page-0592">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
<strong>Fossil (version control system)</strong>
   , 463</p>
<p>
<strong>shunning (deleting data)</strong>
   , 463</p>
<p>
<strong>FoundationDB (database)</strong>
</p>
<p>تراکنش‌های 
   <strong>serializable</strong>
   , 261, 265, 364</p>
<p>درخت‌های 
   <strong>fractal</strong>
   ، 83</p>
<p>
<strong>full table scans</strong>
   , 403</p>
<p>جستجوی متن کامل، 555</p>
<p>و شاخص‌های فازی، 88</p>
<p>موتور ذخیره‌سازی 
   <strong>Lucene</strong>
   ، 79</p>
<p>
<strong>functional reactive programming (FRP)</strong>
   , 504</p>
<p>الزامات کاربردی، 22</p>
<p>
<strong>futures (asynchronous operations)</strong>
   , 135</p>
<p>جستجوی فازی (به 
   <strong>similarity search</strong>
   مراجعه کنید)</p>
<p>
<strong>G</strong>
</p>
<p>
<strong>garbage collection</strong>
</p>
<p>تغییرناپذیری و، 463</p>
<p>مکث‌های فرآیند برای، 14، 296-299، 301</p>
<p>(همچنین به مکث‌های فرآیند مراجعه کنید)</p>
<p>تجزیه و تحلیل ژنوم، 63، 429</p>
<p>
<strong>geographically distributed datacenters</strong>
   , 145,
   </p>
<p>164, 278, 493</p>
<p>شاخص‌های مکانی، 87</p>
<p>
<strong>Giraph (graph processing)</strong>
   , 425</p>
<p>
<strong>Git (version control system)</strong>
   , 174, 342, 463</p>
<p>
<strong>GitHub</strong>
   , postmortems, 157, 158, 309</p>
<p>شاخص‌های جهانی (به شاخص‌های تقسیم‌بندی‌شده ترم مراجعه کنید)</p>
<p>
<strong>GlusterFS (distributed filesystem)</strong>
   , 398</p>
<p>
<strong>GNU Coreutils (Linux)</strong>
   , 394</p>
<p>
<strong>GoldenGate (change data capture)</strong>
   , 161, 170,</p>
<p>455</p>
<p>(همچنین به 
   <strong>Oracle</strong>
   مراجعه کنید)</p>
<p>
<strong>Google</strong>
</p>
<p>
<strong>Bigtable (database)</strong>
</p>
<p>مدل 
   <strong>data</strong>
   (به مدل 
   <strong>data Bigtable</strong>
   مراجعه کنید)</p>
<p>طرح تقسیم‌بندی، 199، 202</p>
<p>چیدمان ذخیره‌سازی، 78</p>
<p>
<strong>Chubby (lock service)</strong>
   , 370</p>
<p>
<strong>Cloud Dataflow (stream processor)</strong>
   , 466,</p>
<p>477, 498</p>
<p>(همچنین به 
   <strong>Beam</strong>
   مراجعه کنید)</p>
<p>
<strong>Cloud Pub/Sub (messaging)</strong>
   , 444, 448</p>
<p>
<strong>Docs (collaborative editor)</strong>
   , 170</p>
<p>
<strong>Dremel (query engine)</strong>
   , 93, 96</p>
<p>
<strong>FlumeJava (dataflow library)</strong>
   , 403, 427</p>
<p>
<strong>GFS (distributed file system)</strong>
   , 398</p>
<p>
<strong>gRPC (RPC framework)</strong>
   , 135</p>
<p>
<strong>MapReduce (batch processing)</strong>
   , 390</p>
<p>(همچنین به 
   <strong>MapReduce</strong>
   مراجعه کنید)</p>
<p>ساخت شاخص‌های جستجو، 411</p>
<p>پیش‌دستی از کار، 418</p>
<p>
<strong>Pregel (graph processing)</strong>
   , 425</p>
<p>
<strong>Spanner (see Spanner)</strong>
</p>
<p>
<strong>TrueTime (clock API)</strong>
   , 294</p>
<p>پروتکل شایعه‌پراکنی، 216</p>
<p>دولت از 
   <strong>data</strong>
   استفاده می‌کند، 541</p>
<p>
<strong>GPS (Global Positioning System)</strong>
</p>
<p>استفاده برای همگام‌سازی ساعت، 287، 290، 294،</p>
<p>295</p>
<p>
<strong>GraphChi (graph processing)</strong>
   , 426</p>
<p>
<strong>graphs</strong>
   , 555</p>
<p>به عنوان مدل‌های 
   <strong>data</strong>
   ، 49-63</p>
<p>مثالی از 
   <strong>data</strong>
   ساختاریافته 
   <strong>graph</strong>
   ، 49</p>
<p>
<strong>property graphs</strong>
   , 50</p>
<p>
<strong>RDF</strong>
   و 
   <strong>triple-stores</strong>
   ، 55-59</p>
<p>در مقابل مدل شبکه، 60</p>
<p>پردازش و تجزیه و تحلیل، 424-426</p>
<p>تحمل خطا، 425</p>
<p>مدل پردازش 
   <strong>Pregel</strong>
   ، 425</p>
<p>زبان‌های پرس و جو</p>
<p>
<strong>Cypher</strong>
   , 52</p>
<p>
<strong>Datalog</strong>
   , 60-63</p>
<p>پرس و جوهای 
   <strong>SQL</strong>
   بازگشتی، 53</p>
<p>جبر رابطه‌ای و 
   <strong>SQL</strong>
   ، 42</p>
<p>
<strong>Gremlin (graph query language)</strong>
   , 50</p>
<p>
<strong>grep (Unix tool)</strong>
   , 392</p>
<p>عبارت 
   <strong>GROUP BY (SQL)</strong>
   , 406</p>
<p>گروه‌بندی رکوردها در 
   <strong>MapReduce</strong>
   ، 406</p>
<p>مدیریت 
   <strong>skew</strong>
   , 407</p>
<p>
<strong>H</strong>
</p>
<p>
<strong>Hadoop (data infrastructure)</strong>
</p>
<p>مقایسه با 
   <strong>databases</strong>
   توزیع‌شده، 390</p>
<p>مقایسه با 
   <strong>databases MPP</strong>
   ، 414-418</p>
<p>مقایسه با یونیکس، 413-414، 499</p>
<p>مدل‌های پردازشی متنوع در اکوسیستم، 417</p>
<p>فایل‌سیستم توزیع‌شده 
   <strong>HDFS (see HDFS)</strong>
</p>
<p>ابزارهای سطح بالاتر، 403</p>
<p>الگوریتم‌های 
   <strong>join</strong>
   ، 403-410</p>
<p>(همچنین به 
   <strong>MapReduce</strong>
   مراجعه کنید)</p>
<p>
<strong>MapReduce (see MapReduce)</strong>
</p>
<p>
<strong>YARN (see YARN)</strong>
</p>
<p>رابطه 
   <strong>happens-before</strong>
   , 340</p>
<p>ثبت، 187</p>
<p>همزمانی و، 186</p>
<p>هارد دیسک‌ها</p>
<p>الگوهای دسترسی، 84</p>
<p>
<strong>Index</strong>
   | 569
  </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0592</div>
            </div>
        </div>
        <!-- Page 0593 -->
        <div class="chapter" id="page-0593">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
<strong>detecting corruption</strong>
   , 519, 530</p>
<p>خطاها در، 7، 227</p>
<p>
<strong>sequential write throughput</strong>
   , 75, 450</p>
<p>خطاهای سخت‌افزاری، 7</p>
<p>شاخص‌های 
   <strong>hash</strong>
   ، 72-75</p>
<p>اتصالات 
   <strong>hash</strong>
   ، 409</p>
<p>اتصالات پارتیشن‌شده 
   <strong>hash</strong>
   ، 409</p>
<p>تقسیم‌بندی 
   <strong>hash</strong>
   , 203-205, 217</p>
<p>
<strong>consistent hashing</strong>
   ، 204</p>
<p>مشکلات با 
   <strong>hash mod N</strong>
   ، 210</p>
<p>پرس و جوهای 
   <strong>range</strong>
   ، 204</p>
<p>توابع 
   <strong>hash</strong>
   مناسب، 203</p>
<p>با تعداد ثابتی از پارتیشن‌ها، 210</p>
<p>
<strong>HAWQ (database)</strong>
   , 428</p>
<p>
<strong>HBase (database)</strong>
</p>
<p>
<strong>bug</strong>
   به دلیل عدم وجود 
   <strong>fencing</strong>
   ، 302</p>
<p>بارگذاری انبوه، 413</p>
<p>مدل 
   <strong>data</strong>
   خانواده ستون، 41، 99</p>
<p>پارتیشن‌بندی پویا، 212</p>
<p>پارتیشن‌بندی کلید-محدوده، 202</p>
<p>ذخیره‌سازی مبتنی بر 
   <strong>log</strong>
   ، 78</p>
<p>
<strong>request routing</strong>
   , 216</p>
<p>فشرده‌سازی اندازه‌دار، 79</p>
<p>استفاده از 
   <strong>HDFS</strong>
   , 417</p>
<p>استفاده از 
   <strong>ZooKeeper</strong>
   , 370</p>
<p>
<strong>HDFS (Hadoop Distributed File System)</strong>
   , 398-399</p>
<p>(همچنین به 
   <strong>distributed filesystems</strong>
   مراجعه کنید)</p>
<p>بررسی یکپارچگی، 530</p>
<p>جدا کردن از موتورهای پرس و جو، 417</p>
<p>به طور بی‌رویه 
   <strong>data</strong>
   را در، 415 می‌ریزد</p>
<p>
<strong>metadata</strong>
   درباره مجموعه‌داده‌ها، 410</p>
<p>
<strong>NameNode</strong>
   , 398</p>
<p>استفاده توسط 
   <strong>Flink</strong>
   ، 479</p>
<p>استفاده توسط 
   <strong>HBase</strong>
   , 212</p>
<p>استفاده توسط 
   <strong>MapReduce</strong>
   , 402</p>
<p>
<strong>HdrHistogram (numerical library)</strong>
   , 16</p>
<p>
<strong>head (Unix tool)</strong>
   , 392</p>
<p>
<strong>head vertex (property graphs)</strong>
   , 51</p>
<p>فایل‌های 
   <strong>heap (databases)</strong>
   , 86</p>
<p>
<strong>Helix (cluster manager)</strong>
   , 216</p>
<p>
<strong>heterogeneous distributed transactions</strong>
   , 360,</p>
<p>364</p>
<p>تصمیمات اکتشافی (در 
   <strong>2PC</strong>
   )، 363</p>
<p>
<strong>Hibernate (object-relational mapper)</strong>
   , 30</p>
<p>مدل سلسله مراتبی، 36</p>
<p>تجارت با فرکانس بالا، 290، 299</p>
<p>
<strong>high-performance computing (HPC)</strong>
   , 275</p>
<p>
<strong>hinted handoff</strong>
   , 183</p>
<p>
<strong>histograms</strong>
   , 16</p>
<p>
<strong>Hive (query engine)</strong>
   , 419, 427</p>
<p>برای 
   <strong>data warehouses</strong>
   ، 93</p>
<p>
<strong>HCatalog and metastore</strong>
   , 410</p>
<p>
<strong>map-side joins</strong>
   , 409</p>
<p>پرس و جو به هم پیوسته، 408</p>
<p>
<strong>workflows</strong>
   , 403</p>
<p>ماشین‌های 
   <strong>Hollerith</strong>
   ، 390</p>
<p>پنجره‌های جهشی (پردازش جریان)، 472</p>
<p>(همچنین به پنجره‌ها مراجعه کنید)</p>
<p>مقیاس‌پذیری افقی (به 
   <strong>scaling out</strong>
   مراجعه کنید)</p>
<p>
<strong>HornetQ (messaging)</strong>
   , 137, 444</p>
<p>پشتیبانی از تراکنش توزیع‌شده، 361</p>
<p>
<strong>hot spots</strong>
   , 201</p>
<p>به دلیل افراد مشهور، 205</p>
<p>برای 
   <strong>data</strong>
   های سری زمانی، 203</p>
<p>در پردازش 
   <strong>batch</strong>
   ، 407</p>
<p>کاهش، 205</p>
<p>استندبای‌های فعال (به تکثیر مبتنی بر 
   <strong>leader</strong>
   مراجعه کنید)</p>
<p>
<strong>HTTP</strong>
   , استفاده در 
   <strong>APIs (see services)</strong>
</p>
<p>خطاهای انسانی، 9، 279، 414</p>
<p>
<strong>HyperDex (database)</strong>
   , 88</p>
<p>
<strong>HyperLogLog (algorithm)</strong>
   , 466</p>
<p>
<strong>I</strong>
</p>
<p>عملیات 
   <strong>I/O</strong>
   ، انتظار برای، 297</p>
<p>
<strong>IBM</strong>
</p>
<p>
<strong>DB2 (database)</strong>
</p>
<p>پشتیبانی از تراکنش توزیع‌شده، 361</p>
<p>پشتیبانی از پرس و جو بازگشتی، 54</p>
<p>
<strong>serializable isolation</strong>
   , 242, 257</p>
<p>پشتیبانی 
   <strong>XML</strong>
   و 
   <strong>JSON</strong>
   ، 30، 42</p>
<p>
<strong>electromechanical card-sorting machines</strong>
   , 390</p>
<p>
<strong>IMS (database)</strong>
   , 36</p>
<p>
<strong>imperative query APIs</strong>
   , 46</p>
<p>
<strong>InfoSphere Streams (CEP engine)</strong>
   , 466</p>
<p>
<strong>MQ (messaging)</strong>
   , 444</p>
<p>پشتیبانی از تراکنش توزیع‌شده، 361</p>
<p>
<strong>System R (database)</strong>
   , 222</p>
<p>
<strong>WebSphere (messaging)</strong>
   , 137</p>
<p>
<strong>idempotence</strong>
   , 134, 478, 555</p>
<p>با دادن 
   <strong>IDs</strong>
   منحصر به فرد به عملیات، 518، 522</p>
<p>عملیات 
   <strong>idempotent</strong>
   ، 517</p>
<p>تغییرناپذیری</p>
<p>مزایای، 460، 531</p>
<p>
<strong>Index</strong>
   | 569
  </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0593</div>
            </div>
        </div>
        <!-- Page 0594 -->
        <div class="chapter" id="page-0594">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>مشتق کردن حالت از 
   <strong>event log</strong>
   , 459-464</p>
<p>برای بازیابی خرابی، 75</p>
<p>در 
   <strong>B-trees</strong>
   ، 82، 242</p>
<p>در 
   <strong>event sourcing</strong>
   , 457</p>
<p>ورودی به دستورات یونیکس، 397</p>
<p>محدودیت‌ها، 463</p>
<p>
<strong>Impala (query engine)</strong>
</p>
<p>برای 
   <strong>data warehouses</strong>
   ، 93</p>
<p>اتصالات 
   <strong>hash</strong>
   , 409</p>
<p>تولید کد بومی، 428</p>
<p>استفاده از 
   <strong>HDFS</strong>
   , 417</p>
<p>
<strong>impedance mismatch</strong>
   , 29</p>
<p>زبان‌های دستوری، 42</p>
<p>تنظیم سبک‌های عنصر (مثال)، 45</p>
<p>در شک (وضعیت 
   <strong>transaction</strong>
   )، 358</p>
<p>نگه داشتن 
   <strong>locks</strong>
   , 362</p>
<p>تراکنش‌های یتیم، 363</p>
<p>
<strong>in-memory databases</strong>
   , 88</p>
<p>ماندگاری، 227</p>
<p>اجرای سریال 
   <strong>transaction</strong>
   , 253</p>
<p>حوادث</p>
<p>شکست‌های آبشاری، 9</p>
<p>خرابی‌ها به دلیل ثانیه‌های کبیسه، 290</p>
<p>فساد 
   <strong>data</strong>
   و زیان‌های مالی به دلیل</p>
<p>
<strong>bugs</strong>
   همزمانی، 233</p>
<p>فساد 
   <strong>data</strong>
   در هارد دیسک‌ها، 227</p>
<p>از دست دادن 
   <strong>data</strong>
   به دلیل 
   <strong>last-write-wins</strong>
   ، 173، 292</p>
<p>
<strong>data</strong>
   در دیسک‌ها غیرقابل خواندن، 309</p>
<p>اقلام حذف شده دوباره ظاهر می‌شوند، 174</p>
<p>افشای 
   <strong>data</strong>
   حساس به دلیل استفاده مجدد از 
   <strong>primary</strong>
</p>
<p>
<strong>key</strong>
   , 157</p>
<p>خطاها در 
   <strong>serializability</strong>
   تراکنش، 529</p>
<p>رابط شبکه گیگابیت با 
   <strong>1 Kb/s</strong>
</p>
<p>توان عملیاتی، 311</p>
<p>خطاهای شبکه، 279</p>
<p>رابط شبکه فقط بسته‌های ورودی را رها می‌کند</p>
<p>بسته‌ها، 279</p>
<p>پارتیشن‌بندی شبکه و خرابی‌های 
   <strong>whole-datacenter</strong>
   , 275</p>
<p>مدیریت نامناسب خطاهای شبکه، 280</p>
<p>ارسال پیام به شریک سابق، 494</p>
<p>کوسه‌ها در حال گاز گرفتن کابل‌های زیر دریا، 279</p>
<p>
<strong>split brain</strong>
   به دلیل تأخیر 1 دقیقه‌ای بسته،</p>
<p>158، 279</p>
<p>ارتعاشات در قفسه سرور، 14</p>
<p>نقض محدودیت منحصر به فرد، 529</p>
<p>شاخص‌ها، 71، 555</p>
<p>و 
   <strong>snapshot isolation</strong>
   , 241</p>
<p>به عنوان 
   <strong>derived data</strong>
   ، 386، 499-504</p>
<p>
<strong>B-trees</strong>
   , 79-83</p>
<p>ساختن در فرآیندهای 
   <strong>batch</strong>
   ، 411</p>
<p>خوشه‌ای، 86</p>
<p>مقایسه 
   <strong>B-trees</strong>
   و 
   <strong>LSM-trees</strong>
   , 83-85</p>
<p>شاخص‌های پیوسته، 87</p>
<p>ایجاد، 500</p>
<p>جستجوی متن کامل، 88</p>
<p>مکانی، 87</p>
<p>شاخص‌های 
   <strong>hash</strong>
   ، 72-75</p>
<p>قفل 
   <strong>index-range</strong>
   ، 260</p>
<p>چند ستونی، 87</p>
<p>پارتیشن‌بندی و شاخص‌های ثانویه،</p>
<p>206-209، 217</p>
<p>ثانویه، 85</p>
<p>(همچنین به شاخص‌های ثانویه مراجعه کنید)</p>
<p>مشکلات با نوشته‌های دوگانه، 452، 491</p>
<p>
<strong>SSTables</strong>
   و 
   <strong>LSM-trees</strong>
   , 76-79</p>
<p>به‌روزرسانی زمانی که 
   <strong>data</strong>
   تغییر می‌کند، 452، 467</p>
<p>انقلاب صنعتی، 541</p>
<p>
<strong>InfiniBand (networks)</strong>
   , 285</p>
<p>
<strong>InfiniteGraph (database)</strong>
   , 50</p>
<p>
<strong>InnoDB (storage engine)</strong>
</p>
<p>شاخص 
   <strong>clustered</strong>
   در کلید اصلی، 86</p>
<p>جلوگیری از به‌روزرسانی‌های از دست رفته، 245</p>
<p>جلوگیری از 
   <strong>write skew</strong>
   ، 248، 257</p>
<p>
<strong>serializable isolation</strong>
   , 257</p>
<p>پشتیبانی از 
   <strong>snapshot isolation</strong>
   , 239</p>
<p>
<strong>inside-out databases</strong>
   , 504</p>
<p>(همچنین به 
   <strong>unbundling databases</strong>
   مراجعه کنید)</p>
<p>ادغام سیستم‌های 
   <strong>data</strong>
   مختلف (به ادغام 
   <strong>data</strong>
   مراجعه کنید)</p>
<p>یکپارچگی، 524</p>
<p>سیستم‌های 
   <strong>data</strong>
   هماهنگی-اجتناب، 528</p>
<p>صحت سیستم‌های 
   <strong>dataflow</strong>
   ، 525</p>
<p>در رسمیت اجماع، 365</p>
<p>بررسی یکپارچگی، 530</p>
<p>(همچنین به 
   <strong>auditing</strong>
   مراجعه کنید)</p>
<p>
<strong>end-to-end</strong>
   ، 519، 531</p>
<p>استفاده از 
   <strong>snapshot isolation</strong>
   ، 238</p>
<p>حفظ با وجود 
   <strong>bugs</strong>
   نرم‌افزار، 529</p>
<p>
<strong>Interface Definition Language (IDL)</strong>
   , 117, 122</p>
<p>حالت میانی، 420-423</p>
<p>
<strong>internet services</strong>
   ، سیستم‌هایی برای پیاده‌سازی،</p>
<p>275</p>
<p>متغیرها، 225</p>
<p>(همچنین به محدودیت‌ها مراجعه کنید)</p>
<p>
<strong>inversion of control</strong>
   , 396</p>
<p>
<strong>IP (Internet Protocol)</strong>
</p>
<p>572 | 
   <strong>Index</strong>
</p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0594</div>
            </div>
        </div>
        <!-- Page 0595 -->
        <div class="chapter" id="page-0595">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
<strong>unreliability of</strong>
   , 277</p>
<p>
<strong>ISDN (Integrated Services Digital Network)</strong>
   ,
   </p>
<p>284</p>
<p>
<strong>isolation (in transactions)</strong>
   , 225, 228, 555</p>
<p>صحت و، 515</p>
<p>برای نوشته‌های 
   <strong>single-object</strong>
   , 230</p>
<p>
<strong>serializability</strong>
   ، 251-266</p>
<p>اجرای سریال واقعی، 252-256</p>
<p>
<strong>serializable snapshot isolation (SSI)</strong>
   , 261-266</p>
<p>
<strong>two-phase locking (2PL)</strong>
   ، 257-261</p>
<p>نقض، 228</p>
<p>سطوح 
   <strong>weak isolation</strong>
   , 233-251</p>
<p>جلوگیری از از دست رفتن به‌روزرسانی‌ها، 242-246</p>
<p>خواندن 
   <strong>read committed</strong>
   , 234-237</p>
<p>
<strong>snapshot isolation</strong>
   , 237-242</p>
<p>پردازش تکراری، 424-426</p>
<p>
<strong>J</strong>
</p>
<p>
<strong>Java Database Connectivity (JDBC)</strong>
</p>
<p>پشتیبانی از تراکنش توزیع‌شده، 361</p>
<p>درایورهای شبکه، 128</p>
<p>
<strong>Java Enterprise Edition (EE)</strong>
   , 134, 356, 361</p>
<p>
<strong>Java Message Service (JMS)</strong>
</p>
<p>(همچنین به سیستم‌های پیام‌رسانی مراجعه کنید)</p>
<p>مقایسه با پیام‌رسانی مبتنی بر 
   <strong>log</strong>
   ، 448،</p>
<p>451</p>
<p>پشتیبانی از تراکنش توزیع‌شده، 361</p>
<p>ترتیب پیام‌ها، 446</p>
<p>
<strong>Java Transaction API (JTA)</strong>
   , 355, 361</p>
<p>
<strong>Java Virtual Machine (JVM)</strong>
</p>
<p>تولید 
   <strong>bytecode</strong>
   , 428</p>
<p>توقف‌های 
   <strong>garbage collection</strong>
   ، 296</p>
<p>فرآیند استفاده مجدد در پردازشگرهای 
   <strong>batch</strong>
   ، 422</p>
<p>
<strong>JavaScript</strong>
</p>
<p>در پرس و جوهای 
   <strong>MapReduce</strong>
   ، 46</p>
<p>تنظیم سبک‌های عنصر (مثال)، 45</p>
<p>استفاده در پرس و جوهای پیشرفته، 48</p>
<p>
<strong>Jena (RDF framework)</strong>
   , 57</p>
<p>
<strong>Jepsen (fault tolerance testing)</strong>
   , 515</p>
<p>
<strong>jitter (network delay)</strong>
   , 284</p>
<p>
<strong>joins</strong>
   , 555</p>
<p>با جستجوی شاخص، 403</p>
<p>بیان به عنوان اپراتورهای رابطه‌ای، 427</p>
<p>در 
   <strong>databases</strong>
   رابطه‌ای و سندی، 34</p>
<p>اتصالات 
   <strong>MapReduce map-side</strong>
   ، 408-410</p>
<p>
<strong>broadcast hash joins</strong>
   , 409</p>
<p>ادغام 
   <strong>joins</strong>
   ، 410</p>
<p>اتصالات 
   <strong>MapReduce reduce-side</strong>
   , 403-408</p>
<p>مدیریت 
   <strong>skew</strong>
   , 407</p>
<p>
<strong>sort-merge joins</strong>
   , 405</p>
<p>اجرای موازی، 415</p>
<p>شاخص‌های ثانویه و، 85</p>
<p>
<strong>stream joins</strong>
   , 472-476</p>
<p>اتصال 
   <strong>stream-stream</strong>
   , 473</p>
<p>اتصال 
   <strong>stream-table</strong>
   , 473</p>
<p>اتصال 
   <strong>table-table</strong>
   , 474</p>
<p>وابستگی به زمان، 475</p>
<p>
<strong>JOTM (transaction coordinator)</strong>
   , 356</p>
<p>
<strong>JSON</strong>
</p>
<p>نمایش 
   <strong>schema Avro</strong>
   ، 122</p>
<p>انواع باینری، 115</p>
<p>برای 
   <strong>application data</strong>
   ، مسائل با، 114</p>
<p>در 
   <strong>databases</strong>
   رابطه‌ای، 30، 42</p>
<p>نشان‌دهنده یک رزومه (مثال)، 31</p>
<p>
<strong>Juttle (query language)</strong>
   , 504</p>
<p>
<strong>K</strong>
</p>
<p>نزدیکترین همسایگان-
   <strong>k</strong>
   ، 429</p>
<p>
<strong>Kafka (messaging)</strong>
   , 137, 448</p>
<p>ادغام 
   <strong>Kafka Connect (database)</strong>
   ، 457،</p>
<p>461</p>
<p>
<strong>Kafka Streams (stream processor)</strong>
   , 466, 467</p>
<p>تحمل خطا، 479</p>
<p>تکثیر مبتنی بر 
   <strong>leader</strong>
   , 153</p>
<p>فشرده‌سازی 
   <strong>log</strong>
   ، 456، 467</p>
<p>
<strong>message offsets</strong>
   , 447, 478</p>
<p>
<strong>request routing</strong>
   , 216</p>
<p>پشتیبانی از تراکنش، 477</p>
<p>مثال استفاده، 4</p>
<p>
<strong>Ketama (partitioning library)</strong>
   , 213</p>
<p>فروشگاه‌های کلید-مقدار، 70</p>
<p>به عنوان خروجی فرآیند 
   <strong>batch</strong>
   ، 412</p>
<p>شاخص‌های 
   <strong>hash</strong>
   , 72-75</p>
<p>در حافظه، 89</p>
<p>پارتیشن‌بندی، 201-205</p>
<p>با 
   <strong>hash</strong>
   کلید، 203، 217</p>
<p>با محدوده کلید، 202، 217</p>
<p>پارتیشن‌بندی پویا، 212</p>
<p>
<strong>skew</strong>
   و نقاط داغ، 205</p>
<p>
<strong>Kryo (Java)</strong>
   , 113</p>
<p>
<strong>Kubernetes (cluster manager)</strong>
   , 418, 506</p>
<p>
<strong>L</strong>
</p>
<p>معماری 
   <strong>lambda</strong>
   ، 497</p>
<p>مهر زمانی 
   <strong>Lamport</strong>
   ، 345</p>
<p>
<strong>Index</strong>
   | 573
  </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0595</div>
            </div>
        </div>
        <!-- Page 0596 -->
        <div class="chapter" id="page-0596">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
<strong>Large Hadron Collider (LHC)</strong>
   , 64</p>
<p>
<strong>last write wins (LWW)</strong>
   , 173, 334</p>
<p>نادیده گرفتن نوشته‌های همزمان، 186</p>
<p>مشکلات با، 292</p>
<p>مستعد از دست رفتن به‌روزرسانی‌ها، 246</p>
<p>
<strong>late binding</strong>
   , 396</p>
<p>
<strong>latency</strong>
</p>
<p>بی‌ثباتی تحت قفل دو فازی، 259</p>
<p>تاخیر شبکه و استفاده از منابع،</p>
<p>286</p>
<p>زمان پاسخ در مقابل، 14</p>
<p>تاخیر دم، 15، 207</p>
<p>
<strong>leader-based replication</strong>
   , 152-161</p>
<p>(همچنین به 
   <strong>replication</strong>
   مراجعه کنید)</p>
<p>
<strong>failover</strong>
   , 157, 301</p>
<p>مدیریت خرابی گره، 156</p>
<p>پیاده‌سازی 
   <strong>logs</strong>
   تکثیر</p>
<p>
<strong>change data capture</strong>
   , 454-457</p>
<p>(همچنین به 
   <strong>changelogs</strong>
   مراجعه کنید)</p>
<p>مبتنی بر دستور، 158</p>
<p>تکثیر مبتنی بر 
   <strong>trigger</strong>
   , 161</p>
<p>
<strong>write-ahead log (WAL)</strong>
   انتقال، 159</p>
<p>
<strong>linearizability</strong>
   از عملیات، 333</p>
<p>قفل و انتخاب رهبر، 330</p>
<p>شماره توالی 
   <strong>log</strong>
   , 156, 449</p>
<p>معماری مقیاس‌پذیری خواندن، 161</p>
<p>ارتباط با اجماع، 367</p>
<p>
<strong>leaderless replication</strong>
   , 177-191</p>
<p>(همچنین به 
   <strong>replication</strong>
   مراجعه کنید)</p>
<p>تشخیص نوشتن همزمان، 184-191</p>
<p>ثبت رابطه 
   <strong>happens-before</strong>
   ،</p>
<p>187</p>
<p>رابطه 
   <strong>happens-before</strong>
   و همزمانی،</p>
<p>186</p>
<p>
<strong>last write wins</strong>
   , 186</p>
<p>ادغام مقادیر نوشته شده به‌طور همزمان،</p>
<p>190</p>
<p>بردار نسخه، 191</p>
<p>چند 
   <strong>datacenter</strong>
   , 184</p>
<p>
<strong>quorums</strong>
   , 179-182</p>
<p>محدودیت‌های سازگاری، 181-183، 334</p>
<p>
<strong>sloppy quorums</strong>
   و 
   <strong>hinted handoff</strong>
   , 183</p>
<p>خواندن تعمیر و 
   <strong>anti-entropy</strong>
   ، 178</p>
<p>
<strong>leap seconds</strong>
   , 8, 290</p>
<p>در ساعت‌های زمان روز، 288</p>
<p>اجاره‌ها، 295</p>
<p>پیاده‌سازی با 
   <strong>ZooKeeper</strong>
   ، 370</p>
<p>نیاز به 
   <strong>fencing</strong>
   ، 302</p>
<p>
<strong>ledgers</strong>
   , 460</p>
<p>فناوری‌های 
   <strong>ledger</strong>
   توزیع شده، 532</p>
<p>سیستم‌های قدیمی، نگهداری از، 18</p>
<p>
<strong>less (Unix tool)</strong>
   , 397</p>
<p>
<strong>LevelDB (storage engine)</strong>
   , 78</p>
<p>تراکم سطح‌بندی‌شده، 79</p>
<p>خودکار 
   <strong>automata</strong>
   , 88</p>
<p>قابلیت اطمینان (
   <strong>reliability</strong>
   )، 324-338</p>
<p>هزینه، 335-338</p>
<p>قضیه 
   <strong>CAP</strong>
   ، 336</p>
<p>حافظه در 
   <strong>CPUs</strong>
   چند هسته‌ای، 338</p>
<p>تعریف، 325-329</p>
<p>پیاده‌سازی با 
   <strong>total order broadcast</strong>
   , 350</p>
<p>در 
   <strong>ZooKeeper</strong>
   , 370</p>
<p>از سیستم‌های 
   <strong>derived data</strong>
   ، 492، 524</p>
<p>اجتناب از هماهنگی، 527</p>
<p>
<strong>relying on</strong>
   , 330-332</p>
<p>محدودیت‌ها و منحصر به فرد بودن، 330</p>
<p>وابستگی‌های زمانی 
   <strong>cross-channel</strong>
   ، 331</p>
<p>قفل و انتخاب رهبر، 330</p>
<p>قوی‌تر از سازگاری علّی، 342</p>
<p>استفاده برای پیاده‌سازی 
   <strong>total order broadcast</strong>
   ، 351</p>
<p>در مقابل 
   <strong>serializability</strong>
   ، 329</p>
<p>
<strong>LinkedIn</strong>
</p>
<p>
<strong>Azkaban (workflow scheduler)</strong>
   , 402</p>
<p>
<strong>Databus (change data capture)</strong>
   , 161, 455</p>
<p>
<strong>Espresso (database)</strong>
   , 31, 126, 130, 153, 216</p>
<p>
<strong>Helix (cluster manager) (see Helix)</strong>
</p>
<p>نمایه (مثال)، 30</p>
<p>اشاره به موجودیت شرکت (مثال)، 34</p>
<p>
<strong>Rest.li (RPC framework)</strong>
   , 135</p>
<p>
<strong>Voldemort (database) (see Voldemort)</strong>
</p>
<p>
<strong>Linux, leap second bug</strong>
   , 8, 290</p>
<p>ویژگی‌های زنده‌بودن، 308</p>
<p>
<strong>LMDB (storage engine)</strong>
   , 82, 242</p>
<p>
<strong>load</strong>
</p>
<p>رویکردهایی برای مقابله با، 17</p>
<p>توصیف، 11</p>
<p>تست بار، 16</p>
<p>تعادل بار (پیام‌رسانی)، 444</p>
<p>شاخص‌های محلی (به شاخص‌های 
   <strong>document-partitioned</strong>
</p>
<p>مراجعه کنید)</p>
<p>مکان، 32، 41، 555</p>
<p>
<strong>Index</strong>
   | 569
  </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0596</div>
            </div>
        </div>
        <!-- Page 0597 -->
        <div class="chapter" id="page-0597">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>در پردازش 
   <strong>batch</strong>
   , 400، 405، 421</p>
<p>در کلاینت‌های 
   <strong>stateful</strong>
   ، 170، 511</p>
<p>در پردازش جریان، 474، 478، 508، 522</p>
<p>شفافیت مکان، 134</p>
<p>در مدل 
   <strong>actor</strong>
   ، 138</p>
<p>
<strong>locks</strong>
   , 556</p>
<p>بن‌بست، 258</p>
<p>قفل‌گذاری توزیع‌شده، 301-304، 330</p>
<p>
<strong>fencing tokens</strong>
   , 303</p>
<p>پیاده‌سازی با 
   <strong>ZooKeeper</strong>
   ، 370</p>
<p>ارتباط با اجماع، 374</p>
<p>برای 
   <strong>transaction isolation</strong>
</p>
<p>در 
   <strong>snapshot isolation</strong>
   , 239</p>
<p>در 
   <strong>two-phase locking (2PL)</strong>
   , 257-261</p>
<p>اتمی کردن عملیات، 243</p>
<p>عملکرد، 258</p>
<p>جلوگیری از نوشتن کثیف، 236</p>
<p>جلوگیری از 
   <strong>phantoms</strong>
   با 
   <strong>index-range</strong>
</p>
<p>
<strong>locks</strong>
   , 260, 265</p>
<p>
<strong>read locks (shared mode)</strong>
   , 236, 258</p>
<p>حالت مشترک و حالت انحصاری، 258</p>
<p>در تعهد دو فازی (
   <strong>2PC</strong>
   )</p>
<p>تشخیص بن‌بست، 364</p>
<p>تراکنش‌های نامعلوم که 
   <strong>locks</strong>
   را نگه می‌دارند، 362</p>
<p>
<strong>materializing</strong>
   تعارضات با، 251</p>
<p>جلوگیری از به‌روزرسانی‌های از دست رفته با قفل‌گذاری صریح،</p>
<p>244</p>
<p>شماره توالی 
   <strong>log</strong>
   , 156, 449</p>
<p>زبان‌های برنامه‌نویسی منطقی، 504</p>
<p>ساعت‌های منطقی، 293، 343، 494</p>
<p>برای سازگاری خواندن-بعد از نوشتن، 164</p>
<p>
<strong>logical logs</strong>
   , 160</p>
<p>
<strong>logs (data structure)</strong>
   , 71, 556</p>
<p>مزایای تغییرناپذیری، 460</p>
<p>فشرده‌سازی، 73، 79، 456، 460</p>
<p>برای وضعیت اپراتور جریان، 479</p>
<p>ایجاد با استفاده از پخش 
   <strong>total order</strong>
   ، 349</p>
<p>پیاده‌سازی محدودیت‌های منحصر به فرد، 522</p>
<p>پیام‌رسانی مبتنی بر 
   <strong>log</strong>
   , 446-451</p>
<p>مقایسه با پیام‌رسانی سنتی،</p>
<p>448، 451</p>
<p>افست‌های مصرف‌کننده، 449</p>
<p>استفاده از فضای دیسک، 450</p>
<p>پخش مجدد پیام‌های قدیمی، 451، 496، 498</p>
<p>مصرف‌کنندگان کند، 450</p>
<p>استفاده از 
   <strong>logs</strong>
   برای ذخیره‌سازی پیام، 447</p>
<p>ذخیره‌سازی مبتنی بر 
   <strong>log</strong>
   ، 71-79</p>
<p>درخت 
   <strong>log-structured merge (see LSM-</strong>
</p>
<p>
<strong>trees)</strong>
</p>
<p>تکثیر، 152، 158-161</p>
<p>
<strong>change data capture</strong>
   , 454-457</p>
<p>(همچنین به 
   <strong>changelogs</strong>
   مراجعه کنید)</p>
<p>هماهنگی با 
   <strong>snapshot</strong>
   ، 156</p>
<p>تکثیر (بر اساس سطر)، 160</p>
<p>تکثیر مبتنی بر دستور، 158</p>
<p>تکثیر مبتنی بر 
   <strong>trigger</strong>
   , 161</p>
<p>
<strong>write-ahead log (WAL)</strong>
   انتقال، 159</p>
<p>محدودیت‌های مقیاس‌پذیری، 493</p>
<p>
<strong>loose coupling</strong>
   , 396, 419, 502</p>
<p>از دست دادن به‌روزرسانی‌ها (به 
   <strong>updates</strong>
   مراجعه کنید)</p>
<p>
<strong>LSM-trees (indexes)</strong>
   , 78-79</p>
<p>مقایسه با 
   <strong>B-trees</strong>
   , 83-85</p>
<p>
<strong>Lucene (storage engine)</strong>
   , 79</p>
<p>ساختن شاخص‌ها در فرآیندهای 
   <strong>batch</strong>
   ، 411</p>
<p>جستجوی مشابهت، 88</p>
<p>
<strong>Luigi (workflow scheduler)</strong>
   , 402</p>
<p>
<strong>LWW (see last write wins)</strong>
</p>
<p>
<strong>M</strong>
</p>
<p>یادگیری ماشینی</p>
<p>ملاحظات اخلاقی، 534</p>
<p>(همچنین به اخلاقیات مراجعه کنید)</p>
<p>پردازش تکراری، 424</p>
<p>مدل‌ها از 
   <strong>training data</strong>
   ، 505</p>
<p>الگوریتم‌های آماری و عددی، 428</p>
<p>
<strong>MADlib (machine learning toolkit)</strong>
   , 428</p>
<p>سس مقیاس‌بندی جادویی، 18</p>
<p>
<strong>Mahout (machine learning toolkit)</strong>
   , 428</p>
<p>قابلیت نگهداری، 18-22، 489</p>
<p>تعریف شده، 23</p>
<p>اصول طراحی برای سیستم‌های 
   <strong>software</strong>
   , 19</p>
<p>قابلیت تکامل (به قابلیت تکامل مراجعه کنید)</p>
<p>قابلیت عملیاتی، 19</p>
<p>سادگی و مدیریت پیچیدگی، 20</p>
<p>روابط 
   <strong>many-to-many</strong>
</p>
<p>در مدل سند در مقابل مدل رابطه‌ای،</p>
<p>39</p>
<p>مدل‌سازی به عنوان نمودارها، 49</p>
<p>روابط 
   <strong>many-to-one and many-to-many</strong>
</p>
<p>33-36</p>
<p>روابط 
   <strong>many-to-one</strong>
   ، 34</p>
<p>
<strong>MapReduce (batch processing)</strong>
   , 390, 399-400</p>
<p>دسترسی به 
   <strong>services</strong>
   خارجی در داخل کار، 404،</p>
<p>412</p>
<p>مقایسه با 
   <strong>databases</strong>
   توزیع‌شده</p>
<p>طراحی برای خطاهای مکرر، 417</p>
<p>تنوع مدل‌های پردازشی، 416</p>
<p>تنوع ذخیره‌سازی، 415</p>
<p>
<strong>Index</strong>
   | 575
  </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0597</div>
            </div>
        </div>
        <!-- Page 0598 -->
        <div class="chapter" id="page-0598">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>مقایسه با پردازش جریان، 464</p>
<p>مقایسه با یونیکس، 413-414</p>
<p>معایب و محدودیت‌های، 419</p>
<p>تحمل خطا، 406، 414، 422</p>
<p>ابزارهای سطح بالاتر، 403، 426</p>
<p>پیاده‌سازی در 
   <strong>Hadoop</strong>
   ، 400-403</p>
<p>
<strong>the shuffle</strong>
   , 402</p>
<p>
<strong>implementation in MongoDB</strong>
   , 46-48</p>
<p>یادگیری ماشینی، 428</p>
<p>پردازش 
   <strong>map-side</strong>
   ، 408-410</p>
<p>
<strong>broadcast hash joins</strong>
   , 409</p>
<p>ادغام، 410</p>
<p>پارتیشن‌شده 
   <strong>hash joins</strong>
   ، 409</p>
<p>
<strong>mapper</strong>
   و توابع 
   <strong>reducer</strong>
   ، 399</p>
<p>
<strong>materialization of intermediate state</strong>
   , 419-423</p>
<p>خروجی 
   <strong>batch workflows</strong>
   , 411-413</p>
<p>ساخت شاخص‌های جستجو، 411</p>
<p>فروشگاه‌های کلید-مقدار، 412</p>
<p>پردازش 
   <strong>reduce-side</strong>
   ، 403-408</p>
<p>تجزیه و تحلیل رویدادهای فعالیت کاربر (مثال)،</p>
<p>404</p>
<p>گروه‌بندی رکوردها با کلید یکسان، 406</p>
<p>مدیریت 
   <strong>skew</strong>
   , 407</p>
<p>
<strong>sort-merge joins</strong>
   , 405</p>
<p>
<strong>workflows</strong>
   , 402</p>
<p>
<strong>marshalling (see encoding)</strong>
</p>
<p>پردازش موازی انبوه (
   <strong>MPP</strong>
   )، 216</p>
<p>مقایسه با ترکیب فناوری‌های ذخیره‌سازی،</p>
<p>502</p>
<p>مقایسه با 
   <strong>Hadoop</strong>
   ، 414-418، 428</p>
<p>تکثیر 
   <strong>master-master (see multi-leader</strong>
</p>
<p>
<strong>replication)</strong>
</p>
<p>تکثیر 
   <strong>master-slave (see leader-based repli-</strong>
</p>
<p>
<strong>cation)</strong>
</p>
<p>
<strong>materialization</strong>
   , 556</p>
<p>مقادیر جمعی، 101</p>
<p>درگیری‌ها، 251</p>
<p>حالت میانی (پردازش 
   <strong>batch</strong>
   )،</p>
<p>420-423</p>
<p>
<strong>materialized views</strong>
   , 101</p>
<p>به عنوان 
   <strong>derived data</strong>
   ، 386، 499-504</p>
<p>حفظ، با استفاده از پردازش جریان،</p>
<p>467، 475</p>
<p>
<strong>Maven (Java build tool)</strong>
   , 428</p>
<p>
<strong>Maxwell (change data capture)</strong>
   , 455</p>
<p>متوسط، 14</p>
<p>پایش رسانه، 467</p>
<p>میانه، 14</p>
<p>رزرو اتاق ملاقات (مثال)، 249، 259،</p>
<p>521</p>
<p>خدمات عضویت، 372</p>
<p>
<strong>Memcached (caching server)</strong>
   , 4, 89</p>
<p>حافظه</p>
<p>
<strong>in-memory databases</strong>
   , 88</p>
<p>ماندگاری، 227</p>
<p>اجرای سریال 
   <strong>transaction</strong>
   ، 253</p>
<p>نمایش 
   <strong>data</strong>
   در حافظه، 112</p>
<p>بیت‌های تصادفی در، 529</p>
<p>استفاده توسط شاخص‌ها، 72، 77</p>
<p>موانع حافظه (دستورالعمل 
   <strong>CPU</strong>
   )، 338</p>
<p>
<strong>MemSQL (database)</strong>
</p>
<p>ذخیره‌سازی در حافظه، 89</p>
<p>
<strong>read committed isolation</strong>
   , 236</p>
<p>
<strong>memtable (in LSM-trees)</strong>
   , 78</p>
<p>
<strong>Mercurial (version control system)</strong>
   , 463</p>
<p>ادغام 
   <strong>joins MapReduce map-side</strong>
   , 410</p>
<p>ساختارهای 
   <strong>data</strong>
   پایدار قابل ادغام، 174</p>
<p>ادغام فایل‌های مرتب‌شده، 76، 402، 405</p>
<p>درخت‌های 
   <strong>Merkle</strong>
   ، 532</p>
<p>
<strong>Mesos (cluster manager)</strong>
   , 418, 506</p>
<p>
<strong>message brokers (see messaging systems)</strong>
</p>
<p>
<strong>message-passing</strong>
   , 136-139</p>
<p>مزایای نسبت به 
   <strong>RPC</strong>
   مستقیم، 137</p>
<p>چارچوب‌های 
   <strong>actor</strong>
   توزیع‌شده، 138</p>
<p>قابلیت تکامل، 138</p>
<p>
<strong>MessagePack (encoding format)</strong>
   , 116</p>
<p>پیام‌ها</p>
<p>معناشناسی دقیقاً یک‌بار، 360، 476</p>
<p>
<strong>loss of</strong>
   , 442</p>
<p>با استفاده از 
   <strong>total order broadcast</strong>
   , 348</p>
<p>سیستم‌های پیام‌رسانی، 440-451</p>
<p>(همچنین به جریان‌ها مراجعه کنید)</p>
<p>
<strong>backpressure</strong>
   ، بافر، یا رها کردن</p>
<p>پیام‌ها، 441</p>
<p>پیام‌رسانی بدون 
   <strong>broker</strong>
   ، 442</p>
<p>
<strong>event logs</strong>
   , 446-451</p>
<p>مقایسه با پیام‌رسانی سنتی،</p>
<p>448، 451</p>
<p>آفست‌های مصرف‌کننده، 449</p>
<p>پخش مجدد پیام‌های قدیمی، 451، 496، 498</p>
<p>مصرف‌کنندگان کند، 450</p>
<p>با استفاده از 
   <strong>logs</strong>
   برای ذخیره‌سازی پیام، 447</p>
<p>
<strong>log-structured storage</strong>
   , 71-79</p>
<p>
<strong>log-structured merge tree (see LSM-</strong>
</p>
<p>
<strong>trees)</strong>
</p>
<p>تکثیر، 152، 158-161</p>
<p>
<strong>change data capture</strong>
   , 454-457</p>
<p>(همچنین به 
   <strong>changelogs</strong>
   مراجعه کنید)</p>
<p>هماهنگی با 
   <strong>snapshot</strong>
   ، 156</p>
<p>تکثیر مبتنی بر 
   <strong>log</strong>
   ، 160</p>
<p>تکثیر مبتنی بر دستور، 158</p>
<p>تکثیر مبتنی بر 
   <strong>trigger</strong>
   ، 161</p>
<p>
<strong>write-ahead log (WAL)</strong>
   انتقال، 159</p>
<p>محدودیت‌های مقیاس‌پذیری، 493</p>
<p>
<strong>loose coupling</strong>
   , 396, 419, 502</p>
<p>از دست دادن به‌روزرسانی‌ها (به به‌روزرسانی‌ها</p>
<p>مراجعه کنید)</p>
<p>
<strong>LSM-trees (indexes)</strong>
   , 78-79</p>
<p>مقایسه با 
   <strong>B-trees</strong>
   , 83-85</p>
<p>
<strong>Lucene (storage engine)</strong>
   , 79</p>
<p>ساخت شاخص‌ها در فرآیندهای 
   <strong>batch</strong>
   ، 411</p>
<p>جستجوی مشابهت، 88</p>
<p>
<strong>Luigi (workflow scheduler)</strong>
   , 402</p>
<p>
<strong>LWW (see last write wins)</strong>
</p>
<p>
<strong>M</strong>
</p>
<p>یادگیری ماشینی، 534</p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0598</div>
            </div>
        </div>
        <!-- Page 0599 -->
        <div class="chapter" id="page-0599">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
<strong>Meteor (web framework)</strong>
   , 456</p>
<p>
<strong>microbatching</strong>
   , 477, 495</p>
<p>
<strong>microservices</strong>
   , 132</p>
<p>(همچنین به 
   <strong>services</strong>
   مراجعه کنید)</p>
<p>وابستگی‌های علّی در سراسر 
   <strong>services</strong>
   ، 493</p>
<p>
<strong>loose coupling</strong>
   , 502</p>
<p>ارتباط با پردازشگرهای 
   <strong>batch/stream</strong>
   ، 389،</p>
<p>508</p>
<p>
<strong>Microsoft</strong>
</p>
<p>
<strong>Azure Service Bus (messaging)</strong>
   , 444</p>
<p>
<strong>Azure Storage</strong>
   , 155, 398</p>
<p>
<strong>Azure Stream Analytics</strong>
   , 466</p>
<p>
<strong>DCOM (Distributed Component Object Model)</strong>
   , 134</p>
<p>
<strong>MSDTC (transaction coordinator)</strong>
   , 356</p>
<p>
<strong>Orleans (see Orleans)</strong>
</p>
<p>
<strong>SQL Server (see SQL Server)</strong>
</p>
<p>مهاجرت (بازنویسی) 
   <strong>data</strong>
   , 40, 130, 461, 497</p>
<p>عملگر پیمانه‌ای (٪)، 210</p>
<p>
<strong>MongoDB (database)</strong>
</p>
<p>خط لوله تجمیع، 48</p>
<p>عملیات اتمی، 243</p>
<p>
<strong>BSON</strong>
   , 41</p>
<p>مدل 
   <strong>data document</strong>
   ، 31</p>
<p>تقسیم‌بندی 
   <strong>hash (sharding)</strong>
   , 203-204</p>
<p>پارتیشن‌بندی کلید-محدوده، 202</p>
<p>کمبود پشتیبانی 
   <strong>join</strong>
   , 34, 42</p>
<p>تکثیر مبتنی بر 
   <strong>leader</strong>
   , 153</p>
<p>پشتیبانی 
   <strong>MapReduce</strong>
   , 46, 400</p>
<p>تجزیه و تحلیل رویدادهای فعالیت کاربر (مثال)،</p>
<p>404</p>
<p>جوین‌های 
   <strong>map-side</strong>
   , 408-410</p>
<p>
<strong>broadcast hash joins</strong>
   , 409</p>
<p>ادغام جوین‌ها، 410</p>
<p>جوین‌های پارتیشن‌شده 
   <strong>hash</strong>
   ، 409</p>
<p>
<strong>mapper</strong>
   و عملکردهای 
   <strong>reducer</strong>
   ، 399</p>
<p>ماده‌گرایی حالت میانی، 419-423</p>
<p>خروجی فرآیندهای 
   <strong>batch</strong>
   ، 411-413</p>
<p>ساخت شاخص‌های جستجو، 411</p>
<p>فروشگاه‌های کلید-مقدار، 412</p>
<p>پردازش 
   <strong>reduce-side</strong>
   , 403-408</p>
<p>تجزیه و تحلیل رویدادهای فعالیت کاربر (مثال)،</p>
<p>404</p>
<p>گروه‌بندی رکوردها با کلید یکسان، 406</p>
<p>مدیریت 
   <strong>skew</strong>
   , 407</p>
<p>
<strong>sort-merge joins</strong>
   , 405</p>
<p>
<strong>workflows</strong>
   , 402</p>
<p>
<strong>marshalling (see encoding)</strong>
</p>
<p>
<strong>massively parallel processing (MPP)</strong>
   , 216</p>
<p>مقایسه با ترکیب فناوری‌های ذخیره‌سازی،</p>
<p>502</p>
<p>مقایسه با 
   <strong>Hadoop</strong>
   ، 414-418، 428</p>
<p>تکثیر 
   <strong>master-master (see multi-leader</strong>
</p>
<p>
<strong>replication)</strong>
</p>
<p>تکثیر 
   <strong>master-slave (see leader-based repli-</strong>
</p>
<p>
<strong>cation)</strong>
</p>
<p>
<strong>materialization</strong>
   , 556</p>
<p>مقادیر جمعی، 101</p>
<p>درگیری‌ها، 251</p>
<p>
<strong>intermediate state (batch processing)</strong>
   ,
  </p>
<p>420-423</p>
<p>
<strong>materialized views</strong>
   , 101</p>
<p>به عنوان 
   <strong>derived data</strong>
   ، 386، 499-504</p>
<p>نگهداری، با استفاده از پردازش جریان،</p>
<p>467، 475</p>
<p>
<strong>Maven (Java build tool)</strong>
   , 428</p>
<p>
<strong>Maxwell (change data capture)</strong>
   , 455</p>
<p>متوسط، 14</p>
<p>پایش رسانه، 467</p>
<p>میانه، 14</p>
<p>رزرو اتاق جلسه (مثال)، 249، 259،</p>
<p>521</p>
<p>خدمات عضویت، 372</p>
<p>
<strong>Memcached (caching server)</strong>
   , 4, 89</p>
<p>حافظه</p>
<p>
<strong>in-memory databases</strong>
   , 88</p>
<p>ماندگاری، 227</p>
<p>اجرای سریال 
   <strong>transaction</strong>
   ، 253</p>
<p>درونی 
   <strong>representation of data</strong>
   ، 112</p>
<p>نوسانات تصادفی بیت در، 529</p>
<p>استفاده توسط شاخص‌ها، 72، 77</p>
<p>موانع حافظه (دستورالعمل 
   <strong>CPU</strong>
   )، 338</p>
<p>
<strong>MemSQL (database)</strong>
</p>
<p>ذخیره‌سازی در حافظه، 89</p>
<p>
<strong>read committed isolation</strong>
   , 236</p>
<p>
<strong>memtable (in LSM-trees)</strong>
   , 78</p>
<p>
<strong>Mercurial (version control system)</strong>
   , 463</p>
<p>ادغام 
   <strong>joins MapReduce map-side</strong>
   , 410</p>
<p>ساختارهای 
   <strong>data</strong>
   پایدار قابل ادغام، 174</p>
<p>
<strong>merging sorted files</strong>
   , 76, 402, 405</p>
<p>درخت‌های 
   <strong>Merkle</strong>
   ، 532</p>
<p>
<strong>Mesos (cluster manager)</strong>
   , 418, 506</p>
<p>
<strong>message brokers (see messaging systems)</strong>
</p>
<p>
<strong>message-passing</strong>
   , 136-139</p>
<p>مزایای نسبت به 
   <strong>RPC</strong>
   مستقیم، 137</p>
<p>چارچوب‌های 
   <strong>actor</strong>
   توزیع‌شده، 138</p>
<p>قابلیت تکامل، 138</p>
<p>
<strong>MessagePack (encoding format)</strong>
   , 116</p>
<p>پیام‌ها</p>
<p>معناشناسی دقیقاً یک‌بار، 360، 476</p>
<p>
<strong>loss of</strong>
   , 442</p>
<p>با استفاده از 
   <strong>total order broadcast</strong>
   , 348</p>
<p>سیستم‌های پیام‌رسانی، 440-451</p>
<p>(همچنین به جریان‌ها مراجعه کنید)</p>
<p>
<strong>backpressure</strong>
   , buffering, or dropping mes‐</p>
<p>
<strong>sages</strong>
   , 441</p>
<p>پیام‌رسانی بدون 
   <strong>broker</strong>
   ، 442</p>
<p>
<strong>event logs</strong>
   , 446-451</p>
<p>مقایسه با پیام‌رسانی سنتی،</p>
<p>448، 451</p>
<p>آفست‌های مصرف‌کننده، 449</p>
<p>پخش مجدد پیام‌های قدیمی، 451، 496، 498</p>
<p>مصرف‌کنندگان کند، 450</p>
<p>
<strong>message brokers</strong>
   , 443-446</p>
<p>تأییدیه و تحویل مجدد، 445</p>
<p>مقایسه با 
   <strong>event logs</strong>
   ، 448، 451</p>
<p>مصرف‌کنندگان متعدد یک موضوع، 444</p>
<p>قابلیت اطمینان، 442</p>
<p>منحصر به فرد بودن در پیام‌رسانی مبتنی بر 
   <strong>log</strong>
   ، 522</p>
<p>
<strong>576</strong>
   | 
   <strong>Index</strong>
</p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0599</div>
            </div>
        </div>
        <!-- Page 0600 -->
        <div class="chapter" id="page-0600">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>در پردازش 
   <strong>batch</strong>
   ، 400، 405، 421</p>
<p>در کلاینت‌های 
   <strong>stateful</strong>
   ، 170، 511</p>
<p>در پردازش جریان، 474، 478، 508، 522</p>
<p>شفافیت مکان، 134</p>
<p>در مدل 
   <strong>actor</strong>
   ، 138</p>
<p>
<strong>locks</strong>
   , 556</p>
<p>بن‌بست، 258</p>
<p>
<strong>lock</strong>
   توزیع‌شده، 301-304، 330</p>
<p>
<strong>fencing tokens</strong>
   , 303</p>
<p>پیاده‌سازی با 
   <strong>ZooKeeper</strong>
   ، 370</p>
<p>ارتباط با اجماع، 374</p>
<p>برای 
   <strong>transaction isolation</strong>
</p>
<p>در 
   <strong>snapshot isolation</strong>
   , 239</p>
<p>در 
   <strong>two-phase locking (2PL)</strong>
   , 257-261</p>
<p>اتمی کردن عملیات، 243</p>
<p>عملکرد، 258</p>
<p>جلوگیری از نوشتن کثیف، 236</p>
<p>جلوگیری از 
   <strong>phantoms</strong>
   با 
   <strong>index-range</strong>
</p>
<p>
<strong>locks</strong>
   , 260, 265</p>
<p>
<strong>read locks (shared mode)</strong>
   , 236, 258</p>
<p>حالت مشترک و حالت انحصاری، 258</p>
<p>در تعهد دو فازی (
   <strong>2PC</strong>
   )</p>
<p>تشخیص بن‌بست، 364</p>
<p>تراکنش‌های نامعلوم که 
   <strong>locks</strong>
   را نگه می‌دارند، 362</p>
<p>
<strong>materializing</strong>
   تعارضات با، 251</p>
<p>جلوگیری از به‌روزرسانی‌های از دست رفته با قفل‌گذاری صریح،</p>
<p>244</p>
<p>شماره توالی 
   <strong>log</strong>
   , 156, 449</p>
<p>زبان‌های برنامه‌نویسی منطقی، 504</p>
<p>ساعت‌های منطقی، 293، 343، 494</p>
<p>برای سازگاری خواندن-بعد از نوشتن، 164</p>
<p>
<strong>log (data structure)</strong>
   , 71, 556</p>
<p>مزایای تغییرناپذیری، 460</p>
<p>فشرده‌سازی، 73، 79، 456، 460</p>
<p>برای وضعیت اپراتور جریان، 479</p>
<p>
<strong>linearizability</strong>
   , 152, 158-161, 308, 322</p>
<p>
<strong>log-structured merge tree (see LSM-</strong>
</p>
<p>
<strong>trees)</strong>
</p>
<p>
<strong>logical logs</strong>
   , 160</p>
<p>
<strong>logical clocks</strong>
   , 293, 343, 494</p>
<p>تکثیر، 152، 158-161</p>
<p>(همچنین به 
   <strong>replication</strong>
   مراجعه کنید)</p>
<p>
<strong>leader-based replication</strong>
   , 152-161</p>
<p>(همچنین به 
   <strong>replication</strong>
   مراجعه کنید)</p>
<p>
<strong>foreign keys</strong>
   , 38, 403</p>
<p>
<strong>forward compatibility</strong>
   , 112</p>
<p>
<strong>forward decay (algorithm)</strong>
   , 16</p>
<p>
<strong>Fossil (version control system)</strong>
   , 463</p>
<p>
<strong>shunning (deleting data)</strong>
   , 463</p>
<p>
<strong>FoundationDB (database)</strong>
</p>
<p>تراکنش‌های 
   <strong>serializable</strong>
   , 261, 265, 364</p>
<p>درختان 
   <strong>fractal</strong>
   , 83</p>
<p>
<strong>full table scans</strong>
   , 403</p>
<p>جستجوی متن کامل، 555</p>
<p>و شاخص‌های فازی، 88</p>
<p>
<strong>Lucene (storage engine)</strong>
   , 79</p>
<p>ساختن شاخص‌ها در فرآیندهای 
   <strong>batch</strong>
   ، 411</p>
<p>جستجوی مشابهت، 88</p>
<p>
<strong>Luigi (workflow scheduler)</strong>
   , 402</p>
<p>
<strong>LWW (see last write wins)</strong>
</p>
<p>
<strong>M</strong>
</p>
<p>یادگیری ماشینی، 534</p>
<p>
<strong>MapReduce (batch processing)</strong>
   , 390, 399-400</p>
<p>دسترسی به 
   <strong>services</strong>
   خارجی در داخل کار، 404،</p>
<p>412</p>
<p>مقایسه با 
   <strong>databases</strong>
   توزیع‌شده</p>
<p>طراحی برای خطاهای مکرر، 417</p>
<p>تنوع مدل‌های پردازشی، 416</p>
<p>تنوع ذخیره‌سازی، 415</p>
<p>
<strong>Index</strong>
   | 575
  </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0600</div>
            </div>
        </div>
        <!-- Page 0601 -->
        <div class="chapter" id="page-0601">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
<strong>partial order</strong>
   , 341</p>
<p>محدودیت‌های مرتب‌سازی کل، 493</p>
<p>
<strong>total order broadcast</strong>
   , 348-352</p>
<p>
<strong>Orleans (actor framework)</strong>
   , 139</p>
<p>خارج از (زمان پاسخ)، 14</p>
<p>
<strong>Oz (programming language)</strong>
   , 504</p>
<p>
<strong>P</strong>
</p>
<p>مدیران بسته، 428، 505</p>
<p>
<strong>packet switching</strong>
   , 285</p>
<p>بسته‌ها</p>
<p>فساد، 306</p>
<p>ارسال از طریق 
   <strong>UDP</strong>
   ، 442</p>
<p>
<strong>PageRank (algorithm)</strong>
   , 49, 424</p>
<p>
<strong>paging (see virtual memory)</strong>
</p>
<p>
<strong>ParAccel (database)</strong>
   , 93</p>
<p>پایگاه‌های داده موازی، (به پردازش موازی انبوه مراجعه کنید)</p>
<p>اجرای موازی</p>
<p>الگوریتم‌های تجزیه و تحلیل نمودار، 426</p>
<p>پرس و جوها در 
   <strong>databases MPP</strong>
   , 216</p>
<p>
<strong>Parquet (data format)</strong>
   , 96, 131</p>
<p>(همچنین به ذخیره‌سازی 
   <strong>column-oriented</strong>
   مراجعه کنید)</p>
<p>استفاده در 
   <strong>Hadoop</strong>
   , 414</p>
<p>
<strong>partial failures</strong>
   , 275, 310</p>
<p>لنگیدن، 311</p>
<p>
<strong>partial order</strong>
   , 341</p>
<p>
<strong>partitioning</strong>
   , 199-218, 556</p>
<p>و تکثیر، 200</p>
<p>در پردازش 
   <strong>batch</strong>
   ، 429</p>
<p>عملیات چند پارتیشن، 514</p>
<p>اعمال محدودیت‌ها، 522</p>
<p>نگهداری شاخص‌های ثانویه، 495</p>
<p>از 
   <strong>data</strong>
   - به کلید مقدار، 201-205</p>
<p>توسط محدوده کلید، 202</p>
<p>
<strong>skew</strong>
   و نقاط داغ، 205</p>
<p>تنظیم مجدد پارتیشن‌ها، 209-214</p>
<p>تنظیم مجدد خودکار یا دستی، 213</p>
<p>مشکلات با 
   <strong>hash mod N</strong>
   ، 210</p>
<p>پارتیشن‌بندی 
   <strong>replication</strong>
   و، 147</p>
<p>
<strong>request routing</strong>
   , 214-216</p>
<p>شاخص‌های ثانویه، 206-209</p>
<p>پارتیشن‌بندی مبتنی بر سند، 206</p>
<p>پارتیشن‌بندی مبتنی بر عبارت، 208</p>
<p>اجرای سریال تراکنش‌ها و، 255</p>
<p>
<strong>Paxos (consensus algorithm)</strong>
   , 366</p>
<p>شماره رای‌گیری، 368</p>
<p>
<strong>Multi-Paxos (total order broadcast)</strong>
   , 367</p>
<p>صدک‌ها، 14، 556</p>
<p>محاسبه کارآمد، 16</p>
<p>اهمیت صدک‌های بالا، 16</p>
<p>استفاده در توافقنامه‌های سطح 
   <strong>service (SLAs)</strong>
   ، 15</p>
<p>
<strong>Percona XtraBackup (MySQL tool)</strong>
   , 156</p>
<p>عملکرد</p>
<p>شرح، 13</p>
<p>از تراکنش‌های توزیع‌شده، 360</p>
<p>در 
   <strong>databases</strong>
   در حافظه، 89</p>
<p>
<strong>linearizability</strong>
   , 338</p>
<p>در تکثیر چند 
   <strong>leader</strong>
   ، 169</p>
<p>
<strong>perpetual inconsistency</strong>
   , 525</p>
<p>کنترل همزمانی بدبینانه، 261</p>
<p>
<strong>phantoms (transaction isolation)</strong>
   , 250</p>
<p>
<strong>materializing</strong>
   درگیری‌ها، 251</p>
<p>جلوگیری، در 
   <strong>serializability</strong>
   ، 259</p>
<p>ساعت‌های فیزیکی (به ساعت‌ها مراجعه کنید)</p>
<p>
<strong>pickle (Python)</strong>
   , 113</p>
<p>
<strong>Pig (dataflow language)</strong>
   , 419, 427</p>
<p>اتصالات تکراری، 409</p>
<p>
<strong>skewed joins</strong>
   , 407</p>
<p>
<strong>workflows</strong>
   , 403</p>
<p>
<strong>Pinball (workflow scheduler)</strong>
   , 402</p>
<p>اجرای 
   <strong>pipelined</strong>
   ، 423</p>
<p>در یونیکس، 394</p>
<p>نقطه در زمان، 287</p>
<p>
<strong>polyglot persistence</strong>
   , 29</p>
<p>
<strong>polystores</strong>
   , 501</p>
<p>
<strong>PostgreSQL (database)</strong>
</p>
<p>
<strong>BDR (multi-leader replication)</strong>
   , 170</p>
<p>ترتیب علّی نوشته‌ها، 177</p>
<p>
<strong>Bottled Water (change data capture)</strong>
   , 455</p>
<p>
<strong>Bucardo (trigger-based replication)</strong>
   , 161, 173</p>
<p>پشتیبانی از تراکنش توزیع‌شده، 361</p>
<p>واژه‌های 
   <strong>data</strong>
   خارجی، 501</p>
<p>پشتیبانی از جستجوی متن کامل، 490</p>
<p>تکثیر مبتنی بر 
   <strong>leader</strong>
   ، 153</p>
<p>شماره توالی 
   <strong>log</strong>
   , 156</p>
<p>پیاده‌سازی 
   <strong>MVCC</strong>
   ، 239، 241</p>
<p>زبان 
   <strong>PL/pgSQL</strong>
   ، 255</p>
<p>شاخص‌های مکانی 
   <strong>PostGIS</strong>
   , 87</p>
<p>جلوگیری از به‌روزرسانی‌های از دست رفته، 245</p>
<p>جلوگیری از 
   <strong>write skew</strong>
   ، 248، 261</p>
<p>
<strong>read committed isolation</strong>
   , 236</p>
<p>پرس و جوهای بازگشتی، 54</p>
<p>نمایش نمودارها، 51</p>
<p>
<strong>Index</strong>
   | 577
  </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0601</div>
            </div>
        </div>
        <!-- Page 0602 -->
        <div class="chapter" id="page-0602">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
<strong>serializable snapshot isolation (SSI)</strong>
   , 261</p>
<p>پشتیبانی از 
   <strong>snapshot isolation</strong>
   ، 239، 242</p>
<p>
<strong>WAL-based replication</strong>
   , 160</p>
<p>پشتیبانی از 
   <strong>XML</strong>
   و 
   <strong>JSON</strong>
   ، 30، 42</p>
<p>
<strong>pre-splitting</strong>
   , 212</p>
<p>
<strong>Precision Time Protocol (PTP)</strong>
   , 290</p>
<p>
<strong>predicate locks</strong>
   , 259</p>
<p>
<strong>predictive analytics</strong>
   , 533-536</p>
<p>تقویت سوگیری، 534</p>
<p>اخلاقیات (به اخلاقیات مراجعه کنید)</p>
<p>حلقه‌های بازخورد، 536</p>
<p>
<strong>preemption</strong>
</p>
<p>از منابع 
   <strong>datacenter</strong>
   ، 418</p>
<p>از 
   <strong>threads</strong>
   ، 298</p>
<p>مدل پردازش 
   <strong>Pregel</strong>
   ، 425</p>
<p>کلیدهای اولیه، 85، 556</p>
<p>
<strong>compound primary key (Cassandra)</strong>
   , 204</p>
<p>تکثیر اولیه-ثانویه (به تکثیر مبتنی بر 
   <strong>leader</strong>
   مراجعه کنید)</p>
<p>حریم خصوصی، 536-543</p>
<p>رضایت و آزادی انتخاب، 538</p>
<p>
<strong>data</strong>
   به عنوان دارایی و قدرت، 540</p>
<p>پاک کردن 
   <strong>data</strong>
   ، 463</p>
<p>ملاحظات اخلاقی (به اخلاقیات مراجعه کنید)</p>
<p>قانون‌گذاری و خودتنظیمی، 542</p>
<p>معنی، 539</p>
<p>نظارت، 537</p>
<p>ردیابی 
   <strong>behavioral data</strong>
   , 536</p>
<p>الگوریتم‌های احتمالی، 16، 466</p>
<p>وقفه فرآیند، 295-299</p>
<p>زمان پردازش (از رویدادها)، 469</p>
<p>تولیدکنندگان (جریان‌های پیام)، 440</p>
<p>زبان‌های برنامه‌نویسی</p>
<p>زبان‌های 
   <strong>dataflow</strong>
   ، 504</p>
<p>برای روال‌های ذخیره‌شده، 255</p>
<p>برنامه‌نویسی واکنشی تابعی (
   <strong>FRP</strong>
   )،</p>
<p>504</p>
<p>برنامه‌نویسی منطقی، 504</p>
<p>
<strong>Prolog (language)</strong>
   , 61</p>
<p>(همچنین به 
   <strong>Datalog</strong>
   مراجعه کنید)</p>
<p>تعهدات (تراکنش‌ها)، 222</p>
<p>
<strong>Q</strong>
</p>
<p>
<strong>Qpid (messaging)</strong>
   , 444</p>
<p>کیفیت 
   <strong>service (QoS)</strong>
   , 285</p>
<p>
<strong>Quantcast File System (distributed filesystem)</strong>
   ,
  </p>
<p>398</p>
<p>زبان‌های پرس و جو، 42-48</p>
<p>خط لوله تجمیع، 48</p>
<p>
<strong>CSS</strong>
   و 
   <strong>XSL</strong>
   ، 44</p>
<p>
<strong>Cypher</strong>
   , 52</p>
<p>
<strong>Datalog</strong>
   , 60</p>
<p>
<strong>Juttle</strong>
   , 504</p>
<p>پرس و جوهای 
   <strong>MapReduce</strong>
   ، 46-48</p>
<p>پرس و جوی بازگشتی 
   <strong>SQL</strong>
   ، 53</p>
<p>جبر رابطه‌ای و 
   <strong>SQL</strong>
   ، 42</p>
<p>
<strong>SPARQL</strong>
   , 59</p>
<p>بهینه‌ساز پرس و جو، 37، 427</p>
<p>تاخیر صف (شبکه‌ها)، 282</p>
<p>مسدود کردن سرصفحه، 15</p>
<p>
<strong>queues (messaging)</strong>
   , 137</p>
<p>
<strong>quorums</strong>
   , 179-182, 556</p>
<p>برای تکثیر بدون 
   <strong>leader</strong>
   ، 179</p>
<p>در الگوریتم‌های 
   <strong>consensus</strong>
   ، 368</p>
<p>محدودیت‌های سازگاری، 181-183، 334</p>
<p>تصمیم‌گیری در سیستم‌های توزیع‌شده،</p>
<p>301</p>
<p>پایش کهنگی، 182</p>
<p>تکثیر چند 
   <strong>datacenter</strong>
   , 184</p>
<p>
<strong>R</strong>
</p>
<p>شاخص‌های 
   <strong>R-trees</strong>
   , 87</p>
<p>
<strong>RabbitMQ (messaging)</strong>
   , 137, 444</p>
<p>تکثیر مبتنی بر 
   <strong>leader</strong>
   , 153</p>
<p>مسئله مسابقه، 225</p>
<p>(همچنین به همزمانی مراجعه کنید)</p>
<p>اجتناب با 
   <strong>linearizability</strong>
   ، 331</p>
<p>ناشی از نوشته‌های دوگانه، 452</p>
<p>نوشتن کثیف، 235</p>
<p>در افزایش شمارنده، 235</p>
<p>از دست دادن به‌روزرسانی‌ها، 242-246</p>
<p>جلوگیری با 
   <strong>event logs</strong>
   ، 462، 507</p>
<p>جلوگیری با 
   <strong>serializable isolation</strong>
   ، 252</p>
<p>
<strong>write skew</strong>
   , 246-251</p>
<p>
<strong>Raft (consensus algorithm)</strong>
   , 366</p>
<p>
<strong>Index</strong>
   | 579
  </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0602</div>
            </div>
        </div>
        <!-- Page 0603 -->
        <div class="chapter" id="page-0603">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>حساسیت به مشکلات شبکه، 369</p>
<p>شماره عبارت، 368</p>
<p>استفاده در 
   <strong>etcd</strong>
   , 353</p>
<p>
<strong>RAID (Redundant Array of Independent</strong>
</p>
<p>
<strong>Disks)</strong>
   , 7, 398</p>
<p>راه‌آهن، مهاجرت 
   <strong>schema</strong>
   در، 496</p>
<p>
<strong>RAMCloud (in-memory storage)</strong>
   , 89</p>
<p>الگوریتم‌های رتبه‌بندی، 424</p>
<p>
<strong>RDF (Resource Description Framework)</strong>
   , 57</p>
<p>پرس و جو با 
   <strong>SPARQL</strong>
   ، 59</p>
<p>
<strong>RDMA (Remote Direct Memory Access)</strong>
   , 276</p>
<p>
<strong>read committed isolation level</strong>
   , 234-237</p>
<p>پیاده‌سازی، 236</p>
<p>کنترل همزمانی چند نسخه</p>
<p>(
   <strong>MVCC</strong>
   )، 239</p>
<p>عدم خواندن کثیف، 234</p>
<p>نوشتن کثیف وجود ندارد، 235</p>
<p>
<strong>snapshot isolation</strong>
   , 237-242</p>
<p>پردازش تکراری، 424</p>
<p>
<strong>real-time</strong>
</p>
<p>ویرایش مشارکتی، 170</p>
<p>پردازش نزدیک-واقعی، 390</p>
<p>(همچنین به پردازش جریان مراجعه کنید)</p>
<p>جریان 
   <strong>publish/subscribe</strong>
   ، 513</p>
<p>تضمین‌های زمان پاسخ، 298</p>
<p>ساعت‌های زمان روز، 288</p>
<p>تعادل مجدد پارتیشن‌ها، 209-214، 556</p>
<p>(همچنین به 
   <strong>partitioning</strong>
   مراجعه کنید)</p>
<p>تعادل مجدد خودکار یا دستی، 213</p>
<p>پارتیشن‌بندی پویا، 212</p>
<p>تعداد ثابتی از پارتیشن در هر گره، 212</p>
<p>مشکلات با 
   <strong>hash mod N</strong>
   ، 210</p>
<p>
<strong>recency guarantee</strong>
   , 324</p>
<p>موتورهای توصیه‌گر</p>
<p>خروجی‌های فرآیند 
   <strong>batch</strong>
   , 412</p>
<p>
<strong>batch workflows</strong>
   , 403, 420</p>
<p>پردازش تکراری، 424</p>
<p>الگوریتم‌های آماری و عددی، 428</p>
<p>رکوردها، 399</p>
<p>رویدادها در پردازش جریان، 440</p>
<p>پرس و جوهای بازگشتی 
   <strong>SQL</strong>
   ، 53</p>
<p>
<strong>redelivery (messaging)</strong>
   , 445</p>
<p>
<strong>Redis (database)</strong>
</p>
<p>عملیات اتمی، 243</p>
<p>ماندگاری، 89</p>
<p>اسکریپت‌نویسی 
   <strong>Lua</strong>
   ، 255</p>
<p>اجرای تک رشته‌ای، 253</p>
<p>مثال استفاده، 4</p>
<p>افزونگی</p>
<p>اجزای سخت‌افزاری، 7</p>
<p>از 
   <strong>derived data</strong>
   ، 386</p>
<p>(همچنین به 
   <strong>derived data</strong>
   مراجعه کنید)</p>
<p>کدهای 
   <strong>Reed–Solomon (error correction)</strong>
   , 398</p>
<p>
<strong>refactoring</strong>
   , 22</p>
<p>(همچنین به قابلیت تکامل مراجعه کنید)</p>
<p>محدوده‌ها (پارتیشن‌بندی)، 199</p>
<p>
<strong>register (data structure)</strong>
   , 325</p>
<p>مدل رابطه‌ای 
   <strong>data</strong>
   ، 28-42</p>
<p>مقایسه با مدل اسناد، 38-42</p>
<p>پرس و جوهای نموداری در 
   <strong>SQL</strong>
   ، 53</p>
<p>در پایگاه داده‌های 
   <strong>in-memory</strong>
   با، 89</p>
<p>روابط 
   <strong>many-to-one and many-to-many</strong>
</p>
<p>33</p>
<p>تراکنش‌های چند 
   <strong>object</strong>
   ، نیاز به، 231</p>
<p>
<strong>NoSQL</strong>
   به عنوان جایگزینی برای، 29</p>
<p>
<strong>object-relational mismatch</strong>
   , 29</p>
<p>الگوی مشاهده‌گر، 506</p>
<p>سیستم‌های 
   <strong>offline</strong>
   , 390</p>
<p>(همچنین به پردازش 
   <strong>batch</strong>
   مراجعه کنید)</p>
<p>کلاینت‌های 
   <strong>stateful</strong>
   ، با قابلیت 
   <strong>offline</strong>
   , 170, 511</p>
<p>برنامه‌های 
   <strong>offline-first</strong>
   , 511</p>
<p>آفست‌ها</p>
<p>آفست‌های مصرف‌کننده در 
   <strong>logs</strong>
   پارتیشن‌بندی شده، 449</p>
<p>پیام‌ها در 
   <strong>logs</strong>
   پارتیشن‌بندی شده، 447</p>
<p>
<strong>OLAP (online analytic processing)</strong>
   , 91, 556</p>
<p>مکعب‌های 
   <strong>data</strong>
   , 102</p>
<p>
<strong>OLTP (online transaction processing)</strong>
   , 90, 556</p>
<p>پرس و جوهای تحلیلی در مقابل، 411</p>
<p>مشخصات کاری، 253</p>
<p>روابط 
   <strong>one-to-many</strong>
   , 30</p>
<p>نمایش 
   <strong>JSON</strong>
   , 32</p>
<p>سیستم‌های 
   <strong>online</strong>
   , 389</p>
<p>(همچنین به خدمات مراجعه کنید)</p>
<p>
<strong>Oozie (workflow scheduler)</strong>
   , 402</p>
<p>
<strong>OpenAPI (service definition format)</strong>
   , 133</p>
<p>
<strong>OpenStack</strong>
</p>
<p>
<strong>Nova (cloud infrastructure)</strong>
</p>
<p>استفاده از 
   <strong>ZooKeeper</strong>
   , 370</p>
<p>
<strong>Swift (object storage)</strong>
   , 398</p>
<p>عملکردی (عملکرد)، 19</p>
<p>سیستم‌های عامل در مقابل 
   <strong>databases</strong>
   ، 499</p>
<p>عملیات، 518، 522</p>
<p>پارتیشن‌بندی، 206-209، 217</p>
<p>
<strong>Index</strong>
   | 577
  </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0603</div>
            </div>
        </div>
        <!-- Page 0604 -->
        <div class="chapter" id="page-0604">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>خطاهای 
   <strong>software</strong>
   ، 8</p>
<p>
<strong>Remote Method Invocation (Java RMI)</strong>
   , 134</p>
<p>
<strong>remote procedure calls (RPCs)</strong>
   , 134-136</p>
<p>(همچنین به 
   <strong>services</strong>
   مراجعه کنید)</p>
<p>مبتنی بر 
   <strong>futures</strong>
   ، 135</p>
<p>رمزگذاری 
   <strong>data</strong>
   و تکامل، 136</p>
<p>مسائل با، 134</p>
<p>با استفاده از 
   <strong>Avro</strong>
   , 126, 135</p>
<p>با استفاده از 
   <strong>Thrift</strong>
   ، 135</p>
<p>در مقابل 
   <strong>message brokers</strong>
   ، 137</p>
<p>خواندن‌های تکراری (
   <strong>transaction isolation</strong>
   )،</p>
<p>242</p>
<p>
<strong>replicas</strong>
   , 152</p>
<p>
<strong>replication</strong>
   , 151-193, 556</p>
<p>و ماندگاری، 227</p>
<p>تکثیر زنجیره‌ای، 155</p>
<p>حل تعارض و، 246</p>
<p>ویژگی‌های سازگاری، 161-167</p>
<p>خواندن‌های پیشوند سازگار، 165</p>
<p>خواندن‌های یکنواخت، 164</p>
<p>خواندن نوشتن خود، 162</p>
<p>در سیستم‌های فایل توزیع‌شده، 398</p>
<p>تکثیر بدون 
   <strong>leader</strong>
   ، 177-191</p>
<p>(همچنین به 
   <strong>replication</strong>
   مراجعه کنید)</p>
<p>تشخیص نوشتن همزمان، 184-191</p>
<p>ثبت رابطه 
   <strong>happens-before</strong>
   , 187</p>
<p>رابطه 
   <strong>happens-before</strong>
   و همزمانی،</p>
<p>186</p>
<p>
<strong>last write wins</strong>
   , 186</p>
<p>ادغام مقادیر نوشته شده به‌طور همزمان،</p>
<p>190</p>
<p>بردار نسخه، 191</p>
<p>چند 
   <strong>datacenter</strong>
   , 184</p>
<p>
<strong>quorums</strong>
   , 179-182</p>
<p>محدودیت‌های سازگاری، 181-183، 334</p>
<p>
<strong>sloppy quorums</strong>
   و 
   <strong>hinted handoff</strong>
   , 183</p>
<p>پایش رکود، 182</p>
<p>تکثیر چند 
   <strong>leader</strong>
   ، 168-177</p>
<p>در سراسر چند 
   <strong>datacenter</strong>
   ، 168، 335</p>
<p>مدیریت تعارض نوشتن، 171-175</p>
<p>توپولوژی‌های تکثیر، 175-177</p>
<p>پارتیشن‌بندی و، 147، 200</p>
<p>دلایل استفاده، 145، 151</p>
<p>تکثیر تک 
   <strong>leader</strong>
   ، 152-161</p>
<p>
<strong>failover</strong>
   , 157</p>
<p>پیاده‌سازی 
   <strong>logs</strong>
   تکثیر،</p>
<p>158-161</p>
<p>ارتباط با اجماع، 367</p>
<p>تنظیم 
   <strong>followers</strong>
   جدید، 155</p>
<p>همزمان در مقابل ناهمزمان،</p>
<p>153-155</p>
<p>تکثیر ماشین حالت، 349، 452</p>
<p>استفاده از کدگذاری خطا، 398</p>
<p>با سیستم‌های 
   <strong>data</strong>
   نامتجانس، 453</p>
<p>
<strong>replication logs (see logs)</strong>
</p>
<p>
<strong>reprocessing data</strong>
   , 496, 498</p>
<p>(همچنین به قابلیت تکامل مراجعه کنید)</p>
<p>از پیام‌رسانی مبتنی بر 
   <strong>log</strong>
   ، 451</p>
<p>
<strong>request routing</strong>
   , 214-216</p>
<p>رویکردهایی برای، 214</p>
<p>اجرای پرس و جو موازی، 216</p>
<p>سیستم‌های مقاوم، 6</p>
<p>(همچنین به تحمل خطا مراجعه کنید)</p>
<p>زمان پاسخ</p>
<p>به عنوان معیار عملکرد برای 
   <strong>services</strong>
   ، 13، 389</p>
<p>تضمین در، 298</p>
<p>تاخیر در مقابل، 14</p>
<p>متوسط و صدک‌ها، 14</p>
<p>تجربه کاربر، 15</p>
<p>مسئولیت و پاسخگویی، 535</p>
<p>
<strong>REST (Representational State Transfer)</strong>
   , 133</p>
<p>(همچنین به 
   <strong>services</strong>
   مراجعه کنید)</p>
<p>
<strong>RethinkDB (database)</strong>
</p>
<p>مدل 
   <strong>data document</strong>
   ، 31</p>
<p>پارتیشن‌بندی پویا، 212</p>
<p>پشتیبانی از 
   <strong>join</strong>
   ، 34، 42</p>
<p>پارتیشن‌بندی کلید-محدوده، 202</p>
<p>تکثیر بدون 
   <strong>leader</strong>
   , 153</p>
<p>اشتراک در تغییرات، 456</p>
<p>
<strong>Riak (database)</strong>
</p>
<p>موتور ذخیره‌سازی 
   <strong>Bitcask</strong>
   , 72</p>
<p>
<strong>CRDTs</strong>
   , 174, 191</p>
<p>بردار 
   <strong>version</strong>
   نقطه‌چین، 191</p>
<p>پروتکل شایعه‌پراکنی، 216</p>
<p>پارتیشن‌بندی 
   <strong>hash</strong>
   , 203-204, 211</p>
<p>
<strong>last-write-wins</strong>
   حل تعارض، 186</p>
<p>تکثیر بدون 
   <strong>leader</strong>
   ، 177</p>
<p>موتور ذخیره‌سازی 
   <strong>LevelDB</strong>
   , 78</p>
<p>
<strong>linearizability</strong>
   ، کمبود، 335</p>
<p>پشتیبانی از چند 
   <strong>datacenter</strong>
   ، 184</p>
<p>جلوگیری از از دست رفتن به‌روزرسانی‌ها در سراسر 
   <strong>replicas</strong>
   ، 246</p>
<p>تنظیم مجدد، 213</p>
<p>ویژگی جستجو، 209</p>
<p>شاخص‌های ثانویه، 207</p>
<p>
<strong>siblings (concurrently written values)</strong>
   , 190</p>
<p>
<strong>sloppy quorums</strong>
   , 184</p>
<p>
<strong>ring buffers</strong>
   , 450</p>
<p>
<strong>Ripple (cryptocurrency)</strong>
   , 532</p>
<p>
<strong>rockets</strong>
   , 10, 36, 305</p>
<p>
<strong>RocksDB (storage engine)</strong>
   , 78</p>
<p>تراکم سطحی، 79</p>
<p>بازگرداندن (تراکنش‌ها)، 222</p>
<p>ارتقاء تدریجی، 8، 112</p>
<p>
<strong>routing (see request routing)</strong>
</p>
<p>
<strong>row-oriented storage</strong>
   , 96</p>
<p>
<strong>rowhammer (memory corruption)</strong>
   , 529</p>
<p>
<strong>RPCs (see remote procedure calls)</strong>
</p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0604</div>
            </div>
        </div>
        <!-- Page 0605 -->
        <div class="chapter" id="page-0605">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
<strong>Rubygems (package manager)</strong>
   , 428</p>
<p>
<strong>rules (Datalog)</strong>
   , 61</p>
<p>ویژگی‌های ایمنی و زنده بودن، 308</p>
<p>در الگوریتم‌های اجماع، 366</p>
<p>در تراکنش‌ها، 222</p>
<p>
<strong>sagas (see compensating transactions)</strong>
</p>
<p>
<strong>Samza (stream processor)</strong>
   , 466, 467</p>
<p>تحمل خطا، 479</p>
<p>پشتیبانی از 
   <strong>streaming SQL</strong>
   , 466</p>
<p>
<strong>sandboxes</strong>
   , 9</p>
<p>
<strong>SAP HANA (database)</strong>
   , 93</p>
<p>مقیاس‌پذیری، 10-18، 489</p>
<p>رویکردی برای مقابله با بار، 17</p>
<p>تعریف، 22</p>
<p>شرح بار، 11</p>
<p>شرح عملکرد، 13</p>
<p>
<strong>partitioning</strong>
   و، 199</p>
<p>
<strong>replication</strong>
   , 161</p>
<p>
<strong>scaling up versus scaling out</strong>
   , 146</p>
<p>
<strong>scaling out</strong>
   , 17, 146</p>
<p>(همچنین به معماری 
   <strong>shared-nothing</strong>
   مراجعه کنید)</p>
<p>
<strong>scaling up</strong>
   , 17, 146</p>
<p>
<strong>scatter/gather approach</strong>
   , querying partitioned</p>
<p>
<strong>databases</strong>
   , 207</p>
<p>
<strong>SCD (slowly changing dimension)</strong>
   , 476</p>
<p>
<strong>schema-on-read</strong>
   , 39, 111, 128</p>
<p>مقایسه با 
   <strong>schema</strong>
   تکامل یافته، 128</p>
<p>در فایل‌سیستم‌های توزیع‌شده، 415</p>
<p>
<strong>schema-on-write</strong>
   , 39</p>
<p>
<strong>schemaless databases (see schema-on-read)</strong>
</p>
<p>
<strong>schemas</strong>
   , 557</p>
<p>
<strong>Avro</strong>
   , 122-127</p>
<p>خواننده 
   <strong>schema</strong>
   نویسنده را تعیین می‌کند، 125</p>
<p>تکامل 
   <strong>schema</strong>
   , 123</p>
<p>به طور پویا تولید شده، 126</p>
<p>تکامل، 496</p>
<p>تأثیر بر کد برنامه، 111</p>
<p>بررسی سازگاری، 126</p>
<p>در 
   <strong>databases</strong>
   ، 129-131</p>
<p>در 
   <strong>message-passing</strong>
   ، 138</p>
<p>در فراخوانی 
   <strong>service</strong>
   ، 136</p>
<p>انعطاف‌پذیری در مدل سند، 39</p>
<p>برای تجزیه و تحلیل، 93-95</p>
<p>برای 
   <strong>JSON</strong>
   و 
   <strong>XML</strong>
   ، 115</p>
<p>مزایای، 127</p>
<p>تغییر 
   <strong>schema</strong>
   در راه‌آهن، 496</p>
<p>
<strong>Thrift</strong>
   و 
   <strong>Protocol Buffers</strong>
   ، 117-121</p>
<p>تکامل 
   <strong>schema</strong>
   ، 120</p>
<p>رویکرد سنتی به طراحی، مغالطه در،</p>
<p>462</p>
<p>جستجوها</p>
<p>ساختن شاخص‌های جستجو در فرآیندهای</p>
<p>
<strong>batch</strong>
   ، 411</p>
<p>همسایگان 
   <strong>k-nearest</strong>
   , 429</p>
<p>در جریان‌ها، 467</p>
<p>شاخص‌های ثانویه تقسیم‌بندی شده، 206</p>
<p>
<strong>secondaries (see leader-based replication)</strong>
</p>
<p>شاخص‌های ثانویه، 85، 557</p>
<p>پارتیشن‌بندی، 206-209، 217</p>
<p>مورد (
   <strong>see leader-based replication</strong>
   )، 452</p>
<p>
<strong>sed (Unix tool)</strong>
   , 392</p>
<p>فایل‌های خود توصیفی، 127</p>
<p>
<strong>self-joins</strong>
   , 480</p>
<p>سیستم‌های خوداعتبارسنجی، 530</p>
<p>وب معنایی، 57</p>
<p>تکثیر نیمه‌همزمان، 154</p>
<p>ترتیب شماره توالی، 343-348</p>
<p>تولیدکنندگان، 294، 344</p>
<p>کافی نبودن برای اعمال محدودیت‌ها، 347</p>
<p>
<strong>sequential consistency</strong>
   , 351</p>
<p>
<strong>serializability</strong>
   , 225, 233, 251-266, 557</p>
<p>در مقابل 
   <strong>linearizability</strong>
   ، 329</p>
<p>کنترل همزمانی بدبینانه در مقابل خوش‌بینانه، 261</p>
<p>اجرای سریال، 252-256</p>
<p>پارتیشن‌بندی، 255</p>
<p>با استفاده از رویه‌های ذخیره‌شده، 253، 349</p>
<p>
<strong>serializable snapshot isolation (SSI)</strong>
   ,
   </p>
<p>261-266</p>
<p>تشخیص خواندن‌های 
   <strong>MVCC</strong>
   منسوخ شده، 263</p>
<p>تشخیص نوشته‌هایی که بر خوانده‌های قبلی تأثیر می‌گذارند،</p>
<p>264</p>
<p>اجرای توزیع‌شده، 265، 364</p>
<p>عملکرد 
   <strong>SSI</strong>
   ، 265</p>
<p>جلوگیری از 
   <strong>write skew</strong>
   , 262-265</p>
<p>قفل دو فازی (
   <strong>2PL</strong>
   )، 257-261</p>
<p>قفل‌های 
   <strong>index-range</strong>
   , 260</p>
<p>عملکرد، 258</p>
<p>
<strong>Serializable (Java)</strong>
   , 113</p>
<p>
<strong>Index</strong>
   | 583
  </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0605</div>
            </div>
        </div>
        <!-- Page 0606 -->
        <div class="chapter" id="page-0606">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
<strong>serialization</strong>
   , 113</p>
<p>(همچنین به رمزگذاری مراجعه کنید)</p>
<p>کشف 
   <strong>service</strong>
   ، 135، 214، 372</p>
<p>با استفاده از 
   <strong>DNS</strong>
   ، 216، 372</p>
<p>توافقنامه‌های سطح 
   <strong>service (SLAs)</strong>
   , 15</p>
<p>
<strong>service-oriented architecture (SOA)</strong>
   , 132</p>
<p>(همچنین به خدمات مراجعه کنید)</p>
<p>
<strong>services</strong>
   , 131-136</p>
<p>
<strong>microservices</strong>
   , 132</p>
<p>وابستگی‌های علّی در سراسر 
   <strong>services</strong>
   ، 493</p>
<p>
<strong>loose coupling</strong>
   , 502</p>
<p>ارتباط با پردازشگرهای 
   <strong>batch/stream</strong>
   ، 389،</p>
<p>508</p>
<p>
<strong>remote procedure calls (RPCs)</strong>
   , 134-136</p>
<p>مسائل با، 134</p>
<p>با استفاده از 
   <strong>Avro</strong>
   ، 126، 135</p>
<p>با استفاده از 
   <strong>Thrift</strong>
   ، 135</p>
<p>در مقابل 
   <strong>message brokers</strong>
   ، 137</p>
<p>
<strong>repeatable reads (transaction isolation)</strong>
   , 242</p>
<p>
<strong>replicas</strong>
   , 152</p>
<p>
<strong>replication</strong>
   , 151-193, 556</p>
<p>و ماندگاری، 227</p>
<p>تکثیر زنجیره‌ای، 155</p>
<p>حل تعارض و، 246</p>
<p>ویژگی‌های سازگاری، 161-167</p>
<p>در سیستم‌های فایل توزیع‌شده، 398</p>
<p>
<strong>leaderless</strong>
   ، 177-191</p>
<p>(همچنین به 
   <strong>replication</strong>
   مراجعه کنید)</p>
<p>تشخیص نوشتن همزمان، 184-191</p>
<p>ثبت رابطه 
   <strong>happens-before</strong>
   ،</p>
<p>187</p>
<p>
<strong>last write wins</strong>
   , 186</p>
<p>ادغام مقادیر نوشته شده به‌طور همزمان،</p>
<p>190</p>
<p>بردار نسخه، 191</p>
<p>
<strong>multi-datacenter</strong>
   , 184</p>
<p>
<strong>quorums</strong>
   , 179-182</p>
<p>محدودیت‌های سازگاری، 181-183، 334</p>
<p>
<strong>sloppy quorums and hinted handoff</strong>
   , 183</p>
<p>
<strong>read repair and anti-entropy</strong>
   , 178</p>
<p>
<strong>leap seconds</strong>
   , 8, 290</p>
<p>در ساعت‌های 
   <strong>time-of-day</strong>
   , 288</p>
<p>
<strong>leases</strong>
   , 295</p>
<p>پیاده‌سازی با 
   <strong>ZooKeeper</strong>
   ، 370</p>
<p>
<strong>ledgers</strong>
   , 460</p>
<p>سیستم‌های 
   <strong>legacy</strong>
   ، نگهداری از، 18</p>
<p>
<strong>less (Unix tool)</strong>
   , 397</p>
<p>
<strong>LevelDB (storage engine)</strong>
   , 78</p>
<p>
<strong>leveled compaction</strong>
   , 79</p>
<p>خودکار 
   <strong>automata</strong>
   ، 88</p>
<p>
<strong>linearizability</strong>
   , 324-338</p>
<p>هزینه، 335-338</p>
<p>قضیه 
   <strong>CAP</strong>
   ، 336</p>
<p>حافظه در 
   <strong>CPUs</strong>
   چند هسته‌ای، 338</p>
<p>تعریف، 325-329</p>
<p>در سیستم‌های 
   <strong>dataflow</strong>
   , 492, 524</p>
<p>اجتناب از هماهنگی، 527</p>
<p>
<strong>relying on</strong>
   , 330-332</p>
<p>محدودیت‌ها و منحصر به فرد بودن، 330</p>
<p>
<strong>constraints</strong>
   و منحصر به فرد بودن، 330</p>
<p>
<strong>cross-channel</strong>
   وابستگی‌های زمانی، 331</p>
<p>
<strong>locking and leader election</strong>
   , 330</p>
<p>
<strong>stronger than causal consistency</strong>
   , 342</p>
<p>استفاده برای پیاده‌سازی 
   <strong>total order broadcast</strong>
   ، 351</p>
<p>در مقابل 
   <strong>serializability</strong>
   ، 329</p>
<p>
<strong>LinkedIn</strong>
</p>
<p>
<strong>Azkaban (workflow scheduler)</strong>
   , 402</p>
<p>
<strong>Databus (change data capture)</strong>
   , 161, 455</p>
<p>
<strong>Espresso (database)</strong>
   , 31, 126, 130, 153, 216</p>
<p>
<strong>Helix (cluster manager) (see Helix)</strong>
</p>
<p>
<strong>profile (example)</strong>
   , 30</p>
<p>ارجاع به موجودیت شرکت (مثال)، 34</p>
<p>
<strong>Rest.li (RPC framework)</strong>
   , 135</p>
<p>
<strong>Voldemort (database) (see Voldemort)</strong>
</p>
<p>
<strong>Linux, leap second bug</strong>
   , 8, 290</p>
<p>ویژگی‌های زنده‌بودن، 308</p>
<p>
<strong>LMDB (storage engine)</strong>
   , 82, 242</p>
<p>
<strong>load</strong>
</p>
<p>
<strong>approaches to coping with</strong>
   , 17</p>
<p>توصیف، 11</p>
<p>
<strong>load testing</strong>
   , 16</p>
<p>تعادل بار (پیام‌رسانی)، 444</p>
<p>شاخص‌های محلی (به شاخص‌های 
   <strong>document-partitioned</strong>
</p>
<p>مراجعه کنید)</p>
<p>مکان، 32، 41، 555</p>
<p>
<strong>serializable snapshot isolation (SSI)</strong>
   ,
   </p>
<p>261</p>
<p>تکثیر، 152</p>
<p>
<strong>index maintenance</strong>
   , 495</p>
<p>در تراکنش‌های 
   <strong>serializable</strong>
   , 255</p>
<p>پوشش 
   <strong>indexes</strong>
   ، 86</p>
<p>شاخص‌های پیوسته‌شده، 87</p>
<p>مورد 
   <strong>(see leader-based replication)</strong>
   ، 452</p>
<p>
<strong>serial execution of transactions</strong>
   , 253</p>
<p>ترتیب کل، 344</p>
<p>
<strong>P</strong>
</p>
<p>
<strong>in batch processing</strong>
   , 400, 405, 421</p>
<p>
<strong>in stateful clients</strong>
   , 170, 511</p>
<p>
<strong>in stream processing</strong>
   , 474, 478, 508, 522</p>
<p>
<strong>location transparency</strong>
   , 134</p>
<p>در مدل 
   <strong>actor</strong>
   ، 138</p>
<p>
<strong>locks</strong>
   , 556</p>
<p>بن‌بست، 258</p>
<p>
<strong>distributed locking</strong>
   , 301-304, 330</p>
<p>
<strong>fencing tokens</strong>
   , 303</p>
<p>پیاده‌سازی با 
   <strong>ZooKeeper</strong>
   ، 370</p>
<p>ارتباط با اجماع، 374</p>
<p>برای 
   <strong>transaction isolation</strong>
</p>
<p>در 
   <strong>snapshot isolation</strong>
   , 239</p>
<p>در 
   <strong>two-phase locking (2PL)</strong>
   , 257-261</p>
<p>اتمی کردن عملیات، 243</p>
<p>عملکرد، 258</p>
<p>جلوگیری از نوشته‌های کثیف، 236</p>
<p>جلوگیری از 
   <strong>phantoms</strong>
   با 
   <strong>index-range</strong>
</p>
<p>
<strong>locks</strong>
   , 260, 265</p>
<p>
<strong>read locks (shared mode)</strong>
   , 236, 258</p>
<p>حالت مشترک و حالت انحصاری، 258</p>
<p>در تعهد دو فازی (
   <strong>2PC</strong>
   )</p>
<p>تشخیص بن‌بست، 364</p>
<p>در-
   <strong>doubt transactions</strong>
   نگه داشتن 
   <strong>locks</strong>
   , 362</p>
<p>
<strong>materializing</strong>
   درگیری‌ها با، 251</p>
<p>جلوگیری از به‌روزرسانی‌های از دست رفته با قفل‌گذاری صریح،</p>
<p>244</p>
<p>شماره توالی 
   <strong>log</strong>
   , 156, 449</p>
<p>زبان‌های برنامه‌نویسی منطقی، 504</p>
<p>ساعت‌های منطقی، 293، 343، 494</p>
<p>برای خواندن 
   <strong>read-after-write</strong>
   ، 164</p>
<p>
<strong>logical logs</strong>
   , 160</p>
<p>
<strong>logs (data structure)</strong>
   , 71, 556</p>
<p>مزایای تغییرناپذیری، 460</p>
<p>فشرده‌سازی، 73، 79، 456، 460</p>
<p>برای وضعیت اپراتور جریان، 479</p>
<p>
<strong>linearizability</strong>
   , 324-338</p>
<p>
<strong>PTP (Precision Time Protocol)</strong>
   , 290</p>
<p>
<strong>predicate locks</strong>
   , 259</p>
<p>
<strong>predictive analytics</strong>
   , 533-536</p>
<p>افزایش تعصب، 534</p>
<p>اخلاقیات (به اخلاقیات مراجعه کنید)</p>
<p>حلقه‌های بازخورد، 536</p>
<p>
<strong>preemption</strong>
</p>
<p>از منابع 
   <strong>datacenter</strong>
   ، 418</p>
<p>از 
   <strong>threads</strong>
   ، 298</p>
<p>مدل پردازش 
   <strong>Pregel</strong>
   ، 425</p>
<p>کلیدهای اولیه، 85، 556</p>
<p>
<strong>compound primary key (Cassandra)</strong>
   , 204</p>
<p>تکثیر اولیه-ثانویه (به تکثیر مبتنی بر 
   <strong>leader</strong>
   مراجعه کنید)</p>
<p>حریم خصوصی، 536-543</p>
<p>رضایت و آزادی انتخاب، 538</p>
<p>
<strong>data</strong>
   به عنوان دارایی و قدرت، 540</p>
<p>پاک کردن 
   <strong>data</strong>
   ، 463</p>
<p>مسائل اخلاقی (به اخلاقیات مراجعه کنید)</p>
<p>قانون‌گذاری و خودتنظیمی، 542</p>
<p>معنی، 539</p>
<p>نظارت، 537</p>
<p>ردیابی 
   <strong>behavioral data</strong>
   , 536</p>
<p>الگوریتم‌های احتمالی، 16، 466</p>
<p>فرآیندهای 
   <strong>batch</strong>
   , 400, 405, 421</p>
<p>خطاها و، 227</p>
<p>شاخص‌های ثانویه، 207</p>
<p>
<strong>point in time</strong>
</p>
<p>576 | 
   <strong>Index</strong>
</p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0606</div>
            </div>
        </div>
        <!-- Page 0607 -->
        <div class="chapter" id="page-0607">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>مثال استفاده، 4</p>
<p>استفاده از 
   <strong>Lucene</strong>
   ، 79</p>
<p>
<strong>sort (Unix tool)</strong>
   , 392, 394, 395</p>
<p>اتصالات 
   <strong>sort-merge (MapReduce)</strong>
   , 405</p>
<p>
<strong>Sorted String Tables (see SSTables)</strong>
</p>
<p>مرتب‌سازی</p>
<p>ترتیب مرتب‌سازی در ذخیره‌سازی ستونی، 99</p>
<p>منبع حقیقت (به سیستم‌های رکورد مراجعه کنید)</p>
<p>
<strong>Spanner (database)</strong>
</p>
<p>جایگاه 
   <strong>data</strong>
   ، 41</p>
<p>
<strong>snapshot isolation</strong>
   با استفاده از ساعت‌ها، 295</p>
<p>
<strong>Spark (processing framework)</strong>
   , 421-423</p>
<p>تولید کد 
   <strong>bytecode</strong>
   ، 428</p>
<p>
<strong>dataflow APIs</strong>
   , 427</p>
<p>تحمل خطا، 422</p>
<p>برای 
   <strong>data warehouses</strong>
   ، 93</p>
<p>
<strong>GraphX API (graph processing)</strong>
   , 425</p>
<p>یادگیری ماشینی، 428</p>
<p>
<strong>query optimizer</strong>
   , 427</p>
<p>
<strong>Spark Streaming</strong>
   , 466</p>
<p>
<strong>microbatching</strong>
   , 477</p>
<p>پردازش جریانی در بالای پردازش 
   <strong>batch</strong>
   , 495</p>
<p>
<strong>SPARQL (query language)</strong>
   , 59</p>
<p>الگوریتم‌های مکانی، 429</p>
<p>
<strong>split brain</strong>
   , 158, 557</p>
<p>در الگوریتم‌های اجماع، 352، 367</p>
<p>جلوگیری از، 322، 333</p>
<p>با استفاده از 
   <strong>fencing tokens</strong>
   برای اجتناب، 302-304</p>
<p>
<strong>spreadsheets</strong>
   , قابلیت‌های برنامه‌نویسی 
   <strong>dataflow</strong>
   ، 504</p>
<p>
<strong>SQL (Structured Query Language)</strong>
   , 21, 28, 43</p>
<p>مزایا و محدودیت‌های، 416</p>
<p>اجرای پرس و جو توزیع‌شده، 48</p>
<p>پرس و جوهای 
   <strong>graph</strong>
   در، 53</p>
<p>سطوح 
   <strong>isolation</strong>
   استاندارد، مسائل با، 242</p>
<p>
<strong>résumé (example)</strong>
   ، 30</p>
<p>تزریق 
   <strong>SQL</strong>
   آسیب‌پذیری، 305</p>
<p>
<strong>SQL on Hadoop</strong>
   , 93</p>
<p>تکثیر مبتنی بر دستور، 158</p>
<p>روال‌های ذخیره‌شده، 255</p>
<p>
<strong>SQL Server (database)</strong>
</p>
<p>پشتیبانی از 
   <strong>data warehousing</strong>
   , 93</p>
<p>پشتیبانی از تراکنش‌های توزیع‌شده، 361</p>
<p>تکثیر مبتنی بر 
   <strong>leader</strong>
   ، 153</p>
<p>جلوگیری از از دست رفتن به‌روزرسانی‌ها، 245</p>
<p>جلوگیری از 
   <strong>write skew</strong>
   , 248, 257</p>
<p>خواندن 
   <strong>read committed isolation</strong>
   , 236</p>
<p>پرس و جوهای بازگشتی، 54</p>
<p>نمایش 
   <strong>graphs</strong>
   , 51</p>
<p>
<strong>Solr (search server)</strong>
</p>
<p>ساختن شاخص‌ها در فرآیندهای 
   <strong>batch</strong>
   ، 411</p>
<p>
<strong>SSTables (storage format)</strong>
   , 76-79</p>
<p>مزایای نسبت به شاخص‌های 
   <strong>hash</strong>
   ، 76</p>
<p>شاخص پیوسته، 204</p>
<p>ساختن و نگهداری، 78</p>
<p>ساختن 
   <strong>LSM-Tree</strong>
   از، 78</p>
<p>
<strong>staleness (old data)</strong>
   , 162</p>
<p>وابستگی‌های زمانی 
   <strong>cross-channel</strong>
   ، 331</p>
<p>در 
   <strong>databases</strong>
   بدون 
   <strong>leader</strong>
   ، 178</p>
<p>در کنترل همزمانی چند نسخه، 263</p>
<p>پایش برای، 182</p>
<p>از وضعیت کلاینت، 512</p>
<p>در مقابل 
   <strong>linearizability</strong>
   ، 324</p>
<p>در مقابل به‌موقع بودن، 524</p>
<p>استندبای‌ها (به تکثیر مبتنی بر 
   <strong>leader</strong>
   مراجعه کنید)</p>
<p>توپولوژی‌های 
   <strong>star replication</strong>
   , 175</p>
<p>مدل 
   <strong>star schemas</strong>
   ، 93-95</p>
<p>شباهت به 
   <strong>event sourcing</strong>
   , 458</p>
<p>
<strong>Star Wars analogy (event time versus process-</strong>
</p>
<p>
<strong>ing time)</strong>
   , 469</p>
<p>
<strong>state</strong>
</p>
<p>
<strong>derived</strong>
   از لاگ رویدادهای تغییرناپذیر، 459</p>
<p>مشتق کردن حالت فعلی از 
   <strong>event log</strong>
   ،</p>
<p>458</p>
<p>تداخل بین تغییرات حالت و کد برنامه،</p>
<p>507</p>
<p>حفظ حالت مشتق شده، 495</p>
<p>نگهداری توسط پردازشگر جریان در جریان-
   </p>
<p>
<strong>stream joins</strong>
   , 473</p>
<p>مشاهده حالت مشتق‌شده، 509-515</p>
<p>بازسازی پس از خرابی پردازنده جریان،</p>
<p>478</p>
<p>جداسازی کد برنامه و، 505</p>
<p>تکثیر ماشین حالت، 349، 452</p>
<p>تکثیر مبتنی بر دستور، 158</p>
<p>
<strong>statically typed languages</strong>
</p>
<p>تشابه با 
   <strong>schema-on-write</strong>
   ، 40</p>
<p>تولید کد و، 127</p>
<p>الگوریتم‌های آماری و عددی، 428</p>
<p>
<strong>StatsD (metrics aggregator)</strong>
   , 442</p>
<p>
<strong>stdin, stdout</strong>
   , 395, 396</p>
<p>
<strong>Stellar (cryptocurrency)</strong>
   , 532</p>
<p>
<strong>Index</strong>
   | 585
  </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0607</div>
            </div>
        </div>
        <!-- Page 0608 -->
        <div class="chapter" id="page-0608">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
<strong>stock market feeds</strong>
   , 442</p>
<p>
<strong>STONITH (Shoot The Other Node In The</strong>
</p>
<p>
<strong>Head)</strong>
   , 158</p>
<p>
<strong>stop-the-world (see garbage collection)</strong>
</p>
<p>ذخیره‌سازی</p>
<p>ترکیب فناوری‌های ذخیره‌سازی 
   <strong>data</strong>
   ،</p>
<p>499-504</p>
<p>تنوع، در 
   <strong>MapReduce</strong>
   ، 415</p>
<p>
<strong>Storage Area Network (SAN)</strong>
   , 146, 398</p>
<p>
<strong>storage engines</strong>
   , 69-104</p>
<p>
<strong>column-oriented</strong>
   , 95-101</p>
<p>فشرده‌سازی ستون، 97-99</p>
<p>تمایز بین خانواده‌های ستون و، 99</p>
<p>
<strong>Parquet</strong>
   , 96, 131</p>
<p>
<strong>sort order</strong>
   در، 99-100</p>
<p>نوشتن به، 101</p>
<p>مقایسه الزامات برای پردازش تراکنش و تجزیه و تحلیل، 90-96</p>
<p>در حافظه، 88</p>
<p>
<strong>row-oriented</strong>
   , 70-90</p>
<p>
<strong>B-trees</strong>
   , 79-83</p>
<p>مقایسه 
   <strong>B-trees</strong>
   و 
   <strong>LSM-trees</strong>
   , 83-85</p>
<p>تعریف، 96</p>
<p>
<strong>log-structured</strong>
   , 72-79</p>
<p>
<strong>log-structured merge tree (see LSM-</strong>
</p>
<p>
<strong>trees)</strong>
</p>
<p>تکثیر، 152، 158-161</p>
<p>
<strong>change data capture</strong>
   , 454-457</p>
<p>(همچنین به 
   <strong>changelogs</strong>
   مراجعه کنید)</p>
<p>هماهنگی با 
   <strong>snapshot</strong>
   , 156</p>
<p>
<strong>serializable snapshot isolation (SSI)</strong>
   ,
   </p>
<p>261</p>
<p>
<strong>(see also snapshot isolation)</strong>
</p>
<p>
<strong>the shuffle</strong>
   , 402</p>
<p>
<strong>(see also  batch processing)</strong>
</p>
<p>محدودیت‌های، 493</p>
<p>
<strong>performance</strong>
   ، 258</p>
<p>
<strong>(see  online analytic processing)</strong>
</p>
<p>
<strong>state</strong>
</p>
<p>
<strong>(see  linearizability)</strong>
</p>
<p>
<strong>(see  read replicas)</strong>
</p>
<p>تولید، 340</p>
<p>و</p>
<p>متمرکز کردن 
   <strong>query execution</strong>
   , 216</p>
<p>
<strong>PTP (Precision Time Protocol)</strong>
   , 290</p>
<p>
<strong>predicate locks</strong>
   , 259</p>
<p>
<strong>(see also  power shifts)</strong>
</p>
<p>
<strong>(see  in serializable transactions)</strong>
</p>
<p>
<strong>(see  with causal consistency)</strong>
</p>
<p>
<strong>(see  for analytical queries)</strong>
</p>
<p>
<strong>(see  distributed transactions)</strong>
</p>
<p>تولید 
   <strong>snapshot isolation and repeatable read</strong>
   , 237-242</p>
<p>نوشتن و اجتناب از 
   <strong>write skew</strong>
   ، 238, 246</p>
<p>
<strong>(see  two-phase locking)</strong>
</p>
<p>
<strong>(see  online services)</strong>
</p>
<p>قوانین به ترتیب 
   <strong>event ordering</strong>
   , 339-343</p>
<p>تأمین 
   <strong>consistency</strong>
   , 344-347</p>
<p>
<strong>(see  horizontal scaling)</strong>
</p>
<p>
<strong>(see  and eventual consistency)</strong>
</p>
<p>
<strong>(see  or, from, the perspective of the, the data )</strong>
</p>
<p>
<strong>(see  and, on, what data model)</strong>
</p>
<p>
<strong>(see  and the, in, a, an, of, using)</strong>
</p>
<p>
<strong>(see  and  with, on, in a,  relying)</strong>
</p>
<p>
<strong>(see  by  for)</strong>
</p>
<p>
<strong>(see  also  with)</strong>
</p>
<p>
<strong>(see  also   in)</strong>
</p>
<p>
<strong>(see  or  for)</strong>
</p>
<p>
<strong>(see  and  of  in  a)</strong>
</p>
<p>
<strong>(see  for)</strong>
</p>
<p>
<strong>(see  or)</strong>
</p>
<p>
<strong>(see  with)</strong>
</p>
<p>
<strong>(see  by)</strong>
</p>
<p>
<strong>(see  with)</strong>
</p>
<p>
<strong>(see  to)</strong>
</p>
<p>
<strong>(see  to, for)</strong>
</p>
<p>
<strong>(see  with)</strong>
</p>
<p>
<strong>(see  with)</strong>
</p>
<p>
<strong>(see  and  a, the)</strong>
</p>
<p>
<strong>(see  also  for, in the, from, of the)</strong>
</p>
<p>
<strong>(see  also  in)</strong>
</p>
<p>
<strong>(see  and  with)</strong>
</p>
<p>
<strong>(see  with)</strong>
</p>
<p>
<strong>(see  in)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  in  a)</strong>
</p>
<p>
<strong>(see  in)</strong>
</p>
<p>
<strong>(see  of)</strong>
</p>
<p>
<strong>(see  on)</strong>
</p>
<p>
<strong>(see  in, from, with, for)</strong>
</p>
<p>
<strong>(see  with)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  in)</strong>
</p>
<p>
<strong>(see  with)</strong>
</p>
<p>
<strong>(see  in)</strong>
</p>
<p>
<strong>(see  also  with)</strong>
</p>
<p>
<strong>(see  with)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  for)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  for)</strong>
</p>
<p>
<strong>(see  also in)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  or)</strong>
</p>
<p>
<strong>(see  for)</strong>
</p>
<p>
<strong>(see  for, to, by)</strong>
</p>
<p>
<strong>(see  for, of the, in)</strong>
</p>
<p>
<strong>(see  also  of, to)</strong>
</p>
<p>
<strong>(see  and  in the)</strong>
</p>
<p>
<strong>(see  for)</strong>
</p>
<p>
<strong>(see  with)</strong>
</p>
<p>
<strong>(see  for)</strong>
</p>
<p>
<strong>(see  also  to)</strong>
</p>
<p>
<strong>(see  with)</strong>
</p>
<p>
<strong>(see  and  of)</strong>
</p>
<p>
<strong>(see  for  and)</strong>
</p>
<p>
<strong>(see  for  to)</strong>
</p>
<p>
<strong>(see  also  in)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  to  for  with)</strong>
</p>
<p>
<strong>(see  for)</strong>
</p>
<p>
<strong>(see  for)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  also  in)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  also  in)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and  in)</strong>
</p>
<p>
<strong>(see  with)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  also  to)</strong>
</p>
<p>
<strong>(see  also  of, to)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  and  of)</strong>
</p>
<p>
<strong>(see  with)</strong>
</p>
<p>
<strong>(see  for  and  in)</strong>
</p>
<p>
<strong>(see  also  for, to)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  for)</strong>
</p>
<p>
<strong>(see  also  to)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also  in)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also  in)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  for)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  also  in)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  also  of)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also  in)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  for, of the)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also  of)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also  of)</strong>
</p>
<p>
<strong>(see  also  in)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  also  in)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also  of)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also  of)</strong>
</p>
<p>
<strong>(see  also  of)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  also  in)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also  in)</strong>
</p>
<p>
<strong>(see  also  of)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  also  to)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  also  in)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  also  in)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  also  of)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  also  in)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  also  in)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  also  of)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also  in)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  also  in)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  also  of)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also  of)</strong>
</p>
<p>
<strong>(see  also  in)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also  in)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  also  of)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also  in)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  also  in)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also  of)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also  in)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also  of)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also  in)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also  of)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also  in)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also  of)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also  of)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  also  of)</strong>
</p>
<p>
</p></div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0608</div>
            </div>
        </div>
        <!-- Page 0609 -->
        <div class="chapter" id="page-0609">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>تشخیص درگیری، 172</p>
<p>مدل‌های سیستم، 300، 306-310</p>
<p>فرضیات در، 528</p>
<p>صحت الگوریتم‌ها، 308</p>
<p>نگاشت به دنیای واقعی، 309</p>
<p>ایمنی و زنده‌بودن، 308</p>
<p>
<strong>systems of record</strong>
   , 386, 557</p>
<p>
<strong>change data capture</strong>
   , 454, 491</p>
<p>به عنوان 
   <strong>event log</strong>
   , 460</p>
<p>
<strong>systems thinking</strong>
   , 536</p>
<p>
<strong>T</strong>
</p>
<p>
<strong>t-digest (algorithm)</strong>
   , 16</p>
<p>اتصالات جدول-جدول، 474</p>
<p>
<strong>Tableau (data visualization software)</strong>
   , 416</p>
<p>
<strong>tail (Unix tool)</strong>
   , 447</p>
<p>
<strong>tail vertex (property graphs)</strong>
   , 51</p>
<p>
<strong>Tajo (query engine)</strong>
   , 93</p>
<p>
<strong>Tandem NonStop SQL (database)</strong>
</p>
<p>تراکنش‌های 
   <strong>serializable</strong>
   ، 261، 265، 364</p>
<p>
<strong>TCP (Transmission Control Protocol)</strong>
   , 277</p>
<p>مقایسه با سوئیچینگ مدار، 285</p>
<p>مقایسه با 
   <strong>UDP</strong>
   ، 283</p>
<p>خطاهای اتصال، 280</p>
<p>کنترل جریان، 282، 441</p>
<p>پاکت‌های شبکه، 306، 519، 529</p>
<p>قابلیت اطمینان و سرکوب مضاعف، 517</p>
<p>از سرگیری 
   <strong>timeouts</strong>
   , 284</p>
<p>
<strong>telemetry (see monitoring)</strong>
</p>
<p>
<strong>Teradata (database)</strong>
   , 93, 200</p>
<p>
<strong>term-partitioned indexes</strong>
   , 208, 217</p>
<p>پایان (
   <strong>consensus</strong>
   )، 365</p>
<p>
<strong>Terrapin (database)</strong>
   , 413</p>
<p>
<strong>Tez (dataflow engine)</strong>
   , 421-423</p>
<p>تحمل خطا، 422</p>
<p>پشتیبانی توسط ابزارهای سطح بالاتر، 427</p>
<p>
<strong>Thrift (data format)</strong>
   , 117-121</p>
<p>
<strong>BinaryProtocol</strong>
   , 118</p>
<p>
<strong>CompactProtocol</strong>
   , 119</p>
<p>
<strong>field tags and schema evolution</strong>
   , 120</p>
<p>
<strong>throughput</strong>
   , 13, 390</p>
<p>
<strong>TIBCO</strong>
</p>
<p>
<strong>Enterprise Message Service</strong>
   , 444</p>
<p>
<strong>StreamBase (stream analytics)</strong>
   , 466</p>
<p>زمان</p>
<p>همزمانی و، 187</p>
<p>وابستگی‌های زمانی 
   <strong>cross-channel</strong>
   , 331</p>
<p>در سیستم‌های توزیع‌شده، 287-299</p>
<p>(همچنین به ساعت‌ها مراجعه کنید)</p>
<p>همگام‌سازی ساعت و دقت، 289</p>
<p>دریافت 
   <strong>data</strong>
   , 471</p>
<p>نوع پنجره، 472</p>
<p>مدل‌های سیستم برای سیستم‌های توزیع‌شده، 307</p>
<p>
<strong>time-dependence in stream joins</strong>
   , 475</p>
<p>ساعت‌های زمان روز، 288</p>
<p>به موقع بودن، 524</p>
<p>پارتیشن‌بندی کلید-محدوده، 203</p>
<p>
<strong>Titan (database)</strong>
   , 50</p>
<p>
<strong>tombstones</strong>
   , 74, 191, 456</p>
<p>موضوعات (پیام‌رسانی)، 137، 440</p>
<p>ترتیب کل، 341، 557</p>
<p>حدود، 493</p>
<p>شماره‌های ترتیبی یا مهر زمانی، 344</p>
<p>
<strong>total order broadcast</strong>
   , 348-352, 493, 522</p>
<p>الگوریتم‌های 
   <strong>consensus</strong>
   و، 366-368</p>
<p>
<strong>Index</strong>
   | 587
  </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0609</div>
            </div>
        </div>
        <!-- Page 0610 -->
        <div class="chapter" id="page-0610">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
<strong>implementation in ZooKeeper and etcd</strong>
   , 370</p>
<p>پیاده‌سازی با ذخیره‌سازی 
   <strong>linearizable</strong>
   , 351</p>
<p>استفاده، 349</p>
<p>
<strong>tracking behavioral data</strong>
   , 536</p>
<p>(همچنین به حریم خصوصی مراجعه کنید)</p>
<p>مدیر تراکنش (به هماهنگ‌کننده مراجعه کنید)</p>
<p>پردازش تراکنش، 28، 90-95</p>
<p>مقایسه با 
   <strong>analytics</strong>
   ، 91</p>
<p>مقایسه با 
   <strong>data warehousing</strong>
   , 93</p>
<p>
<strong>transactions</strong>
   , 221-267, 558</p>
<p>ویژگی‌های 
   <strong>ACID</strong>
   از، 223</p>
<p>اتمی بودن، 223</p>
<p>سازگاری، 224</p>
<p>ماندگاری، 226</p>
<p>
<strong>isolation</strong>
   , 225</p>
<p>تراکنش‌های جبرانی (به تراکنش‌های جبرانی مراجعه کنید)</p>
<p>مفهوم، 222</p>
<p>تراکنش‌های توزیع‌شده، 352-364</p>
<p>اجتناب از، 492، 502، 521-528</p>
<p>افزایش خطا، 364، 495</p>
<p>در وضعیت نامعلوم/نامشخص، 358، 362</p>
<p>تعهد دو فازی، 354-359</p>
<p>استفاده از، 360-361</p>
<p>تراکنش‌های 
   <strong>XA</strong>
   , 361-364</p>
<p>
<strong>OLTP</strong>
   در مقابل پرس و جوهای تجزیه و تحلیل، 411</p>
<p>هدف از، 222</p>
<p>
<strong>serializability</strong>
   , 251-266</p>
<p>اجرای سریال واقعی، 252-256</p>
<p>کنترل همزمانی بدبینانه در مقابل خوش‌بینانه، 261</p>
<p>
<strong>serializable snapshot isolation (SSI)</strong>
   ,
   </p>
<p>261-266</p>
<p>تشخیص خواندن 
   <strong>MVCC</strong>
   منسوخ‌شده، 263</p>
<p>تشخیص نوشته‌هایی که بر خوانده‌های قبلی اثر می‌گذارند،</p>
<p>264</p>
<p>
<strong>two-phase locking (2PL)</strong>
   , 257-261</p>
<p>
<strong>index-range locks</strong>
   , 260</p>
<p>عملکرد، 258</p>
<p>
<strong>transaction isolation</strong>
   ، 225</p>
<p>تراکنش‌های 
   <strong>two-phase commit (2PC)</strong>
</p>
<p>تشخیص بن‌بست، 364</p>
<p>تراکنش‌های نامعلوم که 
   <strong>locks</strong>
   را نگه می‌دارند، 362</p>
<p>
<strong>materializing</strong>
   درگیری‌ها با، 251</p>
<p>جلوگیری از به‌روزرسانی‌های از دست رفته توسط قفل‌گذاری صریح،</p>
<p>244</p>
<p>شماره توالی 
   <strong>log</strong>
   , 156, 449</p>
<p>زبان‌های برنامه‌نویسی منطقی، 504</p>
<p>
<strong>ترتیب و همزمانی، 343</strong>
   348</p>
<p>
<strong>transaction manager (see coordinator)</strong>
</p>
<p>
<strong>(see  asynchronous replication)</strong>
</p>
<p>
<strong>Tungsten Replicator (multi-leader replica-</strong>
</p>
<p>
<strong>tion)</strong>
   , 170</p>
<p>تشخیص درگیری، 177</p>
<p>
<strong>(see  and the,  in, a, a, an,  of, using)</strong>
</p>
<p>
<strong>(see  in a)</strong>
</p>
<p>
<strong>(see  for, or)</strong>
</p>
<p>
<strong>(see  for, also)</strong>
</p>
<p>
<strong>(see  also  in)</strong>
</p>
<p>
<strong>(see  also  of, and)</strong>
</p>
<p>
<strong>(see  for)</strong>
</p>
<p>
<strong>(see  for, to)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  also  in)</strong>
</p>
<p>
<strong>(see  for)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also  in)</strong>
</p>
<p>
<strong>(see  also  in)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also  in)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also  of)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  also  of)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also  in)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  also  in)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  also  of)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also  of)</strong>
</p>
<p>
<strong>(see  also  in)</strong>
</p>
<p>
<strong>(see  also  of)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  also  in)</strong>
</p>
<p>
<strong>(see  also  of)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  also  of)</strong>
</p>
<p>
<strong>(see  also  in)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  also  of)</strong>
</p>
<p>
<strong>(see  also  in)</strong>
</p>
<p>
<strong>(see  also  of)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  also  in)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  also  of)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also  in)</strong>
</p>
<p>
<strong>(see  also  in)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also  in)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also  in)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  also  of)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  also  of)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also  in)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also  in)</strong>
</p>
<p>
<strong>(see  also  in)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also  of)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also  of)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  also  of)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also  in)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  also  of)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  also  of)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also  in)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also  of)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also  in)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  also  of)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also  in)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also  of)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also  of)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  also  in)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also  in)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  also  in)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also  of)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  also  in)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  also  in)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also  in)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also  in)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also  in)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also  in)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also  in)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also  in)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also  in)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also  in)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also  in)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also  in)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also  of)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also  in)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also  in)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>(see  also  in)</strong>
</p>
<p>
<strong>(see  and)</strong>
</p>
<p>
<strong>
</strong></p></div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0610</div>
            </div>
        </div>
        <!-- Page 0611 -->
        <div class="chapter" id="page-0611">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
<strong>uncertain (transaction status) (see in doubt)</strong>
</p>
<p>
<strong>uniform consensus</strong>
   , 365</p>
<p>(همچنین به 
   <strong>consensus</strong>
   مراجعه کنید)</p>
<p>
<strong>uniform interfaces</strong>
   , 395</p>
<p>نوع اتحادیه (در 
   <strong>Avro</strong>
   )، 125</p>
<p>
<strong>uniq (Unix tool)</strong>
   , 392</p>
<p>محدودیت‌های منحصر به فرد</p>
<p>به صورت ناهمزمان بررسی شده، 526</p>
<p>نیازمند اجماع، 521</p>
<p>نیازمند 
   <strong>linearizability</strong>
   , 330</p>
<p>منحصر به فرد بودن در پیام‌رسانی مبتنی بر 
   <strong>log</strong>
   ، 522</p>
<p>فلسفه یونیکس، 394-397</p>
<p>پردازش 
   <strong>batch</strong>
   خط فرمان، 391-394</p>
<p>مقایسه با 
   <strong>Hadoop</strong>
   ، 413-414</p>
<p>مقایسه با 
   <strong>databases</strong>
   رابطه‌ای، 499، 501</p>
<p>مقایسه با پردازش جریان، 464</p>
<p>
<strong>(see also  in,  with,  for)</strong>
</p>
<p>درون‌دادها به دستورات یونیکس، 397</p>
<p>
<strong>(see  also  for)</strong>
</p>
<p>درون‌دادها به عملیات تراکنش‌ها</p>
<p>
<strong>(see  also  with)</strong>
</p>
<p>
<strong>(see  also)</strong>
</p>
<p>دستور 
   <strong>UPDATE (SQL)</strong>
   , 40</p>
<p>به‌روزرسانی‌ها</p>
<p>جلوگیری از از دست رفتن به‌روزرسانی‌ها، 242-246</p>
<p>عملیات‌های نوشتاری اتمی، 243</p>
<p>به‌طور خودکار تشخیص به‌روزرسانی‌های از دست رفته، 245</p>
<p>عملگر مقایسه و تنظیم، 245</p>
<p>حل تعارض و تکثیر، 246</p>
<p>جلوگیری از 
   <strong>write skew</strong>
   ، 246-251</p>
<p>
<strong>V</strong>
</p>
<p>درستی، 365</p>
<p>
<strong>vBuckets (partitioning)</strong>
   , 199</p>
<p>ساعت‌های برداری، 191</p>
<p>(همچنین به بردار نسخه مراجعه کنید)</p>
<p>پردازش برداری، 99، 428</p>
<p>تاییدیه، 528-533</p>
<p>اجتناب از اعتماد کورکورانه، 530</p>
<p>فرهنگ، 530</p>
<p>طراحی برای قابلیت 
   <strong>auditability</strong>
   ، 531</p>
<p>بررسی‌های یکپارچگی 
   <strong>end-to-end</strong>
   ، 531</p>
<p>ابزارهایی برای سیستم‌های 
   <strong>data</strong>
   قابل 
   <strong>audit</strong>
   , 532</p>
<p>
<strong>version control systems</strong>
   , تکیه بر 
   <strong>data</strong>
   تغییرناپذیر، 463</p>
<p>
<strong>version vectors</strong>
   , 177, 191</p>
<p>ثبت وابستگی‌های علّی، 343</p>
<p>
<strong>versus vector clocks</strong>
   , 191</p>
<p>
<strong>Vertica (database)</strong>
</p>
<p>مدیریت نوشته‌ها، 101</p>
<p>
<strong>replicas</strong>
   با استفاده از ترتیب مرتب‌سازی متفاوت، 100</p>
<p>مقیاس‌بندی عمودی (به مقیاس‌بندی مراجعه کنید)</p>
<p>رأس‌ها (در 
   <strong>graphs</strong>
   )، 49</p>
<p>مدل 
   <strong>property graph</strong>
   , 50</p>
<p>
<strong>Viewstamped Replication (consensus algo-</strong>
</p>
<p>
<strong>rithm)</strong>
   , 366</p>
<p>شماره 
   <strong>view</strong>
   , 368</p>
<p>
<strong>virtual machines</strong>
   , 146</p>
<p>(همچنین به محاسبات ابری مراجعه کنید)</p>
<p>تغییرات متن (به‌روزرسانی‌ها)</p>
<p>تغییرات از دست رفته، 242-246</p>
<p>جلوگیری از 
   <strong>write skew</strong>
   , 246-251</p>
<p>
<strong>VisiCalc (spreadsheets)</strong>
   , 504</p>
<p>
<strong>vnodes (partitioning)</strong>
   , 199</p>
<p>
<strong>Voice over IP (VoIP)</strong>
   , 283</p>
<p>
<strong>Voldemort (database)</strong>
</p>
<p>ساختن فروشگاه‌های فقط خواندنی در فرآیندهای</p>
<p>
<strong>batch</strong>
   , 413</p>
<p>تقسیم‌بندی 
   <strong>hash</strong>
   ، 203-204، 211</p>
<p>تکثیر بدون رهبر، 177</p>
<p>
<strong>LevelDB storage engine</strong>
   , 78</p>
<p>
<strong>linearizability</strong>
   ، کمبود، 335</p>
<p>پشتیبانی از چند 
   <strong>datacenter</strong>
   ، 184</p>
<p>اجتناب از، 205</p>
<p>خطاهای 
   <strong>in-memory</strong>
   ، 227</p>
<p>در 
   <strong>databases</strong>
</p>
<p>
<strong>W</strong>
</p>
<p>
<strong>WAL (write-ahead log)</strong>
   , 82</p>
<p>
<strong>web services (see services)</strong>
</p>
<p>
<strong>Web Services Description Language (WSDL)</strong>
   ,
   </p>
<p>133</p>
<p>
<strong>webhooks</strong>
   , 443</p>
<p>
<strong>webMethods (messaging)</strong>
   , 137</p>
<p>
<strong>WebSocket (protocol)</strong>
   , 512</p>
<p>
<strong>Index</strong>
   | 589
  </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0611</div>
            </div>
        </div>
        <!-- Page 0612 -->
        <div class="chapter" id="page-0612">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>
<strong>windows (stream processing)</strong>
   , 466, 468-472</p>
<p>
<strong>infinite windows</strong>
   برای 
   <strong>changelogs</strong>
   , 467, 474</p>
<p>دانستن زمان رسیدن تمام رویدادها، 470</p>
<p>اتصالات جریانی در یک پنجره، 473</p>
<p>انواع پنجره‌ها، 472</p>
<p>برندگان (حل تعارض)، 173</p>
<p>
<strong>WITH RECURSIVE syntax (SQL)</strong>
   , 54</p>
<p>
<strong>workflows (MapReduce)</strong>
   , 402</p>
<p>خروجی‌ها، 411-414</p>
<p>فروشگاه‌های کلید-مقدار، 412</p>
<p>شاخص‌های جستجو، 411</p>
<p>با اتصالات 
   <strong>map-side</strong>
   ، 410</p>
<p>
<strong>working set</strong>
   , 393</p>
<p>
<strong>write amplification</strong>
   , 84</p>
<p>مسیر نوشتن (
   <strong>derived data</strong>
   )، 509</p>
<p>
<strong>write skew (transaction isolation)</strong>
   , 246-251</p>
<p>مشخص کردن، 246-251، 262</p>
<p>نمونه‌هایی از، 247، 249</p>
<p>
<strong>materializing conflicts</strong>
   , 251</p>
<p>وقوع در عمل، 529</p>
<p>
<strong>phantoms</strong>
   , 250</p>
<p>جلوگیری</p>
<p>در 
   <strong>snapshot isolation</strong>
   ، 262-265</p>
<p>در 
   <strong>two-phase locking</strong>
   , 259-261</p>
<p>گزینه‌ها برای، 248</p>
<p>
<strong>write-ahead log (WAL)</strong>
   , 82, 159</p>
<p>نوشتن (
   <strong>database</strong>
   )</p>
<p>عملیات‌های نوشتاری اتمی، 243</p>
<p>جلوگیری از نوشته‌های کثیف با 
   <strong>read commit-</strong>
</p>
<p>
<strong>ted</strong>
   ، 235</p>
<p>
<strong>WS-* framework</strong>
   , 133</p>
<p>(همچنین به 
   <strong>services</strong>
   مراجعه کنید)</p>
<p>
<strong>WS-AtomicTransaction (2PC)</strong>
   , 355</p>
<p>
<strong>X</strong>
</p>
<p>تراکنش‌های 
   <strong>XA</strong>
   , 355, 361-364</p>
<p>تصمیمات اکتشافی، 363</p>
<p>محدودیت‌ها، 363</p>
<p>
<strong>xargs (Unix tool)</strong>
   , 392, 396</p>
<p>
<strong>XML</strong>
</p>
<p>انواع باینری، 115</p>
<p>کدگذاری 
   <strong>RDF data</strong>
   , 57</p>
<p>برای 
   <strong>application data</strong>
   ، مسائل با، 114</p>
<p>در 
   <strong>databases</strong>
   رابطه‌ای، 30، 41</p>
<p>
<strong>XSL/XPath</strong>
   , 45</p>
<p>
<strong>Y</strong>
</p>
<p>
<strong>Yahoo!</strong>
</p>
<p>
<strong>Pistachio (database)</strong>
   , 461</p>
<p>
<strong>Sherpa (database)</strong>
   , 455</p>
<p>
<strong>YARN (job scheduler)</strong>
   , 416, 506</p>
<p>پیش‌دستی از کارها، 418</p>
<p>استفاده از 
   <strong>ZooKeeper</strong>
   , 370</p>
<p>
<strong>Z</strong>
</p>
<p>
<strong>Zab (consensus algorithm)</strong>
   , 366</p>
<p>استفاده در 
   <strong>ZooKeeper</strong>
   ، 353</p>
<p>
<strong>ZeroMQ (messaging library)</strong>
   , 442</p>
<p>
<strong>Index</strong>
   | 589
  </p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0612</div>
            </div>
        </div>
        <!-- Page 0613 -->
        <div class="chapter" id="page-0613">
            <div class="chapter-content">
                <div class="translated-content">
<div>
<p>درباره نویسنده</p>
<p>
<strong>Martin Kleppmann</strong>
   محقق سیستم‌های توزیع‌شده در 
   <strong>University of Cam-</strong>
</p>
<p>
<strong>bridge</strong>
   , 
   <strong>UK</strong>
   است. قبلاً او یک مهندس 
   <strong>software</strong>
   و کارآفرین در شرکت‌های اینترنتی از جمله 
   <strong>LinkedIn</strong>
   و 
   <strong>Rapportive</strong>
   بود، جایی که روی زیرساخت‌های 
   <strong>data</strong>
   در مقیاس بزرگ کار می‌کرد. در این فرآیند او چند چیز را به سختی یاد گرفت، و امیدوار است این کتاب شما را از تکرار اشتباهات مشابه نجات دهد.</p>
<p>
<strong>Martin</strong>
   یک سخنران کنفرانس، وبلاگ‌نویس و مشارکت‌کننده منبع باز است. او معتقد است که ایده‌های فنی عمیق باید برای همه در دسترس باشد، و درک عمیق‌تر به ما کمک می‌کند 
   <strong>software</strong>
   بهتری توسعه دهیم.</p>
<p>
<strong>Colophon</strong>
</p>
<p>حیوان روی جلد 
   <strong>Designing Data-Intensive Applications</strong>
   ، یک گراز وحشی هندی (
   <strong>Sus scrofa cristatus</strong>
   ) است، یک زیرگونه از گراز وحشی که در هند، میانمار، نپال،</p>
<p>سریلانکا و تایلند یافت می‌شود. آنها از گرازهای اروپایی متمایز هستند زیرا دارای موهای پشت بالاتری هستند، بدون زیرپوش پشمی و یک جمجمه بزرگتر و صاف‌تر دارند.</p>
<p>گراز وحشی هندی دارای پوششی از موهای خاکستری یا سیاه است که دارای موهای سفت است که در امتداد ستون فقرات قرار دارد. نرها دارای دندان‌های نیش برجسته (به نام 
   <strong>tusches</strong>
   ) هستند که برای مبارزه با رقبا یا دفع شکارچیان استفاده می‌شوند. نرها بزرگتر از ماده‌ها هستند، اما این گونه به‌طور متوسط 33 تا 35 اینچ قد در شانه و 200 تا 300 پوند وزن دارد. شکارچیان طبیعی آنها شامل خرس‌ها، ببرها و گربه‌سانان بزرگ مختلف است.</p>
<p>این حیوانات شب‌زی و همه‌چیزخوار هستند - آنها انواع مختلفی از چیزها را می‌خورند، از جمله ریشه‌ها، حشرات، لاشه‌ها، آجیل‌ها، توت‌ها و حیوانات کوچک. گرازهای وحشی نیز به کندوکاو در زباله‌ها و مزارع محصول معروف هستند، که باعث تخریب زیادی می‌شود و دشمنی کشاورزان را به دست می‌آورد. آنها باید روزانه 4000-4500 کالری غذا بخورند. گرازها حس بویایی بسیار خوبی دارند که به آنها در جستجوی مواد گیاهی زیرزمینی و حیوانات حفار کمک می‌کند. با این حال، بینایی آنها ضعیف است.</p>
<p>گرازهای وحشی جایگاه طولانی در فرهنگ انسانی دارند. در افسانه‌های هندو، گراز یک آواتار از خدای ویشنو است. در بناهای یادبود تدفینی یونان باستان، نماد یک بازنده گالانت (در مقابل شیر پیروز) بود. به دلیل پرخاشگری آن، روی زره و سلاح جنگجویان اسکاندیناوی، آلمانی و آنگلوساکسون به تصویر کشیده شد. در زودیاک چینی، نماد عزم و شتاب‌زدگی است.</p>
<p>بسیاری از حیوانات روی جلد 
   <strong>O'Reilly</strong>
   در معرض خطر هستند. همه آنها برای جهان مهم هستند. برای کسب اطلاعات بیشتر در مورد اینکه چگونه می‌توانید کمک کنید، به 
   <strong>animals.oreilly.com</strong>
   بروید.</p>
<p>تصویر روی جلد از 
   <strong>Shaw’s Zoology</strong>
   گرفته شده است. فونت‌های روی جلد 
   <strong>URW Typewriter</strong>
   و 
   <strong>Guardian Sans</strong>
   هستند. فونت متن 
   <strong>Adobe Minion Pro</strong>
   است. فونت در نمودارها 
   <strong>Adobe Myriad Pro</strong>
   است. فونت عنوان 
   <strong>Adobe Myriad Condensed</strong>
   است. و فونت کد 
   <strong>Dalton Maag’s Ubuntu Mono</strong>
   است.</p>
</div>
</div>
                <div class="page-images">
</div>
                <div class="page-number">صفحه 0613</div>
            </div>
        </div>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/line-numbers/prism-line-numbers.min.js"></script>
    <script>
        document.addEventListener('DOMContentLoaded', (event) => {
            if (window.Prism) {
                Prism.highlightAll();
            }
        });
    </script>
</body>
</html>