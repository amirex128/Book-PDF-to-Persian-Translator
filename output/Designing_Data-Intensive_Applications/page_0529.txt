Dataflow: Interplay between state changes and application code
Thinking about applications in terms of dataflow implies renegotiating the relation‐
ship between application code and state management. Instead of treating a database
as a passive variable that is manipulated by the application, we think much more
about the interplay and collaboration between state, state changes, and code that pro‐
cesses them. Application code responds to state changes in one place by triggering
state changes in another place.
We saw this line of thinking in “Databases and Streams” on page 451, where we dis‐
cussed treating the log of changes to a database as a stream of events that we can sub‐
scribe to. Message-passing systems such as actors (see “Message-Passing Dataflow”
on page 136) also have this concept of responding to events. Already in the 1980s, the
tuple spaces model explored expressing distributed computations in terms of pro‐
cesses that observe state changes and react to them [38, 39].
As discussed, similar things happen inside a database when a trigger fires due to a
data change, or when a secondary index is updated to reflect a change in the table
being indexed. Unbundling the database means taking this idea and applying it to the
creation of derived datasets outside of the primary database: caches, full-text search
indexes, machine learning, or analytics systems. We can use stream processing and
messaging systems for this purpose.
The important thing to keep in mind is that maintaining derived data is not the same
as asynchronous job execution, for which messaging systems are traditionally
designed (see “Logs compared to traditional messaging” on page 448):
• When maintaining derived data, the order of state changes is often important (if
several views are derived from an event log, they need to process the events in the
same order so that they remain consistent with each other). As discussed in
“Acknowledgments and redelivery” on page 445, many message brokers do not
have this property when redelivering unacknowledged messages. Dual writes are
also ruled out (see “Keeping Systems in Sync” on page 452).
• Fault tolerance is key for derived data: losing just a single message causes the
derived dataset to go permanently out of sync with its data source. Both message
delivery and derived state updates must be reliable. For example, many actor sys‐
tems by default maintain actor state and messages in memory, so they are lost if
the machine running the actor crashes.
Stable message ordering and fault-tolerant message processing are quite stringent
demands, but they are much less expensive and more operationally robust than dis‐
tributed transactions. Modern stream processors can provide these ordering and reli‐
ability guarantees at scale, and they allow application code to be run as stream
operators.
Unbundling Databases 
| 
507
