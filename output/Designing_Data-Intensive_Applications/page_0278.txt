x. If a transaction needs to access data that’s not in memory, the best solution may be to abort the transac‐
tion, asynchronously fetch the data into memory while continuing to process other transactions, and then
restart the transaction when the data has been loaded. This approach is known as anti-caching, as previously
mentioned in “Keeping everything in memory” on page 88.
In order to scale to multiple CPU cores, and multiple nodes, you can potentially par‐
tition your data (see Chapter 6), which is supported in VoltDB. If you can find a way
of partitioning your dataset so that each transaction only needs to read and write data
within a single partition, then each partition can have its own transaction processing
thread running independently from the others. In this case, you can give each CPU
core its own partition, which allows your transaction throughput to scale linearly
with the number of CPU cores [47].
However, for any transaction that needs to access multiple partitions, the database
must coordinate the transaction across all the partitions that it touches. The stored
procedure needs to be performed in lock-step across all partitions to ensure serializa‐
bility across the whole system.
Since cross-partition transactions have additional coordination overhead, they are
vastly slower than single-partition transactions. VoltDB reports a throughput of
about 1,000 cross-partition writes per second, which is orders of magnitude below its
single-partition throughput and cannot be increased by adding more machines [49].
Whether transactions can be single-partition depends very much on the structure of
the data used by the application. Simple key-value data can often be partitioned very
easily, but data with multiple secondary indexes is likely to require a lot of cross-
partition coordination (see “Partitioning and Secondary Indexes” on page 206).
Summary of serial execution
Serial execution of transactions has become a viable way of achieving serializable iso‐
lation within certain constraints:
• Every transaction must be small and fast, because it takes only one slow transac‐
tion to stall all transaction processing.
• It is limited to use cases where the active dataset can fit in memory. Rarely
accessed data could potentially be moved to disk, but if it needed to be accessed
in a single-threaded transaction, the system would get very slow.x
• Write throughput must be low enough to be handled on a single CPU core, or
else transactions need to be partitioned without requiring cross-partition coordi‐
nation.
• Cross-partition transactions are possible, but there is a hard limit to the extent to
which they can be used. 
256 
| 
Chapter 7: Transactions
