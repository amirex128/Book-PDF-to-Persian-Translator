In Figure 7-11, transactions 42 and 43 both search for on-call doctors during shift
1234. If there is an index on shift_id, the database can use the index entry 1234 to
record the fact that transactions 42 and 43 read this data. (If there is no index, this
information can be tracked at the table level.) This information only needs to be kept
for a while: after a transaction has finished (committed or aborted), and all concur‐
rent transactions have finished, the database can forget what data it read.
When a transaction writes to the database, it must look in the indexes for any other
transactions that have recently read the affected data. This process is similar to
acquiring a write lock on the affected key range, but rather than blocking until the
readers have committed, the lock acts as a tripwire: it simply notifies the transactions
that the data they read may no longer be up to date.
In Figure 7-11, transaction 43 notifies transaction 42 that its prior read is outdated,
and vice versa. Transaction 42 is first to commit, and it is successful: although trans‐
action 43’s write affected 42, 43 hasn’t yet committed, so the write has not yet taken
effect. However, when transaction 43 wants to commit, the conflicting write from 42
has already been committed, so 43 must abort. 
Performance of serializable snapshot isolation
As always, many engineering details affect how well an algorithm works in practice.
For example, one trade-off is the granularity at which transactions’ reads and writes
are tracked. If the database keeps track of each transaction’s activity in great detail, it
can be precise about which transactions need to abort, but the bookkeeping overhead
can become significant. Less detailed tracking is faster, but may lead to more transac‐
tions being aborted than strictly necessary.
In some cases, it’s okay for a transaction to read information that was overwritten by
another transaction: depending on what else happened, it’s sometimes possible to
prove that the result of the execution is nevertheless serializable. PostgreSQL uses this
theory to reduce the number of unnecessary aborts [11, 41].
Compared to two-phase locking, the big advantage of serializable snapshot isolation
is that one transaction doesn’t need to block waiting for locks held by another trans‐
action. Like under snapshot isolation, writers don’t block readers, and vice versa. This
design principle makes query latency much more predictable and less variable. In
particular, read-only queries can run on a consistent snapshot without requiring any
locks, which is very appealing for read-heavy workloads.
Compared to serial execution, serializable snapshot isolation is not limited to the
throughput of a single CPU core: FoundationDB distributes the detection of seriali‐
zation conflicts across multiple machines, allowing it to scale to very high through‐
put. Even though data may be partitioned across multiple machines, transactions can
read and write data in multiple partitions while ensuring serializable isolation [54].
Serializability 
| 
265
