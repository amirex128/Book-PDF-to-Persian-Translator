Companies that collect lots of data about people oppose regulation as being a burden
and a hindrance to innovation. To some extent that opposition is justified. For exam‐
ple, when sharing medical data, there are clear risks to privacy, but there are also
potential opportunities: how many deaths could be prevented if data analysis was
able to help us achieve better diagnostics or find better treatments [110]? Over-
regulation may prevent such breakthroughs. It is difficult to balance such potential
opportunities with the risks [105].
Fundamentally, I think we need a culture shift in the tech industry with regard to
personal data. We should stop regarding users as metrics to be optimized, and
remember that they are humans who deserve respect, dignity, and agency. We should
self-regulate our data collection and processing practices in order to establish and
maintain the trust of the people who depend on our software [111]. And we should
take it upon ourselves to educate end users about how their data is used, rather than
keeping them in the dark.
We should allow each individual to maintain their privacy—i.e., their control over
own data—and not steal that control from them through surveillance. Our individual
right to control our data is like the natural environment of a national park: if we
don’t explicitly protect and care for it, it will be destroyed. It will be the tragedy of the
commons, and we will all be worse off for it. Ubiquitous surveillance is not inevitable
—we are still able to stop it.
How exactly we might achieve this is an open question. To begin with, we should not
retain data forever, but purge it as soon as it is no longer needed [111, 112]. Purging
data runs counter to the idea of immutability (see “Limitations of immutability” on
page 463), but that issue can be solved. A promising approach I see is to enforce
access control through cryptographic protocols, rather than merely by policy [113,
114]. Overall, culture and attitude changes will be necessary. 
Summary
In this chapter we discussed new approaches to designing data systems, and I
included my personal opinions and speculations about the future. We started with
the observation that there is no one single tool that can efficiently serve all possible
use cases, and so applications necessarily need to compose several different pieces of
software to accomplish their goals. We discussed how to solve this data integration
problem by using batch processing and event streams to let data changes flow
between different systems.
In this approach, certain systems are designated as systems of record, and other data
is derived from them through transformations. In this way we can maintain indexes,
materialized views, machine learning models, statistical summaries, and more. By
making these derivations and transformations asynchronous and loosely coupled, a
Summary 
| 
543
