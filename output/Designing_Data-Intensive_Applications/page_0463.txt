related records; in a streaming system, related events are usually grouped together
into a topic or stream.
In principle, a file or database is sufficient to connect producers and consumers: a
producer writes every event that it generates to the datastore, and each consumer
periodically polls the datastore to check for events that have appeared since it last ran.
This is essentially what a batch process does when it processes a day’s worth of data at
the end of every day.
However, when moving toward continual processing with low delays, polling
becomes expensive if the datastore is not designed for this kind of usage. The more
often you poll, the lower the percentage of requests that return new events, and thus
the higher the overheads become. Instead, it is better for consumers to be notified
when new events appear.
Databases have traditionally not supported this kind of notification mechanism very
well: relational databases commonly have triggers, which can react to a change (e.g., a
row being inserted into a table), but they are very limited in what they can do and
have been somewhat of an afterthought in database design [4, 5]. Instead, specialized
tools have been developed for the purpose of delivering event notifications.
Messaging Systems
A common approach for notifying consumers about new events is to use a messaging
system: a producer sends a message containing the event, which is then pushed to
consumers. We touched on these systems previously in “Message-Passing Dataflow”
on page 136, but we will now go into more detail.
A direct communication channel like a Unix pipe or TCP connection between pro‐
ducer and consumer would be a simple way of implementing a messaging system.
However, most messaging systems expand on this basic model. In particular, Unix
pipes and TCP connect exactly one sender with one recipient, whereas a messaging
system allows multiple producer nodes to send messages to the same topic and allows
multiple consumer nodes to receive messages in a topic.
Within this publish/subscribe model, different systems take a wide range of
approaches, and there is no one right answer for all purposes. To differentiate the
systems, it is particularly helpful to ask the following two questions:
1. What happens if the producers send messages faster than the consumers can pro‐
cess them? Broadly speaking, there are three options: the system can drop mes‐
sages, buffer messages in a queue, or apply backpressure (also known as flow
control; i.e., blocking the producer from sending more messages). For example,
Unix pipes and TCP use backpressure: they have a small fixed-size buffer, and if
Transmitting Event Streams 
| 
441
