son why those three things should be in the same partition, since they are all
independent from each other.
In the traditional approach to databases, executing this transaction would require an
atomic commit across all three partitions, which essentially forces it into a total order
with respect to all other transactions on any of those partitions. Since there is now
cross-partition coordination, different partitions can no longer be processed inde‐
pendently, so throughput is likely to suffer.
However, it turns out that equivalent correctness can be achieved with partitioned
logs, and without an atomic commit:
1. The request to transfer money from account A to account B is given a unique
request ID by the client, and appended to a log partition based on the request ID.
2. A stream processor reads the log of requests. For each request message it emits
two messages to output streams: a debit instruction to the payer account A (par‐
titioned by A), and a credit instruction to the payee account B (partitioned by B).
The original request ID is included in those emitted messages.
3. Further processors consume the streams of credit and debit instructions, dedu‐
plicate by request ID, and apply the changes to the account balances.
Steps 1 and 2 are necessary because if the client directly sent the credit and debit
instructions, it would require an atomic commit across those two partitions to ensure
that either both or neither happen. To avoid the need for a distributed transaction,
we first durably log the request as a single message, and then derive the credit and
debit instructions from that first message. Single-object writes are atomic in almost
all data systems (see “Single-object writes” on page 230), and so the request either
appears in the log or it doesn’t, without any need for a multi-partition atomic com‐
mit.
If the stream processor in step 2 crashes, it resumes processing from its last check‐
point. In doing so, it does not skip any request messages, but it may process requests
multiple times and produce duplicate credit and debit instructions. However, since it
is deterministic, it will just produce the same instructions again, and the processors in
step 3 can easily deduplicate them using the end-to-end request ID.
If you want to ensure that the payer account is not overdrawn by this transfer, you
can additionally have a stream processor (partitioned by payer account number) that
maintains account balances and validates transactions. Only valid transactions would
then be placed in the request log in step 1.
By breaking down the multi-partition transaction into two differently partitioned
stages and using the end-to-end request ID, we have achieved the same correctness
property (every request is applied exactly once to both the payer and payee accounts),
even in the presence of faults, and without using an atomic commit protocol. The
Aiming for Correctness 
| 
523
