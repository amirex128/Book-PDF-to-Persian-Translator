ii. Thank you to Kostas Kloudas from the Flink community for coming up with this analogy.
deterministic: running the same process again on the same input yields the same
result (see “Fault tolerance” on page 422).
On the other hand, many stream processing frameworks use the local system clock
on the processing machine (the processing time) to determine windowing [79]. This
approach has the advantage of being simple, and it is reasonable if the delay between
event creation and event processing is negligibly short. However, it breaks down if
there is any significant processing lag—i.e., if the processing may happen noticeably
later than the time at which the event actually occurred.
Event time versus processing time
There are many reasons why processing may be delayed: queueing, network faults
(see “Unreliable Networks” on page 277), a performance issue leading to contention
in the message broker or processor, a restart of the stream consumer, or reprocessing
of past events (see “Replaying old messages” on page 451) while recovering from a
fault or after fixing a bug in the code.
Moreover, message delays can also lead to unpredictable ordering of messages. For
example, say a user first makes one web request (which is handled by web server A),
and then a second request (which is handled by server B). A and B emit events
describing the requests they handled, but B’s event reaches the message broker before
A’s event does. Now stream processors will first see the B event and then the A event,
even though they actually occurred in the opposite order.
If it helps to have an analogy, consider the Star Wars movies: Episode IV was released
in 1977, Episode V in 1980, and Episode VI in 1983, followed by Episodes I, II, and
III in 1999, 2002, and 2005, respectively, and Episode VII in 2015 [80].ii If you
watched the movies in the order they came out, the order in which you processed the
movies is inconsistent with the order of their narrative. (The episode number is like
the event timestamp, and the date when you watched the movie is the processing
time.) As humans, we are able to cope with such discontinuities, but stream process‐
ing algorithms need to be specifically written to accommodate such timing and
ordering issues.
Confusing event time and processing time leads to bad data. For example, say you
have a stream processor that measures the rate of requests (counting the number of
requests per second). If you redeploy the stream processor, it may be shut down for a
minute and process the backlog of events when it comes back up. If you measure the
rate based on the processing time, it will look as if there was a sudden anomalous
spike of requests while processing the backlog, when in fact the real rate of requests
was steady (Figure 11-7).
Processing Streams 
| 
469
