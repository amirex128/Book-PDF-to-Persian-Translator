warehouse for offline analysis, or for building custom indexes and caches [18]. This
technique is called change data capture, and we will return to it in Chapter 11.
Trigger-based replication
The replication approaches described so far are implemented by the database system,
without involving any application code. In many cases, that’s what you want—but
there are some circumstances where more flexibility is needed. For example, if you
want to only replicate a subset of the data, or want to replicate from one kind of
database to another, or if you need conflict resolution logic (see “Handling Write
Conflicts” on page 171), then you may need to move replication up to the application
layer.
Some tools, such as Oracle GoldenGate [19], can make data changes available to an
application by reading the database log. An alternative is to use features that are
available in many relational databases: triggers and stored procedures.
A trigger lets you register custom application code that is automatically executed
when a data change (write transaction) occurs in a database system. The trigger has
the opportunity to log this change into a separate table, from which it can be read by
an external process. That external process can then apply any necessary application
logic and replicate the data change to another system. Databus for Oracle [20] and
Bucardo for Postgres [21] work like this, for example.
Trigger-based replication typically has greater overheads than other replication
methods, and is more prone to bugs and limitations than the database’s built-in repli‐
cation. However, it can nevertheless be useful due to its flexibility. 
Problems with Replication Lag
Being able to tolerate node failures is just one reason for wanting replication. As
mentioned in the introduction to Part II, other reasons are scalability (processing
more requests than a single machine can handle) and latency (placing replicas geo‐
graphically closer to users).
Leader-based replication requires all writes to go through a single node, but read-
only queries can go to any replica. For workloads that consist of mostly reads and
only a small percentage of writes (a common pattern on the web), there is an attrac‐
tive option: create many followers, and distribute the read requests across those fol‐
lowers. This removes load from the leader and allows read requests to be served by
nearby replicas.
In this read-scaling architecture, you can increase the capacity for serving read-only
requests simply by adding more followers. However, this approach only realistically
works with asynchronous replication—if you tried to synchronously replicate to all
followers, a single node failure or network outage would make the entire system
Problems with Replication Lag 
| 
161
