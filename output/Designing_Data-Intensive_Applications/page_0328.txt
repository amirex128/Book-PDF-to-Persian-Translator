Similarly, it would be appealing if a protocol could protect us from vulnerabilities,
security compromises, and malicious attacks. Unfortunately, this is not realistic
either: in most systems, if an attacker can compromise one node, they can probably
compromise all of them, because they are probably running the same software. Thus,
traditional mechanisms (authentication, access control, encryption, firewalls, and so
on) continue to be the main protection against attackers.
Weak forms of lying
Although we assume that nodes are generally honest, it can be worth adding mecha‐
nisms to software that guard against weak forms of “lying”—for example, invalid
messages due to hardware issues, software bugs, and misconfiguration. Such protec‐
tion mechanisms are not full-blown Byzantine fault tolerance, as they would not
withstand a determined adversary, but they are nevertheless simple and pragmatic
steps toward better reliability. For example:
• Network packets do sometimes get corrupted due to hardware issues or bugs in
operating systems, drivers, routers, etc. Usually, corrupted packets are caught by
the checksums built into TCP and UDP, but sometimes they evade detection [85,
86, 87]. Simple measures are usually sufficient protection against such corrup‐
tion, such as checksums in the application-level protocol.
• A publicly accessible application must carefully sanitize any inputs from users,
for example checking that a value is within a reasonable range and limiting the
size of strings to prevent denial of service through large memory allocations. An
internal service behind a firewall may be able to get away with less strict checks
on inputs, but some basic sanity-checking of values (e.g., in protocol parsing
[85]) is a good idea.
• NTP clients can be configured with multiple server addresses. When synchroniz‐
ing, the client contacts all of them, estimates their errors, and checks that a
majority of servers agree on some time range. As long as most of the servers are
okay, a misconfigured NTP server that is reporting an incorrect time is detected
as an outlier and is excluded from synchronization [37]. The use of multiple
servers makes NTP more robust than if it only uses a single server. 
System Model and Reality
Many algorithms have been designed to solve distributed systems problems—for
example, we will examine solutions for the consensus problem in Chapter 9. In order
to be useful, these algorithms need to tolerate the various faults of distributed systems
that we discussed in this chapter.
Algorithms need to be written in a way that does not depend too heavily on the
details of the hardware and software configuration on which they are run. This in
306 
| 
Chapter 8: The Trouble with Distributed Systems
