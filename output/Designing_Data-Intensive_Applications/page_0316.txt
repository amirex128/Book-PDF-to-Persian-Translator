doesn’t know any more precisely than that [58]. If we only know the time +/– 100 ms,
the microsecond digits in the timestamp are essentially meaningless.
The uncertainty bound can be calculated based on your time source. If you have a
GPS receiver or atomic (caesium) clock directly attached to your computer, the
expected error range is reported by the manufacturer. If you’re getting the time from
a server, the uncertainty is based on the expected quartz drift since your last sync
with the server, plus the NTP server’s uncertainty, plus the network round-trip time
to the server (to a first approximation, and assuming you trust the server).
Unfortunately, most systems don’t expose this uncertainty: for example, when you
call clock_gettime(), the return value doesn’t tell you the expected error of the
timestamp, so you don’t know if its confidence interval is five milliseconds or five
years.
An interesting exception is Google’s TrueTime API in Spanner [41], which explicitly
reports the confidence interval on the local clock. When you ask it for the current
time, you get back two values: [earliest, latest], which are the earliest possible
and the latest possible timestamp. Based on its uncertainty calculations, the clock
knows that the actual current time is somewhere within that interval. The width of
the interval depends, among other things, on how long it has been since the local
quartz clock was last synchronized with a more accurate clock source. 
Synchronized clocks for global snapshots
In “Snapshot Isolation and Repeatable Read” on page 237 we discussed snapshot iso‐
lation, which is a very useful feature in databases that need to support both small, fast
read-write transactions and large, long-running read-only transactions (e.g., for
backups or analytics). It allows read-only transactions to see the database in a consis‐
tent state at a particular point in time, without locking and interfering with read-
write transactions.
The most common implementation of snapshot isolation requires a monotonically
increasing transaction ID. If a write happened later than the snapshot (i.e., the write
has a greater transaction ID than the snapshot), that write is invisible to the snapshot
transaction. On a single-node database, a simple counter is sufficient for generating
transaction IDs.
However, when a database is distributed across many machines, potentially in multi‐
ple datacenters, a global, monotonically increasing transaction ID (across all parti‐
tions) is difficult to generate, because it requires coordination. The transaction ID
must reflect causality: if transaction B reads a value that was written by transaction A,
then B must have a higher transaction ID than A—otherwise, the snapshot would not
294 
| 
Chapter 8: The Trouble with Distributed Systems
