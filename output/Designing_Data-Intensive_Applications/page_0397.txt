3. Use an algorithm to automatically choose a new leader. This approach requires a
consensus algorithm, and it is advisable to use a proven algorithm that correctly
handles adverse network conditions [107].
Although a single-leader database can provide linearizability without executing a
consensus algorithm on every write, it still requires consensus to maintain its leader‐
ship and for leadership changes. Thus, in some sense, having a leader only “kicks the
can down the road”: consensus is still required, only in a different place, and less fre‐
quently. The good news is that fault-tolerant algorithms and systems for consensus
exist, and we briefly discussed them in this chapter.
Tools like ZooKeeper play an important role in providing an “outsourced” consen‐
sus, failure detection, and membership service that applications can use. It’s not easy
to use, but it is much better than trying to develop your own algorithms that can
withstand all the problems discussed in Chapter 8. If you find yourself wanting to do
one of those things that is reducible to consensus, and you want it to be fault-tolerant,
then it is advisable to use something like ZooKeeper.
Nevertheless, not every system necessarily requires consensus: for example, leaderless
and multi-leader replication systems typically do not use global consensus. The con‐
flicts that occur in these systems (see “Handling Write Conflicts” on page 171) are a
consequence of not having consensus across different leaders, but maybe that’s okay:
maybe we simply need to cope without linearizability and learn to work better with
data that has branching and merging version histories.
This chapter referenced a large body of research on the theory of distributed systems.
Although the theoretical papers and proofs are not always easy to understand, and
sometimes make unrealistic assumptions, they are incredibly valuable for informing
practical work in this field: they help us reason about what can and cannot be done,
and help us find the counterintuitive ways in which distributed systems are often
flawed. If you have the time, the references are well worth exploring. 
This brings us to the end of Part II of this book, in which we covered replication
(Chapter 5), partitioning (Chapter 6), transactions (Chapter 7), distributed system
failure models (Chapter 8), and finally consistency and consensus (Chapter 9). Now
that we have laid a firm foundation of theory, in Part III we will turn once again to
more practical systems, and discuss how to build powerful applications from hetero‐
geneous building blocks.
References
[1] Peter Bailis and Ali Ghodsi: “Eventual Consistency Today: Limitations, Exten‐
sions, and Beyond,” ACM Queue, volume 11, number 3, pages 55-63, March 2013.
doi:10.1145/2460276.2462076
Summary 
| 
375
