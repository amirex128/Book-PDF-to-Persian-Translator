thing about network delays, dead nodes, or other trade-offs. Thus, although CAP has
been historically influential, it has little practical value for designing systems [9, 40].
There are many more interesting impossibility results in distributed systems [41],
and CAP has now been superseded by more precise results [2, 42], so it is of mostly
historical interest today. 
Linearizability and network delays
Although linearizability is a useful guarantee, surprisingly few systems are actually
linearizable in practice. For example, even RAM on a modern multi-core CPU is not
linearizable [43]: if a thread running on one CPU core writes to a memory address,
and a thread on another CPU core reads the same address shortly afterward, it is not
guaranteed to read the value written by the first thread (unless a memory barrier or
fence [44] is used).
The reason for this behavior is that every CPU core has its own memory cache and
store buffer. Memory access first goes to the cache by default, and any changes are
asynchronously written out to main memory. Since accessing data in the cache is
much faster than going to main memory [45], this feature is essential for good per‐
formance on modern CPUs. However, there are now several copies of the data (one
in main memory, and perhaps several more in various caches), and these copies are
asynchronously updated, so linearizability is lost.
Why make this trade-off? It makes no sense to use the CAP theorem to justify the
multi-core memory consistency model: within one computer we usually assume reli‐
able communication, and we don’t expect one CPU core to be able to continue oper‐
ating normally if it is disconnected from the rest of the computer. The reason for
dropping linearizability is performance, not fault tolerance.
The same is true of many distributed databases that choose not to provide lineariza‐
ble guarantees: they do so primarily to increase performance, not so much for fault
tolerance [46]. Linearizability is slow—and this is true all the time, not only during a
network fault.
Can’t we maybe find a more efficient implementation of linearizable storage? It
seems the answer is no: Attiya and Welch [47] prove that if you want linearizability,
the response time of read and write requests is at least proportional to the uncertainty
of delays in the network. In a network with highly variable delays, like most com‐
puter networks (see “Timeouts and Unbounded Delays” on page 281), the response
time of linearizable reads and writes is inevitably going to be high. A faster algorithm
for linearizability does not exist, but weaker consistency models can be much faster,
so this trade-off is important for latency-sensitive systems. In Chapter 12 we will dis‐
cuss some approaches for avoiding linearizability without sacrificing correctness. 
338 
| 
Chapter 9: Consistency and Consensus
