In the end, our task as engineers is to build systems that do their job (i.e., meet the
guarantees that users are expecting), in spite of everything going wrong. In Chapter 9,
we will look at some examples of algorithms that can provide such guarantees in a
distributed system. But first, in this chapter, we must understand what challenges we
are up against.
This chapter is a thoroughly pessimistic and depressing overview of things that may
go wrong in a distributed system. We will look into problems with networks (“Unre‐
liable Networks” on page 277); clocks and timing issues (“Unreliable Clocks” on page
287); and we’ll discuss to what degree they are avoidable. The consequences of all
these issues are disorienting, so we’ll explore how to think about the state of a dis‐
tributed system and how to reason about things that have happened (“Knowledge,
Truth, and Lies” on page 300).
Faults and Partial Failures
When you are writing a program on a single computer, it normally behaves in a fairly
predictable way: either it works or it doesn’t. Buggy software may give the appearance
that the computer is sometimes “having a bad day” (a problem that is often fixed by a
reboot), but that is mostly just a consequence of badly written software.
There is no fundamental reason why software on a single computer should be flaky:
when the hardware is working correctly, the same operation always produces the
same result (it is deterministic). If there is a hardware problem (e.g., memory corrup‐
tion or a loose connector), the consequence is usually a total system failure (e.g., ker‐
nel panic, “blue screen of death,” failure to start up). An individual computer with
good software is usually either fully functional or entirely broken, but not something
in between.
This is a deliberate choice in the design of computers: if an internal fault occurs, we
prefer a computer to crash completely rather than returning a wrong result, because
wrong results are difficult and confusing to deal with. Thus, computers hide the fuzzy
physical reality on which they are implemented and present an idealized system
model that operates with mathematical perfection. A CPU instruction always does
the same thing; if you write some data to memory or disk, that data remains intact
and doesn’t get randomly corrupted. This design goal of always-correct computation
goes all the way back to the very first digital computer [3].
When you are writing software that runs on several computers, connected by a net‐
work, the situation is fundamentally different. In distributed systems, we are no
longer operating in an idealized system model—we have no choice but to confront
the messy reality of the physical world. And in the physical world, a remarkably wide
range of things can go wrong, as illustrated by this anecdote [4]:
274 
| 
Chapter 8: The Trouble with Distributed Systems
