Microbatching and checkpointing
One solution is to break the stream into small blocks, and treat each block like a min‐
iature batch process. This approach is called microbatching, and it is used in Spark
Streaming [91]. The batch size is typically around one second, which is the result of a
performance compromise: smaller batches incur greater scheduling and coordination
overhead, while larger batches mean a longer delay before results of the stream pro‐
cessor become visible.
Microbatching also implicitly provides a tumbling window equal to the batch size
(windowed by processing time, not event timestamps); any jobs that require larger
windows need to explicitly carry over state from one microbatch to the next.
A variant approach, used in Apache Flink, is to periodically generate rolling check‐
points of state and write them to durable storage [92, 93]. If a stream operator
crashes, it can restart from its most recent checkpoint and discard any output gener‐
ated between the last checkpoint and the crash. The checkpoints are triggered by bar‐
riers in the message stream, similar to the boundaries between microbatches, but
without forcing a particular window size.
Within the confines of the stream processing framework, the microbatching and
checkpointing approaches provide the same exactly-once semantics as batch process‐
ing. However, as soon as output leaves the stream processor (for example, by writing
to a database, sending messages to an external message broker, or sending emails),
the framework is no longer able to discard the output of a failed batch. In this case,
restarting a failed task causes the external side effect to happen twice, and micro‐
batching or checkpointing alone is not sufficient to prevent this problem.
Atomic commit revisited
In order to give the appearance of exactly-once processing in the presence of faults,
we need to ensure that all outputs and side effects of processing an event take effect if
and only if the processing is successful. Those effects include any messages sent to
downstream operators or external messaging systems (including email or push notifi‐
cations), any database writes, any changes to operator state, and any acknowledg‐
ment of input messages (including moving the consumer offset forward in a log-
based message broker).
Those things either all need to happen atomically, or none of them must happen, but
they should not go out of sync with each other. If this approach sounds familiar, it is
because we discussed it in “Exactly-once message processing” on page 360 in the con‐
text of distributed transactions and two-phase commit.
In Chapter 9 we discussed the problems in the traditional implementations of dis‐
tributed transactions, such as XA. However, in more restricted environments it is
possible to implement such an atomic commit facility efficiently. This approach is
Processing Streams 
| 
477
