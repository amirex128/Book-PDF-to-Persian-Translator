234 
Part Two  Quality Attributes	
13—Architectural Tactics and Patterns
The reduce function will take that list in sorted order, add up the 1s for each 
word to get a count, and output the result. 
The corresponding reduce function would look like this:
reduce(List <key, value>):
// key: a word
// value: an integer 
int result = 0;
sort input
for each input value:
for each input pair with same word
result ++ ;
Emit (word, result)
result = 0
Larger data sets lead to a much more interesting solution. Suppose we want 
to continuously analyze Twitter posts over the last hour to see what topics are 
currently “trending.” This is analogous to counting word occurrences in millions 
of documents. In that case, each document (tweet) can be assigned to its own in-
stance of the map function. (If you don’t have millions of processors handy, you 
can break the tweet collection into groups that match the number of processors 
in your processor farm, and process the collection in waves, one group after the 
other.) Or we can use a dictionary to give us a list of words, and each map func-
tion can be assigned its own word to look for across all tweets. 
There can also be multiple instances of reduce. These are usually arranged 
so that the reduction happens in stages, with each stage processing a smaller list 
(with a smaller number of reduce instances) than the previous stage. The final 
stage is handled by a single reduce function that produces the final output. 
Of course, the map-reduce pattern is not appropriate in all instances. Some 
considerations that would argue against adopting this pattern are these: 
■
■If you do not have large data sets, then the overhead of map-reduce is not 
justified.
■
■If you cannot divide your data set into similar sized subsets, the advantages 
of parallelism are lost.
■
■If you have operations that require multiple reduces, this will be complex to 
orchestrate.
Commercial implementations of map-reduce provide infrastructure that 
takes care of assignment of function instances to hardware, recovery and reas-
signment in case of hardware failure (a common occurrence in massively parallel 
computing environments), and utilities like sorting of the massive lists that are 
produced along the way. 
Table 13.10 summarizes the solution of the map-reduce pattern.
Map-reduce is a cornerstone of the software of some of the most familiar 
names on the web, including Google, Facebook, eBay, and Yahoo!
