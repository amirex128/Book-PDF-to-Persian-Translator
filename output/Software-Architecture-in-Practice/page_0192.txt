10.3  A Design Checklist for Testability
171
the system meets it requirements for throughput, latency, and response 
time). For unit tests, and usually for user acceptance tests, the test data is 
typically created by hand.
For example, you might need 50 products, 100 customers, and 500 
orders in your test database, so that you can test the functional steps 
involved in creating, amending, or deleting orders. This data has to be 
sufficiently varied to make testing worthwhile, it has to conform to all the 
referential integrity rules and other constraints of your data model, and you 
need to be able to calculate and specify the expected results of the tests.
I’ve seen—and been involved in—two ways of doing this: you either 
write a system to generate your test data, or you capture a representative 
data set from the production environment and anonymize it as necessary. 
(Anonymizing test data involves removing any sensitive information, such as 
personal data about people or organizations, financial details, and so on.)
Creating your own test data is the ideal, because you know what data 
you are using and can ensure that it covers all of your edge cases, but it is 
a lot of effort. Capturing data from the live environment is easier, assum-
ing that there is a system there already, but you don’t know what data and 
hence what coverage you’re going to get, and you may have to take extra 
care to conform to privacy and data protection legislation.
This can have an impact on the system’s architecture in a number of 
ways, and should be given due consideration early on by the architect. For 
example, the system may need to be able to capture live transactions, or 
take “snapshots” of live data, which can be used to generate test data. In ad-
dition, the test-data-generation system may need an architecture of its own.
Test Automation
Your second challenge is around test automation. In practice it is not pos-
sible to test large systems by hand because of the number of tests, their 
complexity, and the amount of checking of results that’s required. In the 
ideal world, you create a test automation framework to do this automati-
cally, which you feed with test data, and set running every night, or even 
run every time you check in something (the continuous integration model).
This is an area that is given too little attention on many large software 
development projects. It is often not budgeted for in the project plan, with 
an unwritten assumption that the effort needed to build it can be somehow 
“absorbed” into the development costs. A test automation framework can 
be a significantly complex thing in its own right (which raises the question 
of how you test it!). It should be scoped and planned like any other project 
deliverable.
Due consideration should be given to how the framework will invoke 
functions on the system under test, particularly for testing user interfaces, 
which is almost without exception a nightmare. (The execution of a UI test 
is highly dependent on the layout of the windows, the ordering of fields, 
and so on, which usually changes a lot in heavily user-focused systems. 
It is sometimes possible to execute window controls programmatically, but 
in the worst case you may have to record and replay keystrokes or mouse 
movements.)
