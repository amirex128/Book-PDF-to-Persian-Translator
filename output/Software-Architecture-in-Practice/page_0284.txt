14.3  Thought Experiments and Back-of-the-Envelope Analysis 
263
The level of formality one would use in performing a thought experiment 
is, as with most techniques discussed in this book, a question of context. If two 
people with a shared understanding of the system are performing the thought ex-
periment for their own private purposes, then circles and lines on a whiteboard 
are adequate, and the discussion proceeds in a kind of shorthand. If a third person 
is to review the results and the third person does not share the common under-
standing, then sufficient details must be captured to enable the third person to un-
derstand the argument—perhaps a quick legend and a set of properties need to be 
added to the diagram. If the results are to be included in documentation as design 
rationale, then even more detail must be captured, as discussed in Chapter 18. 
Frequently such thought experiments are accompanied by rough analyses—back-
of-the-envelope analyses—based on the best data available, based on past expe-
riences, or even based on the guesses of the architects, without too much concern 
for precision.
The purpose of thought experiments and back-of-the-envelope analysis is 
to find problems or confirmation of the nonexistence of problems in the quality 
attribute requirements as applied to sunny-day use cases. That is, for each use 
case, consider the quality attribute requirements that pertain to that use case and 
analyze the use case with the quality attribute requirements in mind. Models and 
checklists focus on one quality attribute. To consider other quality attributes, one 
must model or have a checklist for the second quality attribute and understand 
how those models interact. A thought experiment may consider several of the 
quality attribute requirements simultaneously; typically it will focus on just the 
most important ones.
The process of creating a thought experiment usually begins with listing the 
steps associated with carrying out the use case under consideration; perhaps a se-
quence diagram is employed. At each step of the sequence diagram, the (mental) 
question is asked: What can go wrong with this step with respect to any of the 
quality attribute requirements? For example, if the step involves user input, then 
the possibility of erroneous input must be considered. Also the user may not have 
been properly authenticated and, even if authenticated, may not be authorized to 
provide that particular input. If the step involves interaction with another system, 
then the possibility that the input format will change after some time must be 
considered. The network passing the input to a processor may fail; the processor 
performing the step may fail; or the computation to provide the step may fail, 
take too long, or be dependent on another computation that may have had prob-
lems. In addition, the architect must ask about the frequency of the input, and the 
anticipated distribution of requests (e.g., Are service requests regular and predict-
able or irregular and “bursty”?), other processes that might be competing for the 
same resources, and so forth. These questions go on and on.
For each possible problem with respect to a quality attribute requirement, 
the follow-on questions consist of things like these: 
■
■Are there mechanisms to detect that problem? 
