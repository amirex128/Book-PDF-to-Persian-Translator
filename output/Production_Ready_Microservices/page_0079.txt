neers (or other operations engineers) working on the service meet in a room, draw up
the architecture of the service on a whiteboard, and thoroughly evaluate its architec‐
ture.
Within several minutes into this exercise, it tends to become very clear precisely what
the scope of understanding is at the developer and team levels. Talking through the
architecture, developers will quickly discover scalability and performance bottle‐
necks, previously undiscovered points of failure, possible outages and future inci‐
dents and failures and catastrophe scenarios, and new features that should be added.
Poor architectural decisions that were made in the past will become obvious, and old
technologies that should be replaced by newer and/or better ones will stand out. To
ensure that evaluation and discussion is productive and objective, it’s helpful to bring
in developers from other teams (especially those in infrastructure, DevOps, or site
reliability engineering) who have experience in large-scale distributed systems archi‐
tecture (and the organization’s specific microservice ecosystem) and will be able to
point out problems that developers may not notice.
Each meeting should produce a new, updated architecture diagram for the service,
along with a list of projects to tackle in the coming weeks and months. The new dia‐
gram should definitely be added to the documentation, and projects can be included
in each service’s roadmap (see “Production-Readiness Roadmaps” on page 72) and
objectives and key results (OKRs).
Because microservice development moves rather quickly, microservices evolve at a
rapid pace and the lower layers of the microservice ecosystem will be constantly
changing. In order to keep the architecture and its understanding relevant and pro‐
ductive, these meetings should be held regularly. I’ve found that a good rule of thumb
is to schedule them so that they align with OKR and project planning. If projects and
OKRs are planned and scheduled quarterly, then quarterly architecture reviews
should be held each quarter before the planning cycle begins.
Production-Readiness Audits
To make sure that a microservice meets production-readiness standards and require‐
ments and is actually production-ready, the team can run a production-readiness audit
on the service. Running an audit is quite simple: the team sits down with a checklist
of the production-readiness requirements and checks off whether or not their service
meets each requirement. This enables understanding of a service: each developer and
team will know, by the end of the audit, exactly where their service stands and where
things can be improved.
The structure of an audit should mirror the production-readiness standards and
requirements that the engineering organization has adopted. The team should use the
audits to quantify the stability, reliability, scalability, fault tolerance, catastrophe-
preparedness, performance, monitoring, and documentation of the service. As I’ve
Microservice Understanding 
| 
71
