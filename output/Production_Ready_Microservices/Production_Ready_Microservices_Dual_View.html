<!DOCTYPE html>
<html lang="fa">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Production_Ready_Microservices - نسخه دوزبانه</title>
    <link rel="stylesheet" href="fontiran.css">
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/line-numbers/prism-line-numbers.min.css" rel="stylesheet" />
    <style>
        @page {
            size: A3 landscape;
            margin: 1cm;
        }
        body {
            font-family: IRANSansX, Tahoma, Arial, sans-serif;
            line-height: 1.8;
            margin: 0;
            padding: 20px;
            background-color: white;
        }
        .book-title {
            text-align: center;
            font-size: 24pt;
            margin: 2cm 0 1cm 0;
        }
        .book-subtitle {
            text-align: center;
            font-size: 18pt;
            margin-bottom: 2cm;
        }
        .dual-page-container {
            display: flex;
            flex-wrap: wrap;
        }
        .dual-page-spread {
            display: flex;
            justify-content: space-between;
            width: 100%;
            margin-bottom: 1cm;
            page-break-after: always;
        }
        .page {
            width: 48%;
            box-shadow: 0 0 10px rgba(0,0,0,0.1);
            padding: 1cm;
            margin: 0 0.5%;
            box-sizing: border-box;
        }
        .persian-page {
            text-align: right;
            direction: rtl;
        }
        .original-page {
            text-align: center;
            display: flex;
            align-items: center;
            justify-content: center;
        }
        .original-page img {
            max-width: 100%;
            max-height: 100%;
        }
        .persian-translation {
            font-size: 14pt;
        }
        .page-images {
            text-align: center;
            margin-top: 1cm;
        }
        .page-images img {
            max-width: 100%;
            height: auto;
            margin: 0.5cm 0;
        }
        pre {
            direction: ltr;
            text-align: left;
            background-color: #f5f5f5;
            padding: 15px;
            border-radius: 5px;
            overflow-x: auto;
            margin: 15px 0;
        }
        code {
            font-family: 'Courier New', Courier, monospace;
            direction: ltr;
            text-align: left;
        }
        span[dir="ltr"] {
            display: inline-block;
            direction: ltr;
            text-align: left;
        }
    </style>
</head>
<body>
    <h1 class="book-title">Production_Ready_Microservices</h1>
    <h2 class="book-subtitle">نسخه دوزبانه</h2>
    
    <div class="dual-page-container">
        <div class="dual-page-spread">
            <div class="page persian-page">
                <div class="translated-content">
<div>
<h3>Susan J. Fowler: Microservices آماده‌ی تولید</h3>
<h4>ساخت سیستم‌های استاندارد در سراسر یک سازمان مهندسی</h4>
<p>
   با احترام از طرف Susan J. Fowler
   <br/>
   فصل‌های رایگان
  </p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 1" src="page_0001/image_1.png"/></div>
<div class="page-image"><img alt="Image from page 1" src="page_0001/image_2.png"/></div>
<div class="page-image"><img alt="Image from page 1" src="page_0001/image_3.png"/></div>
<div class="page-image"><img alt="Image from page 1" src="page_0001/image_4.png"/></div>
<div class="page-image"><img alt="Image from page 1" src="page_0001/image_5.png"/></div>
<div class="page-image"><img alt="Image from page 1" src="page_0001/image_6.png"/></div>
<div class="page-image"><img alt="Image from page 1" src="page_0001/image_7.png"/></div>
<div class="page-image"><img alt="Image from page 1" src="page_0001/image_8.png"/></div>
<div class="page-image"><img alt="Image from page 1" src="page_0001/image_9.png"/></div>
<div class="page-image"><img alt="Image from page 1" src="page_0001/image_10.png"/></div>
<div class="page-image"><img alt="Image from page 1" src="page_0001/image_11.png"/></div>
<div class="page-image"><img alt="Image from page 1" src="page_0001/image_12.png"/></div>
<div class="page-image"><img alt="Image from page 1" src="page_0001/image_13.png"/></div>
<div class="page-image"><img alt="Image from page 1" src="page_0001/image_14.png"/></div>
<div class="page-image"><img alt="Image from page 1" src="page_0001/image_15.png"/></div>
<div class="page-image"><img alt="Image from page 1" src="page_0001/image_16.png"/></div>
<div class="page-image"><img alt="Image from page 1" src="page_0001/image_17.png"/></div>
<div class="page-image"><img alt="Image from page 1" src="page_0001/image_18.png"/></div>
<div class="page-image"><img alt="Image from page 1" src="page_0001/image_19.png"/></div>
<div class="page-image"><img alt="Image from page 1" src="page_0001/image_20.png"/></div>
<div class="page-image"><img alt="Image from page 1" src="page_0001/image_21.png"/></div>
<div class="page-image"><img alt="Image from page 1" src="page_0001/image_22.png"/></div>
<div class="page-image"><img alt="Image from page 1" src="page_0001/image_23.png"/></div>
<div class="page-image"><img alt="Image from page 1" src="page_0001/image_24.png"/></div>
<div class="page-image"><img alt="Image from page 1" src="page_0001/image_25.png"/></div>
<div class="page-image"><img alt="Image from page 1" src="page_0001/image_26.png"/></div>
<div class="page-image"><img alt="Image from page 1" src="page_0001/image_27.png"/></div>
<div class="page-image"><img alt="Image from page 1" src="page_0001/image_28.png"/></div>
<div class="page-image"><img alt="Image from page 1" src="page_0001/image_29.png"/></div>
<div class="page-image"><img alt="Image from page 1" src="page_0001/image_30.png"/></div>
</div>
            </div>
            <div class="page original-page">
                <img src="page_0001_original/original_page.png" alt="Original Page 1">
            </div>
        </div>
        <div class="dual-page-spread">
            <div class="page persian-page">
                <div class="translated-content">
<div>
<h3>آزمایشی رایگان</h3>
<p>
<em>بیشتر بیاموزید</em>
</p>
<p>
   تحویل <strong>بی‌نقص</strong> اپلیکیشن
  </p>
<ul>
<li>Load Balancer</li>
<li>Content Cache</li>
<li>Web Server</li>
<li>Security Controls</li>
<li>Monitoring &amp; Management</li>
</ul>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 2" src="page_0002/image_1.png"/></div>
</div>
            </div>
            <div class="page original-page">
                <img src="page_0002_original/original_page.png" alt="Original Page 2">
            </div>
        </div>
        <div class="dual-page-spread">
            <div class="page persian-page">
                <div class="translated-content">
<div>
<h3>این گزیده شامل فصل‌های 1، 3، 4، 7 و پیوست A از کتاب Microservices آماده‌ی تولید است.</h3>
<p>
   کتاب کامل در oreilly.com و از طریق خرده‌فروشان دیگر در دسترس است.
  </p>
<p>
<strong>Susan J. Fowler</strong>
</p>
<p>
   Microservices آماده‌ی تولید
   <br/>
<em>ساخت سیستم‌های استاندارد در سراسر یک سازمان مهندسی</em>
</p>
<p>
   بوستون
   <br/>
   فارنهام
   <br/>
   سباستوپول
   <br/>
   توکیو
   <br/>
   پکن
  </p>
<p>
   بوستون
   <br/>
   فارنهام
   <br/>
   سباستوپول
   <br/>
   توکیو
   <br/>
   پکن
  </p>
</div>
</div>
                <div class="page-images">
</div>
            </div>
            <div class="page original-page">
                <img src="page_0003_original/original_page.png" alt="Original Page 3">
            </div>
        </div>
        <div class="dual-page-spread">
            <div class="page persian-page">
                <div class="translated-content">
<div>
<p>978-1-491-96597-9</p>
<p>[LSI]</p>
<p>
   Microservices آماده‌ی تولید
   <br/>
   توسط Susan J. Fowler
  </p>
<p>
   حق چاپ © 2017 Susan Fowler. تمامی حقوق محفوظ است.
   <br/>
   چاپ‌شده در ایالات متحده آمریکا.
  </p>
<p>
   منتشر شده توسط O’Reilly Media, Inc., 1005 Gravenstein Highway North, Sebastopol, CA 95472.
   <br/>
   کتاب‌های O’Reilly ممکن است برای استفاده‌های آموزشی، تجاری یا تبلیغات فروش خریداری شوند. نسخه‌های آنلاین نیز برای
   بیشتر عناوین (http://oreilly.com/safari) موجود است. برای اطلاعات بیشتر، با بخش فروش شرکتی/موسساتی ما تماس بگیرید:
   800-998-9938 یا corporate@oreilly.com.
  </p>
<p>
   ویراستاران: Nan Barber و Brian Foster
   <br/>
   ویراستار تولید: Kristen Brown
   <br/>
   ویراستار: Amanda Kersey
   <br/>
   تصحیح‌کننده: Jasmine Kwityn
   <br/>
   فهرست‌نویس: Wendy Catalano
   <br/>
   طراح داخلی: David Futato
   <br/>
   طراح جلد: Karen Montgomery
   <br/>
   تصویرگر: Rebecca Demarest
  </p>
<p>دسامبر 2016:</p>
<p>
   نسخه اول
   <br/>
   تاریخچه بازبینی برای نسخه اول
   <br/>
   2016-11-23: انتشار اول
  </p>
<p>
   برای جزئیات انتشار به http://oreilly.com/catalog/errata.csp?isbn=9781491965979 مراجعه کنید.
  </p>
<p>
   لوگوی O’Reilly یک علامت تجاری ثبت شده از O’Reilly Media, Inc. است. Microservices آماده‌ی تولید،
   تصویر جلد و طرح‌های تجاری مرتبط، علائم تجاری O’Reilly Media, Inc. هستند.
  </p>
<p>
   در حالی که ناشر و نویسنده تلاش‌های حسن نیت برای اطمینان از صحت اطلاعات و
   دستورالعمل‌های موجود در این اثر به کار برده‌اند، ناشر و نویسنده تمامی مسئولیت‌ها را رد می‌کنند
   برای خطاها یا حذف‌ها، از جمله بدون محدودیت مسئولیت برای خسارات ناشی از استفاده
   یا اتکا به این اثر. استفاده از اطلاعات و دستورالعمل‌های موجود در این اثر بر عهده شماست
   خطر خودتان است. اگر هر نمونه کد یا فناوری دیگری که این اثر شامل می‌شود یا توضیح می‌دهد، مشمول منبع آزاد است
   مجوزها یا حقوق مالکیت فکری دیگران، این مسئولیت شماست که اطمینان حاصل کنید که استفاده شما
   از این طریق با چنین مجوزها و/یا حقوقی مطابقت دارد.
  </p>
</div>
</div>
                <div class="page-images">
</div>
            </div>
            <div class="page original-page">
                <img src="page_0004_original/original_page.png" alt="Original Page 4">
            </div>
        </div>
        <div class="dual-page-spread">
            <div class="page persian-page">
                <div class="translated-content">
<div>
<h3>فهرست مطالب</h3>
<ol>
<li>Microservices. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1</li>
</ol>
<p>از Monoliths به Microservices</p>
<p>معماری Microservice</p>
<p>اکوسیستم Microservice</p>
<p>Layer 1: Hardware</p>
<p>Layer 2: Communication</p>
<p>Layer 3: The Application Platform</p>
<p>Layer 4: Microservices</p>
<p>چالش‌های سازمانی</p>
<p>The Inverse Conway’s Law</p>
<p>Technical Sprawl</p>
<p>راه‌های بیشتر برای شکست</p>
<p>رقابت برای منابع</p>
<ol start="3">
<li>پایداری و قابلیت اطمینان. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25</li>
</ol>
<p>اصول ساخت Microservices پایدار و قابل اطمینان</p>
<p>چرخه توسعه</p>
<p>Pipeline استقرار</p>
<p>Staging</p>
<p>Canary</p>
<p>Production</p>
<p>اعمال استقرار پایدار و قابل اطمینان</p>
<p>وابستگی‌ها</p>
<p>Routing و کشف</p>
<p>Deprecation و Decommissioning</p>
<p>ارزیابی Microservice خود</p>
<p>چرخه توسعه</p>
<p>Pipeline استقرار</p>
<p>iii</p>
</div>
</div>
                <div class="page-images">
</div>
            </div>
            <div class="page original-page">
                <img src="page_0005_original/original_page.png" alt="Original Page 5">
            </div>
        </div>
        <div class="dual-page-spread">
            <div class="page persian-page">
                <div class="translated-content">
<div>
<p>وابستگی‌ها</p>
<p>Routing و Discovery</p>
<p>Deprecation و Decommissioning</p>
<ol start="4">
<li>مقیاس‌پذیری و عملکرد. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 43</li>
</ol>
<p>اصول مقیاس‌پذیری و عملکرد Microservice</p>
<p>دانستن مقیاس رشد</p>
<p>مقیاس رشد کیفی</p>
<p>مقیاس رشد کمی</p>
<p>استفاده کارآمد از منابع</p>
<p>آگاهی از منابع</p>
<p>نیازمندی‌های منابع</p>
<p>موانع منابع</p>
<p>برنامه‌ریزی ظرفیت</p>
<p>مقیاس‌بندی وابستگی</p>
<p>مدیریت ترافیک</p>
<p>مدیریت و پردازش وظایف</p>
<p>محدودیت‌های زبان برنامه‌نویسی</p>
<p>مدیریت درخواست‌ها و پردازش کارها به طور کارآمد</p>
<p>ذخیره‌سازی داده‌های مقیاس‌پذیر</p>
<p>انتخاب پایگاه داده در اکوسیستم‌های Microservice</p>
<p>چالش‌های پایگاه داده در معماری Microservice</p>
<p>ارزیابی Microservice خود</p>
<p>دانستن مقیاس رشد</p>
<p>استفاده کارآمد از منابع</p>
<p>آگاهی از منابع</p>
<p>برنامه‌ریزی ظرفیت</p>
<p>مقیاس‌بندی وابستگی</p>
<p>مدیریت ترافیک</p>
<p>مدیریت و پردازش وظایف</p>
<p>ذخیره‌سازی داده‌های مقیاس‌پذیر</p>
<ol start="7">
<li>مستندات و درک. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 61</li>
</ol>
<p>اصول مستندسازی و درک Microservice</p>
<p>مستندات Microservice</p>
<p>توضیحات</p>
<p>نمودار معماری</p>
<p>اطلاعات تماس و در دسترس بودن</p>
<p>پیوندها</p>
<p>راهنمای Onboarding و توسعه</p>
<p>جریان‌های درخواست، Endpoints و وابستگی‌ها</p>
<p>Runbooks در دسترس بودن</p>
<p>iv</p>
<p>| فهرست مطالب</p>
</div>
</div>
                <div class="page-images">
</div>
            </div>
            <div class="page original-page">
                <img src="page_0006_original/original_page.png" alt="Original Page 6">
            </div>
        </div>
        <div class="dual-page-spread">
            <div class="page persian-page">
                <div class="translated-content">
<div>
<h3>سوالات متداول</h3>
<p>درک Microservice</p>
<p>مرور معماری</p>
<p>Production-Readiness Audits</p>
<p>Production-Readiness Roadmaps</p>
<p>اتوماسیون Production-Readiness</p>
<p>ارزیابی Microservice خود</p>
<p>مستندات Microservice</p>
<p>درک Microservice</p>
<p>
   A. Production-Readiness Checklist. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 75
  </p>
<p>فهرست مطالب</p>
<p>v</p>
</div>
</div>
                <div class="page-images">
</div>
            </div>
            <div class="page original-page">
                <img src="page_0007_original/original_page.png" alt="Original Page 7">
            </div>
        </div>
        <div class="dual-page-spread">
            <div class="page persian-page">
                <div class="translated-content">
<div>
<h3>فصل 1</h3>
<h3>Microservices</h3>
<p>
   در چند سال گذشته، صنعت فناوری شاهد تغییرات سریعی در معماری سیستم‌های توزیع‌شده کاربردی و عملی بوده است که
   شرکت‌های بزرگ صنعت (مانند Netflix، Twitter، Amazon، eBay و Uber) را از ساخت برنامه‌های monolithic به سمت
   پذیرش معماری microservice سوق داده است. در حالی که مفاهیم اساسی پشت microservices جدید نیستند،
   کاربرد امروزی معماری microservice واقعاً جدید است و پذیرش آن تا حدی به دلیل چالش‌های مقیاس‌پذیری،
   عدم کارایی، سرعت کم توسعه‌دهندگان و مشکلات ناشی از پذیرش فناوری‌های جدید است که زمانی
   سیستم‌های نرم‌افزاری پیچیده در یک برنامه monolithic بزرگ گنجانده شده و به عنوان یک برنامه واحد مستقر می‌شوند.
  </p>
<p>
   پذیرش معماری microservice، چه از ابتدا و چه با تقسیم یک برنامه monolithic موجود به microservices که
   به طور مستقل توسعه و مستقر شده‌اند، این مشکلات را حل می‌کند. با معماری microservice، یک برنامه
   می‌تواند به راحتی هم به صورت افقی و هم عمودی مقیاس‌بندی شود، بهره‌وری و سرعت توسعه‌دهندگان به طرز چشمگیری
   افزایش می‌یابد و فناوری‌های قدیمی را می‌توان به راحتی با جدیدترین‌ها جایگزین کرد.
  </p>
<p>
   همانطور که در این فصل خواهیم دید، پذیرش معماری microservice را می‌توان به عنوان یک گام طبیعی در مقیاس‌بندی
   یک برنامه مشاهده کرد. تقسیم یک برنامه monolithic به microservices به دلیل نگرانی‌های مقیاس‌پذیری و
   کارایی است، اما microservices چالش‌های خاص خود را نیز معرفی می‌کنند. یک اکوسیستم microservice موفق و
   مقیاس‌پذیر مستلزم وجود یک زیرساخت پایدار و پیچیده است. علاوه بر این، ساختار سازمانی شرکتی که
   microservices را می‌پذیرد باید به طور اساسی تغییر کند تا از معماری microservice پشتیبانی کند، و
   ساختارهای تیمی که از این امر نشأت می‌گیرند می‌توانند منجر به سیلینگ و گسترش شوند. با این حال،
   بزرگترین چالش‌هایی که معماری microservice به همراه دارد، نیاز به استانداردسازی معماری خود سرویس‌ها است،
   همراه با الزامات هر microservice به منظور اطمینان از اعتماد و در دسترس بودن.
  </p>
<p>1</p>
</div>
</div>
                <div class="page-images">
</div>
            </div>
            <div class="page original-page">
                <img src="page_0009_original/original_page.png" alt="Original Page 9">
            </div>
        </div>
        <div class="dual-page-spread">
            <div class="page persian-page">
                <div class="translated-content">
<div>
<h3>از Monoliths به Microservices</h3>
<p>
   تقریباً هر برنامه نرم‌افزاری که امروزه نوشته می‌شود را می‌توان به سه عنصر مجزا تقسیم کرد: یک قطعه frontend (یا سمت
   کلاینت)، یک قطعه backend و نوعی datastore (شکل 1-1). درخواست‌ها از طریق قطعه سمت کلاینت به برنامه ارسال می‌شوند،
   کد backend تمام کارهای سنگین را انجام می‌دهد، و هر داده مربوطه که نیاز به ذخیره یا دسترسی (چه موقتی در حافظه یا
   به طور دائم در یک پایگاه داده) دارد، به هر جایی که داده‌ها در آن ذخیره می‌شوند، ارسال یا از آن بازیابی می‌شود. ما
   این را معماری سه لایه می‌نامیم.
  </p>
<p>
   شکل 1-1. معماری سه لایه
  </p>
<p>
   سه روش مختلف وجود دارد که این عناصر را می‌توان برای ایجاد یک برنامه ترکیب کرد. اکثر برنامه‌ها دو قطعه اول را در یک
   codebase (یا repository) قرار می‌دهند، جایی که تمام کد سمت کلاینت و backend ذخیره می‌شوند و به عنوان یک فایل
   اجرایی واحد اجرا می‌شوند، با یک پایگاه داده جداگانه. برخی دیگر، تمام کد frontend و سمت کلاینت را از کد backend
   جدا کرده و آن‌ها را به عنوان فایل‌های اجرایی منطقی جداگانه ذخیره می‌کنند، که با یک پایگاه داده خارجی همراه است.
   برنامه‌هایی که نیازی به یک پایگاه داده خارجی ندارند و تمام داده‌ها را در حافظه ذخیره می‌کنند، تمایل دارند تمام
   سه عنصر را در یک repository ترکیب کنند. صرف نظر از نحوه تقسیم یا ترکیب این عناصر، خود برنامه به عنوان
   مجموع این سه عنصر مجزا در نظر گرفته می‌شود.
  </p>
<p>
   برنامه‌ها معمولاً از ابتدا در چرخه عمر خود به این روش معماری، ساخته و اجرا می‌شوند، و معماری برنامه معمولاً مستقل از
   محصول ارائه شده توسط شرکت یا هدف خود برنامه است. این سه عنصر معماری که معماری سه لایه را تشکیل می‌دهند، در
   هر وب‌سایت، هر برنامه تلفن، هر backend و frontend و برنامه بزرگ سازمانی عجیب و غریب وجود دارند و به عنوان
   یکی از جایگشت‌های شرح داده شده یافت می‌شوند.
  </p>
<p>
   در مراحل اولیه، زمانی که یک شرکت جوان است، برنامه‌های آن ساده است و تعداد توسعه‌دهندگانی که به codebase کمک
   می‌کنند کم است، توسعه‌دهندگان معمولاً بار کمک به و نگهداری codebase را به اشتراک می‌گذارند. با رشد شرکت،
   توسعه‌دهندگان بیشتری استخدام می‌شوند، ویژگی‌های جدید به برنامه اضافه می‌شوند و سه اتفاق مهم رخ می‌دهد.
  </p>
<p>
   اولین مورد، افزایش حجم کاری عملیاتی است. به طور کلی، کار عملیاتی، کاری است که با اجرای و نگهداری برنامه مرتبط
   است. این امر معمولاً منجر به استخدام مهندسان عملیاتی (مدیران سیستم، مهندسان TechOps و مهندسان به اصطلاح
   "DevOps") می‌شود که اکثر وظایف عملیاتی، مانند موارد مربوط به سخت‌افزار، نظارت و در دسترس بودن را بر عهده
   می‌گیرند.
  </p>
<p>2 | فصل 1: Microservices</p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 10" src="page_0010/image_1.png"/></div>
</div>
            </div>
            <div class="page original-page">
                <img src="page_0010_original/original_page.png" alt="Original Page 10">
            </div>
        </div>
        <div class="dual-page-spread">
            <div class="page persian-page">
                <div class="translated-content">
<div>
<p>دومین اتفاقی که می‌افتد، نتیجه یک ریاضیات ساده است: افزودن ویژگی‌های جدید به برنامه شما، هم تعداد خطوط کد در
   برنامه و هم پیچیدگی خود برنامه را افزایش می‌دهد.</p>
<p>سومین مورد، مقیاس‌پذیری افقی و/یا عمودی ضروری برنامه است. افزایش ترافیک، تقاضاهای قابل توجهی برای مقیاس‌پذیری
   و عملکرد بر روی برنامه ایجاد می‌کند، که مستلزم آن است که سرورهای بیشتری میزبان برنامه باشند. سرورهای بیشتری
   اضافه می‌شوند، یک کپی از برنامه بر روی هر سرور مستقر می‌شود و load balancerها در جای خود قرار می‌گیرند تا
   درخواست‌ها به طور مناسب در بین سرورهای میزبان برنامه توزیع شوند (به شکل 1-2، که شامل یک قطعه frontend است که
   ممکن است لایه load-balancing خود را داشته باشد، یک لایه load-balancing backend و سرورهای backend).
   مقیاس‌بندی عمودی به یک ضرورت تبدیل می‌شود زیرا برنامه شروع به پردازش تعداد بیشتری از وظایف مرتبط با مجموعه
   متنوعی از ویژگی‌های خود می‌کند، بنابراین برنامه بر روی سرورهای بزرگتر و قدرتمندتری مستقر می‌شود که می‌توانند
   نیازهای CPU و حافظه را برطرف کنند (شکل 1-3).</p>
<p>شکل 1-2. مقیاس‌بندی یک برنامه به صورت افقی</p>
<p>از Monoliths به Microservices | 3</p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 11" src="page_0011/image_1.png"/></div>
</div>
            </div>
            <div class="page original-page">
                <img src="page_0011_original/original_page.png" alt="Original Page 11">
            </div>
        </div>
        <div class="dual-page-spread">
            <div class="page persian-page">
                <div class="translated-content">
<div>
<p>شکل 1-3. مقیاس‌بندی یک برنامه به صورت عمودی</p>
<p>
   با رشد شرکت و دیگر تعداد مهندسان تک، دو یا حتی سه رقمی نیست، اوضاع کمی پیچیده‌تر می‌شود. به لطف تمام ویژگی‌ها،
   patchها و اصلاحات اضافه شده به codebase توسط توسعه‌دهندگان، برنامه اکنون هزاران هزار خط طول دارد. پیچیدگی
   برنامه به طور پیوسته در حال افزایش است و صدها (اگر نه هزاران) تست باید نوشته شود تا اطمینان حاصل شود که هر
   تغییری (حتی تغییر یک یا دو خط) یکپارچگی هزاران هزار خط کد موجود را به خطر نمی‌اندازد. توسعه و استقرار به یک
   کابوس تبدیل می‌شود، آزمایش به یک بار و یک مانع برای استقرار حتی حیاتی‌ترین اصلاحات تبدیل می‌شود و بدهی فنی
   به سرعت انباشته می‌شود. برنامه‌هایی که چرخه‌های عمرشان با این الگو مطابقت دارند (چه بهتر و چه بدتر) در جامعه نرم‌افزار
   با محبت (و به درستی) به عنوان monoliths نامیده می‌شوند.
  </p>
<p>
   البته، همه برنامه‌های monolithic بد نیستند و همه برنامه‌های monolithic از مشکلات ذکر شده رنج نمی‌برند، اما
   monoliths که در مقطعی از چرخه عمر خود به این مسائل برخورد نکنند (به تجربه من) بسیار نادر هستند. دلیل اینکه
   اکثر monoliths مستعد این مشکلات هستند این است که ماهیت یک monolith مستقیماً با مقیاس‌پذیری در
   کلی‌ترین حالت ممکن مخالف است. مقیاس‌پذیری مستلزم concurrency و partitioning است: دو چیزی که دستیابی به
   آنها با یک monolith دشوار است.
  </p>
<p>4 | فصل 1: Microservices</p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 12" src="page_0012/image_1.png"/></div>
</div>
            </div>
            <div class="page original-page">
                <img src="page_0012_original/original_page.png" alt="Original Page 12">
            </div>
        </div>
        <div class="dual-page-spread">
            <div class="page persian-page">
                <div class="translated-content">
<div>
<h3>مقیاس‌بندی یک برنامه</h3>
<p>بیایید این را کمی تجزیه کنیم.</p>
<p>
   هدف هر برنامه نرم‌افزاری، پردازش وظایفی از نوعی است. صرف نظر از اینکه آن وظایف چه هستند، ما می‌توانیم یک فرض کلی
   در مورد نحوه عملکرد برنامه خود در مورد آن‌ها داشته باشیم: باید آن‌ها را به طور موثر پردازش کند.
  </p>
<p>
   برای پردازش کارها به طور موثر، برنامه ما باید نوعی concurrency داشته باشد. این بدان معناست که ما نمی‌توانیم فقط یک
   process داشته باشیم که تمام کارها را انجام دهد، زیرا در این صورت آن process یک کار را در یک زمان برمی‌دارد،
   تمام قطعات لازم آن را کامل می‌کند (یا شکست می‌خورد!)، و سپس به سراغ کار بعدی می‌رود - این اصلا کارآمد نیست! برای
   اینکه برنامه ما کارآمد باشد، می‌توانیم concurrency را معرفی کنیم تا هر کار به قطعات کوچکتر تقسیم شود.
  </p>
<p>
   دومین کاری که می‌توانیم برای پردازش کارها به طور موثر انجام دهیم، تقسیم و غلبه است با معرفی partitioning، جایی
   که هر کار نه تنها به قطعات کوچک تقسیم می‌شود، بلکه می‌تواند به صورت موازی پردازش شود. اگر تعدادی کار داشته باشیم،
   می‌توانیم همه آن‌ها را همزمان پردازش کنیم با ارسال آن‌ها به مجموعه‌ای از workers که می‌توانند آن‌ها را به موازات پردازش
   کنند. اگر نیاز به پردازش کارهای بیشتری داشته باشیم، می‌توانیم به راحتی با افزودن workers اضافی برای پردازش
   کارهای جدید، بدون تأثیر بر کارایی سیستم خود، با تقاضا مقیاس‌بندی کنیم.
  </p>
<p>
   هنگامی که یک برنامه بزرگ دارید که نیاز به استقرار در هر سرور دارد و باید هر نوع کاری را پردازش کند، concurrency و
   partitioning پشتیبانی از آن دشوار است. اگر برنامه شما حتی کمی پیچیده باشد، تنها راهی که می‌توانید آن را با فهرستی
   رشد یابنده از ویژگی‌ها و افزایش ترافیک مقیاس‌بندی کنید، مقیاس‌بندی سخت‌افزاری است که برنامه روی آن مستقر شده
   است.
  </p>
<p>
   برای اینکه واقعاً کارآمد باشیم، بهترین راه برای مقیاس‌بندی یک برنامه این است که آن را به برنامه‌های کوچک و
   مستقل زیادی تقسیم کنیم که هر کدام یک نوع کار را انجام می‌دهند. آیا نیاز به اضافه کردن گام دیگری به کل process
   دارید؟ به اندازه کافی آسان است: فقط یک برنامه جدید بسازید که فقط آن گام را انجام دهد! آیا نیاز به رسیدگی به
   ترافیک بیشتر دارید؟ ساده است: workers بیشتری به هر برنامه اضافه کنید!
  </p>
<p>
   Concurrency و partitioning در یک برنامه monolithic پشتیبانی از آن دشوار است، که مانع از این می‌شود که معماری
   برنامه monolithic به همان اندازه که نیاز داریم کارآمد باشد.
  </p>
<p>
   ما شاهد ظهور این الگو در شرکت‌هایی مانند Amazon، Twitter، Netflix، eBay و Uber بوده‌ایم: شرکت‌هایی که
   برنامه‌هایی را در سراسر نه صدها، بلکه هزاران، حتی صدها هزار سرور اجرا می‌کنند و برنامه‌های آن‌ها به
   monoliths تبدیل شده و به چالش‌های مقیاس‌پذیری برخورد کرده‌اند. چالش‌هایی که آن‌ها با آن مواجه شدند با
   کنار گذاشتن معماری برنامه monolithic به نفع microservices برطرف شد.
  </p>
<p>
   مفهوم اساسی یک microservice ساده است: این یک برنامه کوچک است که فقط یک کار را انجام می‌دهد و آن یک کار را
   خوب انجام می‌دهد. یک microservice یک component کوچک است که
  </p>
<p>از Monoliths به Microservices | 5</p>
</div>
</div>
                <div class="page-images">
</div>
            </div>
            <div class="page original-page">
                <img src="page_0013_original/original_page.png" alt="Original Page 13">
            </div>
        </div>
        <div class="dual-page-spread">
            <div class="page persian-page">
                <div class="translated-content">
<div>
<p>به راحتی قابل تعویض، به طور مستقل توسعه یافته و به طور مستقل قابل استقرار است. با این حال، یک microservice به تنهایی
   نمی‌تواند زندگی کند - هیچ microservice جزیره‌ای نیست - و بخشی از یک سیستم بزرگتر است، که در کنار microservices دیگر
   اجرا و کار می‌کند تا آنچه را که به طور معمول توسط یک برنامه بزرگ مستقل مدیریت می‌شود، انجام دهد.
  </p>
<p>
   هدف معماری microservice این است که مجموعه‌ای از برنامه‌های کوچک بسازد که هر کدام مسئول انجام یک عملکرد
   (در مقابل روش سنتی ساخت یک برنامه که همه کارها را انجام می‌دهد) هستند و به هر microservice اجازه می‌دهد
   خودمختار، مستقل و خودکفا باشد. تفاوت اصلی بین یک برنامه monolithic و microservices این است: یک برنامه monolithic
   (شکل 1-4) شامل تمام ویژگی‌ها و عملکردهای یک برنامه و یک codebase می‌شود که همگی در یک زمان مستقر شده‌اند، و
   هر سرور میزبان یک کپی کامل از کل برنامه را دارد، در حالی که یک microservice (شکل 1-5) فقط شامل یک عملکرد یا
   ویژگی است و در یک اکوسیستم microservice همراه با سایر microservices که هر کدام یک عملکرد یا ویژگی را انجام
   می‌دهند، زندگی می‌کند.
  </p>
<p>شکل 1-4. Monolith</p>
<p>6 | فصل 1: Microservices</p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 14" src="page_0014/image_1.png"/></div>
</div>
            </div>
            <div class="page original-page">
                <img src="page_0014_original/original_page.png" alt="Original Page 14">
            </div>
        </div>
        <div class="dual-page-spread">
            <div class="page persian-page">
                <div class="translated-content">
<div>
<p>شکل 1-5. Microservices</p>
<p>
   مزایای متعددی برای پذیرش معماری microservice وجود دارد—از جمله (اما نه محدود به) کاهش بدهی فنی، بهبود
   بهره‌وری و سرعت توسعه‌دهندگان، بهبود کارایی تست، افزایش مقیاس‌پذیری و سهولت استقرار—و شرکت‌هایی که معماری
   microservice را اتخاذ می‌کنند معمولاً این کار را پس از ساخت یک برنامه و مواجهه با چالش‌های مقیاس‌پذیری و سازمانی
   انجام می‌دهند. آن‌ها با یک برنامه monolithic شروع می‌کنند و سپس monolith را به microservices تقسیم می‌کنند.
  </p>
<p>
   مشکلات تقسیم یک monolith به microservices کاملاً به پیچیدگی برنامه monolithic بستگی دارد. یک برنامه monolithic با
   ویژگی‌های زیاد، تلاش معماری زیادی و بررسی دقیق را برای موفقیت در تقسیم به microservices می‌طلبد و پیچیدگی
   اضافی با نیاز به سازماندهی مجدد و بازسازی تیم‌ها معرفی می‌شود. تصمیم به انتقال به microservices همیشه باید به یک
   تلاش در سراسر شرکت تبدیل شود.
  </p>
<p>
   چندین مرحله برای جدا کردن یک monolith وجود دارد. اولین قدم شناسایی componentهایی است که باید به عنوان
   سرویس‌های مستقل نوشته شوند. این شاید دشوارترین مرحله در کل این process باشد، زیرا در حالی که ممکن است راه‌های
   درستی برای تقسیم monolith به سرویس‌های component وجود داشته باشد، راه‌های اشتباه بسیار بیشتر وجود دارد.
   قاعده سرانگشتی در شناسایی components این است که عملکردهای کلی اصلی monolith را مشخص کنید، سپس آن
   عملکردها را به اجزای مستقل کوچک تقسیم کنید. Microservices باید تا حد امکان ساده باشند، در غیر این صورت
   شرکت خطر جایگزینی یک monolith را با چندین monolith کوچکتر خواهد داشت که همگی از همان مشکلاتی که با
   رشد شرکت به وجود می‌آید، رنج خواهند برد.
  </p>
<p>
   هنگامی که عملکردهای کلیدی شناسایی و به درستی به microservices مستقل componentized شدند، ساختار سازمانی
   شرکت باید بازسازی شود.
  </p>
<p>از Monoliths به Microservices | 7</p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 15" src="page_0015/image_1.png"/></div>
</div>
            </div>
            <div class="page original-page">
                <img src="page_0015_original/original_page.png" alt="Original Page 15">
            </div>
        </div>
        <div class="dual-page-spread">
            <div class="page persian-page">
                <div class="translated-content">
<div>
<p>
   به گونه‌ای ساختاردهی شود که هر microservice توسط یک تیم مهندسی پشتیبانی شود. چندین راه برای انجام این کار وجود
   دارد. اولین روش سازماندهی مجدد شرکت حول پذیرش microservice این است که یک تیم را به هر microservice اختصاص
   دهید. اندازه تیم کاملاً با پیچیدگی و حجم کار microservice تعیین می‌شود و باید توسط توسعه‌دهندگان و مهندسان قابلیت
   اطمینان سایت به اندازه کافی پشتیبانی شود تا هم توسعه ویژگی و هم چرخش در دسترس بودن سرویس بدون تحمیل بار به تیم
   مدیریت شود. دومی این است که چندین سرویس را به یک تیم اختصاص دهید و از آن تیم بخواهید سرویس‌ها را به موازات هم
   توسعه دهند. این روش زمانی بهترین عملکرد را دارد که تیم‌ها حول محصولات یا حوزه‌های تجاری خاص سازماندهی شده
   باشند و مسئول توسعه هرگونه سرویس مرتبط با آن محصولات یا حوزه‌ها باشند. اگر شرکتی روش دوم سازماندهی مجدد را
   انتخاب کند، باید اطمینان حاصل کند که توسعه‌دهندگان بیش از حد کار نمی‌کنند و با وظایف، قطعی‌ها یا خستگی عملیاتی
   مواجه نمی‌شوند.
  </p>
<p>
   یکی دیگر از بخش‌های مهم پذیرش microservice، ایجاد یک اکوسیستم microservice است. به طور معمول (یا، حداقل،
   امیدواریم)، شرکتی که یک برنامه monolithic بزرگ را اجرا می‌کند، یک سازمان زیرساختی اختصاصی خواهد داشت که
   مسئول طراحی، ساخت و نگهداری زیرساختی است که برنامه بر روی آن اجرا می‌شود. هنگامی که یک monolith به
   microservices تقسیم می‌شود، مسئولیت‌های سازمان زیرساختی برای ارائه یک پلتفرم پایدار برای توسعه و اجرای
   microservices به شدت افزایش می‌یابد. تیم‌های زیرساخت باید زیرساخت پایداری را در اختیار تیم‌های microservice قرار
   دهند که اکثر پیچیدگی‌های تعاملات بین microservices را انتزاع می‌کند.
  </p>
<p>
   هنگامی که این سه مرحله تکمیل شد—componentization برنامه، بازسازی تیم‌های مهندسی برای پشتیبانی از هر
   microservice، و توسعه سازمان زیرساختی در داخل شرکت—مهاجرت می‌تواند آغاز شود. برخی از تیم‌ها کد مربوطه
   microservice خود را مستقیماً از monolith به یک سرویس جداگانه بیرون می‌کشند و ترافیک monolith را تا زمانی که
   متقاعد شوند که microservice می‌تواند عملکرد مورد نظر خود را به تنهایی انجام دهد، در سایه قرار می‌دهند. سایر
   تیم‌ها انتخاب می‌کنند که سرویس را از ابتدا بسازند، با یک صفحه تمیز شروع کنند، و ترافیک را در سایه قرار دهند یا
   پس از گذراندن آزمایش‌های مناسب سرویس را دوباره هدایت کنند. بهترین رویکرد برای مهاجرت به عملکرد
   microservice بستگی دارد و من دیده‌ام که هر دو رویکرد در بیشتر موارد به یک اندازه خوب عمل می‌کنند، اما کلید
   واقعی یک مهاجرت موفق، برنامه‌ریزی و اجرای کامل، دقیق و با دقت مستند شده، همراه با درک این است که
   مهاجرت کامل یک monolith بزرگ می‌تواند چندین سال طول بکشد.
  </p>
<p>
   با توجه به تمام کارهای انجام شده در تقسیم یک monolith به microservices، ممکن است بهتر باشد که با معماری
   microservice شروع کنیم، از تمام چالش‌های مقیاس‌پذیری دردناک صرف نظر کنیم و از درام مهاجرت microservice اجتناب
   کنیم. این رویکرد ممکن است برای برخی از شرکت‌ها درست باشد، اما می‌خواهم چندین کلمه احتیاط را ارائه کنم. شرکت‌های
   کوچک اغلب زیرساخت‌های لازم را برای حفظ microservices، حتی در مقیاس بسیار کوچک، ندارند: معماری microservice
   خوب به زیرساخت پایدار و اغلب بسیار پیچیده نیاز دارد. چنین زیرساخت پایداری به یک تیم بزرگ و اختصاصی نیاز دارد
  </p>
<p>8 | فصل 1: Microservices</p>
</div>
</div>
                <div class="page-images">
</div>
            </div>
            <div class="page original-page">
                <img src="page_0016_original/original_page.png" alt="Original Page 16">
            </div>
        </div>
        <div class="dual-page-spread">
            <div class="page persian-page">
                <div class="translated-content">
<div>
<p>
   که معمولاً هزینه‌های آن فقط توسط شرکت‌هایی که به چالش‌های مقیاس‌پذیری رسیده‌اند که انتقال به معماری
   microservice را توجیه می‌کنند، قابل تحمل است. شرکت‌های کوچک به سادگی ظرفیت عملیاتی کافی برای حفظ یک
   اکوسیستم microservice را نخواهند داشت. علاوه بر این، شناسایی حوزه‌ها و اجزای کلیدی برای ساختن در
   microservices زمانی که یک شرکت در مراحل اولیه قرار دارد، بسیار دشوار است: برنامه‌ها در شرکت‌های جدید
   ویژگی‌های زیادی نخواهند داشت، و نه بسیاری از حوزه‌های عملکردی جداگانه که می‌توانند به درستی به microservices
   تقسیم شوند.
  </p>
<h3>معماری Microservice</h3>
<p>
   معماری یک microservice (شکل 1-6) تفاوت چندانی با معماری استاندارد برنامه که در بخش اول این فصل پوشش داده شد
   (شکل 1-1) ندارد. هر microservice دارای سه component خواهد بود: یک قطعه frontend (سمت کلاینت)، برخی از
   کدهای backend که کار سنگین را انجام می‌دهند، و راهی برای ذخیره یا بازیابی هر داده مربوطه.
  </p>
<p>
   قطعه frontend و سمت کلاینت یک microservice برنامه معمولی شما نیست، بلکه یک API (رابط برنامه‌نویسی
   application programming interface) با endpoints استاتیک است. APIهای microservice که به خوبی طراحی شده‌اند به
   microservices اجازه می‌دهند به راحتی و به طور موثر تعامل داشته باشند و درخواست‌ها را به endpoint(های)
   API مربوطه ارسال کنند. به عنوان مثال، یک microservice که مسئول داده‌های مشتری است، ممکن است یک
   get_customer_information endpoint داشته باشد که سرویس‌های دیگر می‌توانند درخواست‌ها را به آن ارسال کنند تا
   اطلاعاتی درباره مشتریان بازیابی کنند، یک update_customer_information endpoint که سرویس‌های دیگر می‌توانند
   درخواست‌ها را برای به‌روزرسانی اطلاعات یک مشتری خاص ارسال کنند و یک
   delete_customer_information endpoint که سرویس‌ها می‌توانند برای حذف اطلاعات مشتری از آن استفاده کنند.
  </p>
<p>
   شکل 1-6. عناصر معماری microservice
  </p>
<p>
   این endpoints فقط در معماری و نظریه از هم جدا شده‌اند، نه در عمل، زیرا آن‌ها در کنار و به عنوان بخشی از تمام کد
   backend که هر درخواست را پردازش می‌کند، وجود دارند. برای مثال microservice ما که مسئول داده‌های مشتری است،
   درخواستی که به endpoint get_customer_information ارسال می‌شود، یک task را فعال می‌کند که درخواست
   دریافتی را پردازش می‌کند، هر فیلتر یا گزینه‌های خاصی را که در درخواست اعمال شده است، تعیین می‌کند، اطلاعات را
   از یک پایگاه داده بازیابی می‌کند، اطلاعات را قالب‌بندی می‌کند و آن را به کلاینت (microservice) که آن را درخواست
   کرده است، برمی‌گرداند.
  </p>
<p>معماری Microservice | 9</p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 17" src="page_0017/image_1.png"/></div>
</div>
            </div>
            <div class="page original-page">
                <img src="page_0017_original/original_page.png" alt="Original Page 17">
            </div>
        </div>
        <div class="dual-page-spread">
            <div class="page persian-page">
                <div class="translated-content">
<div>
<p>
   اکثر microservices نوعی داده را ذخیره می‌کنند، چه در حافظه (شاید با استفاده از یک cache) یا یک پایگاه داده خارجی. اگر
   داده‌های مربوطه در حافظه ذخیره شوند، نیازی به برقراری یک تماس شبکه اضافی با یک پایگاه داده خارجی نیست و
   microservice می‌تواند به راحتی هر داده مربوطه را به یک کلاینت برگرداند. اگر داده‌ها در یک پایگاه داده خارجی ذخیره
   شوند، microservice باید یک درخواست دیگر به پایگاه داده ارسال کند، منتظر پاسخ بماند و سپس به پردازش task
   ادامه دهد.
  </p>
<p>
   این معماری در صورتی ضروری است که microservices قرار باشد با هم خوب کار کنند. پارادایم معماری microservice
   مستلزم این است که مجموعه‌ای از microservices با هم کار کنند تا آنچه در غیر این صورت به عنوان یک برنامه بزرگ واحد
   وجود دارد را تشکیل دهند، بنابراین عناصر خاصی از این معماری وجود دارد که در سراسر یک سازمان باید استاندارد شوند تا
   مجموعه‌ای از microservices با موفقیت و کارآمد تعامل داشته باشند.
  </p>
<p>
   API endpointsهای microservices باید در سراسر یک سازمان استاندارد شوند. این بدان معنا نیست که همه microservices
   باید endpointsهای خاص یکسانی داشته باشند، بلکه نوع endpoint باید یکسان باشد. دو نوع بسیار رایج از API
   endpoints برای microservices REST یا Apache Thrift هستند، و من برخی از microservicesها را دیده‌ام که هر دو
   نوع endpoint را دارند (اگرچه این مورد نادر است، نظارت را نسبتاً پیچیده می‌کند، و من شخصاً آن را توصیه نمی‌کنم).
   انتخاب نوع endpoint نشان‌دهنده عملکرد داخلی خود microservice است و همچنین معماری آن را دیکته می‌کند: به عنوان
   مثال، ساختن یک microservice ناهمزمان که از طریق HTTP بر روی endpointsهای REST ارتباط برقرار می‌کند، دشوار
   است، که مستلزم افزودن یک endpoint مبتنی بر پیام‌رسانی به سرویس‌ها نیز می‌شود.
  </p>
<p>
   Microservices از طریق remote procedure calls (RPC) با یکدیگر تعامل دارند، که تماس‌هایی بر روی شبکه هستند که
   دقیقاً شبیه تماس‌های procedure محلی به نظر می‌رسند و رفتار می‌کنند. پروتکل‌های مورد استفاده به انتخاب‌های
   معماری و پشتیبانی سازمانی، و همچنین endpointsهای مورد استفاده، بستگی دارد. به عنوان مثال، یک microservice
   با endpointsهای REST احتمالاً با microservices دیگر از طریق HTTP تعامل دارد، در حالی که یک microservice با
   Thrift endpoints ممکن است با microservices دیگر از طریق HTTP یا یک راه‌حل داخلی‌تر و سفارشی‌شده ارتباط
   برقرار کند.
  </p>
<p>
   از نسخه سازی Microservices و Endpoints خودداری کنید
   <br/>
   یک microservice یک library نیست (در زمان کامپایل یا در طول زمان اجرا در حافظه بارگذاری نمی‌شود) بلکه یک برنامه
   نرم‌افزاری مستقل است. با توجه به ماهیت سریع توسعه microservice، نسخه سازی microservices می‌تواند به
   راحتی به یک کابوس سازمانی تبدیل شود، با توسعه‌دهندگانی در سرویس‌های کلاینت که نسخه‌های خاص (منسوخ شده،
   بدون نگهداری) یک microservice را در کد خود پین می‌کنند. باید با microservices به عنوان چیزهای زنده و در حال
   تغییر رفتار کرد، نه releases یا librariesهای ثابت. نسخه سازی API endpoints یک anti-pattern دیگر است که به
   همین دلایل باید از آن اجتناب شود.
  </p>
<p>10 | فصل 1: Microservices</p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 18" src="page_0018/image_1.png"/></div>
</div>
            </div>
            <div class="page original-page">
                <img src="page_0018_original/original_page.png" alt="Original Page 18">
            </div>
        </div>
        <div class="dual-page-spread">
            <div class="page persian-page">
                <div class="translated-content">
<div>
<p>
   هر نوع endpoint و هر پروتکلی که برای برقراری ارتباط با سایر microservices استفاده می‌شود، مزایا و معایبی خواهد
   داشت. تصمیمات معماری در اینجا نباید توسط توسعه‌دهنده فردی که در حال ساخت یک microservice است، گرفته شود،
   بلکه باید بخشی از طراحی معماری کل اکوسیستم microservice باشد (در بخش بعدی به این موضوع خواهیم پرداخت).
  </p>
<p>
   نوشتن یک microservice به توسعه‌دهنده آزادی زیادی می‌دهد: جدا از هر انتخاب سازمانی در مورد API endpoints و
   پروتکل‌های ارتباطی، توسعه‌دهندگان می‌توانند عملکرد داخلی microservice خود را به هر نحوی که می‌خواهند، بنویسند.
   می‌توان آن را به هر زبانی نوشت—می‌توان آن را به زبان Go، Java، Erlang، Haskell نوشت—تا زمانی که به endpoints و
   پروتکل‌های ارتباطی رسیدگی شود. توسعه یک microservice تفاوت چندانی با توسعه یک برنامه مستقل ندارد. برخی
   از هشدارها در این مورد وجود دارد، همانطور که در بخش پایانی این فصل ("Organizational Challenges" در صفحه 20)
   خواهیم دید، زیرا آزادی توسعه‌دهنده در مورد انتخاب زبان، هزینه سنگینی را برای سازمان مهندسی به همراه دارد.
  </p>
<p>
   به این ترتیب، یک microservice می‌تواند توسط دیگران به عنوان یک جعبه سیاه در نظر گرفته شود: شما مقداری
   اطلاعات را با ارسال یک درخواست به یکی از endpointsهای آن وارد می‌کنید و چیزی را بیرون می‌آورید. اگر آنچه را
   که می‌خواهید و نیاز دارید از microservice در زمان معقول و بدون هیچ خطای دیوانه‌واری دریافت کنید، کار خود را انجام
   داده است و نیازی به درک چیزی فراتر از endpointsهایی که باید به آن‌ها ضربه بزنید و اینکه آیا سرویس به درستی
   کار می‌کند یا خیر، وجود ندارد.
  </p>
<p>
   بحث ما در مورد جزئیات معماری microservice در اینجا به پایان می‌رسد—نه به این دلیل که همه چیز در مورد معماری
   microservice همین است، بلکه به این دلیل که هر یک از فصل‌های زیر در این کتاب به اختصاص دادن microservices به این
   حالت ideal black-box اختصاص دارد.
  </p>
<h3>اکوسیستم Microservice</h3>
<p>
   Microservices در انزوا زندگی نمی‌کنند. محیطی که microservices در آن ساخته می‌شوند، اجرا می‌شوند و با آن تعامل
   دارند، جایی است که آن‌ها زندگی می‌کنند. پیچیدگی‌های محیط microservice در مقیاس بزرگ با پیچیدگی‌های زیست‌محیطی
   یک جنگل بارانی، یک صحرا یا یک اقیانوس برابری می‌کند و در نظر گرفتن این محیط به عنوان یک اکوسیستم—یک
   اکوسیستم microservice—در پذیرش معماری microservice مفید است.
  </p>
<p>
   در اکوسیستم‌های microservice که به خوبی طراحی شده‌اند و پایدار هستند، microservices از تمام زیرساخت‌ها
   انتزاع شده‌اند. آن‌ها از سخت‌افزار، از شبکه‌ها، از build و pipeline استقرار، از کشف سرویس و load balancing
   انتزاع شده‌اند. این همه بخشی از زیرساخت اکوسیستم microservice است و ساخت، استانداردسازی و نگهداری این
   زیرساخت به روشی پایدار، مقیاس‌پذیر، تحمل‌کننده خطا و قابل اعتماد برای عملکرد موفق microservice ضروری است.
  </p>
<p>اکوسیستم Microservice | 11</p>
</div>
</div>
                <div class="page-images">
</div>
            </div>
            <div class="page original-page">
                <img src="page_0019_original/original_page.png" alt="Original Page 19">
            </div>
        </div>
        <div class="dual-page-spread">
            <div class="page persian-page">
                <div class="translated-content">
<div>
<p>
   زیرساخت باید اکوسیستم microservice را حفظ کند. هدف تمام مهندسان و معماران زیرساخت باید حذف نگرانی‌های
   عملیاتی سطح پایین از توسعه microservice و ساخت یک زیرساخت پایدار باشد که بتواند مقیاس‌پذیری داشته باشد،
   زیرساختی که توسعه‌دهندگان بتوانند به راحتی microservices را بر روی آن بسازند و اجرا کنند. توسعه یک microservice
   در یک اکوسیستم microservice پایدار باید درست مانند توسعه یک برنامه مستقل کوچک باشد. این امر نیازمند
   زیرساخت بسیار پیچیده و درجه یک است.
  </p>
<p>
   اکوسیستم microservice را می‌توان به چهار لایه تقسیم کرد (شکل 1-7)، اگرچه مرزهای هر کدام همیشه به وضوح
   مشخص نیستند: برخی از عناصر زیرساخت به هر قسمت از stack دست می‌زنند. سه لایه پایینی، لایه‌های زیرساخت
   هستند: در پایین stack لایه سخت‌افزار را می‌یابیم و در بالای آن، لایه ارتباطی (که به لایه چهارم می‌رود)، و به
   دنبال آن پلتفرم برنامه. لایه چهارم (بالایی) جایی است که تمام microservicesهای جداگانه در آن زندگی می‌کنند.
  </p>
<p>شکل 1-7. مدل چهار لایه از اکوسیستم microservice</p>
<h3>Layer 1: Hardware</h3>
<p>
   در پایین‌ترین قسمت اکوسیستم microservice، لایه سخت‌افزار را می‌یابیم. این‌ها ماشین‌های واقعی، رایانه‌های فیزیکی
   واقعی هستند که تمام ابزارهای داخلی و تمام microservices بر روی آن‌ها اجرا می‌شوند. این سرورها در قفسه‌ها در
   داخل datacenters قرار دارند که توسط سیستم‌های HVAC گران قیمت خنک می‌شوند و با برق تغذیه می‌شوند.
   بسیاری از انواع مختلف سرورها می‌توانند در اینجا وجود داشته باشند: برخی برای پایگاه‌های داده بهینه شده‌اند. برخی
   دیگر برای پردازش کارهای فشرده CPU. این سرورها می‌توانند متعلق به خود شرکت باشند، یا از ارائه دهندگان ابری به
   اصطلاح مانند Elastic Compute Cloud (AWS EC2) آمازون وب سرویس، Google Cloud Platform (GCP) یا
   Microsoft Azure "اجاره" شوند.
  </p>
<p>
   انتخاب سخت‌افزار خاص توسط صاحبان سرورها تعیین می‌شود. اگر شرکت شما datacenters خود را اجرا می‌کند، انتخاب
   سخت‌افزار بر عهده شماست و می‌توانید انتخاب سرور را برای نیازهای خاص خود بهینه کنید. اگر سرورها را در cloud
   اجرا می‌کنید (که سناریوی رایج‌تر است)، انتخاب شما محدود به هر سخت‌افزاری است که توسط ارائه دهنده cloud ارائه
   می‌شود. انتخاب بین bare metal و cloud
  </p>
<p>12 | فصل 1: Microservices</p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 20" src="page_0020/image_1.png"/></div>
</div>
            </div>
            <div class="page original-page">
                <img src="page_0020_original/original_page.png" alt="Original Page 20">
            </div>
        </div>
        <div class="dual-page-spread">
            <div class="page persian-page">
                <div class="translated-content">
<div>
<p>
   انتخاب ارائه دهنده (یا ارائه دهندگان) یک تصمیم آسان نیست و هزینه، در دسترس بودن، قابلیت اطمینان و هزینه‌های عملیاتی
   موارد مهمی هستند که باید در نظر گرفته شوند.
  </p>
<p>
   مدیریت این سرورها بخشی از لایه سخت‌افزار است. هر سرور باید یک سیستم عامل نصب شده داشته باشد، و سیستم عامل باید
   در همه سرورها استاندارد شود. هیچ پاسخ صحیح و درستی در مورد اینکه یک اکوسیستم microservice باید از چه
   سیستم عاملی استفاده کند، وجود ندارد: پاسخ به این سوال کاملاً به برنامه‌هایی که می‌سازید، زبان‌هایی که با آن‌ها
   نوشته می‌شوند، و libraries و ابزارهایی که microservices شما نیاز دارند، بستگی دارد. اکثر اکوسیستم‌های
   microservice نوعی از لینوکس، معمولاً CentOS، Debian یا Ubuntu را اجرا می‌کنند، اما یک شرکت .NET، بدیهی
   است که متفاوت انتخاب می‌کند. انتزاعات اضافی را می‌توان ساخت و روی سخت‌افزار لایه‌بندی کرد: جداسازی منابع و
   انتزاع منابع (همانطور که توسط فناوری‌هایی مانند Docker و Apache Mesos ارائه می‌شود) نیز به این لایه تعلق
   دارند، همانطور که پایگاه‌های داده (اختصاصی یا مشترک) نیز تعلق دارند.
  </p>
<p>
   نصب یک سیستم عامل و تهیه سخت‌افزار، اولین لایه در بالای خود سرورها است. هر host باید تهیه و پیکربندی شود، و پس
   از نصب سیستم عامل، یک ابزار مدیریت پیکربندی (مانند Ansible، Chef یا Puppet) باید برای نصب تمام
   برنامه‌ها و تنظیم تمام پیکربندی‌های لازم استفاده شود.
  </p>
<p>
   Hostsها به نظارت در سطح host (با استفاده از چیزی مانند Nagios) و logging در سطح host مناسب نیاز دارند تا در
   صورت بروز هر اتفاقی (خرابی دیسک، خرابی شبکه، یا اگر استفاده از CPU افزایش یابد)، مشکلات مربوط به hosts
   را بتوان به راحتی تشخیص داد، کاهش داد و حل کرد. نظارت در سطح Host در ??? با جزئیات بیشتری پوشش داده شده
   است.
  </p>
<h3>خلاصه Layer 1: The Hardware Layer</h3>
<p>
   لایه سخت‌افزار (لایه 1) اکوسیستم microservice شامل موارد زیر است:
  </p>
<ul>
<li>سرورهای فیزیکی (متعلق به شرکت یا اجاره شده از ارائه دهندگان cloud)</li>
<li>پایگاه‌های داده (اختصاصی و/یا مشترک)</li>
<li>سیستم عامل</li>
<li>جداسازی و انتزاع منابع</li>
<li>مدیریت پیکربندی</li>
<li>نظارت در سطح Host</li>
<li>Logging در سطح Host</li>
</ul>
<h3>Layer 2: Communication</h3>
<p>
   لایه دوم اکوسیستم microservice، لایه ارتباطی است. لایه ارتباطی به تمام لایه‌های دیگر اکوسیستم (از جمله
  </p>
<p>The Microservice Ecosystem | 13</p>
</div>
</div>
                <div class="page-images">
</div>
            </div>
            <div class="page original-page">
                <img src="page_0021_original/original_page.png" alt="Original Page 21">
            </div>
        </div>
        <div class="dual-page-spread">
            <div class="page persian-page">
                <div class="translated-content">
<div>
<p>
   لایه application platform و لایه‌های microservices) است، زیرا جایی است که تمام ارتباطات بین سرویس‌ها مدیریت
   می‌شود؛ مرزهای بین لایه ارتباطی و هر لایه دیگر از اکوسیستم microservice ضعیف تعریف شده‌اند. در حالی که
   مرزها ممکن است واضح نباشند، عناصر مشخص هستند: لایه دوم یک اکوسیستم microservice همیشه شامل شبکه، DNS،
   RPCها و API endpoints، کشف سرویس، ثبت سرویس و load balancing است.
  </p>
<p>
   بحث در مورد عناصر شبکه و DNS لایه ارتباطی فراتر از محدوده این کتاب است، بنابراین ما در این بخش بر RPCها، API
   endpoints، کشف سرویس، ثبت سرویس و load balancing تمرکز خواهیم کرد.
  </p>
<h3>RPCها، endpointsها و پیام‌رسانی</h3>
<p>
   Microservices از طریق شبکه با استفاده از remote procedure calls (RPC) یا پیام‌رسانی به API endpointsهای
   microservicesهای دیگر (یا، همانطور که در مورد پیام‌رسانی خواهیم دید، به یک message broker که پیام را به درستی
   هدایت می‌کند) با یکدیگر تعامل دارند. ایده اصلی این است: با استفاده از یک پروتکل مشخص، یک microservice مقداری
   داده را با یک فرمت استاندارد از طریق شبکه به یک سرویس دیگر (شاید به API endpoint یک microservice دیگر) یا به یک
   message broker ارسال می‌کند که اطمینان حاصل می‌کند که داده‌ها به API endpoint یک microservice دیگر ارسال
   می‌شود.
  </p>
<p>
   چندین پارادایم ارتباطی microservice وجود دارد. اولین مورد، رایج‌ترین است: HTTP+REST/THRIFT. در
   HTTP+REST/THRIFT، سرویس‌ها با یکدیگر از طریق شبکه با استفاده از پروتکل انتقال ابرمتن (HTTP) ارتباط
   برقرار می‌کنند، و درخواست‌ها را ارسال و پاسخ‌ها را از یا به نقاط پایانی خاص انتقال حالت نمایندگی (REST)
   (با استفاده از روش‌های مختلف، مانند GET، POST و غیره) یا نقاط پایانی خاص Apache Thrift (یا هر دو) دریافت
   می‌کنند. داده‌ها معمولاً به صورت JSON (یا protocol buffers) از طریق HTTP فرمت‌بندی و ارسال می‌شوند.
  </p>
<p>
   HTTP+REST راحت‌ترین شکل ارتباط microservice است. هیچ سورپرایزی وجود ندارد، راه‌اندازی آن آسان است و
   پایدارترین و قابل اعتمادترین است—عمدتاً به این دلیل که پیاده‌سازی نادرست آن دشوار است. نقطه ضعف پذیرش این
   پارادایم این است که به‌ناچار، synchronous (مسدودکننده) است.
  </p>
<p>
   پارادایم ارتباطی دوم، messaging است. Messaging ناهمزمان (non-blocking) است، اما کمی پیچیده‌تر است.
   Messaging به روش زیر عمل می‌کند: یک microservice داده‌ها (یک پیام) را از طریق شبکه (HTTP یا غیره) به یک
   message broker ارسال می‌کند، که ارتباط را به microservicesهای دیگر هدایت می‌کند.
  </p>
<p>
   Messaging در چندین نوع ارائه می‌شود، که دو مورد از محبوب‌ترین آن‌ها publish–subscribe (pubsub) messaging
   و request–response messaging هستند. در مدل‌های pubsub، کلاینت‌ها در یک موضوع مشترک می‌شوند و هر زمان که
   یک ناشر پیامی را به آن موضوع منتشر می‌کند، پیامی دریافت می‌کنند. مدل‌های request–response سرراست‌تر هستند،
   جایی که یک کلاینت درخواستی را به یک سرویس (یا message broker) ارسال می‌کند، که با اطلاعات درخواستی پاسخ
   می‌دهد. برخی از فناوری‌های پیام‌رسانی وجود دارند که ترکیبی منحصربه‌فرد از هر دو مدل هستند، مانند Apache Kafka.
   Celery و Redis (یا Celery با RabbitMQ) می‌توانند باشند
  </p>
<p>14 | فصل 1: Microservices</p>
</div>
</div>
                <div class="page-images">
</div>
            </div>
            <div class="page original-page">
                <img src="page_0022_original/original_page.png" alt="Original Page 22">
            </div>
        </div>
        <div class="dual-page-spread">
            <div class="page persian-page">
                <div class="translated-content">
<div>
<p>
   استفاده شده برای پیام‌رسانی (و پردازش وظایف) برای microservices نوشته شده در Python: Celery وظایف و/یا پیام‌ها را با استفاده
   از Redis یا RabbitMQ به عنوان broker پردازش می‌کند.
  </p>
<p>
   Messaging دارای چندین نقطه ضعف مهم است که باید کاهش یابد. اگر برای مقیاس‌پذیری از همان ابتدا معماری شده باشد،
   Messaging می‌تواند به همان اندازه مقیاس‌پذیر (اگر نه بیشتر مقیاس‌پذیر) از راه‌حل‌های HTTP+REST باشد. ذاتاً،
   messaging به همان اندازه آسان برای تغییر و به‌روزرسانی نیست، و ماهیت متمرکز آن (در حالی که ممکن است مانند
   یک مزیت به نظر برسد) می‌تواند منجر به تبدیل صف‌ها و brokers به نقاط شکست برای کل اکوسیستم شود.
  </p>
<p>
   ماهیت ناهمزمان messaging می‌تواند در صورت عدم آمادگی، منجر به race conditions و حلقه‌های بی‌پایان شود. اگر یک
   سیستم پیام‌رسانی با محافظت در برابر این مشکلات پیاده‌سازی شود، می‌تواند به اندازه یک راه‌حل synchronous، پایدار
   و کارآمد شود.
  </p>
<h3>کشف سرویس، ثبت سرویس و load balancing</h3>
<p>
   در معماری monolithic، فقط لازم است ترافیک به یک برنامه ارسال شود و به سرورهای میزبان برنامه به درستی توزیع
   شود. در معماری microservice، ترافیک باید به تعداد زیادی از برنامه‌های مختلف به درستی هدایت شود، و سپس به سرورهای
   میزبان هر microservice خاص به درستی توزیع شود. برای اینکه این کار به طور کارآمد و موثر انجام شود، معماری
   microservice مستلزم آن است که سه فناوری در لایه ارتباطی پیاده‌سازی شوند: کشف سرویس، ثبت سرویس و load
   balancing.
  </p>
<p>
   به طور کلی، هنگامی که یک microservice A نیاز به ایجاد یک درخواست به microservice B دیگری دارد،
   microservice A باید آدرس IP و پورت یک نمونه خاص که در آن microservice B میزبانی می‌شود را بداند. به طور
   مشخص‌تر، لایه ارتباطی بین microservices باید آدرس‌های IP و پورت‌های این microservices را بداند تا
   درخواست‌ها بین آن‌ها به درستی هدایت شوند. این کار از طریق کشف سرویس (مانند etcd، Consul، Hyperbahn یا
   ZooKeeper) انجام می‌شود، که اطمینان می‌دهد که درخواست‌ها دقیقاً به جایی که باید ارسال شوند، هدایت می‌شوند و
   (بسیار مهم) فقط به نمونه‌های سالم هدایت می‌شوند. کشف سرویس نیاز به یک ثبت سرویس دارد، که یک پایگاه داده است
   که تمام پورت‌ها و IPهای تمام microservicesها را در سراسر اکوسیستم ردیابی می‌کند.
  </p>
<h3>Dynamic Scaling و پورت‌های اختصاص داده شده</h3>
<p>
   در معماری microservice، پورت‌ها و IPها می‌توانند (و تغییر می‌کنند) دائماً تغییر کنند، به خصوص با مقیاس‌بندی و
   استقرار مجدد microservices (به خصوص با یک لایه انتزاع سخت‌افزاری مانند Apache Mesos).
   <br/>
   یک راه برای نزدیک شدن به کشف و مسیریابی، اختصاص پورت‌های static (هم frontend و هم backend) به هر
   microservice است.
  </p>
<p>
   مگر اینکه شما هر microservice را فقط روی یک نمونه میزبانی کنید (که بسیار بعید است)، به load balancing در
   بخش‌های مختلف لایه ارتباطی در سراسر اکوسیستم microservice نیاز خواهید داشت. load balancing، در یک سطح
   بسیار بالا، اینگونه کار می‌کند: اگر 10 نمونه مختلف دارید که یک microservice را میزبانی می‌کنند، load-balancing
  </p>
<p>اکوسیستم Microservice | 15</p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 23" src="page_0023/image_1.png"/></div>
</div>
            </div>
            <div class="page original-page">
                <img src="page_0023_original/original_page.png" alt="Original Page 23">
            </div>
        </div>
        <div class="dual-page-spread">
            <div class="page persian-page">
                <div class="translated-content">
<div>
<p>
   نرم‌افزار (و/یا سخت‌افزار) اطمینان حاصل می‌کند که ترافیک در سراسر تمام نمونه‌ها توزیع (متعادل) می‌شود.
   load balancing در هر مکانی در اکوسیستم که در آن درخواستی به یک برنامه ارسال می‌شود، مورد نیاز خواهد بود، به
   این معنی که هر اکوسیستم microservice بزرگ شامل لایه‌های load balancing زیادی خواهد بود. load balancerهای
   معمولاً مورد استفاده برای این منظور عبارتند از Amazon Web Services Elastic Load Balancer، Netflix Eureka،
   HAProxy و Nginx.
  </p>
<h3>خلاصه Layer 2: The Communication Layer</h3>
<p>
   لایه ارتباطی (لایه 2) اکوسیستم microservice شامل موارد زیر است:
  </p>
<ul>
<li>شبکه</li>
<li>DNS</li>
<li>Remote procedure calls (RPCs)</li>
<li>Endpoints</li>
<li>پیام‌رسانی</li>
<li>کشف سرویس</li>
<li>ثبت سرویس</li>
<li>Load balancing</li>
</ul>
<h3>Layer 3: The Application Platform</h3>
<p>
   پلتفرم برنامه، لایه سوم اکوسیستم microservice است و شامل تمام ابزارها و سرویس‌های داخلی است که مستقل از
   microservices هستند. این لایه پر از ابزارها و سرویس‌های مرکزی و سراسری اکوسیستم است که باید به گونه‌ای
   ساخته شوند که تیم‌های توسعه microservice مجبور نباشند چیزی به جز microservices خود را طراحی، ساخت یا
   نگهداری کنند.
  </p>
<p>
   یک پلتفرم برنامه خوب، پلتفرمی است با ابزارهای داخلی سلف‌سرویس برای توسعه‌دهندگان، یک process توسعه
   استاندارد، یک سیستم ساخت و release متمرکز و خودکار، تست خودکار، یک راه‌حل استقرار استاندارد و متمرکز،
   و logging متمرکز و نظارت در سطح microservice. بسیاری از جزئیات این عناصر در فصل‌های بعدی پوشش داده شده
   است، اما ما چندین مورد از آن‌ها را در اینجا به طور خلاصه پوشش خواهیم داد تا مقدمه‌ای بر مفاهیم اساسی ارائه
   دهیم.
  </p>
<p>ابزارهای توسعه داخلی سلف‌سرویس</p>
<p>
   چندین مورد را می‌توان به عنوان ابزارهای توسعه داخلی سلف‌سرویس طبقه‌بندی کرد، و اینکه چه چیزهایی در این
   دسته قرار می‌گیرند، نه تنها به نیازهای توسعه‌دهندگان، بلکه به سطح انتزاع و پیچیدگی زیرساخت و اکوسیستم به
   طور کلی بستگی دارد. کلید تعیین اینکه کدام ابزارها باید ساخته شوند،
  </p>
<p>16 | فصل 1: Microservices</p>
</div>
</div>
                <div class="page-images">
</div>
            </div>
            <div class="page original-page">
                <img src="page_0024_original/original_page.png" alt="Original Page 24">
            </div>
        </div>
        <div class="dual-page-spread">
            <div class="page persian-page">
                <div class="translated-content">
<div>
<p>
   برای اولین بار، حوزه‌های مسئولیت را تقسیم کنید و سپس مشخص کنید که توسعه‌دهندگان برای طراحی، ساخت و نگهداری
   سرویس‌های خود به چه وظایفی باید قادر باشند.
  </p>
<p>
   در یک شرکت که معماری microservice را پذیرفته است، مسئولیت‌ها باید با دقت به تیم‌های مهندسی مختلف واگذار
   شوند. یک راه آسان برای انجام این کار این است که یک زیرسازمان مهندسی برای هر لایه از اکوسیستم microservice،
   همراه با تیم‌های دیگری که هر لایه را به هم متصل می‌کنند، ایجاد کنید. هر یک از این سازمان‌های مهندسی، که
   به‌طور نیمه مستقل عمل می‌کنند، مسئولیت همه چیز در لایه خود را بر عهده خواهند داشت: تیم‌های TechOps
   مسئول لایه 1 خواهند بود، تیم‌های زیرساخت مسئول لایه 2 خواهند بود، تیم‌های پلتفرم برنامه مسئول لایه 3
   خواهند بود و تیم‌های microservice مسئول لایه 4 خواهند بود (البته این یک دیدگاه بسیار ساده شده است، اما شما
   ایده کلی را دریافت می‌کنید).
  </p>
<p>
   در این طرح سازمانی، هر زمان که یک مهندس که روی یکی از لایه‌های بالاتر کار می‌کند نیاز به راه‌اندازی، پیکربندی
   یا استفاده از چیزی در یکی از لایه‌های پایین‌تر داشته باشد، باید یک ابزار سلف‌سرویس وجود داشته باشد که مهندس
   بتواند از آن استفاده کند. به عنوان مثال، تیمی که روی پیام‌رسانی برای اکوسیستم کار می‌کند باید یک ابزار
   سلف‌سرویس بسازد تا اگر یک توسعه‌دهنده در تیم microservice نیاز به پیکربندی پیام‌رسانی برای سرویس خود دارد،
   بتواند به راحتی پیام‌رسانی را بدون نیاز به درک تمام پیچیدگی‌های سیستم پیام‌رسانی، پیکربندی کند.
  </p>
<p>
   دلایل زیادی برای داشتن این ابزارهای متمرکز و سلف‌سرویس برای هر لایه وجود دارد. در یک اکوسیستم microservice
   متنوع، مهندس متوسط ​​در هر تیم، هیچ دانش (یا بسیار کم) در مورد نحوه عملکرد سرویس‌ها و سیستم‌ها در تیم‌های
   دیگر نخواهد داشت، و به سادگی هیچ راهی وجود ندارد که آن‌ها بتوانند در هر سرویس و سیستم متخصص شوند، در حالی
   که روی خودشان کار می‌کنند—به سادگی نمی‌توان این کار را انجام داد. هر توسعه‌دهنده به طور جداگانه تقریباً هیچ
   چیز به جز سرویس خود را نخواهد دانست، اما در کنار هم، تمام توسعه‌دهندگان که در اکوسیستم کار می‌کنند،
   به‌طور جمعی همه چیز را خواهند دانست. به جای تلاش برای آموزش هر توسعه‌دهنده در مورد پیچیدگی‌های هر ابزار و
   سرویس در اکوسیستم، رابط‌های کاربری پایدار و آسان برای استفاده را برای هر قسمت از اکوسیستم بسازید، و سپس
   آن‌ها را در مورد نحوه استفاده از آن‌ها آموزش دهید و تربیت کنید. همه چیز را به یک جعبه سیاه تبدیل کنید و دقیقاً
   نحوه عملکرد و نحوه استفاده از آن را مستند کنید.
  </p>
<p>
   دلیل دوم برای ساختن این ابزارها و ساختن آن‌ها به خوبی این است که، صادقانه بگویم، شما نمی‌خواهید توسعه‌دهنده‌ای از
   تیم دیگر بتواند تغییرات اساسی در سرویس یا سیستم شما ایجاد کند، به خصوص تغییری که می‌تواند باعث قطعی شود.
   این امر به ویژه برای سرویس‌ها و سیستم‌های متعلق به لایه‌های پایین‌تر (لایه 1، لایه 2 و لایه 3) صادق و اجباری
   است. اجازه دادن به افراد غیرمتخصص برای ایجاد تغییرات در چیزهای داخل این لایه‌ها، یا درخواست (یا بدتر از آن،
   انتظار) از آن‌ها برای متخصص شدن در این حوزه‌ها، یک دستورالعمل برای فاجعه است. نمونه‌ای از جایی که این می‌تواند
   به طرز وحشتناکی اشتباه شود، مدیریت پیکربندی است: اجازه دادن به توسعه‌دهندگان در تیم‌های microservice برای
   ایجاد تغییرات در پیکربندی‌های سیستم بدون داشتن تخصص لازم برای انجام این کار، می‌تواند و منجر به قطعی‌های
   تولید در مقیاس بزرگ شود، اگر تغییری ایجاد شود که بر چیزی غیر از سرویس خودشان تأثیر بگذارد.
  </p>
<p>اکوسیستم Microservice | 17</p>
</div>
</div>
                <div class="page-images">
</div>
            </div>
            <div class="page original-page">
                <img src="page_0025_original/original_page.png" alt="Original Page 25">
            </div>
        </div>
        <div class="dual-page-spread">
            <div class="page persian-page">
                <div class="translated-content">
<div>
<h3>چرخه توسعه</h3>
<p>
   هنگامی که توسعه‌دهندگان در حال ایجاد تغییراتی در microservices موجود هستند یا microservices جدیدی ایجاد
   می‌کنند، توسعه را می‌توان با ساده‌سازی و استانداردسازی process توسعه و خودکارسازی تا حد امکان، موثرتر کرد.
   جزئیات استانداردسازی خود process توسعه پایدار و قابل اعتماد در فصل 4، مقیاس‌پذیری و عملکرد، پوشش داده شده
   است، اما چندین مورد وجود دارد که برای امکان توسعه پایدار و قابل اعتماد باید در لایه سوم یک اکوسیستم microservice
   وجود داشته باشند.
  </p>
<p>
   اولین نیاز، یک سیستم کنترل نسخه متمرکز است که در آن همه کدها را می‌توان ذخیره، ردیابی، نسخه‌بندی و جستجو
   کرد. این معمولاً از طریق چیزی مانند GitHub، یا یک repository git یا svn که خود میزبانی می‌شود و به نوعی ابزار
   همکاری مانند Phabrictor متصل است، انجام می‌شود و این ابزارها نگهداری و بررسی کد را آسان می‌کنند.
  </p>
<p>
   نیاز دوم، یک محیط توسعه پایدار و کارآمد است. محیط‌های توسعه به دلیل وابستگی‌های پیچیده‌ای که هر microservice
   به سرویس‌های دیگر خواهد داشت، پیاده‌سازی آن‌ها در اکوسیستم‌های microservice بسیار دشوار است، اما آن‌ها
   کاملاً ضروری هستند. برخی از سازمان‌های مهندسی ترجیح می‌دهند که تمام توسعه به صورت محلی (روی لپ‌تاپ
   توسعه‌دهنده) انجام شود، اما این می‌تواند منجر به استقرارهای بد شود، زیرا به توسعه‌دهنده تصویری دقیقی از نحوه
   عملکرد تغییرات کدش در دنیای تولید نمی‌دهد. پایدارترین و قابل اعتمادترین راه برای طراحی یک محیط توسعه، ایجاد
   یک آینه از محیط production (که staging نیست، نه canary، و نه production) است که حاوی تمام زنجیره‌های
   وابستگی پیچیده است.
  </p>
<h3>Test، build، package و release</h3>
<p>
   مراحل test، build، package و release در بین توسعه و استقرار باید تا حد امکان استاندارد و متمرکز شوند. پس از
   چرخه توسعه، هنگامی که هر تغییری در کد انجام شده است، باید تمام تست‌های لازم اجرا شوند و releases جدید باید
   به طور خودکار build و packaged شوند. ابزارهای continuous integration دقیقاً برای این منظور وجود دارد و
   راه‌حل‌های موجود (مانند Jenkins) بسیار پیشرفته و آسان برای پیکربندی هستند. این ابزارها خودکارسازی کل process
   را آسان می‌کنند و فضای بسیار کمی را برای خطای انسانی باقی می‌گذارند.
  </p>
<h3>Pipeline استقرار</h3>
<p>
   pipeline استقرار، processی است که از طریق آن کد جدید پس از چرخه توسعه و پس از مراحل test، build، package و
   release، به سرورهای تولید می‌رسد. استقرار می‌تواند به سرعت در یک اکوسیستم microservice بسیار پیچیده شود،
   جایی که صدها استقرار در روز غیرعادی نیست. ایجاد ابزار حول استقرار و استانداردسازی practiceهای استقرار برای
   تمام تیم‌های توسعه اغلب ضروری است. اصول ساخت پایدار و قابل اعتماد
  </p>
<p>18 | فصل 1: Microservices</p>
</div>
</div>
                <div class="page-images">
</div>
            </div>
            <div class="page original-page">
                <img src="page_0026_original/original_page.png" alt="Original Page 26">
            </div>
        </div>
        <div class="dual-page-spread">
            <div class="page persian-page">
                <div class="translated-content">
<div>
<p>
   (آماده تولید) pipelineهای استقرار در فصل 3، پایداری و قابلیت اطمینان، با جزئیات پوشش داده شده است.
  </p>
<h3>Logging و نظارت</h3>
<p>
   تمام microservicesها باید logging در سطح microservice از تمام درخواست‌های ارسالی به microservice
   (شامل تمام اطلاعات مربوطه و مهم) و پاسخ‌های آن داشته باشند.
  </p>
<p>
   با توجه به ماهیت سریع توسعه microservice، اغلب بازتولید باگ‌ها در کد غیرممکن است زیرا بازسازی وضعیت
   سیستم در زمان خرابی غیرممکن است. Logging خوب در سطح microservice اطلاعاتی را در اختیار توسعه‌دهندگان
   قرار می‌دهد که برای درک کامل وضعیت سرویس‌شان در یک زمان خاص در گذشته یا حال نیاز دارند. نظارت در سطح
   microservice بر تمام معیارهای کلیدی microservices به دلایل مشابه ضروری است: نظارت دقیق و بلادرنگ به
   توسعه‌دهندگان اجازه می‌دهد تا همیشه از سلامت و وضعیت سرویس خود آگاه باشند. Logging و نظارت در سطح
   microservice در ??? با جزئیات بیشتری پوشش داده شده است.
  </p>
<h3>خلاصه Layer 3: The Application Platform Layer</h3>
<p>
   لایه پلتفرم برنامه (لایه 3) اکوسیستم microservice شامل موارد زیر است:
  </p>
<ul>
<li>ابزارهای توسعه داخلی سلف‌سرویس</li>
<li>محیط توسعه</li>
<li>ابزارهای test، package، build و release</li>
<li>Pipeline استقرار</li>
<li>Logging در سطح Microservice</li>
<li>نظارت در سطح Microservice</li>
</ul>
<h3>Layer 4: Microservices</h3>
<p>
   در بالای اکوسیستم microservice، لایه microservice (لایه 4) قرار دارد. این لایه جایی است که microservicesها—و
   هر چیز خاصی که به آن‌ها مربوط می‌شود—زندگی می‌کنند، که کاملاً از لایه‌های زیرساخت پایین‌تر انتزاع شده‌اند. در
   اینجا آن‌ها از سخت‌افزار، از استقرار، از کشف سرویس، از load balancing و از ارتباط انتزاع شده‌اند. تنها
   چیزهایی که از لایه microservice انتزاع نشده‌اند، پیکربندی‌های خاص هر سرویس برای استفاده از ابزارها هستند.
  </p>
<p>
   در مهندسی نرم‌افزار، این practice رایج است که تمام پیکربندی‌های برنامه را متمرکز کنیم تا پیکربندی‌ها برای یک
   ابزار یا مجموعه خاصی از ابزارها (مانند مدیریت پیکربندی، جداسازی منابع یا ابزارهای استقرار) همگی با خود ابزار
   ذخیره شوند. به عنوان مثال، پیکربندی‌های استقرار سفارشی برای برنامه‌ها اغلب نه با کد برنامه، بلکه با کد ابزار
   استقرار ذخیره می‌شوند. این
  </p>
<p>اکوسیستم Microservice | 19</p>
</div>
</div>
                <div class="page-images">
</div>
            </div>
            <div class="page original-page">
                <img src="page_0027_original/original_page.png" alt="Original Page 27">
            </div>
        </div>
        <div class="dual-page-spread">
            <div class="page persian-page">
                <div class="translated-content">
<div>
<p>
   این practice برای معماری monolithic و حتی برای اکوسیستم‌های microservice کوچک خوب عمل می‌کند، اما در اکوسیستم‌های
   microservice بسیار بزرگ که شامل صدها microservices و ده‌ها ابزار داخلی (که هر کدام پیکربندی‌های سفارشی خود را
   دارند) می‌شود، این practice نسبتاً نامرتب می‌شود: توسعه‌دهندگان در تیم‌های microservice ملزم به ایجاد تغییراتی در
   codebaseهای ابزارهای موجود در لایه‌های زیر هستند و اغلب فراموش می‌کنند که پیکربندی‌های خاصی کجا قرار دارند (یا
   اصلاً وجود دارند). برای کاهش این مشکل، تمام پیکربندی‌های مختص microservice می‌تواند در repository microservice
   قرار داشته باشد و باید توسط ابزارها و سیستم‌های لایه‌های زیر در آنجا قابل دسترسی باشد.
  </p>
<h3>خلاصه Layer 4: The Microservice Layer</h3>
<p>
   لایه microservice (لایه 4) اکوسیستم microservice شامل موارد زیر است:
  </p>
<ul>
<li>Microservicesها</li>
<li>تمام پیکربندی‌های مختص microservice</li>
</ul>
<h3>چالش‌های سازمانی</h3>
<p>
   پذیرش معماری microservice، مهم‌ترین چالش‌های ارائه شده توسط معماری برنامه monolithic را حل می‌کند.
   Microservicesها به دلیل چالش‌های مقیاس‌پذیری یکسان، عدم کارایی یا مشکلات در پذیرش فناوری‌های جدید،
   دچار مشکل نمی‌شوند: آن‌ها برای مقیاس‌پذیری، برای کارایی، برای سرعت توسعه‌دهنده بهینه شده‌اند. در صنعتی که
   فناوری‌های جدید به سرعت مورد توجه بازار قرار می‌گیرند، هزینه سازمانی محض نگهداری و تلاش برای بهبود یک
   برنامه monolithic دست و پا گیر، به سادگی عملی نیست. با در نظر گرفتن این موارد، تصور اینکه چرا هر کسی در
   تقسیم یک monolith به microservices، اکراه دارد، چرا هر کسی در مورد ساخت یک اکوسیستم microservice از
   ابتدا محتاط است، دشوار است.
  </p>
<p>
   Microservices راه‌حل جادویی (و تا حدودی بدیهی) به نظر می‌رسند، اما ما بهتر از این می‌دانیم. در The Mythical
   Man-Month، فردریک بروکس توضیح داد که چرا هیچ گلوله نقره‌ای در مهندسی نرم‌افزار وجود ندارد، ایده‌ای که او
   به شرح زیر خلاصه کرد:
  </p>
<p>
   "هیچ توسعه‌ای واحد، چه در فناوری و چه در تکنیک مدیریت، که به خودی خود بهبود یک مرتبه را در
   بهره‌وری، قابلیت اطمینان و سادگی در طول یک دهه نوید می‌دهد، وجود ندارد."
  </p>
<p>
   وقتی خودمان را با فناوری مواجه می‌بینیم که نوید ارائه بهبودهای چشمگیر را می‌دهد، باید به دنبال trade-offs
   باشیم. Microservices مقیاس‌پذیری بیشتر و کارایی بیشتری را نوید می‌دهند، اما می‌دانیم که این‌ها هزینه‌ای را
   برای بخشی از کل سیستم به همراه خواهد داشت.
  </p>
<p>
   چهار trade-off به ویژه مهم وجود دارد که با معماری microservice همراه است. اولین مورد، تغییر در ساختار
   سازمانی است که به سمت isolation تمایل دارد
  </p>
<p>20 | فصل 1: Microservices</p>
</div>
</div>
                <div class="page-images">
</div>
            </div>
            <div class="page original-page">
                <img src="page_0028_original/original_page.png" alt="Original Page 28">
            </div>
        </div>
        <div class="dual-page-spread">
            <div class="page persian-page">
                <div class="translated-content">
<div>
<p>
   و ارتباط ضعیف بین تیم‌ها—نتیجه معکوس قانون Conway.
   <br/>
   دومین مورد، افزایش چشمگیر technical sprawl است، sprawling که نه تنها برای کل سازمان بسیار پرهزینه است، بلکه هزینه‌های
   قابل توجهی را نیز برای هر مهندس به همراه دارد. سومین trade-off، افزایش توانایی سیستم در شکست است.
   <br/>
   چهارمین مورد، رقابت برای منابع مهندسی و زیرساختی است.
  </p>
<h3>قانون معکوس Conway</h3>
<p>
   ایده پشت قانون Conway (به نام برنامه‌نویس Melvin Conway در سال 1968) این است: معماری یک سیستم توسط
   ساختارهای ارتباطی و سازمانی شرکت تعیین می‌شود. قانون معکوس Conway (که ما آن را قانون معکوس Conway می‌نامیم)
   نیز معتبر است و به ویژه برای اکوسیستم microservice مرتبط است: ساختار سازمانی یک شرکت توسط معماری محصول آن
   تعیین می‌شود. بیش از 40 سال پس از معرفی قانون Conway، هر دو قانون و معکوس آن همچنان معتبر به نظر می‌رسند.
   اگر ساختار سازمانی مایکروسافت به عنوان معماری یک سیستم ترسیم شود، شباهت قابل توجهی به معماری محصولات آن
   دارد—همین امر در مورد گوگل، آمازون و هر شرکت بزرگ فناوری دیگر نیز صدق می‌کند. شرکت‌هایی که معماری
   microservice را اتخاذ می‌کنند، هرگز استثنایی برای این قانون نخواهند بود.
  </p>
<p>
   معماری Microservice از تعداد زیادی microservices کوچک، مجزا و مستقل تشکیل شده است. قانون معکوس Conway
   ایجاب می‌کند که ساختار سازمانی هر شرکتی که از معماری microservice استفاده می‌کند، از تعداد زیادی تیم بسیار
   کوچک، مجزا و مستقل تشکیل شده باشد. ساختارهای تیمی که از این امر ناشی می‌شوند، به طور اجتناب‌ناپذیری منجر به
   siloing و sprawling می‌شوند، مشکلاتی که هر بار که اکوسیستم microservice پیچیده‌تر، پیچیده‌تر، همزمان‌تر و
   کارآمدتر می‌شود، بدتر می‌شوند.
  </p>
<p>
   قانون معکوس Conway همچنین به این معنی است که توسعه‌دهندگان، از جهاتی، درست مانند microservices خواهند بود:
   آن‌ها قادر به انجام یک کار خواهند بود، و (امیدواریم) آن یک کار را خیلی خوب انجام دهند، اما از بقیه اکوسیستم
   جدا خواهند بود (در مسئولیت، در دانش دامنه و تجربه). هنگامی که با هم در نظر گرفته شوند، تمام توسعه‌دهندگانی که
   به طور جمعی در یک اکوسیستم microservice کار می‌کنند، همه چیز را که باید در مورد آن بدانند، می‌دانند، اما به
   طور جداگانه، آن‌ها بسیار تخصصی خواهند بود و فقط قطعات اکوسیستمی را که مسئول آن هستند، می‌دانند.
  </p>
<p>
   این امر یک مشکل سازمانی اجتناب‌ناپذیر را ایجاد می‌کند: حتی اگر microservicesها باید به طور جداگانه توسعه
   یابند (که منجر به تیم‌های جدا و سیلویی می‌شود)، آن‌ها در انزوا زندگی نمی‌کنند و باید بدون هیچ مشکلی با یکدیگر
   تعامل داشته باشند تا محصول کلی بتواند اصلاً کار کند. این امر مستلزم آن است که این تیم‌های جداگانه و با عملکرد
   مستقل، با هم نزدیک و مکرراً کار کنند—چیزی که با توجه به اینکه اهداف و پروژه‌های اکثر تیم‌ها (که در اهداف و
   نتایج کلیدی تیمشان، یا OKRها، کدگذاری شده‌اند) خاص یک microservice خاص هستند که روی آن کار می‌کنند،
   دشوار است.
  </p>
<p>چالش‌های سازمانی | 21</p>
</div>
</div>
                <div class="page-images">
</div>
            </div>
            <div class="page original-page">
                <img src="page_0029_original/original_page.png" alt="Original Page 29">
            </div>
        </div>
        <div class="dual-page-spread">
            <div class="page persian-page">
                <div class="translated-content">
<div>
<p>
   همچنین یک شکاف ارتباطی بزرگ بین تیم‌های microservice و تیم‌های زیرساخت وجود دارد که باید برطرف شود. به عنوان
   مثال، تیم‌های پلتفرم برنامه، باید سرویس‌ها و ابزارهای پلتفرمی را بسازند که تمام تیم‌های microservice از آن‌ها
   استفاده خواهند کرد، اما به دست آوردن الزامات و نیازها از صدها تیم microservice قبل از ساخت یک پروژه کوچک
   می‌تواند ماه‌ها (حتی سال‌ها) طول بکشد. وادار کردن توسعه‌دهندگان و تیم‌های زیرساخت برای همکاری یک کار آسان
   نیست.
  </p>
<p>
   یک مشکل مرتبط نیز وجود دارد که به لطف قانون معکوس Conway به وجود می‌آید، مشکلی که فقط به ندرت در شرکت‌هایی با
   معماری monolithic یافت می‌شود: دشواری در اجرای یک سازمان عملیاتی. با یک monolith، یک سازمان عملیاتی می‌تواند
   به راحتی برای برنامه نیرو بگیرد و در دسترس باشد، اما دستیابی به این امر با معماری microservice بسیار دشوار
   است زیرا مستلزم آن است که هر microservice توسط یک تیم توسعه و یک تیم عملیاتی پشتیبانی شود. در نتیجه،
   تیم‌های توسعه microservice باید مسئولیت انجام وظایف و کارهای عملیاتی مرتبط با microservice خود باشند. هیچ
   سازمان عملیاتی جداگانه‌ای برای تحویل در دسترس بودن وجود ندارد، هیچ سازمان عملیاتی جداگانه‌ای مسئول نظارت
   نیست: توسعه‌دهندگان باید برای سرویس‌های خود در دسترس باشند.
  </p>
<h3>Technical Sprawl</h3>
<p>
   trade-off دوم، technical sprawl است، که مربوط به مورد اول است. در حالی که قانون Conway و معکوس آن،
   sprawl سازمانی و siloing را برای microservices پیش‌بینی می‌کنند، نوع دوم sprawl (مرتبط با فناوری‌ها، ابزارها و
   مانند آن) نیز در معماری microservice اجتناب‌ناپذیر است. راه‌های مختلفی وجود دارد که technical sprawl می‌تواند
   خود را نشان دهد. ما در اینجا چند مورد از رایج‌ترین راه‌ها را پوشش خواهیم داد.
  </p>
<p>
   اگر یک اکوسیستم microservice بزرگ را در نظر بگیریم، که شامل 1000 microservices است، درک اینکه چرا معماری
   microservice منجر به technical sprawl می‌شود، آسان است. فرض کنید هر یک از این microservices توسط یک تیم
   توسعه شش نفره پشتیبانی می‌شود و هر توسعه‌دهنده از مجموعه ابزارهای مورد علاقه، کتابخانه‌های مورد علاقه خود
   استفاده می‌کند و به زبان‌های مورد علاقه خود کار می‌کند. هر یک از این تیم‌های توسعه روش استقرار خود، معیارهای
   مشخص‌شده خود را برای نظارت و هشدار، کتابخانه‌های خارجی و وابستگی‌های داخلی خود را که استفاده می‌کنند،
   scriptهای سفارشی برای اجرا بر روی ماشین‌های تولید و غیره دارند.
  </p>
<p>
   اگر هزار تا از این تیم‌ها داشته باشید، این بدان معناست که در یک سیستم هزار راه برای انجام یک کار وجود دارد. هزار
   راه برای استقرار، هزار library برای نگهداری، هزار روش مختلف برای هشدار، نظارت، تست و رسیدگی به قطعی‌ها
   وجود خواهد داشت. تنها راه برای کاهش technical sprawl، استانداردسازی در هر سطح از اکوسیستم microservice است.
  </p>
<p>
   نوع دیگری از technical sprawl نیز وجود دارد که مربوط به انتخاب زبان است. Microservicesها به خاطر وعده آزادی
   بیشتر توسعه‌دهنده، آزادی انتخاب هر زبان و library که فرد می‌خواهد، بدنام هستند. این در اصل امکان‌پذیر است و
   می‌تواند در عمل درست باشد، اما با رشد یک اکوسیستم microservice، اغلب
  </p>
<p>22 | فصل 1: Microservices</p>
</div>
</div>
                <div class="page-images">
</div>
            </div>
            <div class="page original-page">
                <img src="page_0030_original/original_page.png" alt="Original Page 30">
            </div>
        </div>
        <div class="dual-page-spread">
            <div class="page persian-page">
                <div class="translated-content">
<div>
<p>
   غیرعملی، پرهزینه و خطرناک است. برای اینکه ببینیم چرا این می‌تواند به یک مشکل تبدیل شود، سناریوی زیر را در نظر
   بگیرید. فرض کنید ما یک اکوسیستم microservice داریم که شامل 200 سرویس است، و تصور کنید که برخی از این
   microservicesها به زبان Python نوشته شده‌اند، برخی دیگر به زبان JavaScript، برخی به زبان Haskell، تعدادی به
   زبان Go، و چند مورد دیگر به زبان‌های Ruby، Java و C++. برای هر ابزار داخلی، برای هر سیستم و سرویس در هر
   لایه از اکوسیستم، باید برای هر یک از این زبان‌ها، libraryها نوشته شود.
  </p>
<p>
   لحظه‌ای را به تأمل در مورد میزان نگهداری و توسعه‌ای که باید انجام شود تا هر زبان از پشتیبانی مورد نیاز خود برخوردار
   شود، اختصاص دهید: این امر فوق‌العاده است و تعداد کمی از سازمان‌های مهندسی می‌توانند منابع مهندسی لازم را برای
   به انجام رساندن آن، تأمین کنند. انتخاب تعداد کمی از زبان‌های پشتیبانی شده و اطمینان از اینکه تمام libraryها و
   ابزارها با این زبان‌ها سازگار هستند و برای آن‌ها وجود دارند، واقع‌بینانه‌تر است تا تلاش برای پشتیبانی از تعداد زیادی
   زبان.
  </p>
<p>
   آخرین نوع technical sprawl که در اینجا به آن خواهیم پرداخت، technical debt است، که معمولاً به کاری اشاره دارد که
   باید انجام شود زیرا چیزی به روشی پیاده‌سازی شده است که کار را سریع انجام داده است، اما نه به بهترین یا بهینه‌ترین
   روش. با توجه به اینکه تیم‌های توسعه microservice می‌توانند ویژگی‌های جدید را با سرعت زیادی ارائه دهند،
   technical debt اغلب در پس‌زمینه به آرامی جمع می‌شود. هنگامی که قطعی‌ها رخ می‌دهند، هنگامی که چیزها خراب
   می‌شوند، هر کاری که از بررسی incident بیرون می‌آید، به ندرت بهترین راه‌حل کلی خواهد بود: تا آنجا که به تیم‌های
   توسعه microservice مربوط می‌شود، هر چیزی که مشکل را به سرعت و در لحظه برطرف کرد (یا برطرف کرد) به اندازه
   کافی خوب بود، و هر راه‌حل بهتری به آینده موکول می‌شود.
  </p>
<h3>راه‌های بیشتر برای شکست</h3>
<p>
   Microservicesها، سیستم‌های توزیع‌شده بزرگ و پیچیده‌ای هستند که دارای قطعات کوچک و مستقل زیادی هستند که
   به‌طور مداوم در حال تغییر هستند. واقعیت کار با سیستم‌های پیچیده از این نوع این است که componentهای جداگانه
   شکست خواهند خورد، آن‌ها اغلب شکست خواهند خورد و به روش‌هایی شکست خواهند خورد که هیچ‌کس نمی‌تواند
   پیش‌بینی کند. اینجاست که trade-off سوم وارد عمل می‌شود: معماری microservice راه‌های بیشتری را برای شکست
   سیستم شما معرفی می‌کند.
  </p>
<p>
   راه‌هایی برای آمادگی برای شکست، برای کاهش شکست‌ها زمانی که رخ می‌دهند، و برای آزمایش محدودیت‌ها و مرزهای
   componentهای جداگانه و کل اکوسیستم وجود دارد، که من در ??? پوشش می‌دهم. با این حال، مهم است که درک
   کنیم که صرف نظر از تعداد آزمایش‌های انعطاف‌پذیری که اجرا می‌کنید، صرف نظر از تعداد شکست‌ها و سناریوهای فاجعه
   که تعیین کرده‌اید، نمی‌توانید از این واقعیت فرار کنید که سیستم شکست خواهد خورد. شما فقط می‌توانید تمام تلاش
   خود را بکنید تا برای زمانی که این اتفاق می‌افتد، آماده شوید.
  </p>
<h3>رقابت برای منابع</h3>
<p>
   درست مانند هر اکوسیستم دیگری در دنیای طبیعی، رقابت برای منابع در اکوسیستم microservice شدید است. هر
   سازمان مهندسی دارای منابع محدودی است: دارای منابع مهندسی محدود (تیم‌ها، توسعه‌دهندگان) و سخت‌افزار و
   زیرساخت‌های محدود
  </p>
<p>چالش‌های سازمانی | 23</p>
</div>
</div>
                <div class="page-images">
</div>
            </div>
            <div class="page original-page">
                <img src="page_0031_original/original_page.png" alt="Original Page 31">
            </div>
        </div>
        <div class="dual-page-spread">
            <div class="page persian-page">
                <div class="translated-content">
<div>
<p>
   ساختاری منابع (ماشین‌های فیزیکی، سخت‌افزار cloud، ذخیره‌سازی پایگاه داده و غیره) و هر منبع هزینه‌های زیادی را برای
   شرکت به همراه دارد.
  </p>
<p>
   هنگامی که اکوسیستم microservice شما دارای تعداد زیادی microservice و یک پلتفرم application platform بزرگ و
   پیشرفته است، رقابت بین تیم‌ها برای سخت‌افزار و منابع زیرساختی اجتناب‌ناپذیر است: هر سرویس، هر ابزار به یک
   اندازه مهم تلقی می‌شود، نیازهای مقیاس‌بندی آن به عنوان بالاترین اولویت ارائه می‌شود.
  </p>
<p>
   به همین ترتیب، هنگامی که تیم‌های پلتفرم برنامه از تیم‌های microservice برای مشخصات و نیازها درخواست می‌کنند تا
   بتوانند سیستم‌ها و ابزارهای خود را به درستی طراحی کنند، هر تیم توسعه microservice استدلال خواهد کرد که نیازهای
   آن‌ها مهم‌ترین است و اگر شامل نشوند، ناامید (و بالقوه بسیار ناامید) خواهند شد. این نوع رقابت برای منابع مهندسی
   می‌تواند منجر به رنجش بین تیم‌ها شود.
  </p>
<p>
   شاید آخرین نوع رقابت برای منابع، بدیهی‌ترین باشد: رقابت بین مدیران، بین تیم‌ها و بین بخش‌ها/سازمان‌های مهندسی
   مختلف برای نیروی کار مهندسی. حتی با افزایش فارغ‌التحصیلان علوم کامپیوتر و ظهور developer bootcamps،
   توسعه‌دهندگان واقعاً عالی یافتن آن‌ها دشوار است و نشان‌دهنده یکی از کمیاب‌ترین و کمیاب‌ترین منابع است.
  </p>
<p>
   هنگامی که صدها یا هزاران تیم وجود دارند که می‌توانند از یک مهندس یا دو مهندس اضافی استفاده کنند، هر تیم
   اصرار خواهد کرد که تیم آن‌ها بیشتر از هر یک از تیم‌های دیگر به یک مهندس اضافی نیاز دارد.
  </p>
<p>
   هیچ راهی برای اجتناب از رقابت برای منابع وجود ندارد، اگرچه راه‌هایی برای کاهش تا حدودی رقابت وجود دارد. مؤثرترین
   روش به نظر می‌رسد این است که تیم‌ها را از نظر اهمیت و بحرانی بودن برای کسب و کار کلی سازماندهی یا طبقه‌بندی
   کنیم و سپس دسترسی تیم‌ها به منابع را بر اساس اولویت یا اهمیت آن‌ها فراهم کنیم. این روش دارای اشکالاتی است،
   زیرا تمایل دارد منجر به تیم‌های ابزار توسعه‌ای با کارکنان ضعیف و پروژه‌هایی شود که اهمیت آن‌ها در شکل دادن به
   آینده نهفته است (مانند پذیرش فناوری‌های زیرساختی جدید) که رها می‌شوند.
  </p>
<p>24 | فصل 1: Microservices</p>
</div>
</div>
                <div class="page-images">
</div>
            </div>
            <div class="page original-page">
                <img src="page_0032_original/original_page.png" alt="Original Page 32">
            </div>
        </div>
        <div class="dual-page-spread">
            <div class="page persian-page">
                <div class="translated-content">
<div>
<h3>فصل 3</h3>
<h3>پایداری و قابلیت اطمینان</h3>
<p>
   یک microservice آماده تولید، پایدار و قابل اعتماد است. هم microservicesهای جداگانه و هم اکوسیستم
   microservice به طور مداوم در حال تغییر و تحول هستند، و هر تلاشی که برای افزایش پایداری و قابلیت اطمینان یک
   microservice انجام شود، راه درازی را به سمت اطمینان از سلامت و در دسترس بودن کل اکوسیستم طی می‌کند. در این
   فصل، راه‌های مختلفی برای ساخت و اجرای یک microservice پایدار و قابل اعتماد بررسی می‌شود، از جمله استانداردسازی
   process توسعه، ساخت pipelineهای استقرار جامع، درک وابستگی‌ها و محافظت در برابر شکست‌های آن‌ها، ساخت
   routing و کشف پایدار و قابل اعتماد، و ایجاد proceduresهای deprecation و decommissioning مناسب برای
   microservices قدیمی یا منسوخ شده و/یا endpointsهای آن‌ها.
  </p>
<h3>اصول ساخت Microservices پایدار و قابل اعتماد</h3>
<p>
   معماری microservice خود را به توسعه سریع می‌سپارد. آزادی ارائه شده توسط microservices به این معنی است که
   اکوسیستم در حالت تغییر مداوم خواهد بود، هرگز ثابت نخواهد بود، همیشه در حال تحول است. ویژگی‌ها هر روز اضافه
   خواهند شد، ساخت‌های جدید چندین بار در روز مستقر می‌شوند و فناوری‌های قدیمی با فناوری‌های جدیدتر و بهتر با
   سرعت خیره‌کننده‌ای جایگزین می‌شوند. این آزادی و انعطاف‌پذیری منجر به نوآوری واقعی و ملموس می‌شود، اما هزینه‌های
   زیادی را به همراه دارد.
  </p>
<p>
   نوآوری، افزایش سرعت و بهره‌وری توسعه‌دهندگان، پیشرفت سریع فناوری، و اکوسیستم microservice در حال تغییر
   به‌طور مداوم، اگر هر قطعه‌ای از اکوسیستم microservice ناپایدار یا غیرقابل اعتماد شود، می‌توانند به سرعت به یک
   توقف ناگهانی برسند. در برخی موارد، آنچه برای تعطیلی کل کسب‌وکار لازم است، استقرار یک build خراب یا یک build
   حاوی یک باگ در یک microservice حیاتی برای کسب‌وکار است.
  </p>
<p>25</p>
</div>
</div>
                <div class="page-images">
</div>
            </div>
            <div class="page original-page">
                <img src="page_0033_original/original_page.png" alt="Original Page 33">
            </div>
        </div>
        <div class="dual-page-spread">
            <div class="page persian-page">
                <div class="translated-content">
<div>
<p>
   یک microservice پایدار، سرویسی است که برای آن، توسعه، استقرار، پذیرش فناوری‌های جدید و از رده خارج کردن یا
   deprecate کردن سایر سرویس‌ها، منجر به بی‌ثباتی در سراسر اکوسیستم microservice بزرگ‌تر نمی‌شود. این امر مستلزم
   اعمال اقداماتی برای محافظت در برابر عواقب منفی است که ممکن است توسط این نوع تغییرات معرفی شوند. یک
   microservice قابل اعتماد، سرویسی است که می‌توان به آن توسط سایر microservicesها و توسط کل اکوسیستم اعتماد
   کرد. پایداری با قابلیت اطمینان همراه است زیرا هر نیاز به پایداری، نیاز به قابلیت اطمینان را نیز به همراه دارد (و
   برعکس): به عنوان مثال، processهای استقرار پایدار با این الزام همراه است که هر استقرار جدید قابلیت اطمینان
   microservice را از دیدگاه یکی از کلاینت‌ها یا وابستگی‌های آن‌ها به خطر نیندازد.
  </p>
<p>
   چندین کار وجود دارد که می‌توان برای اطمینان از پایداری و قابلیت اطمینان یک microservice انجام داد. یک چرخه توسعه
   استاندارد را می‌توان برای محافظت در برابر practiceهای توسعه ضعیف پیاده‌سازی کرد. process استقرار را می‌توان به
   گونه‌ای طراحی کرد که تغییرات کد مجبور شوند قبل از راه‌اندازی در تمام سرورهای تولید، از مراحل متعددی عبور کنند.
   می‌توان از شکست‌های وابستگی محافظت کرد. health checkها، routing مناسب و circuit breaking می‌توانند در کانال‌های
   routing و کشف ایجاد شوند تا الگوهای ترافیکی غیرعادی را مدیریت کنند. در نهایت، microservicesها و endpointsهای
   آن‌ها می‌توانند deprecate و/یا decommission شوند بدون اینکه باعث هیچ‌گونه شکستی برای سایر microservicesها
   شوند.
  </p>
<h3>یک سرویس آماده تولید، پایدار و قابل اعتماد است</h3>
<ul>
<li>دارای یک چرخه توسعه استاندارد است.</li>
<li>کد آن از طریق تست‌های lint، unit، integration و end-to-end کاملاً تست شده است.</li>
<li>process تست، بسته‌بندی، ساخت و release آن کاملاً خودکار است.</li>
<li>دارای یک pipeline استقرار استاندارد است که شامل مراحل staging، canary و production است.</li>
<li>کلاینت‌های آن شناخته شده‌اند.</li>
<li>وابستگی‌های آن شناخته شده‌اند، و پشتیبان‌گیری، جایگزین‌ها، fallbacks و caching در صورت خرابی وجود دارد.</li>
<li>دارای routing و کشف پایدار و قابل اعتماد است.</li>
</ul>
<h3>چرخه توسعه</h3>
<p>
   پایداری و قابلیت اطمینان یک microservice با توسعه‌دهنده فردی که کد را به سرویس کمک می‌کند، شروع می‌شود.
   اکثر قطعی‌ها و خرابی‌های microservice ناشی از باگ‌هایی است که در کد معرفی شده‌اند و در مرحله توسعه، در هیچ یک
   از تست‌ها، یا در هیچ مرحله‌ای از process استقرار، شناسایی نشده‌اند. کاهش
  </p>
<p>26 | فصل 3: پایداری و قابلیت اطمینان</p>
</div>
</div>
                <div class="page-images">
</div>
            </div>
            <div class="page original-page">
                <img src="page_0034_original/original_page.png" alt="Original Page 34">
            </div>
        </div>
        <div class="dual-page-spread">
            <div class="page persian-page">
                <div class="translated-content">
<div>
<p>
   افزایش و حل این قطعی‌ها و شکست‌ها معمولاً مستلزم چیزی بیش از rollback به آخرین build پایدار، بازگرداندن هر
   commit حاوی باگ، و استقرار مجدد یک نسخه جدید (بدون باگ) از کد نیست.
  </p>
<h3>هزینه واقعی توسعه ناپایدار و غیرقابل اعتماد</h3>
<p>
   یک اکوسیستم microservice، غرب وحشی نیست. هر قطعی، هر incident و هر باگ می‌تواند و هزینه‌هایی را برای شرکت به
   اندازه هزاران (اگر نه میلیون‌ها) دلار در ساعات مهندسی و از دست دادن درآمد به همراه خواهد داشت. باید در طول چرخه
   توسعه (و همانطور که خواهیم دید، در pipeline استقرار) اقدامات احتیاطی برای گرفتن هر باگ قبل از رسیدن به production
   انجام شود.
  </p>
<p>
   یک چرخه توسعه پایدار و قابل اعتماد دارای چندین مرحله است (شکل 3-1).
  </p>
<p>شکل 3-1. چرخه توسعه</p>
<p>
   اول، توسعه‌دهنده تغییری در کد ایجاد می‌کند. این معمولاً با بررسی یک کپی از کد از یک repository مرکزی (معمولاً با
   استفاده از git یا svn)، ایجاد یک branch فردی که در آن تغییرات ایجاد می‌کنند، افزودن تغییرات خود به branch خود
   و اجرای هر unit و integration test شروع می‌شود. این مرحله از توسعه می‌تواند
  </p>
<p>چرخه توسعه | 27</p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 35" src="page_0035/image_1.png"/></div>
<div class="page-image"><img alt="Image from page 35" src="page_0035/image_2.png"/></div>
</div>
            </div>
            <div class="page original-page">
                <img src="page_0035_original/original_page.png" alt="Original Page 35">
            </div>
        </div>
        <div class="dual-page-spread">
            <div class="page persian-page">
                <div class="translated-content">
<div>
<p>
   در هر جایی رخ دهد: به صورت محلی روی لپ‌تاپ یک توسعه‌دهنده یا روی یک سرور در یک محیط توسعه. یک محیط توسعه
   قابل اعتماد—محیطی که دنیای production را با دقت منعکس می‌کند—کلیدی است، به خصوص اگر تست سرویس مورد نظر
   نیازمند ایجاد درخواست‌ها به سایر microservicesها یا خواندن یا نوشتن داده‌ها در یک پایگاه داده باشد.
  </p>
<p>
   هنگامی که کد به repository مرکزی commit شد، مرحله دوم شامل بررسی دقیق و کامل تغییر(ها) توسط سایر مهندسان تیم
   می‌شود. اگر همه بازبین‌ها، تغییرات را تأیید کرده باشند و تمام تست‌های lint، unit و integration در یک build جدید
   پاس شده باشد، تغییر می‌تواند در repository ادغام شود (به ???، برای اطلاعات بیشتر در مورد تست‌های lint، unit و
   integration مراجعه کنید). سپس، و فقط در این صورت، می‌توان تغییر جدید را به pipeline استقرار معرفی کرد.
  </p>
<h3>Test قبل از بررسی کد</h3>
<p>
   یک راه برای اطمینان از اینکه همه باگ‌ها قبل از رسیدن به production گرفته می‌شوند، اجرای تمام تست‌های lint، unit،
   integration و end-to-end قبل از فاز بررسی کد است. این کار را می‌توان با داشتن توسعه‌دهندگانی که روی یک branch
   جداگانه کار می‌کنند، آغاز کردن تمام تست‌ها بر روی آن branch به محض اینکه توسعه‌دهنده آن را برای بررسی کد
   ارسال می‌کند، و سپس فقط اجازه دادن به آن برای رسیدن به بررسی کد (یا فقط اجازه دادن به build شدن آن) پس از
   پاس کردن موفقیت‌آمیز تمام تست‌ها، انجام داد.
  </p>
<p>
   همانطور که در بخش مربوط به لایه 4 از اکوسیستم microservice در فصل 1، Microservices، ذکر شد، اتفاقات زیادی
   در بین چرخه توسعه و pipeline استقرار رخ می‌دهد. release جدید باید بسته‌بندی، build و کاملاً تست شود قبل از
   اینکه به اولین مرحله از pipeline استقرار برسد.
  </p>
<h3>Pipeline استقرار</h3>
<p>
   در اکوسیستم‌های microservice، فضای زیادی برای خطای انسانی وجود دارد، به خصوص در مورد practiceهای استقرار، و
   (همانطور که قبلاً ذکر کردم) اکثر قطعی‌ها در سیستم‌های production در مقیاس بزرگ ناشی از استقرارهای بد هستند.
   sprawl سازمانی را که همراه با پذیرش معماری microservice است و آنچه را که برای process استقرار به همراه
   دارد، در نظر بگیرید: شما حداقل ده‌ها (اگر نه صدها یا هزاران) تیم مستقل و مجزا دارید که تغییرات را در
   microservicesهای خود طبق برنامه‌های خود استقرار می‌دهند و اغلب بدون هماهنگی متقابل تیم‌ها بین کلاینت‌ها و
   وابستگی‌ها. اگر مشکلی پیش آمد، اگر باگی به production معرفی شد، یا اگر یک سرویس در طول استقرار به‌طور موقت
   در دسترس نبود، کل اکوسیستم می‌تواند تحت تأثیر منفی قرار گیرد. برای اطمینان از اینکه مشکلات با فرکانس کمتری
   رخ می‌دهند، و اینکه هرگونه شکست را می‌توان قبل از راه‌اندازی در تمام سرورهای تولید شناسایی کرد، معرفی یک
   pipeline استقرار استاندارد در سراسر سازمان مهندسی می‌تواند به اطمینان از پایداری و قابلیت اطمینان در سراسر
   اکوسیستم کمک کند.
  </p>
<p>28 | فصل 3: پایداری و قابلیت اطمینان</p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 36" src="page_0036/image_1.png"/></div>
</div>
            </div>
            <div class="page original-page">
                <img src="page_0036_original/original_page.png" alt="Original Page 36">
            </div>
        </div>
        <div class="dual-page-spread">
            <div class="page persian-page">
                <div class="translated-content">
<div>
<p>
   من در اینجا به process استقرار به عنوان یک "pipeline" اشاره می‌کنم زیرا قابل اعتمادترین استقرارها، استقرارهایی هستند که
   ملزم به گذراندن مجموعه‌ای از تست‌ها قبل از رسیدن به سرورهای production شده‌اند. ما می‌توانیم سه مرحله یا فاز مجزا را در
   این pipeline قرار دهیم (شکل 3-2): اول، می‌توانیم یک release جدید را در یک محیط staging آزمایش کنیم؛ دوم، اگر
   از فاز staging عبور کرد، می‌توانیم آن را در یک محیط canary کوچک مستقر کنیم، جایی که 5٪ تا 10٪ از ترافیک
   production را سرویس‌دهی می‌کند؛ و سوم، اگر از فاز canary عبور کرد، می‌توانیم آن را به آرامی در سرورهای production
   راه‌اندازی کنیم تا زمانی که در هر host مستقر شود.
  </p>
<p>شکل 3-2. مراحل یک pipeline استقرار پایدار و قابل اعتماد</p>
<h3>Staging</h3>
<p>
   هر release جدید ابتدا می‌تواند در یک محیط staging مستقر شود. یک محیط staging باید یک کپی دقیق از محیط
   production باشد: این بازتابی از وضعیت دنیای واقعی است، اما بدون ترافیک واقعی. محیط‌های staging معمولاً در همان
   مقیاس production اجرا نمی‌شوند (به عنوان مثال، آن‌ها معمولاً با همان تعداد hostها مانند production اجرا
   نمی‌شوند، پدیده‌ای که به آن host parity نیز گفته می‌شود)، زیرا اجرای آنچه به دو اکوسیستم جداگانه می‌رسد،
   می‌تواند هزینه سخت‌افزاری زیادی را به شرکت تحمیل کند. با این حال، برخی از سازمان‌های مهندسی ممکن است تعیین
   کنند که تنها راه برای کپی دقیق محیط production به روشی پایدار و قابل اعتماد، ساخت یک محیط staging یکسان با
   host parity است.
  </p>
<p>
   برای اکثر سازمان‌های مهندسی، تعیین ظرفیت و مقیاس سخت‌افزاری محیط staging به عنوان درصدی از production
   معمولاً به اندازه کافی دقیق است. ظرفیت staging لازم را می‌توان با روشی که برای تست microservice در فاز
   staging استفاده می‌کنیم، تعیین کرد. برای تست در محیط staging، ما چندین گزینه داریم: می‌توانیم ترافیک mock (یا
   ضبط شده) را از طریق microservice اجرا کنیم؛ می‌توانیم آن را به صورت دستی با ضربه زدن به endpointsهای آن و
   ارزیابی پاسخ‌های آن تست کنیم؛ می‌توانیم unit، integration و سایر تست‌های تخصصی خودکار را اجرا کنیم؛ یا
   می‌توانیم هر release جدید را با هر ترکیبی از این روش‌ها تست کنیم.
  </p>
<p>The Deployment Pipeline | 29</p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 37" src="page_0037/image_1.png"/></div>
</div>
            </div>
            <div class="page original-page">
                <img src="page_0037_original/original_page.png" alt="Original Page 37">
            </div>
        </div>
        <div class="dual-page-spread">
            <div class="page persian-page">
                <div class="translated-content">
<div>
<p>
   با Staging و Production به عنوان استقرارهای جداگانه از همان سرویس رفتار کنید
   <br/>
   ممکن است وسوسه شوید که staging و production را به عنوان سرویس‌های جداگانه اجرا کنید و آن‌ها را در
   repositoryهای جداگانه ذخیره کنید. این کار را می‌توان با موفقیت انجام داد، اما مستلزم این است که تغییرات در
   سراسر هر دو سرویس و repositoryها، از جمله تغییرات پیکربندی (که اغلب فراموش می‌شوند)، همگام‌سازی
   شوند. بسیار آسان‌تر است که با staging و production به عنوان "استقرارها" یا "فازها"ی جداگانه از همان
   microservice رفتار شود.
  </p>
<p>
   حتی اگر محیط‌های staging، محیط‌های تست هستند، با فاز توسعه و محیط توسعه در این مورد متفاوت هستند که یک
   release که به staging مستقر شده است، release است که کاندیدای production است. یک کاندیدای production
   باید قبلاً تست‌های lint، unit، integration و بررسی کد را با موفقیت پشت سر گذاشته باشد قبل از اینکه در یک
   محیط staging مستقر شود.
  </p>
<p>
   استقرار در یک محیط staging باید توسط توسعه‌دهندگان با همان جدیت و احتیاطی که استقرار در production انجام
   می‌شود، رفتار شود. اگر یک release با موفقیت در staging مستقر شود، می‌تواند به طور خودکار در canaries مستقر
   شود، که ترافیک production را اجرا می‌کنند.
  </p>
<p>
   راه‌اندازی محیط‌های staging در یک اکوسیستم microservice می‌تواند دشوار باشد، به دلیل پیچیدگی‌هایی که
   توسط وابستگی‌ها معرفی می‌شوند. اگر microservice شما به نه microservice دیگر بستگی دارد، پس به آن
   وابستگی‌ها متکی است تا در هنگام ارسال درخواست‌ها و خواندن یا نوشتن داده‌ها در پایگاه داده(های) مربوطه، پاسخ‌های
   دقیقی ارائه دهد. در نتیجه این پیچیدگی‌ها، موفقیت یک محیط staging به روشی که staging در سراسر شرکت
   استاندارد شده است، بستگی دارد.
  </p>
<h3>Full staging</h3>
<p>
   راه‌های مختلفی وجود دارد که می‌توان فاز staging از pipeline استقرار را پیکربندی کرد. اولین مورد، full staging (شکل
   3-3) است، که در آن یک اکوسیستم staging جداگانه به عنوان یک کپی آینه‌ای کامل از کل اکوسیستم production در حال
   اجرا است (اگرچه لزوماً با host parity نیست). Full staging همچنان بر روی همان زیرساخت اصلی production اجرا
   می‌شود، اما چندین تفاوت کلیدی وجود دارد. محیط‌های staging سرویس‌ها، حداقل، برای سایر سرویس‌ها توسط
   پورت‌های frontend و backend مخصوص staging در دسترس قرار می‌گیرند. مهم‌تر از آن، محیط‌های staging در یک
   اکوسیستم full-staging فقط با محیط‌های staging سایر سرویس‌ها ارتباط برقرار می‌کنند، و هرگز هیچ درخواستی را
   از سرویس‌هایی که در production اجرا می‌شوند، ارسال یا دریافت نمی‌کنند (که به معنی ارسال ترافیک به پورت‌های
   production از staging ممنوع است).
  </p>
<p>30 | فصل 3: پایداری و قابلیت اطمینان</p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 38" src="page_0038/image_1.png"/></div>
</div>
            </div>
            <div class="page original-page">
                <img src="page_0038_original/original_page.png" alt="Original Page 38">
            </div>
        </div>
        <div class="dual-page-spread">
            <div class="page persian-page">
                <div class="translated-content">
<div>
<p>شکل 3-3. Full staging</p>
<p>
   Full staging مستلزم این است که هر microservice دارای یک محیط staging کاملاً کاربردی باشد که سایر microservicesها
   می‌توانند با آن ارتباط برقرار کنند، زمانی که releases جدید مستقر می‌شوند. برقراری ارتباط با سایر microservicesها در
   اکوسیستم staging را می‌توان یا با نوشتن تست‌های خاصی که هنگام استقرار یک build جدید در محیط staging راه‌اندازی
   می‌شوند، یا همانطور که ذکر شد، با اجرای ترافیک production ضبط شده قدیمی یا ترافیک mock از طریق سرویس در حال
   استقرار همراه با تمام وابستگی‌های upstream و downstream انجام داد.
  </p>
<p>
   Full staging همچنین مستلزم رسیدگی دقیق به داده‌های تست است: محیط‌های staging نباید هرگز به هیچ پایگاه داده
   production دسترسی نوشتن داشته باشند و اعطای دسترسی خواندن به پایگاه‌های داده production نیز توصیه نمی‌شود.
   از آنجایی که full staging برای یک کپی آینه‌ای کامل از production طراحی شده است، هر محیط staging microservice
   باید حاوی یک پایگاه داده تست جداگانه باشد که بتواند از آن خوانده و در آن بنویسد.
  </p>
<h3>خطرات Full Staging</h3>
<p>
   هنگام پیاده‌سازی و استقرار محیط‌های full staging باید احتیاط کرد، زیرا releases جدید سرویس‌ها تقریباً همیشه با
   releasesهای جدید دیگر از هر وابستگی upstream و downstream ارتباط برقرار می‌کنند—این ممکن است بازتاب دقیقی از
   دنیای واقعی نباشد. سازمان‌های مهندسی ممکن است نیاز داشته باشند که از تیم‌ها بخواهند استقرارهایی را در staging
   هماهنگ و/یا برنامه‌ریزی کنند تا از استقرار یک سرویس که محیط staging را برای همه سرویس‌های مرتبط دیگر مختل
   می‌کند، جلوگیری کنند.
  </p>
<p>The Deployment Pipeline | 31</p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 39" src="page_0039/image_1.png"/></div>
<div class="page-image"><img alt="Image from page 39" src="page_0039/image_2.png"/></div>
</div>
            </div>
            <div class="page original-page">
                <img src="page_0039_original/original_page.png" alt="Original Page 39">
            </div>
        </div>
        <div class="dual-page-spread">
            <div class="page persian-page">
                <div class="translated-content">
<div>
<p>
   Partial staging
   <br/>
   نوع دوم محیط staging، partial staging نامیده می‌شود. همانطور که از نامش پیداست، این یک کپی آینه‌ای
   کامل از محیط production نیست. بلکه، هر microservice محیط staging خاص خود را دارد، که یک pool از سرورها
   با (حداقل) پورت‌های frontend و backend مخصوص staging است، و هنگامی که buildsهای جدید به فاز staging معرفی
   می‌شوند، با کلاینت‌های upstream و وابستگی‌های downstream که در production اجرا می‌شوند، ارتباط
   برقرار می‌کنند (شکل 3-4).
  </p>
<p>شکل 3-4. Partial staging</p>
<p>
   استقرارهای Partial staging باید به تمام endpointsهای production کلاینت‌ها و وابستگی‌های یک microservice ضربه
   بزنند تا وضعیت دنیای واقعی را تا حد امکان دقیق شبیه‌سازی کنند. برای انجام این کار، تست‌های staging خاصی باید
   نوشته و اجرا شوند، و هر ویژگی جدیدی که اضافه می‌شود، احتمالاً باید با حداقل یک تست staging اضافی همراه
   باشد تا اطمینان حاصل شود که به طور کامل تست شده است.
  </p>
<h3>خطرات Partial Staging</h3>
<p>
   از آنجایی که microservices با محیط‌های partial staging با microservicesهای production ارتباط برقرار
   می‌کنند، باید نهایت دقت را به عمل آورد.
   <br/>
   حتی اگر partial staging به درخواست‌های فقط خواندنی محدود شده باشد، سرویس‌های production می‌توانند به
   راحتی توسط استقرارهای staging بد که درخواست‌های بد ارسال می‌کنند و/یا سرویس‌های production را با
   درخواست‌های بیش از حد بارگذاری می‌کنند، از کار بیفتند.
  </p>
<p>
   این نوع از محیط‌های staging نیز باید به دسترسی فقط خواندنی پایگاه داده محدود شوند: یک محیط staging هرگز
   نباید در یک پایگاه داده production بنویسد. با این حال،
  </p>
<p>32 | فصل 3: پایداری و قابلیت اطمینان</p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 40" src="page_0040/image_1.png"/></div>
<div class="page-image"><img alt="Image from page 40" src="page_0040/image_2.png"/></div>
</div>
            </div>
            <div class="page original-page">
                <img src="page_0040_original/original_page.png" alt="Original Page 40">
            </div>
        </div>
        <div class="dual-page-spread">
            <div class="page persian-page">
                <div class="translated-content">
<div>
<p>
   برخی از microservicesها ممکن است بسیار write-heavy باشند، و تست کردن عملکرد نوشتن یک build جدید ضروری
   خواهد بود. رایج‌ترین راه برای انجام این کار این است که هر داده‌ای را که توسط یک محیط staging نوشته شده است،
   به عنوان داده‌های تست علامت‌گذاری کنید (این به عنوان test tenancy شناخته می‌شود)، اما ایمن‌ترین راه برای انجام این
   کار، نوشتن در یک پایگاه داده تست جداگانه است، زیرا دادن دسترسی نوشتن به یک محیط staging همچنان خطر
   تغییر داده‌های دنیای واقعی را به همراه دارد. برای مقایسه محیط‌های full و partial staging به جدول 3-1 مراجعه کنید.
  </p>
<p>جدول 3-1. محیط‌های Full staging در مقابل partial staging</p>
<table>
<tr>
<td></td>
<td>Full staging</td>
<td>Partial staging</td>
</tr>
<tr>
<td>کپی کامل از محیط production</td>
<td>بله</td>
<td>خیر</td>
</tr>
<tr>
<td>پورت‌های frontend و backend جداگانه staging</td>
<td>بله</td>
<td>بله</td>
</tr>
<tr>
<td>دسترسی به سرویس‌های production</td>
<td>خیر</td>
<td>بله</td>
</tr>
<tr>
<td>دسترسی خواندن به پایگاه‌های داده production</td>
<td>خیر</td>
<td>بله</td>
</tr>
<tr>
<td>دسترسی نوشتن به پایگاه‌های داده production</td>
<td>خیر</td>
<td>خیر</td>
</tr>
<tr>
<td>نیازمند rollbacks خودکار</td>
<td>خیر</td>
<td>بله</td>
</tr>
</table>
<p>
   محیط‌های Staging (full یا partial) باید مانند محیط‌های production، dashboardها، نظارت و logging داشته
   باشند—که همگی باید دقیقاً مشابه dashboardها، نظارت و logging محیط production microservice تنظیم شوند
   (به ??? مراجعه کنید). نمودارهای تمام معیارهای کلیدی را می‌توان در همان dashboard به‌عنوان تمام معیارهای
   production نگه داشت، اگرچه تیم‌ها ممکن است انتخاب کنند که برای هر قسمت از process استقرار، dashboardهای
   جداگانه داشته باشند: یک dashboard staging، یک dashboard canary و یک dashboard production. بسته به
   نحوه پیکربندی dashboardها، ممکن است بهتر باشد که تمام نمودارها را برای تمام استقرارها در یک dashboard
   نگه دارید و آن‌ها را بر اساس استقرار (یا بر اساس معیار) سازماندهی کنید. صرف نظر از اینکه یک تیم تصمیم می‌گیرد
   dashboardهای خود را چگونه راه‌اندازی کند، نباید هدف ساختن dashboardهای خوب و مفید آماده برای تولید را فراموش
   کرد: dashboard(ها) یک microservice آماده تولید باید تعیین سلامت و وضعیت سرویس را برای یک فرد بیرونی آسان
   کند.
  </p>
<p>
   نظارت و logging برای محیط staging باید با نظارت و logging استقرارهای staging و production یکسان باشد تا هرگونه
   شکست تست و خطاهای موجود در releases جدید که در staging مستقر می‌شوند قبل از اینکه به فاز بعدی pipeline
   استقرار منتقل شوند، شناسایی شوند. راه‌اندازی هشدارها و logs به گونه‌ای که بر اساس نوع استقرار تمایز و جدا
   شوند، بسیار مفید است، و اطمینان حاصل می‌شود که هر هشداری که توسط شکست‌ها یا خطاها ایجاد می‌شود، مشخص
   می‌کند که کدام محیط با مشکل مواجه است، و اشکال‌زدایی، کاهش و حل هرگونه باگ یا شکست را نسبتاً آسان و
   سرراست می‌کند.
  </p>
<p>
   هدف یک محیط staging، گرفتن هر گونه باگ معرفی شده توسط تغییرات کد قبل از تأثیرگذاری بر ترافیک production است.
   هنگامی که یک باگ توسط کد معرفی می‌شود، معمولاً در محیط staging شناسایی می‌شود (اگر به درستی تنظیم شده
   باشد). Rollbacksهای خودکار از استقرارهای بد، یک ضرورت برای محیط‌های partial staging هستند (اگرچه
  </p>
<p>The Deployment Pipeline | 33</p>
</div>
</div>
                <div class="page-images">
</div>
            </div>
            <div class="page original-page">
                <img src="page_0041_original/original_page.png" alt="Original Page 41">
            </div>
        </div>
        <div class="dual-page-spread">
            <div class="page persian-page">
                <div class="translated-content">
<div>
<p>
   (در محیط‌های full staging مورد نیاز نیستند). تعیین زمان برای بازگشت به یک build قبلی باید توسط آستانه‌های
   مختلف در معیارهای کلیدی microservice تعیین شود.
  </p>
<p>
   از آنجایی که partial staging مستلزم تعامل با microservicesهایی است که در production در حال اجرا هستند، باگ‌های
   معرفی شده توسط releases جدید که در یک محیط partial staging مستقر می‌شوند، می‌توانند سایر microservicesها را
   که در production در حال اجرا هستند، از کار بیندازند. اگر هیچ rollback خودکاری وجود نداشته باشد، کاهش و حل
   این مشکلات باید به صورت دستی انجام شود. هر مرحله از process استقرار که نیاز به مداخله دستی دارد، نقطه شکست
   نه تنها برای خود microservice، بلکه برای کل اکوسیستم microservice است.
  </p>
<p>
   آخرین سؤالی که یک تیم microservice باید هنگام راه‌اندازی یک محیط staging به آن پاسخ دهد این است که یک release
   جدید باید چه مدت در staging اجرا شود قبل از اینکه بتواند به canary (و پس از آن، به production) مستقر شود. پاسخ
   به این سوال توسط تست‌های خاص staging که در staging اجرا می‌شوند، تعیین می‌شود: یک build جدید به محض اینکه
   همه تست‌ها بدون شکست پاس شدند، آماده است که به مرحله بعدی process استقرار برود.
  </p>
<h3>Canary</h3>
<p>
   هنگامی که یک release جدید با موفقیت در staging مستقر شد و تمام تست‌های مورد نیاز را پشت سر گذاشت، build
   را می‌توان به مرحله بعدی در pipeline استقرار مستقر کرد: محیط canary. نام منحصربه‌فرد این محیط از یک تاکتیک
   استفاده شده توسط معدنچیان زغال سنگ گرفته شده است: آن‌ها canaries را با خود به معادن زغال سنگ می‌بردند تا سطح
   مونوکسید کربن را در هوا نظارت کنند؛ اگر canary می‌مرد، می‌دانستند که سطح گاز سمی در هوا زیاد است و معادن را
   ترک می‌کردند. ارسال یک build جدید به یک محیط canary همان هدف را دنبال می‌کند: آن را در یک pool کوچک از سرورها
   که ترافیک production را اجرا می‌کنند (حدود 5٪ تا 10٪ از ظرفیت production) مستقر کنید، و اگر زنده ماند،
   در بقیه سرورهای production مستقر کنید.
  </p>
<h3>توزیع ترافیک Canary</h3>
<p>
   اگر سرویس production در چندین datacenter، منطقه یا ارائه دهنده cloud مختلف مستقر شده باشد، آنگاه pool
   canary باید شامل سرورهایی در هر یک از این موارد باشد تا production را دقیقاً نمونه‌برداری کند.
  </p>
<p>
   از آنجایی که یک محیط canary به ترافیک production سرویس‌دهی می‌کند، باید بخشی از production در نظر گرفته
   شود. باید پورت‌های backend و frontend یکسانی داشته باشد، و hostsهای canary باید به طور تصادفی از pool سرورهای
   production انتخاب شوند تا نمونه‌برداری دقیقی از ترافیک production را تضمین کنند. Canaries می‌توانند (و باید)
   دسترسی کامل به سرویس‌های production داشته باشند: آن‌ها باید به تمام endpointsهای production upstream و
   downstream
  </p>
<p>34 | فصل 3: پایداری و قابلیت اطمینان</p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 42" src="page_0042/image_1.png"/></div>
</div>
            </div>
            <div class="page original-page">
                <img src="page_0042_original/original_page.png" alt="Original Page 42">
            </div>
        </div>
        <div class="dual-page-spread">
            <div class="page persian-page">
                <div class="translated-content">
<div>
<p>
   وابستگی‌ها، و آن‌ها باید به هر پایگاه داده‌ای (در صورت وجود) دسترسی خواندن و نوشتن داشته باشند.
  </p>
<p>
   همانند staging، dashboardها، نظارت و logging باید برای canariesها و production یکسان باشند. هشدارها و logs
   باید متمایز و برچسب‌گذاری شوند که از استقرار canary آمده‌اند تا توسعه‌دهندگان بتوانند به راحتی مشکلات را کاهش
   دهند، اشکال‌زدایی کنند و حل کنند.
  </p>
<h3>پورت‌های جداگانه برای Canaries و Production</h3>
<p>
   اختصاص پورت‌های frontend و backend جداگانه برای canaries و production به طوری که ترافیک بتواند
   عمدتاً هدایت شود، ممکن است ایده خوبی به نظر برسد، اما متأسفانه جدا کردن ترافیک به این شکل، هدف canaries را
   از بین می‌برد: نمونه‌برداری تصادفی از ترافیک production در یک pool کوچک از سرورها برای تست یک release
   جدید.
  </p>
<p>
   Rollbacks خودکار، مطلقاً برای canaries لازم است: اگر هر خطای شناخته‌شده‌ای رخ دهد، سیستم استقرار باید به طور
   خودکار به آخرین نسخه پایدار شناخته‌شده بازگردد. به یاد داشته باشید، canaries در حال ارائه ترافیک production
   هستند، و هر مشکلی که رخ می‌دهد، بر دنیای واقعی تأثیر می‌گذارد.
  </p>
<p>
   یک release جدید باید چه مدت در pool canary باقی بماند تا توسعه‌دهندگان بتوانند از آماده بودن آن برای production
   مطمئن شوند؟ این می‌تواند دقیقه، ساعت یا حتی روزها باشد، و پاسخ با الگوهای ترافیکی microservice تعیین می‌شود.
   ترافیک هر microservice، صرف نظر از اینکه microservice یا کسب و کار شما چقدر عجیب باشد، نوعی الگو را
   خواهد داشت. یک release جدید نباید مرحله canary استقرار را ترک کند تا زمانی که یک چرخه ترافیکی کامل تکمیل شده
   باشد. نحوه تعریف "چرخه ترافیکی" باید در سراسر کل سازمان مهندسی استاندارد شود، اما مدت زمان و الزامات چرخه
   ترافیکی ممکن است نیاز به ایجاد بر اساس یک سرویس به سرویس داشته باشد.
  </p>
<h3>Production</h3>
<p>Production دنیای واقعی است. هنگامی که یک build با موفقیت از چرخه توسعه عبور کرد، از staging جان سالم به
   در برد و در معادن زغال سنگ فاز canary زندگی کرد، آماده است که به استقرار production راه‌اندازی شود. در این
   مرحله از pipeline استقرار—آخرین گام—تیم توسعه باید کاملاً به build جدید اطمینان داشته باشد. هرگونه خطا در
   کد باید قبل از رسیدن به این مرحله، کشف، کاهش و حل شده باشد.
  </p>
<p>
   هر build که به production می‌رسد باید کاملاً پایدار و قابل اعتماد باشد. یک build که در حال استقرار در production
   است، باید از قبل کاملاً تست شده باشد، و یک build هرگز نباید به production مستقر شود تا زمانی که مراحل staging
   و canary را بدون هیچ مشکلی پشت سر گذاشته باشد. استقرار در production را می‌توان پس از اینکه build از canaries
   عبور کرد، در یک ضرب‌المثل انجام داد، یا می‌توان آن را به تدریج
  </p>
<p>The Deployment Pipeline | 35</p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 43" src="page_0043/image_1.png"/></div>
</div>
            </div>
            <div class="page original-page">
                <img src="page_0043_original/original_page.png" alt="Original Page 43">
            </div>
        </div>
        <div class="dual-page-spread">
            <div class="page persian-page">
                <div class="translated-content">
<div>
<p>
   به صورت مرحله‌ای راه‌اندازی می‌شود: توسعه‌دهندگان می‌توانند انتخاب کنند که با توجه به درصد سخت‌افزار
   (به عنوان مثال، ابتدا به 25٪ از تمام سرورها، سپس به 50٪، سپس 75٪ و در نهایت 100٪)، یا بر اساس datacenter، یا بر
   اساس منطقه، یا بر اساس کشور، یا هر ترکیبی از این موارد، به production راه‌اندازی کنند.
  </p>
<h3>اعمال استقرار پایدار و قابل اعتماد</h3>
<p>
   تا زمانی که یک کاندیدای جدید برای production، process توسعه را طی کرده باشد، از محیط staging جان سالم به در
   برده باشد و با موفقیت به فاز canary مستقر شده باشد، احتمال ایجاد یک قطعی بزرگ بسیار کم است، زیرا اکثر باگ‌ها
   در کد قبل از اینکه کاندیدای production به production راه‌اندازی شود، گرفته شده‌اند. دقیقاً به همین دلیل است که
   داشتن یک pipeline استقرار جامع برای ساختن یک microservice پایدار و قابل اعتماد ضروری است.
  </p>
<p>
   برای برخی از توسعه‌دهندگان، تأخیر ایجاد شده توسط pipeline استقرار ممکن است مانند یک بار غیر ضروری به نظر
   برسد زیرا باعث تأخیر در تغییرات کد و/یا ویژگی‌های جدید آن‌ها می‌شود تا بلافاصله پس از نوشته شدن، در production
   مستقر شوند. در واقعیت، تأخیر ایجاد شده توسط فازهای pipeline استقرار بسیار کوتاه و به راحتی قابل تنظیم است،
   اما پایبندی به process استقرار استاندارد باید برای اطمینان از قابلیت اطمینان اعمال شود. استقرار در یک
   microservice چندین بار در روز می‌تواند (و انجام می‌دهد) پایداری و قابلیت اطمینان microservice و هر سرویس
   دیگری را در زنجیره وابستگی پیچیده آن به خطر بیندازد: یک microservice که هر چند ساعت یک‌بار تغییر می‌کند،
   به‌ندرت یک microservice پایدار یا قابل اعتماد است.
  </p>
<p>
   توسعه‌دهندگان ممکن است وسوسه شوند که از فازهای staging و canary از process استقرار صرف‌نظر کنند و یک
   اصلاحیه را مستقیماً در production مستقر کنند اگر، به عنوان مثال، یک باگ جدی در production کشف شود. در حالی
   که این کار مشکل را به سرعت حل می‌کند، احتمالاً می‌تواند شرکت را از از دست دادن درآمد نجات دهد و از قطعی‌های
   وابستگی‌ها جلوگیری کند، اجازه دادن به توسعه‌دهندگان برای استقرار مستقیم در production فقط باید برای شدیدترین
   قطعی‌ها محفوظ باشد. بدون وجود این محدودیت‌ها، همیشه این احتمال ناگوار وجود دارد که از process سوء استفاده
   شود و مستقیماً در production مستقر شود: برای اکثر توسعه‌دهندگان، هر تغییر کد، هر استقرار مهم است و ممکن است
   به اندازه کافی مهم به نظر برسد که از staging و canary چشم‌پوشی شود، که پایداری و قابلیت اطمینان کل
   اکوسیستم microservice را به خطر می‌اندازد. هنگامی که شکست‌ها رخ می‌دهند، تیم‌های توسعه باید در عوض
   تشویق شوند که همیشه به آخرین build پایدار microservice برگردند، که microservice را به حالت شناخته شده
   (و قابل اعتماد) بازمی‌گرداند، که می‌تواند بدون هیچ مشکلی در production اجرا شود در حالی که تیم برای کشف
   علت اصلی شکست رخ داده تلاش می‌کند.
  </p>
<p>36 | فصل 3: پایداری و قابلیت اطمینان</p>
</div>
</div>
                <div class="page-images">
</div>
            </div>
            <div class="page original-page">
                <img src="page_0044_original/original_page.png" alt="Original Page 44">
            </div>
        </div>
        <div class="dual-page-spread">
            <div class="page persian-page">
                <div class="translated-content">
<div>
<h3>Hotfixes یک Anti-Pattern هستند</h3>
<p>
   هنگامی که یک pipeline استقرار در جای خود قرار دارد، نباید هرگز استقرار مستقیمی در production وجود داشته باشد،
   مگر اینکه یک موقعیت اضطراری وجود داشته باشد، اما حتی این نیز باید دلسرد شود. دور زدن مراحل اولیه pipeline
   استقرار اغلب باگ‌های جدیدی را به production وارد می‌کند، زیرا اصلاحات کد اضطراری خطر عدم تست مناسب را به همراه
   دارند.
   <br/>
   به جای استقرار یک hotfix مستقیماً در production، توسعه‌دهندگان باید در صورت امکان به آخرین build پایدار بازگردند.
  </p>
<p>
   استقرار پایدار و قابل اعتماد فقط به دنبال کردن pipeline استقرار محدود نمی‌شود، و موارد مختلفی وجود دارد که
   در آن‌ها مسدود کردن یک microservice خاص از استقرار می‌تواند در دسترس بودن را در سراسر اکوسیستم افزایش
   دهد.
  </p>
<p>
   اگر یک سرویس، SLAهای خود را (به ??? مراجعه کنید) برآورده نمی‌کند، در صورت استفاده از سهمیه downtime
   سرویس، می‌توان تمام استقرار را به تعویق انداخت. به عنوان مثال، اگر یک سرویس دارای یک SLA باشد که 99.99٪
   در دسترس بودن را وعده می‌دهد (اجازه 4.38 دقیقه downtime در هر ماه را می‌دهد)، اما در یک ماه 12 دقیقه
   غیرقابل دسترس بوده است، استقرارهای جدید آن microservice می‌توانند برای سه ماه آینده مسدود شوند، و
   اطمینان حاصل شود که SLA خود را برآورده می‌کند.
  </p>
<p>
   اگر یک سرویس در تست load شکست بخورد (به ??? مراجعه کنید)، پس استقرار در production می‌تواند قفل شود تا
   زمانی که سرویس بتواند به درستی هر تست load لازم را پاس کند. برای سرویس‌های حیاتی برای کسب‌وکار، که قطعی‌های
   آن‌ها باعث توقف عملکرد شرکت می‌شود، گاهی اوقات ممکن است لازم باشد که استقرار را مسدود کرد اگر آن‌ها معیارهای
   آمادگی برای تولیدی را که توسط سازمان مهندسی تعیین شده است، برآورده نکنند.
  </p>
<h3>وابستگی‌ها</h3>
<p>
   پذیرش معماری microservice، گاهی اوقات با این ایده هدایت می‌شود که microservices را می‌توان به عنوان اجزای
   کاملاً مستقل و قابل تعویض یک سیستم بزرگتر، در انزوا ساخت و اجرا کرد. این در اصل درست است، اما در دنیای
   واقعی، هر microservice دارای وابستگی‌هایی است، هم upstream و هم downstream. هر microservice از
   کلاینت‌ها (microservicesهای دیگر) درخواست‌هایی دریافت می‌کند که روی سرویس حساب می‌کنند تا همانطور که
   انتظار می‌رود عمل کند و به SLAهای خود عمل کند، و همچنین وابستگی‌های downstream (سایر سرویس‌ها) که برای
   انجام کار به آن‌ها وابسته خواهد بود.
  </p>
<p>
   ساخت و اجرای microservicesهای آماده تولید مستلزم آن است که توسعه‌دهندگان برای شکست‌های وابستگی برنامه‌ریزی
   کنند، آن‌ها را کاهش دهند و در برابر آن‌ها محافظت کنند. درک وابستگی‌های یک سرویس و برنامه‌ریزی برای شکست‌های
   آن‌ها یکی از مهم‌ترین جنبه‌های ساخت یک microservice پایدار و قابل اعتماد است.
  </p>
<p>
   برای درک میزان اهمیت این موضوع، بیایید یک microservice نمونه به نام receipt-sender را در نظر بگیریم که SLA
   آن چهار-نه (وعده 99.99٪ در دسترس بودن به کلاینت‌های upstream) است. اکنون، receipt-sender به چندین
   microservice دیگر، از جمله یکی به نام customers (یک microservice که تمام اطلاعات مشتری را مدیریت می‌کند) و
   یکی به نام orders (یک microservice که اطلاعات مربوط به سفارشات هر cus—
  </p>
<p>Dependencies | 37</p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 45" src="page_0045/image_1.png"/></div>
</div>
            </div>
            <div class="page original-page">
                <img src="page_0045_original/original_page.png" alt="Original Page 45">
            </div>
        </div>
        <div class="dual-page-spread">
            <div class="page persian-page">
                <div class="translated-content">
<div>
<p>
   توسط مشتری قرار می‌دهد). هم customers و هم orders به microservicesهای دیگری وابسته هستند: customers به microservice
   دیگری که آن را customers-dependency می‌نامیم وابسته است، و orders به یکی که آن را orders-dependency می‌نامیم
   وابسته است. احتمال اینکه customers-dependency و orders-dependency وابستگی‌های خاص خود را داشته باشند، بسیار
   زیاد است، بنابراین نمودار وابستگی برای receipt-sender به سرعت بسیار، بسیار پیچیده می‌شود.
  </p>
<p>
   از آنجایی که receipt-sender می‌خواهد از SLA خود محافظت کند و 99.99٪ زمان uptime را به همه کلاینت‌های خود ارائه
   دهد، تیم آن باید اطمینان حاصل کند که به SLAهای تمام وابستگی‌های downstream به‌شدت پایبند است. اگر SLA
   receipt-sender به در دسترس بودن customers 99.99٪ از زمان بستگی داشته باشد، اما uptime واقعی customers
   فقط 89.99٪ از زمان باشد، در دسترس بودن receipt-sender به خطر می‌افتد و اکنون فقط 89.98٪ است. هر یک از
   وابستگی‌های receipt-sender می‌توانند ضربه‌ای مشابه به در دسترس بودن خود وارد کنند، اگر هیچ یک از وابستگی‌ها در
   زنجیره وابستگی، SLAهای خود را برآورده نکنند.
  </p>
<p>
   یک microservice پایدار و قابل اعتماد باید شکست‌های وابستگی از این نوع را کاهش دهد (و بله، برآورده نکردن یک SLA
   یک شکست است!). این کار را می‌توان با داشتن backups، fallbacks، caching و/یا جایگزین‌هایی برای هر وابستگی در
   صورت شکست آن‌ها، انجام داد.
  </p>
<p>
   قبل از اینکه بتوان برای شکست‌های وابستگی برنامه‌ریزی و کاهش داد، باید وابستگی‌های یک microservice شناخته،
   مستند و ردیابی شوند. هر وابستگی که می‌تواند به SLA یک microservice آسیب برساند، باید در نمودار معماری و
   مستندات microservice (به فصل 7، مستندات و درک مراجعه کنید) گنجانده شود و باید در dashboard(های) سرویس (به
   ??? مراجعه کنید) گنجانده شود. علاوه بر این، تمام وابستگی‌ها باید با ایجاد خودکار نمودارهای وابستگی برای هر
   سرویس، ردیابی شوند، که می‌توان با پیاده‌سازی یک سیستم ردیابی توزیع‌شده در سراسر تمام microservices در
   سازمان، این کار را انجام داد.
  </p>
<p>
   هنگامی که تمام وابستگی‌ها شناخته و ردیابی شدند، گام بعدی این است که backups، جایگزین‌ها، fallbacks یا caching را
   برای هر وابستگی تنظیم کنید. روش درست برای انجام این کار کاملاً به نیازهای سرویس بستگی دارد. به عنوان مثال، اگر
   عملکرد یک وابستگی را می‌توان با فراخوانی endpoint یک سرویس دیگر پر کرد، پس شکست وابستگی اولیه باید توسط
   microservice مدیریت شود تا درخواست‌ها به جای آن به جایگزین ارسال شوند. اگر درخواست‌هایی که باید به
   وابستگی ارسال شوند، در صورت عدم در دسترس بودن وابستگی، در یک صف نگهداری شوند، باید یک صف پیاده‌سازی
   شود. راه دیگری برای مدیریت شکست‌های وابستگی، قرار دادن caching برای وابستگی در داخل سرویس است: هر داده
   مربوطه را cache کنید تا هرگونه شکست به درستی مدیریت شود.
  </p>
<p>
   نوع cache که اغلب در این موارد استفاده می‌شود، یک cache Least Recently Used (LRU) است، که در آن داده‌های
   مربوطه در یک صف نگهداری می‌شوند، و داده‌های استفاده نشده حذف می‌شوند، زمانی که صف cache پر می‌شود.
   کتابخانه‌های LRU آسان برای پیاده‌سازی (اغلب یک خط کد برای هر نمونه‌سازی)، کارآمد (نیازی به برقراری تماس‌های
   شبکه گران‌قیمت نیست)، با عملکرد خوب (داده‌ها بلافاصله در دسترس هستند) هستند، و کار مناسبی را در کاهش هرگونه
   شکست وابستگی انجام می‌دهند. این به عنوان defensive caching شناخته می‌شود و برای محافظت از یک microservice
   در برابر شکست‌های وابستگی‌های آن مفید است: اطلاعاتی را که
  </p>
<p>38 | فصل 3: پایداری و قابلیت اطمینان</p>
</div>
</div>
                <div class="page-images">
</div>
            </div>
            <div class="page original-page">
                <img src="page_0046_original/original_page.png" alt="Original Page 46">
            </div>
        </div>
        <div class="dual-page-spread">
            <div class="page persian-page">
                <div class="translated-content">
<div>
<p>
   microservice از وابستگی‌های خود دریافت می‌کند، و اگر وابستگی‌ها از کار بیفتند، در دسترس بودن
   microservice شما تحت تأثیر قرار نخواهد گرفت. پیاده‌سازی defensive caching برای هر وابستگی ضروری
   نیست، اما اگر یک وابستگی یا مجموعه‌ای از وابستگی‌ها غیرقابل اعتماد هستند، defensive caching از آسیب
   دیدن microservice شما جلوگیری می‌کند.
  </p>
<h3>Routing و کشف</h3>
<p>
   یکی دیگر از جنبه‌های ساخت microservices پایدار و قابل اعتماد، اطمینان از این است که ارتباط و تعامل بین
   microservicesها نیز پایدار و قابل اعتماد است، به این معنی که لایه 2 (لایه ارتباطی) از اکوسیستم microservice (به
   فصل 1، Microservices مراجعه کنید) باید به گونه‌ای ساخته شود که در برابر الگوهای ترافیکی مضر محافظت
   کند و اعتماد را در سراسر اکوسیستم حفظ کند. بخش‌های مربوطه از لایه ارتباطی برای پایداری و قابلیت اطمینان (جدا
   از خود شبکه) کشف سرویس، ثبت سرویس و load balancing هستند.
  </p>
<p>
   سلامت یک microservice هم در سطح host و هم در سطح سرویس به عنوان یک کل، همیشه باید مشخص باشد. این
   به این معنی است که health checkها باید به‌طور مداوم اجرا شوند تا هرگز درخواستی به یک host یا سرویس ناسالم
   ارسال نشود. اجرای health checkها در یک کانال جداگانه (که برای ارتباطات عمومی microservice استفاده نمی‌شود)
   آسان‌ترین راه برای اطمینان از این است که health checkها هرگز توسط چیزی مانند یک شبکه مسدود شده به خطر
   نیفتند. سخت‌کد کردن پاسخ‌های "200 OK" در یک endpoint /health برای health checkها نیز برای هر microservice
   ایده‌آل نیست، اگرچه ممکن است برای اکثر آن‌ها کافی باشد. پاسخ‌های hardcoded، به شما چیز زیادی نمی‌گویند، به
   جز اینکه microservice با موفقیت نیمه در host راه‌اندازی شده است: هر endpoint /health از یک microservice
   باید یک پاسخ مفید و دقیق ارائه دهد.
  </p>
<p>
   اگر یک نمونه از یک سرویس در یک host ناسالم باشد، load balancerها دیگر نباید ترافیک را به آن هدایت کنند. اگر یک
   microservice به عنوان یک کل ناسالم باشد (با شکست همه health checkها در درصد معینی از hostsها یا تمام
   hostsها در production)، پس ترافیک دیگر نباید به آن microservice خاص هدایت شود تا زمانی که مشکلات باعث
   شکست health checkها حل شوند.
  </p>
<p>
   با این حال، health checkها نباید تنها عامل تعیین‌کننده در مورد سالم بودن یا نبودن یک سرویس باشند. تعداد زیادی
   استثناهای رسیدگی نشده نیز باید منجر به علامت‌گذاری یک سرویس ناسالم شوند، و circuit breakerها باید برای این
   شکست‌ها اعمال شوند تا اگر یک سرویس مقدار غیرعادی خطاهایی را تجربه کرد، دیگر هیچ درخواستی به سرویس ارسال
   نشود تا زمانی که مشکل حل شود. کلید در routing و کشف پایدار و قابل اعتماد این است: با جلوگیری از سرویس‌دهی
   actorهای بد از ترافیک production و پذیرش درخواست‌ها از microservicesهای دیگر، از اکوسیستم microservice
   محافظت کنید.
  </p>
<p>Routing و کشف | 39</p>
</div>
</div>
                <div class="page-images">
</div>
            </div>
            <div class="page original-page">
                <img src="page_0047_original/original_page.png" alt="Original Page 47">
            </div>
        </div>
        <div class="dual-page-spread">
            <div class="page persian-page">
                <div class="translated-content">
<div>
<h3>Deprecation و Decommissioning</h3>
<p>
   یک علت اغلب فراموش شده و نادیده گرفته شده بی‌ثباتی و عدم قابلیت اطمینان در اکوسیستم‌های microservice،
   deprecate کردن یا از رده خارج کردن یک microservice یا یکی از API endpointsهای آن است. هنگامی که یک
   microservice دیگر مورد استفاده قرار نمی‌گیرد یا توسط یک تیم توسعه پشتیبانی نمی‌شود، باید با دقت از رده خارج
   شود تا اطمینان حاصل شود که هیچ کلاینتی به خطر نمی‌افتد. Deprecation یک یا چند API endpoints از یک
   microservice، حتی رایج‌تر است: هنگامی که ویژگی‌های جدیدی اضافه می‌شوند یا ویژگی‌های قدیمی حذف می‌شوند،
   endpointsها اغلب تغییر می‌کنند و نیاز به به‌روزرسانی تیم‌های کلاینت و سوئیچ کردن هرگونه درخواست ارسال شده به
   endpointsهای قدیمی به endpointsهای جدید (یا حذف کامل آن‌ها) دارد.
  </p>
<p>
   در اکثر اکوسیستم‌های microservice، deprecation و decommissioning بیشتر یک مشکل جامعه‌شناختی در داخل
   سازمان مهندسی است تا یک مشکل فنی، که این امر، رسیدگی به آن را دشوارتر می‌کند. هنگامی که یک microservice
   قصد دارد از رده خارج شود، تیم توسعه آن باید مراقب باشد که به همه سرویس‌های کلاینت هشدار دهد و به آن‌ها
   در مورد نحوه تطبیق با از دست دادن وابستگی‌شان مشاوره دهد. اگر microservice که در حال decommissioning
   است، با یک microservice جدید دیگر جایگزین می‌شود، یا اگر عملکرد microservice در یک microservice موجود
   دیگر ساخته می‌شود، سپس تیم باید به تمام کلاینت‌ها کمک کند تا microservicesهای خود را به‌روزرسانی کنند تا
   درخواست‌ها را به endpointsهای جدید ارسال کنند. Deprecation یک endpoint از یک process مشابه پیروی می‌کند:
   باید به کلاینت‌ها هشدار داده شود، و یا endpoint جدید به آن‌ها داده شود یا در مورد چگونگی در نظر گرفتن از دست
   دادن کامل endpoint به آن‌ها مشاوره داده شود. در هر دو مورد deprecation و decommissioning، نظارت نقش مهمی
   ایفا می‌کند: endpointsها قبل از اینکه سرویس یا endpoint به‌طور کامل decommissioned و/یا deprecated شود،
   باید از نزدیک نظارت شوند تا هرگونه درخواستی که ممکن است همچنان به سرویس یا endpoint منسوخ شده ارسال
   شود، بررسی شود.
  </p>
<p>
   برعکس، عدم deprecate صحیح یک endpoint یا عدم decommissioning یک microservice می‌تواند اثرات فاجعه‌باری
   بر اکوسیستم microservice داشته باشد. این اتفاق بیشتر از آن چیزی می‌افتد که توسعه‌دهندگان مایل به اعتراف
   به آن هستند. در یک اکوسیستم که شامل صدها یا هزاران microservice می‌شود، توسعه‌دهندگان اغلب بین تیم‌ها
   جابه‌جا می‌شوند، اولویت‌ها تغییر می‌کنند، و microservicesها و فناوری‌ها همگی به‌طور مداوم برای موارد جدیدتر و
   بهتر تعویض می‌شوند. هنگامی که این microservicesها یا فناوری‌های قدیمی بدون هیچ‌گونه (یا خیلی کم) درگیر
   بودن، نظارت یا بررسی رها می‌شوند، هرگونه شکست، مورد توجه قرار نمی‌گیرد، و هر شکستی که مورد توجه قرار
   بگیرد ممکن است برای مدت طولانی حل نشود. اگر یک microservice قرار است به حال خود رها شود، در صورت قطعی،
   خطر به خطر انداختن کلاینت‌های خود را دارد—باید به جای رها کردن، این microservicesها را از رده خارج کرد.
  </p>
<p>
   هیچ چیز مخرب‌تر از از دست دادن کامل یکی از وابستگی‌هایش برای یک microservice نیست. هیچ چیز باعث بی‌ثباتی و
   عدم اطمینان بیشتر از شکست ناگهانی و غیرمنتظره یکی از وابستگی‌هایش نمی‌شود، حتی اگر شکست توسط تیم دیگری
   برنامه‌ریزی شده باشد. اهمیت decommissioning و deprecation پایدار و قابل اعتماد، صادقانه نمی‌تواند به اندازه
   کافی مورد تأکید قرار گیرد.
  </p>
<p>40 | فصل 3: پایداری و قابلیت اطمینان</p>
</div>
</div>
                <div class="page-images">
</div>
            </div>
            <div class="page original-page">
                <img src="page_0048_original/original_page.png" alt="Original Page 48">
            </div>
        </div>
        <div class="dual-page-spread">
            <div class="page persian-page">
                <div class="translated-content">
<div>
<h3>ارزیابی Microservice شما</h3>
<p>
   اکنون که درک بهتری از پایداری و قابلیت اطمینان دارید، از لیست سوالات زیر برای ارزیابی آمادگی production
   microservice(های) خود و اکوسیستم microservice استفاده کنید. سؤالات بر اساس موضوع سازماندهی شده‌اند و با
   بخش‌های این فصل مطابقت دارند.
  </p>
<h3>چرخه توسعه</h3>
<ul>
<li>آیا microservice دارای یک repository مرکزی است که در آن همه کدها ذخیره می‌شوند؟</li>
<li>آیا توسعه‌دهندگان در یک محیط توسعه کار می‌کنند که وضعیت production را به درستی منعکس می‌کند (به عنوان مثال، که
    دنیای واقعی را با دقت منعکس می‌کند)؟</li>
<li>آیا تست‌های lint، unit، integration و end-to-end مناسب برای microservice وجود دارد؟</li>
<li>آیا procedures و policyهای بررسی کد وجود دارد؟</li>
<li>آیا process تست، بسته‌بندی، ساخت و release خودکار است؟</li>
</ul>
<h3>Pipeline استقرار</h3>
<ul>
<li>آیا اکوسیستم microservice دارای یک pipeline استقرار استاندارد است؟</li>
<li>آیا یک فاز staging در pipeline استقرار وجود دارد که full یا partial staging باشد؟</li>
<li>محیط staging به چه سرویس‌های production دسترسی دارد؟</li>
<li>آیا یک فاز canary در pipeline استقرار وجود دارد؟</li>
<li>آیا استقرارها در فاز canary برای دوره‌ای اجرا می‌شوند که به اندازه کافی طولانی باشد تا هرگونه شکست را بگیرد؟</li>
<li>آیا فاز canary نمونه‌ای تصادفی از ترافیک production را با دقت میزبانی می‌کند؟</li>
<li>آیا پورت‌های microservice برای canary و production یکسان هستند؟</li>
<li>آیا استقرارها در production در یک زمان انجام می‌شوند یا به تدریج راه‌اندازی می‌شوند؟</li>
<li>آیا روشی برای رد شدن از فازهای staging و canary در صورت اضطراری وجود دارد؟</li>
</ul>
<h3>وابستگی‌ها</h3>
<ul>
<li>وابستگی‌های این microservice چیست؟</li>
<li>کلاینت‌های آن چه کسانی هستند؟</li>
</ul>
<p>ارزیابی Microservice شما | 41</p>
</div>
</div>
                <div class="page-images">
</div>
            </div>
            <div class="page original-page">
                <img src="page_0049_original/original_page.png" alt="Original Page 49">
            </div>
        </div>
        <div class="dual-page-spread">
            <div class="page persian-page">
                <div class="translated-content">
<div>
<ul>
<li>این microservice چگونه شکست‌های وابستگی را کاهش می‌دهد؟</li>
<li>آیا backups، alternatives، fallbacks یا defensive caching برای هر وابستگی وجود دارد؟</li>
</ul>
<h3>Routing و کشف</h3>
<ul>
<li>آیا health checkها برای microservice قابل اعتماد هستند؟</li>
<li>آیا health checkها، سلامت microservice را با دقت منعکس می‌کنند؟</li>
<li>آیا health checkها در یک کانال جداگانه در داخل لایه ارتباطی اجرا می‌شوند؟</li>
<li>آیا circuit breakerها برای جلوگیری از ایجاد درخواست توسط microservicesهای ناسالم وجود دارد؟</li>
<li>آیا circuit breakerها برای جلوگیری از ارسال ترافیک production به hosts و microservicesهای ناسالم وجود
    دارد؟</li>
</ul>
<h3>Deprecation و Decommissioning</h3>
<ul>
<li>آیا proceduresهایی برای از رده خارج کردن یک microservice وجود دارد؟</li>
<li>آیا proceduresهایی برای deprecate کردن API endpoints یک microservice وجود دارد؟</li>
</ul>
<p>42 | فصل 3: پایداری و قابلیت اطمینان</p>
</div>
</div>
                <div class="page-images">
</div>
            </div>
            <div class="page original-page">
                <img src="page_0050_original/original_page.png" alt="Original Page 50">
            </div>
        </div>
        <div class="dual-page-spread">
            <div class="page persian-page">
                <div class="translated-content">
<div>
<h3>فصل 4</h3>
<h3>مقیاس‌پذیری و عملکرد</h3>
<p>
   یک microservice آماده تولید، مقیاس‌پذیر و با عملکرد بالا است. یک microservice مقیاس‌پذیر و با عملکرد بالا،
   microservice است که توسط کارایی هدایت می‌شود، microservice که نه‌تنها می‌تواند تعداد زیادی از وظایف یا
   درخواست‌ها را همزمان مدیریت کند، بلکه می‌تواند آن‌ها را به طور موثر مدیریت کند و برای افزایش وظایف یا
   درخواست‌ها در آینده آماده است. در این فصل، اجزای ضروری مقیاس‌پذیری و عملکرد microservice، از جمله
   درک مقیاس‌های رشد کیفی و کمی، کارایی سخت‌افزار، شناسایی الزامات و موانع منابع، آگاهی از ظرفیت و
   برنامه‌ریزی، مدیریت ترافیک مقیاس‌پذیر، مقیاس‌بندی وابستگی‌ها، مدیریت و پردازش وظایف و ذخیره‌سازی
   داده‌های مقیاس‌پذیر پوشش داده شده است.
  </p>
<h3>اصول مقیاس‌پذیری و عملکرد Microservice</h3>
<p>
   کارایی از اهمیت بالایی در معماری سیستم‌های توزیع‌شده در مقیاس بزرگ و در دنیای واقعی برخوردار است، و اکوسیستم‌های
   microservice نیز از این قاعده مستثنی نیستند. اندازه‌گیری کارایی یک سیستم واحد (مانند یک برنامه monolithic) آسان
   است، اما ارزیابی کارایی و دستیابی به کارایی بیشتر در یک اکوسیستم بزرگ از microservices، جایی که وظایف بین
   صدها (اگر نه هزاران) سرویس کوچک تقسیم می‌شوند، فوق‌العاده دشوار است. همچنین با قوانین معماری کامپیوتر و
   سیستم‌های توزیع‌شده محدود می‌شود، که محدودیت‌هایی را برای کارایی سیستم‌های توزیع‌شده پیچیده در مقیاس بزرگ
   قرار می‌دهند: هرچه سیستم شما توزیع‌شده‌تر باشد، و هرچه microservices بیشتری را در آن سیستم داشته باشید،
   تفاوت کارایی یک microservice بر کل سیستم کمتر خواهد بود. استانداردسازی اصولی که کارایی کلی را افزایش
   می‌دهند، به یک ضرورت تبدیل می‌شود. دو استاندارد آمادگی تولید ما—مقیاس‌پذیری و عملکرد—به دستیابی به این
   کارایی کلی کمک می‌کنند و در دسترس بودن اکوسیستم microservice را افزایش می‌دهند.
  </p>
<p>
   مقیاس‌پذیری و عملکرد به دلیل تأثیراتی که بر کارایی هر microservice و کل اکوسیستم دارند، به‌طور منحصربه‌فردی
   به هم پیوسته‌اند. همانطور که در
  </p>
<p>43</p>
</div>
</div>
                <div class="page-images">
</div>
            </div>
            <div class="page original-page">
                <img src="page_0051_original/original_page.png" alt="Original Page 51">
            </div>
        </div>
        <div class="dual-page-spread">
            <div class="page persian-page">
                <div class="translated-content">
<div>
<p>
   فصل 1، Microservices، برای ساخت یک برنامه مقیاس‌پذیر، ما باید برای concurrency و partitioning طراحی
   کنیم: concurrency به هر task اجازه می‌دهد به قطعات کوچکتر تقسیم شود، در حالی که partitioning برای اجازه دادن
   به این قطعات کوچکتر برای پردازش موازی ضروری است. بنابراین، در حالی که مقیاس‌پذیری مربوط به چگونگی تقسیم
   و غلبه ما بر پردازش tasks است، عملکرد، اندازه‌گیری میزان کارآمدی پردازش آن tasksها توسط برنامه است.
  </p>
<p>
   در یک اکوسیستم microservice در حال رشد و شکوفایی، که ترافیک به طور پیوسته در حال افزایش است، هر
   microservice باید بتواند بدون مواجهه با مشکلات عملکردی، با کل سیستم مقیاس‌پذیری داشته باشد. برای اطمینان
   از اینکه microservicesهای ما مقیاس‌پذیر و با عملکرد بالا هستند، ما باید چندین مورد را از هر microservice
   درخواست کنیم. ما باید مقیاس رشد آن را، هم کمی و هم کیفی، درک کنیم تا بتوانیم برای رشد مورد انتظار آماده شویم.
   ما باید از منابع سخت‌افزاری خود به طور کارآمد استفاده کنیم، از موانع و الزامات منابع آگاه باشیم و برنامه‌ریزی
   ظرفیت مناسب را انجام دهیم. ما باید اطمینان حاصل کنیم که وابستگی‌های یک microservice با آن مقیاس‌پذیری
   خواهند داشت. ما باید ترافیک را به روشی مقیاس‌پذیر و با عملکرد بالا مدیریت کنیم. ما باید وظایف را به روشی با
   عملکرد بالا مدیریت و پردازش کنیم. آخرین و نه کم‌اهمیت‌ترین، ما باید داده‌ها را به روشی مقیاس‌پذیر ذخیره کنیم.
  </p>
<h3>یک سرویس آماده تولید، مقیاس‌پذیر و با عملکرد بالاست</h3>
<ul>
<li>مقیاس‌های رشد کیفی و کمی آن مشخص است.</li>
<li>از منابع سخت‌افزاری به طور کارآمد استفاده می‌کند.</li>
<li>موانع و الزامات منابع آن شناسایی شده‌اند.</li>
<li>برنامه‌ریزی ظرفیت خودکار است و به‌صورت زمان‌بندی‌شده انجام می‌شود.</li>
<li>وابستگی‌های آن با آن مقیاس‌پذیری خواهند داشت.</li>
<li>با کلاینت‌هایش مقیاس‌پذیری خواهد داشت.</li>
<li>الگوهای ترافیکی آن درک شده است.</li>
<li>ترافیک در صورت شکست، می‌تواند دوباره هدایت شود.</li>
<li>به زبان برنامه‌نویسی نوشته شده است که به آن اجازه می‌دهد مقیاس‌پذیر و با عملکرد بالا باشد.</li>
<li>وظایف را به روشی با عملکرد بالا مدیریت و پردازش می‌کند.</li>
<li>داده‌ها را به روشی مقیاس‌پذیر و با عملکرد بالا مدیریت و ذخیره می‌کند.</li>
</ul>
<h3>دانستن مقیاس رشد</h3>
<p>
   تعیین اینکه چگونه یک microservice مقیاس‌پذیری دارد (در یک سطح بسیار بالا) اولین گام به سمت درک چگونگی ساخت
   و نگهداری یک microservice مقیاس‌پذیر است. دو جنبه برای دانستن مقیاس رشد یک microservice وجود دارد، و هر دو
   نقش مهمی در درک و برنامه‌ریزی برای مقیاس‌پذیری یک سرویس ایفا می‌کنند. اولین مورد
  </p>
<p>44 | فصل 4: مقیاس‌پذیری و عملکرد</p>
</div>
</div>
                <div class="page-images">
</div>
            </div>
            <div class="page original-page">
                <img src="page_0052_original/original_page.png" alt="Original Page 52">
            </div>
        </div>
        <div class="dual-page-spread">
            <div class="page persian-page">
                <div class="translated-content">
<div>
<p>
   مقیاس رشد کیفی است، که از درک اینکه سرویس در کجا در اکوسیستم microservice کلی قرار دارد و کدام
   معیارهای کلیدی کسب‌وکار سطح بالا تحت تأثیر آن قرار خواهند گرفت، ناشی می‌شود. دومی، مقیاس رشد کمی
   است، که، همانطور که از نامش پیداست، درک دقیق، قابل اندازه‌گیری و کمی از میزان ترافیکی است که یک
   microservice می‌تواند مدیریت کند.
  </p>
<h3>مقیاس رشد کیفی</h3>
<p>
   تمایل طبیعی هنگام تلاش برای تعیین مقیاس رشد یک microservice، این است که مقیاس رشد را بر حسب
   درخواست در ثانیه (RPS) یا query در ثانیه (QPS) که سرویس می‌تواند پشتیبانی کند، بیان کنیم، سپس پیش‌بینی
   کنیم که چه تعداد RPS/QPS در آینده به سرویس ارسال خواهد شد. اصطلاح "درخواست در ثانیه" عموماً هنگام
   صحبت در مورد microservices استفاده می‌شود، و "query در ثانیه" هنگام صحبت در مورد پایگاه‌های داده یا
   microservicesهایی که داده‌ها را به کلاینت‌ها برمی‌گردانند، استفاده می‌شود، اگرچه در بسیاری از موارد قابل تعویض
   هستند. این اطلاعات بسیار مهمی است، اما بدون زمینه اضافی بی‌فایده است—به‌ویژه، بدون زمینه اینکه microservice
   در کجا در تصویر کلی قرار می‌گیرد.
  </p>
<p>
   در اکثر موارد، اطلاعات مربوط به RPS/QPS که یک microservice می‌تواند پشتیبانی کند، توسط وضعیت
   microservice در زمانی که مقیاس رشد در ابتدا محاسبه می‌شود، تعیین می‌شود: اگر مقیاس رشد تنها با نگاهی به
   سطوح فعلی ترافیک و نحوه مدیریت microservice بار ترافیک فعلی محاسبه شود، هرگونه استنتاج در مورد میزان
   ترافیکی که microservice می‌تواند در آینده مدیریت کند، خطر گمراه‌کننده بودن را به همراه دارد. چندین رویکرد
   وجود دارد که می‌توان برای حل این مشکل اتخاذ کرد، از جمله load testing (تست microservice با بار ترافیکی
   بالاتر)، که می‌تواند تصویر دقیق‌تری از مقیاس‌پذیری سرویس ارائه دهد، و تجزیه و تحلیل داده‌های ترافیکی
   تاریخی برای دیدن اینکه سطح ترافیک در طول زمان چگونه رشد می‌کند. اما چیزی بسیار مهم در اینجا وجود دارد که
   در حال از دست رفتن است، چیزی که یک ویژگی ذاتی معماری microservice است—یعنی، microservicesها به تنهایی
   زندگی نمی‌کنند، بلکه به عنوان بخشی از یک اکوسیستم بزرگتر زندگی می‌کنند.
  </p>
<p>
   اینجاست که مقیاس رشد کیفی وارد عمل می‌شود. مقیاس‌های رشد کیفی به مقیاس‌پذیری یک سرویس اجازه می‌دهد
   با معیارهای کسب‌وکار سطح بالاتر گره بخورد: برای مثال، یک microservice ممکن است با تعداد کاربران، با
   تعداد افرادی که یک برنامه تلفن را باز می‌کنند ("eyeballs")، یا با تعداد سفارشات (برای یک سرویس تحویل غذا)
   مقیاس‌پذیری داشته باشد. این معیارها، این مقیاس‌های رشد کیفی، به یک microservice جداگانه گره نخورده‌اند، بلکه
   به سیستم کلی یا محصول(ها) گره خورده‌اند. در سطح کسب‌وکار، سازمان، برای بخش عمده‌ای، ایده‌ای در مورد نحوه
   تغییر این معیارها در طول زمان خواهد داشت. هنگامی که این معیارهای کسب‌وکار سطح بالاتر به تیم‌های مهندسی
   منتقل می‌شوند، توسعه‌دهندگان می‌توانند آن‌ها را در رابطه با microservicesهای مربوطه خود تفسیر کنند: اگر یکی
   از microservicesهای آن‌ها بخشی از جریان سفارش برای یک سرویس تحویل غذا باشد، آن‌ها می‌دانند که هر
   معیاری مربوط به تعداد سفارشات مورد انتظار در آینده به آن‌ها می‌گوید که سرویس آن‌ها باید چه نوع ترافیکی را
   انتظار داشته باشد.
  </p>
<p>دانستن مقیاس رشد | 45</p>
</div>
</div>
                <div class="page-images">
</div>
            </div>
            <div class="page original-page">
                <img src="page_0053_original/original_page.png" alt="Original Page 53">
            </div>
        </div>
        <div class="dual-page-spread">
            <div class="page persian-page">
                <div class="translated-content">
<div>
<p>
   وقتی از تیم‌های توسعه microservice می‌پرسم که آیا مقیاس رشد سرویس خود را می‌دانند، پاسخ معمول این است: "این می‌تواند x
   درخواست در ثانیه را مدیریت کند." سؤالات پیگیری من همیشه به سمت کشف این است که سرویس مورد نظر در کجا در محصول
   کلی قرار می‌گیرد: چه زمانی درخواست‌ها انجام می‌شوند؟ آیا این یک درخواست در هر سفر است؟ یک درخواست هر بار که
   کسی برنامه را باز می‌کند؟ یک درخواست هر بار که یک کاربر جدید برای محصول ما ثبت‌نام می‌کند؟ هنگامی که به این
   سوالات زمینه‌ساز پاسخ داده می‌شود، مقیاس رشد روشن می‌شود—و مفید می‌شود. اگر تعداد درخواست‌های ارسالی به
   سرویس مستقیماً با تعداد افرادی که یک برنامه تلفن را باز می‌کنند مرتبط باشد، پس سرویس با eyeballs مقیاس
   می‌گیرد، و ما می‌توانیم با پیش‌بینی اینکه چند نفر برنامه را باز خواهند کرد، برای مقیاس‌بندی سرویس برنامه‌ریزی
   کنیم. اگر تعداد درخواست‌های ارسالی به سرویس توسط تعداد افرادی که غذای تحویلی سفارش می‌دهند، تعیین شود، پس
   سرویس با تحویل‌ها مقیاس‌پذیری دارد، و ما می‌توانیم با استفاده از معیارهای کسب‌وکار سطح بالاتر در مورد اینکه
   چند تحویل آینده پیش‌بینی می‌شود، برنامه‌ریزی و پیش‌بینی برای مقیاس‌بندی سرویس خود انجام دهیم.
  </p>
<p>
   استثنائاتی برای قوانین مقیاس‌های رشد کیفی وجود دارد، و تعیین یک مقیاس رشد کیفی مناسب می‌تواند هرچه سرویس
   در stack پایین‌تر یافت می‌شود، بسیار پیچیده شود. ابزارهای داخلی تمایل دارند از این عوارض رنج ببرند، و با این حال
   تمایل دارند آن‌قدر برای کسب‌وکار حیاتی باشند که اگر مقیاس‌پذیر نباشند، بقیه سازمان به سرعت با چالش‌های
   مقیاس‌پذیری مواجه می‌شوند. قرار دادن مقیاس رشد یک سرویس مانند یک پلتفرم نظارتی یا هشداردهنده بر حسب
   معیارهای کسب‌وکار (کاربران، eyeballs و غیره) آسان نیست، بنابراین سازمان‌های پلتفرم و/یا زیرساخت باید
   مقیاس‌های رشد دقیقی را برای سرویس‌های خود بر حسب مشتریان خود (توسعه‌دهندگان، سرویس‌ها و غیره) و
   مشخصات مشتریانشان تعیین کنند. ابزارهای داخلی می‌توانند با، به عنوان مثال، تعداد استقرارها، تعداد سرویس‌ها، تعداد
   logsهای جمع‌آوری‌شده، یا گیگابایت داده، مقیاس‌پذیری داشته باشند. این‌ها به دلیل دشواری ذاتی در پیش‌بینی این
   اعداد، پیچیده‌تر هستند، اما باید به همان اندازه ساده و قابل پیش‌بینی باشند که مقیاس‌های رشد microservices
   بالاتر در stack هستند.
  </p>
<h3>مقیاس رشد کمی</h3>
<p>
   بخش دوم دانستن مقیاس رشد، تعیین جنبه‌های کمی آن است، که در آن RPS/QPS و معیارهای مشابه وارد عمل
   می‌شوند. برای تعیین مقیاس رشد کمی، ما باید با در نظر گرفتن مقیاس رشد کیفی به microservicesهای خود نزدیک
   شویم: مقیاس رشد کمی با ترجمه مقیاس رشد کیفی به یک کمیت قابل اندازه‌گیری تعریف می‌شود. به عنوان مثال، اگر
   مقیاس رشد کیفی microservice ما بر حسب "eyeballs" (به عنوان مثال، چند نفر یک برنامه تلفن را باز می‌کنند)
   اندازه‌گیری شود، و هر "eyeball" منجر به دو درخواست به microservice ما و یک تراکنش پایگاه داده می‌شود، سپس
   مقیاس رشد کمی ما بر حسب درخواست‌ها و تراکنش‌ها اندازه‌گیری می‌شود، که منجر به درخواست در ثانیه و تراکنش
   در ثانیه به عنوان دو کمیت کلیدی که مقیاس‌پذیری ما را تعیین می‌کنند، می‌شود.
  </p>
<p>
   اهمیت انتخاب مقیاس‌های رشد کیفی و کمی دقیق را نمی‌توان بیش از حد مورد تأکید قرار داد. همانطور که به زودی خواهیم
   دید، از مقیاس رشد هنگام پیش‌بینی هزینه‌های عملیاتی سرویس، نیازهای سخت‌افزاری و محدودیت‌ها استفاده خواهد
   شد.
  </p>
<p>46 | فصل 4: مقیاس‌پذیری و عملکرد</p>
</div>
</div>
                <div class="page-images">
</div>
            </div>
            <div class="page original-page">
                <img src="page_0054_original/original_page.png" alt="Original Page 54">
            </div>
        </div>
        <div class="dual-page-spread">
            <div class="page persian-page">
                <div class="translated-content">
<div>
<h3>استفاده کارآمد از منابع</h3>
<p>
   هنگام در نظر گرفتن مقیاس‌پذیری سیستم‌های توزیع‌شده در مقیاس بزرگ مانند اکوسیستم‌های microservice، یکی از
   مفیدترین انتزاع‌هایی که می‌توانیم انجام دهیم این است که خصوصیات سخت‌افزار و سیستم‌های زیرساختی خود را به
   عنوان منابع در نظر بگیریم. CPU، حافظه، ذخیره‌سازی داده‌ها و شبکه شبیه منابع در دنیای طبیعی هستند: آن‌ها
   محدود هستند، اشیای فیزیکی در دنیای واقعی هستند و باید بین بازیگران کلیدی مختلف در اکوسیستم توزیع و به اشتراک
   گذاشته شوند. همانطور که به طور خلاصه در "چالش‌های سازمانی" در صفحه 20 بحث کردیم، منابع سخت‌افزاری گران،
   باارزش و گاهی نادر هستند، که منجر به رقابت شدید برای منابع در داخل اکوسیستم microservice می‌شود.
  </p>
<p>
   چالش سازمانی تخصیص و توزیع منابع را می‌توان با دادن سهم بیشتری از منابع به microservicesهای حیاتی برای
   کسب‌وکار، کاهش داد. نیازهای منابع را می‌توان با طبقه‌بندی microservicesهای مختلف در اکوسیستم با توجه به
   اهمیت و ارزش آن‌ها برای کل کسب‌وکار اولویت‌بندی کرد: اگر منابع در سراسر اکوسیستم کمیاب هستند، به سرویس‌های
   حیاتی برای کسب‌وکار می‌توان در تخصیص منابع اولویت بالاتری داد.
  </p>
<p>
   چالش فنی تخصیص و توزیع منابع، مشکلاتی را به همراه دارد، زیرا تصمیمات زیادی باید در مورد لایه اول (لایه
   سخت‌افزار) اکوسیستم microservice گرفته شود. به microservices می‌توان سخت‌افزار اختصاصی داد تا فقط یک
   سرویس در هر host اجرا شود، اما این می‌تواند نسبتاً گران و استفاده ناکارآمد از منابع سخت‌افزاری باشد. بسیاری
   از سازمان‌های مهندسی ترجیح می‌دهند سخت‌افزار را بین چندین microservice به اشتراک بگذارند، و هر host
   چندین سرویس مختلف را اجرا می‌کند—یک عمل که، در اکثر موارد، استفاده کارآمدتری از منابع سخت‌افزاری است.
  </p>
<h3>خطرات منابع سخت‌افزاری مشترک</h3>
<p>
   در حالی که اجرای بسیاری از microservicesهای مختلف در یک دستگاه (یعنی، به اشتراک گذاشتن دستگاه‌ها بین
   microservices) معمولاً استفاده کارآمدتری از منابع سخت‌افزاری است، باید مراقب بود تا اطمینان حاصل شود که
   microservicesها به اندازه کافی ایزوله شده‌اند و عملکرد، کارایی یا در دسترس بودن microservicesهای مجاور
   خود را به خطر نمی‌اندازند. Containerization (با استفاده از Docker) همراه با جداسازی منابع می‌تواند به
   جلوگیری از آسیب رسیدن به microservices توسط همسایگان بد رفتار، کمک کند.
  </p>
<p>
   یکی از مؤثرترین راه‌ها برای تخصیص و توزیع منابع سخت‌افزاری در یک اکوسیستم microservice، انتزاع کامل مفهوم
   یک host و جایگزینی آن با منابع سخت‌افزاری با استفاده از فناوری‌های انتزاع منابع مانند Apache Mesos است.
   استفاده از این سطح از انتزاع منابع به تخصیص پویا منابع اجازه می‌دهد، که بسیاری از مشکلات مرتبط با تخصیص و
   توزیع منابع را در سیستم‌های توزیع‌شده در مقیاس بزرگ مانند اکوسیستم‌های microservice حذف می‌کند.
  </p>
<p>استفاده کارآمد از منابع | 47</p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 55" src="page_0055/image_1.png"/></div>
</div>
            </div>
            <div class="page original-page">
                <img src="page_0055_original/original_page.png" alt="Original Page 55">
            </div>
        </div>
        <div class="dual-page-spread">
            <div class="page persian-page">
                <div class="translated-content">
<div>
<h3>آگاهی از منابع</h3>
<p>
   قبل از اینکه منابع سخت‌افزاری را بتوان به طور کارآمد به microservicesها در داخل اکوسیستم microservice تخصیص داد و
   توزیع کرد، مهم است که الزامات منابع و موانع منابع هر microservice را شناسایی کنیم. الزامات منابع، منابع خاص
   (CPU، RAM و غیره) هستند که هر microservice نیاز دارد؛ شناسایی این موارد برای اجرای یک سرویس مقیاس‌پذیر
   ضروری است. موانع منابع، محدودیت‌های مقیاس‌پذیری و عملکرد هر microservice جداگانه هستند که به ویژگی‌های
   منابع آن بستگی دارد.
  </p>
<h3>الزامات منابع</h3>
<p>
   الزامات منابع یک microservice، منابع سخت‌افزاری هستند که microservice برای اجرای صحیح، پردازش کارها به طور
   موثر، و مقیاس‌پذیری عمودی و/یا افقی به آن‌ها نیاز دارد. دو منبع سخت‌افزاری مهم و مرتبط، تعجب‌آور نیست، CPU و
   RAM هستند (در محیط‌های multithreaded، threads به منبع مهم سوم تبدیل می‌شوند). تعیین الزامات منابع یک
   microservice سپس مستلزم اندازه‌گیری CPU و RAM است که یک نمونه از سرویس برای اجرا به آن نیاز دارد. این
   برای انتزاع منابع، برای تخصیص و توزیع منابع، و برای تعیین مقیاس‌پذیری و عملکرد کلی microservice ضروری است.
  </p>
<h3>شناسایی الزامات منابع اضافی</h3>
<p>
   در حالی که CPU و RAM دو مورد از رایج‌ترین الزامات منابع هستند، مهم است که مراقب سایر منابعی که یک microservice
   ممکن است در داخل اکوسیستم به آن‌ها نیاز داشته باشد، باشید. این‌ها می‌توانند منابع سخت‌افزاری مانند اتصالات پایگاه
   داده یا منابع پلتفرم برنامه مانند سهمیه‌های logging باشند. آگاهی از نیازهای یک microservice خاص می‌تواند کمک
   زیادی به بهبود مقیاس‌پذیری و عملکرد کند.
  </p>
<p>
   محاسبه الزامات منابع خاص یک microservice می‌تواند یک process دشوار و طولانی باشد، زیرا عوامل مرتبط زیادی
   وجود دارد. نکته اصلی در اینجا، همانطور که قبلاً ذکر کردم، تعیین این است که الزامات فقط برای یک نمونه از سرویس
   چه مواردی هستند. مؤثرترین و کارآمدترین راه برای مقیاس‌بندی سرویس ما، مقیاس‌بندی آن به صورت افقی است: اگر
   ترافیک ما در حال افزایش است، می‌خواهیم چند host دیگر اضافه کنیم و سرویس خود را در آن hostsهای جدید مستقر
   کنیم. برای اینکه ما بدانیم که چند host باید اضافه کنیم، باید بدانیم که سرویس ما چگونه روی فقط یک host اجرا
   می‌شود: چقدر ترافیک را می‌تواند مدیریت کند؟ چقدر از CPU استفاده می‌کند؟ چقدر حافظه؟
  </p>
<p>
   این اعداد دقیقاً به ما می‌گویند که الزامات منابع microservice ما چه هستند.
  </p>
<p>48 | فصل 4: مقیاس‌پذیری و عملکرد</p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 56" src="page_0056/image_1.png"/></div>
</div>
            </div>
            <div class="page original-page">
                <img src="page_0056_original/original_page.png" alt="Original Page 56">
            </div>
        </div>
        <div class="dual-page-spread">
            <div class="page persian-page">
                <div class="translated-content">
<div>
<h3>موانع منابع</h3>
<p>
   ما می‌توانیم محدودیت‌های عملکرد و مقیاس‌پذیری microservicesهای خود را با شناسایی موانع منابع کشف و اندازه‌گیری
   کنیم. یک مانع منبع، هر چیزی است که ذاتاً در مورد نحوه استفاده microservice از منابع خود وجود دارد و مقیاس‌پذیری
   برنامه را محدود می‌کند. این می‌تواند یک مانع زیرساختی یا چیزی در داخل معماری سرویس باشد که مانع از مقیاس‌پذیری
   آن می‌شود. به عنوان مثال، تعداد اتصالات پایگاه داده باز که یک microservice نیاز دارد، می‌تواند یک مانع باشد، اگر
   به حد اتصال پایگاه داده نزدیک شود. مثال دیگری از یک مانع منبع رایج زمانی است که microservicesها نیاز به
   مقیاس‌پذیری عمودی (به جای مقیاس‌پذیری افقی، که در آن نمونه‌ها/سخت‌افزار بیشتری اضافه می‌شود) دارند، زمانی که
   افزایش ترافیک را تجربه می‌کنند: اگر تنها راه برای مقیاس‌پذیری یک microservice افزایش منابع هر نمونه باشد (CPU
   بیشتر، حافظه بیشتر)، پس دو اصل مقیاس‌پذیری (concurrenty و partitioning) کنار گذاشته می‌شوند.
  </p>
<p>
   برخی از موانع منابع به راحتی قابل شناسایی هستند. اگر microservice شما فقط می‌تواند برای برآورده کردن ترافیک
   در حال رشد با استقرار آن در دستگاه‌هایی با CPU و حافظه بیشتر مقیاس‌پذیری داشته باشد، پس یک مانع
   مقیاس‌پذیری دارید و باید microservice را refactor کنید تا بتواند به صورت افقی مقیاس‌پذیری داشته باشد، و از
   concurrency و partitioning به عنوان اصول راهنمای خود استفاده کنید.
  </p>
<h3>مشکلات مقیاس‌پذیری عمودی</h3>
<p>
   مقیاس‌پذیری عمودی، یک روش پایدار یا مقیاس‌پذیر برای معماری microservices نیست. ممکن است در شرایطی که هر
   microservice دارای سخت‌افزار اختصاصی است، درست عمل کند، اما با فناوری‌های انتزاع و جداسازی سخت‌افزاری
   جدیدی که امروزه در دنیای فناوری استفاده می‌شود، مانند Docker و Apache Mesos، خوب عمل نخواهد کرد. اگر
   می‌خواهید یک برنامه مقیاس‌پذیر بسازید، همیشه برای concurrency و partitioning بهینه کنید.
  </p>
<p>
   سایر موانع منابع به همان اندازه واضح نیستند، و بهترین راه برای کشف آن‌ها، اجرای load testing گسترده در سرویس
   است. ما load testing را با جزئیات بیشتر در ??? پوشش خواهیم داد.
  </p>
<h3>Capacity Planning</h3>
<p>
   یکی از مهم‌ترین الزامات ساخت یک microservice مقیاس‌پذیر، اطمینان از این است که به منابع سخت‌افزاری لازم و
   مورد نیاز در حین مقیاس‌پذیری، دسترسی داشته باشد. استفاده کارآمد از منابع، برنامه‌ریزی برای رشد، و طراحی یک
   microservice برای کارایی و مقیاس‌پذیری عالی از ابتدا، اگر هیچ منبع سخت‌افزاری در دسترس نباشد، زمانی که
   microservice نیاز به میزبانی ترافیک production بیشتری داشته باشد، به سرعت بی‌فایده می‌شود. این چالش به
   ویژه برای microservicesهایی که برای مقیاس‌پذیری افقی بهینه شده‌اند، مرتبط است.
  </p>
<p>Capacity Planning | 49</p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 57" src="page_0057/image_1.png"/></div>
</div>
            </div>
            <div class="page original-page">
                <img src="page_0057_original/original_page.png" alt="Original Page 57">
            </div>
        </div>
        <div class="dual-page-spread">
            <div class="page persian-page">
                <div class="translated-content">
<div>
<p>
   علاوه بر چالش‌های فنی که همراه با این مشکل بالقوه وجود دارد، سازمان‌های مهندسی اغلب با مسائل مربوط به سطح
   سازمانی و مرتبط با کسب‌وکار بزرگ‌تری نیز مواجه هستند که همراه با آن می‌آیند: منابع سخت‌افزاری هزینه زیادی را
   در بر دارند، کسب‌وکارها و تیم‌های توسعه فردی در داخل آن‌ها بودجه‌هایی دارند که باید به آن‌ها پایبند باشند، و
   این بودجه‌ها (که تمایل دارند شامل سخت‌افزار شوند) باید از قبل برنامه‌ریزی شوند. برای اطمینان از اینکه microservicesها
   می‌توانند به درستی با افزایش ترافیک مقیاس‌پذیری داشته باشند، ما می‌توانیم capacity planning برنامه‌ریزی شده را
   انجام دهیم. اصول capacity planning کاملاً سرراست هستند: نیازهای سخت‌افزاری هر microservice را از قبل
   تعیین کنید، نیازها را در بودجه قرار دهید، و اطمینان حاصل کنید که سخت‌افزار مورد نیاز رزرو شده است.
  </p>
<p>
   برای تعیین نیازهای سخت‌افزاری هر سرویس، ما می‌توانیم از مقیاس‌های رشد (کمی و کیفی)، معیارهای کلیدی کسب‌وکار و
   پیش‌بینی‌های ترافیک، موانع و الزامات منابع شناخته شده، و داده‌های تاریخی در مورد ترافیک microservice استفاده
   کنیم. اینجاست که مقیاس‌های رشد کیفی و کمی بسیار مفید هستند، زیرا به ما اجازه می‌دهند دقیقاً بفهمیم که چگونه رفتار
   مقیاس‌پذیری microservicesهای ما با پیش‌بینی‌های کسب‌وکار سطح بالا مرتبط است. به عنوان مثال، اگر ما
   می‌دانیم که (1) microservice ما با بازدیدکنندگان منحصربه‌فرد از محصول کلی مقیاس‌پذیری دارد، (2) هر
   بازدیدکننده منحصربه‌فرد با تعداد معینی از درخواست‌ها در ثانیه که به microservice ما ارسال می‌شود مطابقت
   دارد، و (3) شرکت پیش‌بینی می‌کند که محصول در سه ماهه آینده 20000 بازدیدکننده منحصربه‌فرد جدید دریافت
   خواهد کرد، سپس ما دقیقاً می‌دانیم که نیازهای ظرفیت ما برای سه ماهه آینده چه خواهد بود.
  </p>
<p>
   این امر باید در بودجه هر تیم توسعه، هر سازمان مهندسی و هر شرکت لحاظ شود. اجرای این تمرین به‌صورت
   زمان‌بندی‌شده قبل از تعیین بودجه‌بندی می‌تواند به سازمان‌های مهندسی کمک کند تا اطمینان حاصل کنند که منابع
   سخت‌افزاری هرگز در دسترس نیستند، به این دلیل ساده که بودجه‌بندی منابع تکمیل یا آماده نشده است. نکته مهم
   در اینجا (هم از دیدگاه مهندسی و هم از دیدگاه کسب‌وکار) این است که هزینه برنامه‌ریزی ناکافی ظرفیت را تشخیص
   دهیم: microservicesهایی که به دلیل کمبود سخت‌افزار نمی‌توانند به درستی مقیاس‌پذیری داشته باشند، منجر به
   کاهش در دسترس بودن در کل اکوسیستم می‌شوند، که منجر به قطعی‌ها می‌شود، که هزینه‌هایی را برای شرکت به
   همراه دارد.
  </p>
<h3>Lead Time برای درخواست‌های سخت‌افزاری جدید</h3>
<p>
   یک مشکل بالقوه که معمولاً توسط تیم‌های توسعه در طول فاز capacity planning نادیده گرفته می‌شود این است که
   سخت‌افزاری که برای microservice مورد نیاز است ممکن است در زمان برنامه‌ریزی وجود نداشته باشد و ممکن است
   قبل از اینکه هر microservice بتواند روی آن اجرا شود، نیاز به تهیه، نصب و پیکربندی داشته باشد. قبل از برنامه‌ریزی
   capacity planning، مراقب باشید که زمان دقیق مورد نیاز برای تهیه سخت‌افزار جدید را پیدا کنید تا از کمبودهای
   طولانی در زمان‌های بحرانی جلوگیری کنید، و کمی فضا برای تأخیر در process در نظر بگیرید.
  </p>
<p>50 | فصل 4: مقیاس‌پذیری و عملکرد</p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 58" src="page_0058/image_1.png"/></div>
</div>
            </div>
            <div class="page original-page">
                <img src="page_0058_original/original_page.png" alt="Original Page 58">
            </div>
        </div>
        <div class="dual-page-spread">
            <div class="page persian-page">
                <div class="translated-content">
<div>
<p>
   هنگامی که منابع سخت‌افزاری تأمین و به هر microservice اختصاص داده شد، capacity planning تکمیل می‌شود. تعیین
   زمان و نحوه تخصیص سخت‌افزار پس از فاز برنامه‌ریزی، البته، به هر سازمان مهندسی و تیم‌های توسعه، زیرساخت و
   عملیات آن‌ها بستگی دارد.
  </p>
<p>
   Capacity planning می‌تواند یک task واقعاً دشوار و دستی باشد. مانند اکثر وظایف دستی در مهندسی، این موارد
   راه‌های جدید شکست را معرفی می‌کند: محاسبات دستی ممکن است اشتباه باشد، و حتی یک کمبود کوچک می‌تواند
   برای سرویس‌های حیاتی برای کسب‌وکار فاجعه‌بار باشد. خودکارسازی اکثر process capacity planning، تیم‌های
   توسعه و عملیات را حذف می‌کند و از خطاهای بالقوه و شکست‌ها می‌کاهد، و یک راه عالی برای انجام این کار، ساخت
   و اجرای یک ابزار سلف‌سرویس capacity planning در لایه پلتفرم application platform از اکوسیستم microservice
   است.
  </p>
<h3>مقیاس‌بندی وابستگی‌ها</h3>
<p>
   مقیاس‌پذیری وابستگی‌های یک microservice می‌تواند یک مشکل مقیاس‌پذیری خاص خود را ایجاد کند. یک
   microservice که معماری، ساخته و اجرا شده است تا از هر نظر کاملاً مقیاس‌پذیر باشد، همچنان با چالش‌های
   مقیاس‌پذیری مواجه است اگر وابستگی‌های آن نتوانند با آن مقیاس‌پذیری داشته باشند. اگر حتی یک وابستگی حیاتی
   نتواند با کلاینت‌هایش مقیاس‌پذیری داشته باشد، کل زنجیره وابستگی رنج می‌برد. اطمینان از اینکه تمام وابستگی‌ها
   با رشد مورد انتظار یک microservice مقیاس‌پذیری خواهند داشت، برای ساخت سرویس‌های آماده تولید ضروری
   است.
  </p>
<p>
   این چالش برای هر microservice جداگانه و هر قسمت از stack اکوسیستم microservice مربوط است، به این معنی
   که تیم‌های microservice نیز باید اطمینان حاصل کنند که سرویس آن‌ها یک مانع مقیاس‌پذیری برای کلاینت‌هایش
   نیست. به عبارت دیگر، پیچیدگی اضافی توسط بقیه اکوسیستم microservice معرفی می‌شود. باید برای ترافیک و
   رشد اضافی اجتناب‌ناپذیر از کلاینت‌های یک microservice آماده شد.
  </p>
<h3>مقیاس‌های رشد کیفی و مقیاس‌پذیری وابستگی</h3>
<p>
   هنگام برخورد با زنجیره‌های وابستگی فوق‌العاده پیچیده، اطمینان از اینکه تمام تیم‌های microservice، مقیاس‌پذیری
   سرویس‌های خود را با معیارهای کسب‌وکار سطح بالا مرتبط می‌کنند (با استفاده از مقیاس رشد کیفی) می‌تواند
   اطمینان حاصل کند که همه سرویس‌ها به‌درستی برای رشد مورد انتظار آماده شده‌اند، حتی زمانی که ارتباطات
   بین‌تیمی دشوار می‌شود.
  </p>
<p>
   مشکل مقیاس‌بندی وابستگی یک استدلال به‌ویژه قوی برای پیاده‌سازی استانداردهای مقیاس‌پذیری و عملکرد در سراسر
   هر قسمت از اکوسیستم microservice است. اکثر microservicesها در انزوا زندگی نمی‌کنند. تقریباً هر
   microservice یک بخش کوچک از زنجیره‌های وابستگی بزرگ، درهم‌تنیده و پیچیده است. در اکثر موارد، مقیاس‌بندی
   کل محصول، سازمان و اکوسیستم به‌طور مؤثر مستلزم آن است که هر قسمت از سیستم با بقیه مقیاس‌پذیری داشته
   باشد. داشتن تعداد کمی microservices با راندمان فوق‌العاده بالا، با عملکرد بالا و مقیاس‌پذیر در یک سیستم
  </p>
<p>مقیاس‌پذیری وابستگی | 51</p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 59" src="page_0059/image_1.png"/></div>
</div>
            </div>
            <div class="page original-page">
                <img src="page_0059_original/original_page.png" alt="Original Page 59">
            </div>
        </div>
        <div class="dual-page-spread">
            <div class="page persian-page">
                <div class="translated-content">
<div>
<p>
   جایی که بقیه سرویس‌ها به همان استانداردها پایبند نیستند (و آن‌ها را برآورده نمی‌کنند) کارایی سرویس‌های
   استاندارد شده را کاملاً بی‌اثر می‌کند.
  </p>
<p>
   جدا از استانداردسازی در سراسر اکوسیستم، و پایبندی هر تیم توسعه microservice به استانداردهای مقیاس‌پذیری
   بالا، مهم است که تیم‌های توسعه در سراسر مرزهای microservice با هم کار کنند تا اطمینان حاصل شود که هر
   زنجیره وابستگی با هم مقیاس‌پذیری خواهد داشت. تیم‌های توسعه مسئول هرگونه وابستگی یک microservice
   باید در هنگام انتظار افزایش ترافیک، هشدار داده شوند. ارتباطات و همکاری بین‌تیمی در اینجا ضروری است:
   ارتباط منظم با کلاینت‌ها و وابستگی‌ها در مورد الزامات مقیاس‌پذیری، وضعیت و هرگونه موانع یک سرویس می‌تواند به
   تضمین این کمک کند که هر سرویسی که به یکدیگر متکی هستند، برای رشد آماده هستند و از هرگونه موانع
   مقیاس‌پذیری بالقوه آگاه هستند. یک استراتژی که من برای کمک به تیم‌ها برای انجام این کار استفاده کرده‌ام، برگزاری
   جلسات بررسی معماری و مقیاس‌پذیری با تیم‌هایی است که سرویس‌هایشان به یکدیگر وابسته است. در این جلسات،
   ما معماری هر سرویس و محدودیت‌های مقیاس‌پذیری آن را پوشش می‌دهیم، سپس با هم در مورد آنچه که برای
   مقیاس‌پذیری کل مجموعه سرویس‌ها باید انجام شود، بحث می‌کنیم.
  </p>
<h3>مدیریت ترافیک</h3>
<p>
   همانطور که سرویس‌ها مقیاس‌پذیری دارند و تعداد درخواست‌هایی که هر سرویس باید مدیریت کند افزایش می‌یابد، یک
   سرویس مقیاس‌پذیر و با عملکرد بالا نیز باید ترافیک را هوشمندانه مدیریت کند. چندین جنبه برای مدیریت ترافیک به
   روش مقیاس‌پذیر و با عملکرد بالا وجود دارد: اول از همه، مقیاس رشد (کمی و کیفی) باید برای پیش‌بینی افزایش‌ها
   (یا کاهش‌ها) در ترافیک در آینده استفاده شود؛ دوم، الگوهای ترافیک باید به‌خوبی درک و برای آن آماده شوند؛ و
   سوم، microservicesها باید بتوانند افزایش ترافیک را به‌طور هوشمندانه مدیریت کنند، و همچنین فوران یا انفجارهای
   ترافیک را نیز مدیریت کنند.
  </p>
<p>
   ما قبلاً به جنبه اول در این فصل پرداختیم: درک مقیاس‌های رشد (هم کمی و هم کیفی) یک microservice به ما اجازه
   می‌دهد که بارهای ترافیکی فعلی را در سرویس درک کنیم و همچنین برای رشد ترافیک در آینده آماده شویم. درک
   الگوهای ترافیکی فعلی هنگام تعامل با سرویس در سطح پایه به روش‌های بسیار جالب کمک می‌کند. هنگامی که الگوهای
   ترافیکی به‌وضوح مشخص شدند، هم بر حسب درخواست در ثانیه ارسال‌شده به سرویس در طول زمان و هم تمام معیارهای
   کلیدی (به ???، برای اطلاعات بیشتر در مورد معیارهای کلیدی مراجعه کنید)، تغییرات در سرویس، downtimeهای
   عملیاتی، و استقرارها را می‌توان برای جلوگیری از زمان‌های اوج ترافیک برنامه‌ریزی کرد، و از قطعی‌های احتمالی
   آینده در صورت استقرار باگ و از downtime بالقوه در صورت راه‌اندازی مجدد microservice در حالی که بار ترافیکی
   بالایی را تجربه می‌کند، کاسته می‌شود. نظارت دقیق بر ترافیک با توجه به الگوهای ترافیکی و تنظیم دقیق آستانه‌های
   نظارت با در نظر گرفتن الگوهای ترافیکی microservice می‌تواند به سرعت به شناسایی هرگونه مشکل و incident
   قبل از ایجاد قطعی یا منجر به کاهش در دسترس بودن شود (اصول نظارت آماده برای تولید با جزئیات بیشتری در ???
   پوشش داده شده است).
  </p>
<p>52 | فصل 4: مقیاس‌پذیری و عملکرد</p>
</div>
</div>
                <div class="page-images">
</div>
            </div>
            <div class="page original-page">
                <img src="page_0060_original/original_page.png" alt="Original Page 60">
            </div>
        </div>
        <div class="dual-page-spread">
            <div class="page persian-page">
                <div class="translated-content">
<div>
<p>
   وقتی ما می‌توانیم رشد ترافیک آینده را پیش‌بینی کنیم و الگوهای ترافیکی فعلی و گذشته را به اندازه‌ای خوب درک
   کنیم که بدانیم الگوها با رشد مورد انتظار چگونه تغییر خواهند کرد، ما می‌توانیم load testing را در سرویس‌های خود
   انجام دهیم تا مطمئن شویم که آن‌ها همانطور که انتظار داریم در زیر بار ترافیک سنگین‌تر رفتار می‌کنند. جزئیات load
   testing در ??? پوشش داده شده است.
  </p>
<p>
   جنبه سوم مدیریت ترافیک، جایی است که اوضاع به‌ویژه دشوار می‌شود. نحوه رسیدگی یک microservice به ترافیک
   باید مقیاس‌پذیر باشد، به این معنی که باید برای تغییرات شدید در ترافیک آماده باشد، به‌ویژه فوران ترافیک، آن‌ها را
   با دقت مدیریت کند، و از این که آن‌ها سرویس را به‌طور کامل از کار بیندازند، جلوگیری کند. گفتنش آسان‌تر از
   انجام دادنش است، زیرا حتی microservicesهای با نظارت، مقیاس‌پذیر و با عملکرد بالا نیز می‌توانند در صورت
   افزایش ناگهانی ترافیک، مشکلات نظارت، logging و مشکلات عمومی دیگر را تجربه کنند. این نوع افزایش‌ها باید در
   سطح زیرساخت، در تمام سیستم‌های نظارت و logging، و توسط تیم توسعه به عنوان بخشی از مجموعه تست
   resiliency سرویس، آماده شوند.
  </p>
<p>
   یک جنبه اضافی دیگر وجود دارد که می‌خواهم ذکر کنم و مربوط به مدیریت ترافیک بین و در مکان‌های مختلف است.
   بسیاری از اکوسیستم‌های microservice فقط در یک مکان، یک datacenter، یا یک شهر مستقر نخواهند شد، بلکه در
   چندین datacenter در سراسر کشور (یا حتی جهان) مستقر می‌شوند. غیر معمول نیست که خود datacenterها،
   قطعی‌های در مقیاس بزرگ را تجربه کنند، و هنگامی که این اتفاق می‌افتد، کل اکوسیستم microservice می‌تواند (و
   معمولاً خواهد شد) همراه با datacenter از کار بیفتد. توزیع و هدایت ترافیک به طور مناسب بین datacenters
   مسئولیت سطح زیرساخت (به‌ویژه، لایه ارتباطی) از اکوسیستم microservice است، اما هر microservice باید آماده
   باشد تا ترافیک را از یک datacenter به دیگری دوباره هدایت کند بدون اینکه سرویس، هیچ‌گونه کاهش در
   دسترسی را تجربه کند.
  </p>
<h3>مدیریت و پردازش وظایف</h3>
<p>
   هر microservice در اکوسیستم microservice باید وظایفی از نوعی را پردازش کند. یعنی، هر microservice
   درخواست‌هایی را از سرویس‌های کلاینت upstream دریافت خواهد کرد که یا به نوعی اطلاعات از microservice نیاز
   دارند یا نیاز دارند که microservice چیزی را محاسبه یا پردازش کند و سپس اطلاعاتی در مورد آن محاسبه یا
   process برگرداند، و سپس microservice باید آن درخواست را برآورده کند (معمولاً با برقراری ارتباط با
   سرویس‌های downstream علاوه بر انجام مقداری کار خود) و هرگونه اطلاعات یا پاسخ درخواستی را به کلاینت
   ارسال‌کننده درخواست، برگرداند.
  </p>
<h3>محدودیت‌های زبان برنامه‌نویسی</h3>
<p>
   Microservices می‌توانند این کار را انجام دهند و نقش مورد نیاز خود را به طرق بی‌شماری ایفا کنند، و راه‌هایی که
   آن‌ها محاسبات را انجام می‌دهند، با سرویس‌های downstream تعامل می‌کنند و وظایف مختلف را پردازش
   می‌کنند، به زبانی که سرویس با آن نوشته شده است، و در نتیجه، به معماری سرویس (که از بسیاری جهات، با
   زبان تعیین می‌شود) بستگی دارد. به عنوان مثال، یک microservice که به زبان Python نوشته شده است
  </p>
<p>مدیریت و پردازش وظایف | 53</p>
</div>
</div>
                <div class="page-images">
</div>
            </div>
            <div class="page original-page">
                <img src="page_0061_original/original_page.png" alt="Original Page 61">
            </div>
        </div>
        <div class="dual-page-spread">
            <div class="page persian-page">
                <div class="translated-content">
<div>
<p>
   راه‌هایی برای پردازش وظایف مختلف دارد، که برخی از آن‌ها نیازمند استفاده از فریم‌ورک‌های ناهمزمان (مانند Tornado)
   و برخی دیگر از فناوری‌های پیام‌رسانی مانند RabbitMQ و Celery برای پردازش کارآمد وظایف هستند. به همین دلایل،
   توانایی یک microservice برای مدیریت و پردازش وظایف به روشی مقیاس‌پذیر و با عملکرد بالا، تا حدی با انتخاب
   زبان دیکته می‌شود.
  </p>
<h3>مراقب محدودیت‌های مقیاس‌پذیری و عملکرد زبان‌های برنامه‌نویسی باشید</h3>
<p>
   بسیاری از زبان‌های برنامه‌نویسی برای الزامات عملکرد و مقیاس‌پذیری معماری microservice بهینه نشده‌اند، یا
   فریم‌ورک‌های مقیاس‌پذیر یا با عملکرد بالایی ندارند که به microservices اجازه می‌دهند وظایف را به طور موثر
   پردازش کنند.
  </p>
<p>
   به دلیل محدودیت‌هایی که توسط انتخاب زبان در مورد توانایی یک microservice در پردازش کارآمد وظایف ایجاد
   می‌شود، انتخاب زبان در معماری microservice بسیار مهم می‌شود. برای بسیاری از توسعه‌دهندگان، یکی از نکات
   فروش پذیرش معماری microservice، توانایی نوشتن یک microservice به هر زبانی است، و این معمولاً درست است،
   اما با یک هشدار: باید محدودیت‌های زبان برنامه‌نویسی را در نظر گرفت، و انتخاب زبان نباید با این باشد که آیا
   زبان مد است یا سرگرم‌کننده است (یا حتی آیا رایج‌ترین زبانی است که تیم توسعه با آن آشنا است) تعیین
   شود، بلکه با محدودیت‌های عملکرد و مقیاس‌پذیری هر زبان بالقوه به عنوان عوامل تعیین‌کننده در نظر گرفته شود.
   هیچ زبان "بهترین" برای نوشتن یک microservice وجود ندارد، اما زبان‌هایی وجود دارد که برای انواع خاصی از
   microservices مناسب‌تر هستند.
  </p>
<h3>مدیریت درخواست‌ها و پردازش کارآمد وظایف</h3>
<p>
   صرف نظر از انتخاب زبان، استانداردسازی آمادگی برای تولید مستلزم آن است که هر microservice هم مقیاس‌پذیر
   و هم با عملکرد بالا باشد، به این معنی که microservicesها باید بتوانند تعداد زیادی از وظایف را همزمان مدیریت
   و پردازش کنند، آن وظایف را به طور موثر مدیریت و پردازش کنند، و برای افزایش وظایف و درخواست‌ها در آینده
   آماده باشند. با در نظر گرفتن این موضوع، تیم‌های توسعه باید بتوانند به سه سوال اساسی در مورد microservicesهای
   خود پاسخ دهند: microservice آن‌ها چگونه وظایف را پردازش می‌کند، microservice آن‌ها چقدر این وظایف را
   کارآمد پردازش می‌کند، و microservice آن‌ها چگونه با افزایش تعداد درخواست‌ها، عملکرد خواهد داشت.
  </p>
<p>
   برای اطمینان از مقیاس‌پذیری و عملکرد، microservicesها باید وظایف را به طور موثر پردازش کنند. برای انجام این
   کار، آن‌ها باید هم concurrency و هم partitioning داشته باشند. Concurrency مستلزم آن است که سرویس
   نمی‌تواند یک process واحد داشته باشد که تمام کار را انجام می‌دهد: آن process یک task را در یک زمان برمی‌دارد،
   مراحل را به ترتیب خاصی تکمیل می‌کند و سپس به سراغ مورد بعدی می‌رود، که یک راه نسبتاً ناکارآمد برای
   پردازش وظایف است. به جای معماری سرویس خود برای استفاده از یک process واحد، ما می‌توانیم concurrency را
   معرفی کنیم تا هر task به قطعات کوچکتر تقسیم شود.
  </p>
<p>54 | فصل 4: مقیاس‌پذیری و عملکرد</p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 62" src="page_0062/image_1.png"/></div>
</div>
            </div>
            <div class="page original-page">
                <img src="page_0062_original/original_page.png" alt="Original Page 62">
            </div>
        </div>
        <div class="dual-page-spread">
            <div class="page persian-page">
                <div class="translated-content">
<div>
<p>
   Microservices را به زبان‌های برنامه‌نویسی بنویسید که برای concurrency و partitioning بهینه شده‌اند
   <br/>
   برخی از زبان‌ها برای مدیریت و پردازش کارآمد (همزمان و partitioned) وظایف، مناسب‌تر از بقیه هستند. هنگام نوشتن یک
   microservice جدید، مطمئن شوید که زبانی که سرویس با آن نوشته می‌شود، محدودیت‌های مقیاس‌پذیری و عملکرد را به
   microservicesها وارد نمی‌کند. microservicesهایی که قبلاً به زبان‌هایی با محدودیت‌های کارایی نوشته شده‌اند،
   می‌توانند (و باید) به زبان‌های مناسب‌تری بازنویسی شوند، که یک task زمان‌بر اما فوق‌العاده ارزشمند است که می‌تواند
   مقیاس‌پذیری و عملکرد را به‌طور چشمگیری بهبود بخشد. به عنوان مثال، اگر شما برای concurrency و partitioning بهینه
   می‌کنید، و می‌خواهید از یک فریم‌ورک ناهمزمان برای کمک به انجام این کار استفاده کنید، نوشتن سرویس خود به زبان
   Python (به جای C++، Java یا Go—سه زبان ساخته شده برای concurrency و partitioning) باعث ایجاد موانع
   مقیاس‌پذیری و عملکرد زیادی می‌شود که کاهش آن‌ها دشوار خواهد بود.
  </p>
<p>
   با گرفتن قطعات کوچکتر از این وظایف، ما می‌توانیم آن‌ها را با استفاده از partitioning، که در آن هر task نه‌تنها به
   قطعات کوچکتر تقسیم می‌شود بلکه می‌تواند به موازات هم پردازش شود، کارآمدتر پردازش کنیم. اگر ما تعداد زیادی
   وظیفه کوچک داشته باشیم، می‌توانیم همه آن‌ها را همزمان با ارسال آن‌ها به مجموعه‌ای از workersها که می‌توانند
   آن‌ها را به موازات پردازش کنند، پردازش کنیم. اگر ما نیاز به پردازش وظایف بیشتری داشته باشیم، می‌توانیم به
   راحتی با افزودن workersهای اضافی برای پردازش وظایف جدید بدون تأثیر بر کارایی سیستم خود، با افزایش تقاضا
   مقیاس‌پذیری داشته باشیم. با هم، concurrency و partitioning به اطمینان از اینکه microservice ما برای
   مقیاس‌پذیری و partitioning بهینه شده است، کمک می‌کنند.
  </p>
<h3>ذخیره‌سازی داده‌های مقیاس‌پذیر</h3>
<p>
   Microservicesها باید داده‌ها را به روشی مقیاس‌پذیر و با عملکرد بالا مدیریت کنند. نحوه ذخیره و مدیریت داده‌ها توسط
   یک microservice می‌تواند به راحتی به مهم‌ترین محدودیت یا مانعی تبدیل شود که از مقیاس‌پذیر و با عملکرد بالا
   شدن آن جلوگیری می‌کند: انتخاب پایگاه داده اشتباه، schema اشتباه، یا یک پایگاه داده که از test tenancy پشتیبانی
   نمی‌کند، می‌تواند در نهایت در دسترس بودن کلی یک microservice را به خطر بیندازد. انتخاب پایگاه داده مناسب
   برای یک microservice، موضوعی است که، مانند تمام موضوعات دیگری که در این کتاب پوشش داده شده است،
   فوق‌العاده پیچیده است، و ما فقط در این فصل به آن اشاره‌ای خواهیم کرد. در بخش‌های زیر، ما به چندین نکته برای
   در نظر گرفتن هنگام انتخاب پایگاه‌های داده در اکوسیستم‌های microservice، و سپس به برخی از چالش‌های پایگاه
   داده که مختص معماری microservice هستند، خواهیم پرداخت.
  </p>
<h3>انتخاب پایگاه داده در اکوسیستم‌های Microservice</h3>
<p>
   ساختن، اجرای و نگهداری پایگاه‌های داده در اکوسیستم‌های microservice بزرگ، یک کار آسان نیست. برخی از
   شرکت‌هایی که معماری microservice را اتخاذ می‌کنند، انتخاب می‌کنند که به توسعه‌دهندگان اجازه دهند
  </p>
<p>ذخیره‌سازی داده‌های مقیاس‌پذیر | 55</p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 63" src="page_0063/image_1.png"/></div>
</div>
            </div>
            <div class="page original-page">
                <img src="page_0063_original/original_page.png" alt="Original Page 63">
            </div>
        </div>
        <div class="dual-page-spread">
            <div class="page persian-page">
                <div class="translated-content">
<div>
<p>
   teamهای توسعه را قادر سازند که پایگاه‌های داده خود را انتخاب، بسازند و نگهداری کنند، در حالی که بقیه حداقل در مورد
   یک گزینه پایگاه داده که برای اکثر microservicesها در شرکت کار می‌کند، تصمیم می‌گیرند، و یک تیم جداگانه برای
   اجرا و نگهداری پایگاه داده(ها) ایجاد می‌کنند تا توسعه‌دهندگان بتوانند فقط بر روی microservicesهای خود تمرکز
   کنند.
  </p>
<p>
   اگر ما در مورد معماری microservice به عنوان متشکل از چهار لایه جداگانه فکر کنیم (برای جزئیات بیشتر به
   "معماری Microservice" در صفحه 9 مراجعه کنید) و تشخیص دهیم که، به لطف قانون معکوس Conway، سازمان‌های
   مهندسی شرکت‌هایی که معماری microservice را اتخاذ می‌کنند، معماری محصول آن را منعکس خواهند کرد، پس
   می‌توانیم ببینیم که مسئولیت انتخاب پایگاه‌های داده مناسب، ساختن آن‌ها، اجرای آن‌ها و نگهداری آن‌ها در کجا
   قرار دارد: یا در لایه پلتفرم application platform، که به پایگاه‌های داده اجازه می‌دهد به عنوان یک سرویس به
   تیم‌های microservice ارائه شوند، یا لایه microservice، جایی که پایگاه داده استفاده شده توسط یک microservice
   به عنوان بخشی از سرویس در نظر گرفته می‌شود. من هر دوی این تنظیمات را در عمل در شرکت‌های مختلف دیده‌ام، و
   برخی بهتر از بقیه کار می‌کنند. من همچنین متوجه شده‌ام که یک رویکرد در این زمینه به‌خوبی کار می‌کند: ارائه
   پایگاه‌های داده به عنوان یک سرویس در داخل لایه application platform، و سپس اجازه دادن به تیم‌های توسعه
   microservice جداگانه برای اجرای پایگاه داده خودشان اگر پایگاه‌های داده ارائه شده به عنوان بخشی از application
   platform، نیازهای خاص آن‌ها را برآورده نمی‌کنند.
  </p>
<p>
   رایج‌ترین انواع پایگاه‌های داده، پایگاه‌های داده رابطه‌ای (SQL، MySQL) و پایگاه‌های داده NoSQL (Cassandra،
   Vertica، MongoDB و key-value storesها مانند Dynamo، Redis و Riak) هستند. انتخاب بین یک پایگاه داده
   رابطه‌ای و یک پایگاه داده NoSQL، و سپس انتخاب پایگاه داده مناسب خاص برای نیازهای یک microservice به
   پاسخ به چندین سؤال بستگی دارد:
  </p>
<ul>
<li>تراکنش‌های مورد نیاز در ثانیه هر microservice چقدر است؟</li>
<li>هر microservice چه نوع داده‌ای را باید ذخیره کند؟</li>
<li>schema مورد نیاز هر microservice چیست؟ و چند وقت یک‌بار نیاز به تغییر آن خواهد بود؟</li>
<li>آیا microservicesها به سازگاری قوی یا سازگاری نهایی نیاز دارند؟</li>
<li>آیا microservicesها read-heavy هستند، write-heavy هستند یا هر دو؟</li>
<li>آیا پایگاه داده باید به صورت افقی یا عمودی مقیاس‌پذیری داشته باشد؟</li>
</ul>
<p>
   صرف نظر از اینکه پایگاه داده به عنوان بخشی از application platform نگهداری می‌شود یا توسط هر تیم توسعه
   microservice جداگانه، انتخاب پایگاه داده باید با پاسخ به آن سؤالات هدایت شود. به عنوان مثال، اگر پایگاه داده
   مورد نظر نیاز به مقیاس‌پذیری افقی داشته باشد، یا اگر خواندن و نوشتن نیاز به انجام موازی داشته باشد، پس باید یک
   پایگاه داده NoSQL انتخاب شود، زیرا پایگاه‌های داده رابطه‌ای با مقیاس‌پذیری افقی و خواندن و نوشتن موازی
   مشکل دارند.
  </p>
<p>56 | فصل 4: مقیاس‌پذیری و عملکرد</p>
</div>
</div>
                <div class="page-images">
</div>
            </div>
            <div class="page original-page">
                <img src="page_0064_original/original_page.png" alt="Original Page 64">
            </div>
        </div>
        <div class="dual-page-spread">
            <div class="page persian-page">
                <div class="translated-content">
<div>
<h3>چالش‌های پایگاه داده در معماری Microservice</h3>
<p>
   چندین چالش با پایگاه‌های داده وجود دارد که مختص معماری microservice است. هنگامی که پایگاه‌های داده بین
   microservicesها به اشتراک گذاشته می‌شوند، رقابت برای منابع شروع می‌شود، و برخی از microservicesها ممکن
   است بیش از سهم منصفانه خود از فضای ذخیره‌سازی موجود استفاده کنند. مهندسان که پایگاه‌های داده مشترک را
   می‌سازند و نگهداری می‌کنند، باید راه‌حل‌های ذخیره‌سازی داده‌های خود را به گونه‌ای طراحی کنند که پایگاه داده
   بتواند به راحتی مقیاس‌پذیر شود اگر هر یک از microservicesهای tenant یا به فضای اضافی نیاز داشته باشند یا در
   معرض خطر استفاده از تمام فضای موجود باشند.
  </p>
<h3>مراقب اتصالات پایگاه داده باشید</h3>
<p>
   برخی از پایگاه‌های داده، محدودیت‌های شدیدی در تعداد اتصالات پایگاه داده که می‌توانند به‌طور همزمان باز باشند،
   دارند. اطمینان حاصل کنید که تمام اتصالات به‌درستی بسته شده‌اند تا از به خطر افتادن در دسترس بودن سرویس و
   در دسترس بودن پایگاه داده برای تمام microservicesهایی که از آن استفاده می‌کنند، جلوگیری شود.
  </p>
<p>
   چالش دیگری که microservicesها اغلب با آن مواجه می‌شوند، به‌ویژه پس از اینکه چرخه‌های توسعه و pipelineهای
   استقرار پایدار و قابل اعتماد را ساختند و استاندارد کردند، مدیریت داده‌های تست از تست end-to-end، load
   testing، و هر نوشتن تست انجام شده در staging است. همانطور که در "The Deployment Pipeline" در صفحه 28
   ذکر شد، فاز staging از pipeline استقرار نیازمند خواندن و/یا نوشتن در پایگاه‌های داده است. اگر full staging
   پیاده‌سازی شده باشد، سپس فاز staging، پایگاه داده تست و staging جداگانه خود را خواهد داشت، اما partial
   staging به دسترسی خواندن و نوشتن به سرورهای production نیاز دارد، بنابراین باید مراقبت زیادی انجام شود تا
   اطمینان حاصل شود که داده‌های تست به‌درستی مدیریت می‌شوند: باید به‌وضوح به عنوان داده‌های تست علامت‌گذاری
   شوند (proccessی که به عنوان test tenancy شناخته می‌شود)، و سپس تمام داده‌های تست باید در فواصل منظم
   حذف شوند.
  </p>
<h3>ارزیابی Microservice شما</h3>
<p>
   اکنون که درک بهتری از مقیاس‌پذیری و عملکرد دارید، از لیست سؤالات زیر برای ارزیابی آمادگی production
   microservice(های) خود و اکوسیستم microservice استفاده کنید. سؤالات بر اساس موضوع سازماندهی شده‌اند و
   با بخش‌های این فصل مطابقت دارند.
  </p>
<p>ارزیابی Microservice شما | 57</p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 65" src="page_0065/image_1.png"/></div>
</div>
            </div>
            <div class="page original-page">
                <img src="page_0065_original/original_page.png" alt="Original Page 65">
            </div>
        </div>
        <div class="dual-page-spread">
            <div class="page persian-page">
                <div class="translated-content">
<div>
<h3>دانستن مقیاس رشد</h3>
<ul>
<li>مقیاس رشد کیفی این microservice چیست؟</li>
<li>مقیاس رشد کمی این microservice چیست؟</li>
</ul>
<h3>استفاده کارآمد از منابع</h3>
<ul>
<li>آیا microservice بر روی سخت‌افزار اختصاصی یا مشترک اجرا می‌شود؟</li>
<li>آیا از فناوری‌های انتزاع و تخصیص منابع استفاده می‌شود؟</li>
</ul>
<h3>آگاهی از منابع</h3>
<ul>
<li>الزامات منابع microservice (CPU، RAM و غیره) چیست؟</li>
<li>یک نمونه از microservice چقدر ترافیک را می‌تواند مدیریت کند؟</li>
<li>یک نمونه از microservice به چقدر CPU نیاز دارد؟</li>
<li>یک نمونه از microservice به چقدر حافظه نیاز دارد؟</li>
<li>آیا الزامات منابع دیگری وجود دارد که مختص این microservice باشد؟</li>
<li>موانع منابع این microservice چیست؟</li>
<li>آیا این microservice نیاز به مقیاس‌پذیری عمودی، افقی یا هر دو دارد؟</li>
</ul>
<h3>Capacity Planning</h3>
<ul>
<li>آیا capacity planning به‌صورت زمان‌بندی‌شده انجام می‌شود؟</li>
<li>زمان تحویل برای سخت‌افزار جدید چقدر است؟</li>
<li>درخواست‌های سخت‌افزاری چند بار انجام می‌شوند؟</li>
<li>آیا هنگام درخواست سخت‌افزار، به microservicesها اولویت داده می‌شود؟</li>
<li>آیا capacity planning خودکار است یا دستی؟</li>
</ul>
<h3>مقیاس‌بندی وابستگی‌ها</h3>
<ul>
<li>وابستگی‌های این microservice چیست؟</li>
<li>آیا وابستگی‌ها مقیاس‌پذیر و با عملکرد بالا هستند؟</li>
<li>آیا وابستگی‌ها با رشد مورد انتظار این microservice مقیاس‌پذیری خواهند داشت؟</li>
</ul>
<p>58 | فصل 4: مقیاس‌پذیری و عملکرد</p>
</div>
</div>
                <div class="page-images">
</div>
            </div>
            <div class="page original-page">
                <img src="page_0066_original/original_page.png" alt="Original Page 66">
            </div>
        </div>
        <div class="dual-page-spread">
            <div class="page persian-page">
                <div class="translated-content">
<div>
<ul>
<li>آیا مالکان وابستگی برای رشد مورد انتظار این microservice آماده هستند؟</li>
</ul>
<h3>مدیریت ترافیک</h3>
<ul>
<li>آیا الگوهای ترافیکی microservice به‌خوبی درک شده‌اند؟</li>
<li>آیا تغییرات سرویس در اطراف الگوهای ترافیکی برنامه‌ریزی شده‌اند؟</li>
<li>آیا تغییرات شدید در الگوهای ترافیکی (به‌ویژه فوران ترافیک) با دقت و به‌درستی مدیریت می‌شوند؟</li>
<li>آیا ترافیک را می‌توان در صورت شکست، به‌طور خودکار به datacentersهای دیگر هدایت کرد؟</li>
</ul>
<h3>مدیریت و پردازش وظایف</h3>
<ul>
<li>آیا microservice به زبانی برنامه‌نویسی نوشته شده است که به سرویس اجازه می‌دهد مقیاس‌پذیر و با
    عملکرد بالا باشد؟</li>
<li>آیا محدودیت‌های مقیاس‌پذیری یا عملکردی در نحوه رسیدگی microservice به درخواست‌ها وجود دارد؟</li>
<li>آیا محدودیت‌های مقیاس‌پذیری یا عملکردی در نحوه پردازش وظایف microservice وجود دارد؟</li>
<li>آیا توسعه‌دهندگان در تیم microservice درک می‌کنند که سرویس آن‌ها چگونه وظایف را پردازش می‌کند، چقدر
    کارآمد آن‌ها را پردازش می‌کند، و چگونه سرویس با افزایش تعداد وظایف و درخواست‌ها، عملکرد خواهد
    داشت؟</li>
</ul>
<h3>ذخیره‌سازی داده‌های مقیاس‌پذیر</h3>
<ul>
<li>آیا این microservice داده‌ها را به روشی مقیاس‌پذیر و با عملکرد بالا مدیریت می‌کند؟</li>
<li>این microservice به چه نوع داده‌ای نیاز دارد تا ذخیره کند؟</li>
<li>schema مورد نیاز برای داده‌های آن چیست؟</li>
<li>چند تراکنش در ثانیه مورد نیاز است و/یا انجام می‌شود؟</li>
<li>آیا این microservice به عملکرد خواندن یا نوشتن بالاتری نیاز دارد؟</li>
<li>آیا read-heavy است، write-heavy است یا هر دو؟</li>
<li>آیا پایگاه داده این سرویس به‌صورت افقی یا عمودی مقیاس‌بندی می‌شود؟ آیا replication یا partitioned
    شده است؟</li>
<li>آیا این microservice از یک پایگاه داده اختصاصی یا مشترک استفاده می‌کند؟</li>
<li>سرویس چگونه داده‌های تست را مدیریت و/یا ذخیره می‌کند؟</li>
</ul>
<p>ارزیابی Microservice شما | 59</p>
</div>
</div>
                <div class="page-images">
</div>
            </div>
            <div class="page original-page">
                <img src="page_0067_original/original_page.png" alt="Original Page 67">
            </div>
        </div>
        <div class="dual-page-spread">
            <div class="page persian-page">
                <div class="translated-content">
<div>
<h3>فصل 7</h3>
<h3>مستندات و درک</h3>
<p>
   یک microservice آماده تولید، مستند شده و درک شده است. مستندات و درک سازمانی، سرعت توسعه‌دهنده را افزایش
   می‌دهند در حالی که دو مورد از مهم‌ترین trade-offها را که با اتخاذ معماری microservice همراه هستند، کاهش
   می‌دهند: organizational sprawl و technical debt. این فصل عناصر ضروری مستندسازی و درک یک microservice
   را بررسی می‌کند، از جمله نحوه ساخت مستندات جامع و مفید، نحوه افزایش درک microservice در هر سطح از اکوسیستم
   microservice، و نحوه پیاده‌سازی production-readiness در سراسر یک سازمان مهندسی.
  </p>
<h3>اصول مستندسازی و درک Microservice</h3>
<p>
   من این فصل پایانی را در مورد آخرین اصل استانداردسازی microservice با یک داستان معروف از ادبیات روسیه آغاز
   می‌کنم. در حالی که ممکن است نقل قول از داستایفسکی در یک کتاب در مورد معماری نرم‌افزار نسبتاً نامتعارف به
   نظر برسد، شخصیت Grushenka در The Brothers Karamazov، آنچه را که من کلید مستندسازی و درک
   microservice می‌دانم، کاملاً به تصویر می‌کشد: "فقط یک چیز را بدان، Rakitka، من ممکن است شرور باشم، اما
   من همچنان یک پیاز دادم."
  </p>
<p>
   بخش مورد علاقه من در رمان درخشان داستایفسکی، داستانی است که توسط شخصیت Grushenka در مورد یک زن
   پیر و یک پیاز نقل شده است. داستان این‌گونه است: روزی روزگاری، یک زن پیر و تلخ وجود داشت که بسیار خودخواه
   و بی‌دل بود. روزی، او با یک گدا برخورد کرد و به دلایلی، احساس ترحم زیادی کرد. او می‌خواست چیزی به گدا
   بدهد، اما تنها چیزی که داشت یک پیاز بود، بنابراین او پیاز خود را به گدا داد.
   <br/>
   زن پیر در نهایت درگذشت، و به لطف تلخی و سردی قلبش، سر از جهنم درآورد. پس از اینکه او مدتی رنج کشید،
   یک فرشته آمد تا او را نجات دهد، زیرا خداوند یک عمل ایثارگرانه او در زندگی را به یاد آورده بود، و می‌خواست این
   را گسترش دهد
  </p>
<p>61</p>
</div>
</div>
                <div class="page-images">
</div>
            </div>
            <div class="page original-page">
                <img src="page_0069_original/original_page.png" alt="Original Page 69">
            </div>
        </div>
        <div class="dual-page-spread">
            <div class="page persian-page">
                <div class="translated-content">
<div>
<p>
   همان مهربانی را در پاسخ به او بدهد. فرشته با یک پیاز در دستش به او رسید. زن پیر پیاز را گرفت، اما
   متأسفانه، گناهکاران دیگر اطراف او نیز به سمت پیاز رفتند. ماهیت سرد و تلخ او شروع به کار کرد، و او
   سعی کرد آن‌ها را دفع کند، نخواست که هیچ‌کدام از آن‌ها تکه‌ای از پیاز را داشته باشند، و متأسفانه، وقتی
   سعی کرد پیاز را از آن‌ها دور کند، پیاز به لایه‌های زیادی تقسیم شد و او و گناهکاران دیگر دوباره به جهنم
   افتادند.
  </p>
<p>
   این دلگرم‌کننده‌ترین داستان نیست، اما یک درس اخلاقی در داستان Grushenka وجود دارد که من آن را به طرز
   قابل‌توجهی برای practice مستندسازی microservice قابل استفاده می‌دانم: همیشه یک پیاز بدهید.
  </p>
<p>
   اهمیت مستندات کامل و به‌روزرسانی‌شده برای هر microservice را نمی‌توان به‌اندازه کافی مورد تأکید قرار داد. از
   توسعه‌دهندگان که در یک اکوسیستم microservice کار می‌کنند بپرسید که نگرانی‌های اصلی آن‌ها چیست، و آن‌ها
   یک لیست از ویژگی‌هایی که هنوز باید پیاده‌سازی شوند، باگ‌هایی که باید رفع شوند، وابستگی‌هایی که مشکل
   ایجاد می‌کنند، و چیزهایی که در مورد سرویس خودشان و وابستگی‌هایی که به آن‌ها تکیه می‌کنند، درک
   نمی‌کنند، را با سرعت زیادی بیان خواهند کرد. وقتی از آن‌ها خواسته می‌شود که به جزئیات بیشتر در مورد
   دو مورد دوم بپردازند، آن‌ها تمایل دارند پاسخ‌های مشابهی ارائه دهند: آن‌ها درک نمی‌کنند که چگونه کار
   می‌کند، یک جعبه سیاه است، و مستندات کاملاً بی‌فایده است.
  </p>
<p>
   مستندات ضعیف از وابستگی‌ها و ابزارهای داخلی، توسعه‌دهندگان را کند می‌کند و بر توانایی آن‌ها در آماده کردن
   سرویس‌های خود برای production تأثیر می‌گذارد. این امر آن‌ها را از استفاده صحیح از وابستگی‌ها و ابزارهای
   داخلی باز می‌دارد و ساعت‌های بی‌شماری از مهندسی را هدر می‌دهد، زیرا گاهی اوقات تنها راه برای فهمیدن
   کاری که یک سرویس یا ابزار انجام می‌دهد (بدون مستندات مناسب) مهندسی معکوس آن است تا زمانی که بفهمید
   چگونه کار می‌کند.
  </p>
<p>
   مستندات ضعیف یک سرویس نیز به بهره‌وری توسعه‌دهندگانی که به آن کمک می‌کنند، آسیب می‌رساند. به عنوان
   مثال، عدم وجود runbookها برای یک شیفت در دسترس بودن به این معنی است که هر کسی که در دسترس است،
   باید هر بار هر مشکل را از ابتدا حل کند. بدون یک راهنمای onboarding، هر توسعه‌دهنده جدیدی که روی سرویس
   کار می‌کند، باید از ابتدا شروع کند تا نحوه عملکرد سرویس را درک کند. نقاط شکست واحد و مشکلات مربوط به
   سرویس تا زمانی که باعث قطعی نشوند، مورد توجه قرار نمی‌گیرند. ویژگی‌های جدید اضافه شده به سرویس اغلب
   تصویر بزرگی از نحوه عملکرد واقعی سرویس را از دست می‌دهند.
  </p>
<p>
   هدف از مستندات خوب و آماده تولید، ایجاد و نگهداری یک repository متمرکز از دانش در مورد سرویس است. به
   اشتراک گذاشتن این دانش دارای دو component است: حقایق محض در مورد سرویس، و درک سازمانی از کاری که
   سرویس انجام می‌دهد و جایی که در سازمان به عنوان یک کل قرار می‌گیرد. سپس مشکل مستندات ضعیف را می‌توان
   به دو زیرمشکل تقسیم کرد: کمبود مستندات (حقایق) و کمبود درک. حل این دو زیرمشکل مستلزم استانداردسازی
   مستندات برای هر microservice و قرار دادن ساختارهای سازمانی برای به اشتراک گذاشتن درک microservice
   است.
  </p>
<p>62 | فصل 7: مستندات و درک</p>
</div>
</div>
                <div class="page-images">
</div>
            </div>
            <div class="page original-page">
                <img src="page_0070_original/original_page.png" alt="Original Page 70">
            </div>
        </div>
        <div class="dual-page-spread">
            <div class="page persian-page">
                <div class="translated-content">
<div>
<p>
   داستان Grushenka، قانون طلایی مستندسازی microservice است: همیشه یک پیاز بدهید. برای خودتان، برای توسعه‌دهندگان
   همکار که روی سرویس شما کار می‌کنند، و برای توسعه‌دهندگانی که سرویس‌هایشان به شما وابسته است، یک پیاز بدهید.
  </p>
<h3>یک سرویس آماده تولید، مستندسازی شده و درک شده است</h3>
<ul>
<li>دارای مستندات جامع است.</li>
<li>مستندات آن به‌طور منظم به‌روزرسانی می‌شوند.</li>
<li>مستندات آن شامل توضیحی از microservice؛ یک نمودار معماری؛ اطلاعات تماس و در دسترس بودن؛ پیوندهایی به
    اطلاعات مهم؛ یک راهنمای onboarding و توسعه؛ اطلاعاتی در مورد جریان(های) درخواست سرویس، endpointsها و
    وابستگی‌ها؛ یک runbook در دسترس بودن؛ و پاسخ به سؤالات متداول است.</li>
<li>در سطح توسعه‌دهنده، تیم و سازمان به‌خوبی درک شده است.</li>
<li>به مجموعه‌ای از استانداردهای آمادگی برای تولید پایبند است و الزامات مرتبط را برآورده می‌کند.</li>
<li>معماری آن به‌طور مکرر بررسی و ممیزی می‌شود.</li>
</ul>
<h3>مستندات Microservice</h3>
<p>
   مستندات برای تمام microservicesها در یک سازمان مهندسی باید در یک مکان متمرکز، مشترک و با دسترسی آسان
   ذخیره شود. هر توسعه‌دهنده در هر تیمی باید بتواند مستندات هر microservice را بدون هیچ مشکلی پیدا کند. یک وب‌سایت
   داخلی که حاوی مستندات برای تمام microservicesها و ابزارهای داخلی است، معمولاً بهترین رسانه برای این کار
   است.
  </p>
<h3>READMEها و نظرات کد، مستندات نیستند</h3>
<p>
   بسیاری از توسعه‌دهندگان، مستندات microservices خود را به یک فایل README در repository خود یا به
   نظراتی که در سراسر کد پراکنده شده‌اند، محدود می‌کنند. در حالی که داشتن یک README ضروری است، و تمام
   کدهای microservice باید حاوی نظرات مناسب باشند، این مستندات آماده تولید نیست و مستلزم این است که
   توسعه‌دهندگان کد را بررسی و جستجو کنند. مستندات مناسب در یک مکان متمرکز (مانند یک وب‌سایت) ذخیره
   می‌شود، جایی که مستندات برای تمام microservicesها در سازمان مهندسی وجود دارد.
  </p>
<p>
   مستندات باید به‌طور منظم به‌روزرسانی شوند. هر زمان که تغییر قابل‌توجهی در سرویس ایجاد شد، مستندات باید
   به‌روز شوند. به عنوان مثال، اگر یک API endpoint جدید اضافه شد، اطلاعات مربوط به endpoint باید به
   مستندات اضافه شود
  </p>
<p>مستندات Microservice | 63</p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 71" src="page_0071/image_1.png"/></div>
</div>
            </div>
            <div class="page original-page">
                <img src="page_0071_original/original_page.png" alt="Original Page 71">
            </div>
        </div>
        <div class="dual-page-spread">
            <div class="page persian-page">
                <div class="translated-content">
<div>
<p>
   همچنین. اگر یک هشدار جدید اضافه شد، دستورالعمل‌های گام به گام در مورد نحوه triage، کاهش و حل هشدار نیز باید به
   runbook در دسترس بودن سرویس اضافه شود. اگر یک وابستگی جدید اضافه شد، اطلاعات مربوط به آن وابستگی باید به
   مستندات اضافه شود. همیشه یک پیاز بدهید.
  </p>
<p>
   بهترین راه برای انجام این کار این است که process به‌روزرسانی مستندات را به بخشی از workflow توسعه تبدیل
   کنیم. اگر به‌روزرسانی مستندات به عنوان یک task جداگانه (و ثانویه نسبت به) توسعه دیده شود، هرگز انجام نخواهد
   شد و به بخشی از technical debt سرویس تبدیل می‌شود. برای کاهش technical debt، توسعه‌دهندگان باید تشویق
   شوند (یا، در صورت نیاز، ملزم شوند) که هر تغییر کد مهم را با یک به‌روزرسانی در مستندات همراه کنند.
  </p>
<h3>به‌روزرسانی مستندات را به بخشی از چرخه توسعه تبدیل کنید</h3>
<p>
   اگر به‌روزرسانی و بهبود مستندات به‌عنوان ثانویه نسبت به نوشتن کد در نظر گرفته شود، اغلب کنار گذاشته می‌شود و به
   بخشی از technical debt سرویس تبدیل می‌شود. برای جلوگیری از این امر، به‌روزرسانی‌ها و بهبودهای مستندات را
   به بخش ضروری از چرخه توسعه سرویس تبدیل کنید.
  </p>
<p>
   مستندات باید جامع و مفید باشند. مستندات باید شامل تمام حقایق مربوطه و مهم در مورد سرویس باشد. پس از خواندن
   مستندات، یک توسعه‌دهنده باید بداند که چگونه سرویس را توسعه دهد و به آن کمک کند؛ معماری سرویس؛ اطلاعات
   تماس و در دسترس بودن برای سرویس؛ نحوه عملکرد سرویس (جریان‌های درخواست، endpointsها، وابستگی‌ها و
   غیره)؛ نحوه triage، کاهش و رفع حوادث و قطعی‌ها و همچنین حل هشدارها تولید شده توسط سرویس؛ و پاسخ به
   سوالات متداول در مورد سرویس.
  </p>
<p>
   از همه مهم‌تر، مستندات باید به‌وضوح نوشته شوند و باید به راحتی قابل درک باشند. مستندات سنگین از نظر اصطلاحات،
   بی‌فایده است، مستنداتی که بیش از حد فنی هستند و چیزهایی را که ممکن است مختص سرویس باشند توضیح نمی‌دهند
   نیز بی‌فایده هستند، همانطور که مستنداتی که اصلاً به جزئیات مهم نمی‌پردازند، بی‌فایده هستند. هدف از نوشتن
   مستندات خوب، تمیز و واضح این است که آن را به گونه‌ای بنویسید که توسط هر توسعه‌دهنده، مدیر، مدیر محصول یا
   مدیر اجرایی در داخل شرکت قابل درک باشد.
  </p>
<p>
   بیایید کمی عمیق‌تر به هر یک از عناصر مستندات microservice آماده برای تولید بپردازیم.
  </p>
<h3>توضیحات</h3>
<p>
   مستندات هر microservice باید با توضیحی از سرویس شروع شود. باید کوتاه، مختصر و مفید باشد. به عنوان مثال،
   اگر یک microservice به نام receipt-sender وجود دارد که هدف آن ارسال یک رسید پس از تکمیل سفارش توسط
   مشتری است، توضیحات باید به این صورت باشد:
  </p>
<p>64 | فصل 7: مستندات و درک</p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 72" src="page_0072/image_1.png"/></div>
</div>
            </div>
            <div class="page original-page">
                <img src="page_0072_original/original_page.png" alt="Original Page 72">
            </div>
        </div>
        <div class="dual-page-spread">
            <div class="page persian-page">
                <div class="translated-content">
<div>
<h3>توضیحات:</h3>
<p>
   پس از اینکه مشتری سفارشی را ثبت کرد، receipt-sender یک رسید را از طریق ایمیل به مشتری ارسال
   می‌کند.
  </p>
<p>
   این امر ضروری است زیرا تضمین می‌کند که هر کسی که مستندات را پیدا می‌کند، می‌داند microservice چه نقشی در
   اکوسیستم microservice ایفا می‌کند.
  </p>
<h3>نمودار معماری</h3>
<p>
   توضیحات سرویس باید با یک نمودار معماری دنبال شود. این نمودار باید معماری سرویس، از جمله componentها،
   endpointsها، جریان درخواست، وابستگی‌های آن (هم upstream و هم downstream) و اطلاعاتی در مورد هر پایگاه
   داده یا cache را شرح دهد. یک نمونه نمودار معماری را در شکل 7-1 مشاهده کنید.
  </p>
<p>
   نمودارهای معماری به چندین دلیل ضروری هستند. تقریباً غیرممکن است که فقط با خواندن کد، نحوه و چرایی
   عملکرد یک microservice را درک کنید، و بنابراین یک نمودار معماری که به‌خوبی طراحی شده است، یک توصیف و
   خلاصه بصری آسان و قابل درک از microservice است. این نمودارها همچنین به توسعه‌دهندگان در افزودن
   ویژگی‌های جدید با انتزاع کارکرد داخلی سرویس کمک می‌کنند تا توسعه‌دهندگان بتوانند ببینند که ویژگی‌های جدید
   کجا و چگونه (یا نخواهند) جا می‌افتند. مهم‌تر از همه، آن‌ها مسائل و مشکلات مربوط به سرویس را روشن می‌کنند که
   بدون یک نمایش بصری کامل از معماری آن، مورد توجه قرار نمی‌گرفت: کشف نقاط شکست یک سرویس با بررسی
   خطوط کد دشوار است، اما آن‌ها تمایل دارند در یک نمودار معماری دقیق مانند شست دردناک به چشم بیایند.
  </p>
<p>شکل 7-1. نمونه نمودار معماری microservice</p>
<p>مستندات Microservice | 65</p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 73" src="page_0073/image_1.png"/></div>
</div>
            </div>
            <div class="page original-page">
                <img src="page_0073_original/original_page.png" alt="Original Page 73">
            </div>
        </div>
        <div class="dual-page-spread">
            <div class="page persian-page">
                <div class="translated-content">
<div>
<h3>اطلاعات تماس و در دسترس بودن</h3>
<p>
   احتمالاً، هر کسی که مستندات یک سرویس را بررسی می‌کند، یا شخصی از تیم سرویس خواهد بود، یا فردی از یک تیم
   متفاوت خواهد بود که با سرویس مشکل دارد یا می‌خواهد بداند که سرویس چگونه کار می‌کند. برای توسعه‌دهندگان در
   گروه دوم، دسترسی به اطلاعات در مورد تیم هم مفید و هم ضروری است، و بنابراین باید چندین واقعیت مهم در یک
   بخش اطلاعات تماس و در دسترس بودن در مستندات گنجانده شود.
  </p>
<p>
   این بخش باید شامل نام‌ها، موقعیت‌ها و اطلاعات تماس همه افراد در تیم (از جمله مشارکت‌کنندگان فردی، مدیران و
   مدیران برنامه/محصول) باشد. این کار را برای توسعه‌دهندگان در تیم‌های دیگر آسان می‌کند تا به سرعت مشخص کنند
   که در صورت مواجهه با مشکلی با سرویس یا داشتن سؤالی در مورد آن، با چه کسی باید تماس بگیرند. به عنوان مثال،
   این اطلاعات زمانی مفید است که یک توسعه‌دهنده با یکی از وابستگی‌های خود مشکل دارد: دانستن اینکه با چه کسی
   باید تماس گرفت و نقش او در تیم چیست، ارتباط بین تیمی را آسان و کارآمد می‌کند.
  </p>
<p>
   افزودن اطلاعات در مورد چرخش در دسترس بودن (و به‌روز نگه‌داشتن آن به طوری که نشان‌دهنده این باشد که چه
   کسی در هر زمان معین برای سرویس در دسترس است) تضمین می‌کند که افراد دقیقاً می‌دانند که با چه کسی برای
   مشکلات عمومی یا موارد اضطراری تماس بگیرند: مهندسی که برای سرویس در دسترس است.
  </p>
<h3>پیوندها</h3>
<p>
   مستندات باید یک منبع متمرکز برای تمام اطلاعات مربوط به یک microservice باشد. برای اینکه این موضوع درست
   باشد، مستندات باید شامل پیوندهایی به repository (به طوری که توسعه‌دهندگان بتوانند به‌راحتی کد را بررسی
   کنند)، پیوندی به dashboard، پیوندی به RFC اصلی برای microservice، و پیوندی به جدیدترین اسلایدهای بررسی
   معماری باشد. هر اطلاعات اضافی در مورد microservicesهای دیگر، فناوری‌های مورد استفاده توسط microservice
   و غیره، که ممکن است برای توسعه‌دهنده مفید باشد، باید در یک بخش پیوند از مستندات گنجانده شود.
  </p>
<h3>راهنمای Onboarding و توسعه</h3>
<p>
   هدف از یک بخش onboarding و توسعه، این است که کار را برای یک توسعه‌دهنده جدید برای پیوستن به تیم، شروع
   contribution کد، افزودن ویژگی‌ها به microservice، و معرفی تغییرات جدید به pipeline استقرار آسان کند.
  </p>
<p>
   بخش اول این بخش باید یک راهنمای گام به گام برای راه‌اندازی سرویس باشد. این باید یک توسعه‌دهنده را در طول
   بررسی کد، راه‌اندازی محیط، راه‌اندازی سرویس، و تأیید اینکه سرویس به‌درستی کار می‌کند (شامل تمام دستورات
   یا اسکریپت‌هایی که باید برای انجام این کار اجرا شوند) راهنمایی کند.
  </p>
<p>
   بخش دوم باید توسعه‌دهنده را در طول چرخه توسعه و pipeline استقرار سرویس راهنمایی کند (جزئیات یک چرخه
   توسعه آماده تولید
  </p>
<p>66 | فصل 7: مستندات و درک</p>
</div>
</div>
                <div class="page-images">
</div>
            </div>
            <div class="page original-page">
                <img src="page_0074_original/original_page.png" alt="Original Page 74">
            </div>
        </div>
        <div class="dual-page-spread">
            <div class="page persian-page">
                <div class="translated-content">
<div>
<p>
   و pipeline استقرار را می‌توان در "The Development Cycle" در صفحه 26 و "The Deployment Pipeline" در صفحه 28
   یافت). این باید شامل جزئیات فنی (به عنوان مثال، دستوراتی که باید اجرا شوند، همراه با چندین مثال) هر یک از
   مراحل باشد: نحوه بررسی کد، نحوه ایجاد تغییر در کد، نحوه نوشتن یک unit test برای تغییر (در صورت نیاز)،
   نحوه اجرای تست‌های مورد نیاز، نحوه commit کردن تغییرات، نحوه ارسال تغییرات برای بررسی کد، نحوه اطمینان
   از اینکه سرویس به‌درستی build و release می‌شود، و سپس نحوه استقرار (و همچنین نحوه راه‌اندازی pipeline
   استقرار برای سرویس).
  </p>
<h3>جریان‌های درخواست، Endpoints و وابستگی‌ها</h3>
<p>
   مستندات باید همچنین حاوی اطلاعات مهمی در مورد جریان‌های درخواست، endpoints و وابستگی‌های microservice
   باشد.
  </p>
<p>
   مستندات جریان درخواست می‌تواند شامل یک نمودار از جریان‌های درخواست برنامه باشد. این می‌تواند نمودار معماری
   باشد، اگر جریان درخواست به‌درستی در داخل نمودار معماری شرح داده شده باشد. هر نمودار باید با توضیحات کیفی
   در مورد انواع درخواست‌هایی که به microservice ارسال می‌شوند و نحوه مدیریت آن‌ها، همراه باشد.
  </p>
<p>
   این همچنین مکانی است برای مستندسازی تمام API endpointsهای سرویس. یک لیست نقطه‌دار از endpointsها با
   نام‌هایشان و یک توضیح کیفی از هر کدام همراه با پاسخ‌هایشان معمولاً کافی است. باید به اندازه کافی واضح و قابل
   درک باشد که توسعه‌دهنده دیگری که روی یک تیم متفاوت کار می‌کند بتواند توضیحات API endpoints سرویس شما
   را بخواند و با موفقیت از microservice شما به عنوان یک جعبه سیاه استفاده کند، endpointsها را با موفقیت
   بزند و پاسخ‌های مورد انتظار را دریافت کند.
  </p>
<p>
   عنصر سوم این بخش، اطلاعات مربوط به وابستگی‌های سرویس است. وابستگی‌ها، endpointsهای مربوطه این
   وابستگی‌ها، و هر درخواستی را که سرویس به آن‌ها می‌دهد، به همراه اطلاعاتی در مورد SLAهای آن‌ها، هر جایگزین/
   caching/backups که در صورت شکست در نظر گرفته شده است، و پیوندهایی به مستندات و dashboardهای آن‌ها،
   فهرست کنید.
  </p>
<h3>On-Call Runbooks</h3>
<p>
   همانطور که در ??? پوشش داده شد، هر هشدار باید در یک on-call runbook گنجانده شود و با دستورالعمل‌های گام به
   گام که نحوه triage، کاهش و حل آن را توضیح می‌دهد، همراه باشد. on-call runbook باید در مستندات متمرکز
   سرویس، در یک بخش on-call runbook، همراه با راهنمایی‌های عمومی و دقیق در مورد عیب‌یابی و اشکال‌زدایی
   خطاهای جدید، نگهداری شود.
  </p>
<p>
   یک runbook خوب با هرگونه الزامات و proceduresهای عمومی در دسترس بودن شروع می‌شود، و سپس شامل یک لیست
   کامل از هشدارهای سرویس می‌شود. برای هر هشدار، on-call runbook باید شامل نام هشدار، توضیحی از هشدار،
   توضیحی از مشکل، و یک راهنمای گام به گام در مورد نحوه triage هشدار، کاهش آن و سپس
  </p>
<p>مستندات Microservice | 67</p>
</div>
</div>
                <div class="page-images">
</div>
            </div>
            <div class="page original-page">
                <img src="page_0075_original/original_page.png" alt="Original Page 75">
            </div>
        </div>
        <div class="dual-page-spread">
            <div class="page persian-page">
                <div class="translated-content">
<div>
<p>
   آن را حل کند. همچنین هر پیامد سازمانی هشدار را توصیف می‌کند: شدت مشکل، اینکه آیا هشدار نشان‌دهنده یک
   قطعی است یا خیر، و اطلاعاتی در مورد نحوه برقراری ارتباط هرگونه incident و قطعی با تیم، و در صورت لزوم،
   با بقیه سازمان مهندسی.
  </p>
<h3>نوشتن On-Call Runbookهایی که توسعه‌دهندگان خواب‌آلود در ساعت 2 بامداد می‌توانند درک کنند</h3>
<p>
   توسعه‌دهندگانی که برای یک سرویس در دسترس هستند، ممکن است (یا، به واقعیت نزدیک‌تر، خواهند شد) در هر
   ساعتی از شبانه‌روز، از جمله اواخر شب یا بسیار صبح زود، صفحه‌بندی شوند. on-call runbookهای خود را به گونه‌ای
   بنویسید که یک توسعه‌دهنده نیمه‌خواب بتواند بدون هیچ مشکلی دنبال کند.
  </p>
<p>
   نوشتن on-call runbookهای خوب، واضح و به راحتی قابل درک، بسیار مهم است. آن‌ها باید به گونه‌ای نوشته شوند
   که هر توسعه‌دهنده‌ای که برای سرویس در دسترس است یا با سرویس مشکل دارد، بتواند سریع عمل کند، مشکل را
   تشخیص دهد، incident را کاهش دهد، و آن را حل کند، همه در یک بازه زمانی بسیار کوتاه برای کم نگه داشتن
   downtime سرویس.
  </p>
<p>
   همه هشدارها به راحتی کاهش یا حل نخواهند شد، و اکثر قطعی‌ها (جدا از مواردی که توسط باگ‌های کد معرفی شده
   توسط یک استقرار اخیر ایجاد می‌شوند) قبلاً دیده نشده‌اند. برای تجهیز توسعه‌دهندگان برای مدیریت عاقلانه این
   مشکلات، یک بخش عمومی عیب‌یابی و اشکال‌زدایی را به on-call runbook در مستندات اضافه کنید که پر از
   نکاتی در مورد نحوه برخورد با مشکلات جدید به روشی استراتژیک و روشمند است.
  </p>
<h3>سوالات متداول (FAQ)</h3>
<p>
   یک عنصر اغلب فراموش شده در مستندات، بخشی است که به پاسخگویی به سؤالات متداول در مورد سرویس اختصاص
   داده شده است. داشتن یک بخش "سوالات متداول" (Frequently Asked Questions) بار پاسخ دادن به سؤالات
   متداول را از هر کسی که در دسترس است، و در نتیجه، بقیه تیم، برمی‌دارد.
  </p>
<p>
   دو دسته از سؤالات وجود دارد که باید در اینجا به آن‌ها پاسخ داده شود. اولین دسته، سؤالاتی هستند که توسعه‌دهندگان
   در تیم‌های دیگر در مورد سرویس می‌پرسند. روش برخورد با پاسخ به این سؤالات در یک تنظیمات FAQ ساده
   است: اگر کسی از شما سؤالی می‌پرسد، و فکر می‌کنید ممکن است دوباره پرسیده شود، آن را به FAQ اضافه
   کنید. دسته دوم سؤالاتی هستند که از اعضای تیم می‌آیند، و همین رویکرد را می‌توان در اینجا اتخاذ کرد: اگر
   سؤالی در مورد نحوه یا چرایی یا زمان انجام کاری مرتبط با سرویس وجود دارد، آن را به FAQ اضافه کنید.
  </p>
<p>68 | فصل 7: مستندات و درک</p>
</div>
</div>
                <div class="page-images">
<div class="page-image"><img alt="Image from page 76" src="page_0076/image_1.png"/></div>
</div>
            </div>
            <div class="page original-page">
                <img src="page_0076_original/original_page.png" alt="Original Page 76">
            </div>
        </div>
        <div class="dual-page-spread">
            <div class="page persian-page">
                <div class="translated-content">
<div>
<h3>خلاصه: عناصر مستندات Microservice آماده تولید</h3>
<p>
   مستندات microservice آماده تولید شامل موارد زیر است:
  </p>
<ul>
<li>توضیحی از microservice و جایگاه آن در اکوسیستم microservice کلی و کسب‌وکار</li>
<li>یک نمودار معماری که معماری سرویس و کلاینت‌ها و وابستگی‌های آن را در سطح بالایی از انتزاع شرح می‌دهد</li>
<li>اطلاعات تماس و در دسترس بودن در مورد تیم توسعه microservice</li>
<li>پیوندهایی به repository، dashboard(ها)، RFC برای سرویس، بررسی‌های معماری، و هر اطلاعات مرتبط یا مفید دیگر</li>
<li>یک راهنمای onboarding و توسعه که حاوی جزئیاتی در مورد process توسعه، pipeline استقرار، و هر اطلاعات
    دیگری است که برای توسعه‌دهندگانی که به سرویس کمک می‌کنند مفید خواهد بود</li>
<li>اطلاعات دقیق در مورد جریان‌های درخواست، SLA، وضعیت آمادگی برای تولید، API endpointsها، کلاینت‌های مهم، و
    وابستگی‌های microservice</li>
<li>یک on-call runbook که شامل proceduresهای عمومی پاسخ به incident و قطعی، دستورالعمل‌های گام به گام
    در مورد نحوه triage، کاهش و حل هر هشدار، و یک بخش عمومی عیب‌یابی و اشکال‌زدایی است</li>
<li>یک بخش "سوالات متداول" (FAQ)</li>
</ul>
<h3>درک Microservice</h3>
<p>
   مستندات متمرکز، به‌روز و کامل فقط یک بخش از مستندات و درک microservice آماده تولید است. جدا از نوشتن و
   به‌روزرسانی مستندات، processهای سازمانی باید برای اطمینان از اینکه microservicesها نه‌تنها توسط تیم‌های
   توسعه جداگانه بلکه توسط کل سازمان به‌خوبی درک می‌شوند، اجرا شوند. از بسیاری جهات، یک microservice که
   به‌خوبی درک شده است، سرویسی است که تمام الزامات آمادگی برای تولید را برآورده می‌کند.
  </p>
<p>
   درک Microservice برای توسعه‌دهنده، تیم و سازمان واقعاً ضروری است. در حالی که مفهوم "درک" یک microservice
   ممکن است در نگاه اول بیش از حد مبهم به نظر برسد، مفهوم یک microservice آماده تولید می‌تواند برای هدایت و
   تعریف درک microservice در هر سطح استفاده شود. با در دست داشتن استانداردهای آمادگی برای تولید و الزامات،
   همراه با درک واقع‌بینانه از پیچیدگی سازمانی و چالش‌هایی که معماری microservice به عرصه می‌آورد،
   توسعه‌دهندگان می‌توانند درک خود را از هر microservice اندازه‌گیری کنند
  </p>
<p>درک Microservice | 69</p>
</div>
</div>
                <div class="page-images">
</div>
            </div>
            <div class="page original-page">
                <img src="page_0077_original/original_page.png" alt="Original Page 77">
            </div>
        </div>
        <div class="dual-page-spread">
            <div class="page persian-page">
                <div class="translated-content">
<div>
<p>
   (و همانطور که من خواننده را در اوایل این فصل ترغیب کردم) می‌تواند یک پیاز به بقیه سازمان بدهد.
  </p>
<p>
   برای توسعه‌دهنده فردی، این به این معنی است که بتواند به سؤالات مربوط به microservice خود پاسخ دهد. به عنوان
   مثال، وقتی از او سؤال می‌شود که آیا microservice او مقیاس‌پذیر است، او می‌تواند به یک لیست از الزامات
   مقیاس‌پذیری نگاه کند و با اطمینان پاسخ دهد "بله"، "خیر"، یا چیزی در این بین (به عنوان مثال، "الزامات x و z را
   برآورده می‌کند، اما y هنوز پیاده‌سازی نشده است"). به همین ترتیب، وقتی از او سؤال می‌شود که آیا microservice او
   تحمل‌پذیر خطا است، او می‌تواند تمام سناریوهای شکست و فجایع احتمالی را بر زبان بیاورد، و سپس با جزئیات توضیح
   دهد که چگونه با استفاده از انواع مختلف تست‌های resiliency برای این موارد آماده شده است.
  </p>
<p>
   در سطح تیم، درک نشان می‌دهد که تیم از جایگاه microservice خود با توجه به production-readiness و آنچه که
   برای آوردن سرویس خود به یک حالت آماده برای production باید انجام شود، آگاه است. این باید یک عنصر فرهنگی
   از هر تیم باشد تا موفق شود: استانداردهای و الزامات production-readiness باید تصمیمات گرفته شده توسط تیم
   را هدایت کند و نه صرفاً به‌عنوان کادرهایی برای علامت زدن در یک checklist، بلکه به عنوان اصولی دیده شوند که تیم
   را به سمت ساخت بهترین microservice ممکن هدایت می‌کنند.
  </p>
<p>
   درک باید در ساختار خود سازمان ساخته شود. این مستلزم آن است که استانداردهای و الزامات production-readiness
   به بخشی از process سازمانی تبدیل شوند. حتی قبل از اینکه یک سرویس ساخته شود، و یک درخواست برای نظرات
   (RFC) برای بررسی ارسال شود، سرویس می‌تواند در برابر استانداردهای و الزامات production-readiness ارزیابی
   شود. توسعه‌دهندگان، معماران و مهندسان عملیات می‌توانند اطمینان حاصل کنند که سرویس برای پایداری، قابلیت
   اطمینان، مقیاس‌پذیری، عملکرد، تحمل خطا، آمادگی برای فاجعه، نظارت مناسب، و مستندسازی و درک مناسب
   ساخته شده است، حتی قبل از اینکه شروع به اجرا کند—اطمینان از اینکه هنگامی که سرویس جدید شروع به
   میزبانی ترافیک production می‌کند، برای در دسترس بودن معماری شده و بهینه شده است و می‌توان به آن در ترافیک
   production اعتماد کرد.
  </p>
<p>
   فقط بررسی و معماری برای production-readiness در ابتدای چرخه عمر یک microservice کافی نیست. سرویس‌های
   موجود باید به‌طور مداوم بررسی و ممیزی شوند تا کیفیت هر microservice در سطح کافی بالایی حفظ شود، و
   قابلیت اطمینان و اعتماد بالا را در سراسر تیم‌های microservice مختلف و کل اکوسیستم microservice تضمین
   کند. خودکارسازی این ممیزی‌های production-readiness از سرویس‌های موجود و انتشار داخلی نتایج می‌تواند به
   ایجاد آگاهی در سراسر سازمان در مورد کیفیت اکوسیستم microservice کلی کمک کند.
  </p>
<h3>Architecture Reviews</h3>
<p>
   یک چیزی که من پس از هدایت این استانداردهای production-readiness و الزامات آن‌ها در بیش از هزار microservice
   و تیم توسعه آن‌ها آموخته‌ام این است که مؤثرترین راه برای دستیابی فوری به درک microservice، برگزاری
   architecture reviewsهای زمان‌بندی‌شده برای هر microservice است. یک architecture review خوب، جلسه‌ای است
   که در آن تمام توسعه‌دهندگان و مهندسان قابلیت اطمینان سایت
  </p>
<p>70 | فصل 7: مستندات و درک</p>
</div>
</div>
                <div class="page-images">
</div>
            </div>
            <div class="page original-page">
                <img src="page_0078_original/original_page.png" alt="Original Page 78">
            </div>
        </div>
        <div class="dual-page-spread">
            <div class="page persian-page">
                <div class="translated-content">
<div>
<p>
   مهندسان (یا سایر مهندسان عملیات) که روی سرویس کار می‌کنند در یک اتاق جمع می‌شوند، معماری سرویس را روی
   یک تخته وایت‌برد ترسیم می‌کنند، و معماری آن را به‌طور کامل ارزیابی می‌کنند.
  </p>
<p>
   در عرض چند دقیقه از این تمرین، تمایل دارد که دقیقاً مشخص شود که محدوده درک در سطح توسعه‌دهنده و تیم
   چیست. با صحبت در مورد معماری، توسعه‌دهندگان به سرعت موانع مقیاس‌پذیری و عملکرد را کشف خواهند کرد، نقاط
   شکست کشف‌نشده قبلی، قطعی‌های احتمالی و حوادث و شکست‌ها و سناریوهای فاجعه در آینده، و ویژگی‌های
   جدیدی که باید اضافه شوند. تصمیمات معماری ضعیفی که در گذشته گرفته شده‌اند، آشکار می‌شوند و فناوری‌های
   قدیمی که باید با فناوری‌های جدیدتر و/یا بهتر جایگزین شوند، برجسته خواهند شد. برای اطمینان از اینکه ارزیابی و
   بحث سازنده و عینی است، مفید است که توسعه‌دهندگانی از تیم‌های دیگر (به‌ویژه آن‌هایی که در زیرساخت، DevOps،
   یا مهندسی قابلیت اطمینان سایت هستند) را که در معماری سیستم‌های توزیع‌شده در مقیاس بزرگ (و اکوسیستم
   microservice خاص سازمان) تجربه دارند، وارد کنید و قادر به اشاره به مشکلاتی خواهند بود که توسعه‌دهندگان
   ممکن است متوجه آن نشوند.
  </p>
<p>
   هر جلسه باید یک نمودار معماری جدید و به‌روز شده برای سرویس، همراه با لیستی از پروژه‌ها برای رسیدگی در هفته‌ها و
   ماه‌های آینده تولید کند. نمودار جدید قطعاً باید به مستندات اضافه شود، و پروژه‌ها را می‌توان در roadmap هر
   سرویس (به "Production-Readiness Roadmaps" در صفحه 72 مراجعه کنید) و اهداف و نتایج کلیدی (OKRs)
   گنجاند.
  </p>
<p>
   از آنجایی که توسعه microservice نسبتاً سریع پیش می‌رود، microservicesها با سرعت زیادی تکامل می‌یابند و لایه‌های
   پایین‌تر اکوسیستم microservice به‌طور مداوم در حال تغییر هستند. برای مرتبط و مفید نگه داشتن معماری و درک
   آن، این جلسات باید به‌طور منظم برگزار شوند. من متوجه شده‌ام که یک قانون خوب این است که آن‌ها را طوری
   برنامه‌ریزی کنیم که با OKR و برنامه‌ریزی پروژه هماهنگ باشند. اگر پروژه‌ها و OKRها به‌صورت فصلی برنامه‌ریزی و
   زمان‌بندی می‌شوند، سپس architecture reviewsهای فصلی باید هر فصل قبل از شروع چرخه برنامه‌ریزی برگزار شوند.
  </p>
<h3>Production-Readiness Audits</h3>
<p>
   برای اطمینان از اینکه یک microservice، استانداردهای و الزامات production-readiness را برآورده می‌کند و واقعاً
   آماده تولید است، تیم می‌تواند یک production-readiness audit را در سرویس اجرا کند. اجرای یک audit کاملاً
   ساده است: تیم با یک checklist از الزامات production-readiness می‌نشیند و بررسی می‌کند که آیا سرویس آن‌ها هر
   یک از الزامات را برآورده می‌کند یا خیر. این امر درک یک سرویس را ممکن می‌سازد: هر توسعه‌دهنده و تیم تا پایان
   audit دقیقاً می‌دانند که سرویس آن‌ها در کجا قرار دارد و در کجا می‌توان موارد را بهبود داد.
  </p>
<p>
   ساختار یک audit باید استانداردهای و الزامات production-readiness را که سازمان مهندسی اتخاذ کرده است، منعکس
   کند. تیم باید از ممیزی‌ها برای اندازه‌گیری پایداری، قابلیت اطمینان، مقیاس‌پذیری، تحمل خطا، آمادگی برای فاجعه،
   عملکرد، نظارت و مستندسازی سرویس استفاده کند. همانطور که من
  </p>
<p>درک Microservice | 71</p>
</div>
</div>
                <div class="page-images">
</div>
            </div>
            <div class="page original-page">
                <img src="page_0079_original/original_page.png" alt="Original Page 79">
            </div>
        </div>
        <div class="dual-page-spread">
            <div class="page persian-page">
                <div class="translated-content">
<div>
<p>
   همانطور که در فصل‌های قبلی شرح داده شد، هر یک از این استانداردها با مجموعه‌ای از الزامات همراه است که می‌تواند
   برای رساندن هر سرویس به آن استانداردها استفاده شود—توسعه‌دهندگان می‌توانند این الزامات هر استاندارد
   production-readiness را تنظیم کنند تا نیازها و اهداف سازمان را برآورده کنند. الزامات دقیق به جزئیات اکوسیستم
   microservice شرکت بستگی دارد، اما استانداردها و اجزای اساسی آن‌ها در سراسر هر اکوسیستم مربوط هستند (برای
   یک checklist خلاصه که شامل استانداردهای production-readiness و الزامات عمومی آن‌ها است، به پیوست A
   مراجعه کنید).
  </p>
<h3>Production-Readiness Roadmaps</h3>
<p>
   هنگامی که یک تیم توسعه microservice، یک production-readiness audit کامل از microservice خود را تکمیل
   کرد و تیم درک کرد که آیا سرویس آن‌ها آماده تولید است یا خیر، گام بعدی این است که برنامه‌ریزی کند که چگونه
   سرویس را به یک حالت آماده تولید برساند. Audits این کار را آسان می‌کنند: در این مرحله، تیم یک checklist از
   الزامات production-readiness دارد که سرویس آن‌ها برآورده نمی‌کند، و تنها کاری که باقی می‌ماند این است که هر
   الزامی را که برآورده نشده است، برآورده کنند.
  </p>
<p>
   اینجاست که production-readiness roadmapsها می‌توانند توسعه یابند، و من آن‌ها را یک قطعه بسیار مفید از
   process درک production-readiness و microservice می‌دانم. هر microservice متفاوت است، و جزئیات
   پیاده‌سازی هر الزامی که برآورده نشده است بین سرویس‌ها متفاوت خواهد بود، بنابراین تولید یک roadmap
   تفصیلی که تمام جزئیات پیاده‌سازی را مستند می‌کند، تیم را به سمت آماده کردن microservice آن‌ها برای
   production، هدایت می‌کند. الزامات مورد نیاز را می‌توان با جزئیات فنی، مشکلاتی که به وجود آمده‌اند (قطعی‌ها و
   incidentها) که مربوط به این الزام هستند، پیوندی به یک تیکت در یک سیستم مدیریت task، و نام (های)
   توسعه‌دهندگانی که روی پروژه کار خواهند کرد، همراه کرد.
  </p>
<p>
   roadmap و لیست الزامات production-readiness برآورده نشده‌ای که شامل می‌شود، می‌تواند بخشی از هر
   برنامه‌ریزی و (در صورت استفاده در شرکت) OKRهایی باشد که برای سرویس در نظر گرفته شده است. برآورده کردن
   الزامات production-readiness زمانی بهترین عملکرد را دارد که process همزمان با توسعه ویژگی و با پذیرش
   فناوری‌های جدید پیش رود. ساختن هر سرویس در اکوسیستم microservice به‌صورت پایدار، قابل اعتماد، مقیاس‌پذیر،
   با عملکرد بالا، تحمل‌پذیر خطا، آماده برای فاجعه، نظارت‌شده، مستند شده و درک‌شده، یک راه ساده و قابل اندازه‌گیری
   برای تضمین این است که هر سرویس واقعاً آماده تولید است، و در دسترس بودن کل اکوسیستم microservice را
   تضمین می‌کند.
  </p>
<h3>اتوماسیون Production-Readiness</h3>
<p>
   Architecture reviewsها، auditsها و roadmapsها، چالش‌های درک microservice را در سطوح توسعه‌دهنده و تیم حل
   می‌کنند، اما درک در سطح سازمانی نیازمند یک component اضافی است. همانطور که من تا به حال ارائه کرده‌ام،
   تمام کارهایی که برای ساخت یک microservice آماده تولید انجام می‌شود، عمدتاً دستی است،
  </p>
<p>72 | فصل 7: مستندات و درک</p>
</div>
</div>
                <div class="page-images">
</div>
            </div>
            <div class="page original-page">
                <img src="page_0080_original/original_page.png" alt="Original Page 80">
            </div>
        </div>
        <div class="dual-page-spread">
            <div class="page persian-page">
                <div class="translated-content">
<div>
<p>
   که از توسعه‌دهندگان می‌خواهد که به‌صورت جداگانه هر مرحله از audit را دنبال کنند، وظایف و لیست‌ها و roadmaps
   را ایجاد کنند و کادرهای الزامات فردی را علامت بزنند. کارهای دستی مانند این اغلب به حاشیه می‌روند تا به بقیه
   technical debt بپیوندند، حتی در تیم‌های با بالاترین بهره‌وری و production-readiness.
  </p>
<p>
   یکی از اصول کلیدی مهندسی نرم‌افزار در عمل این است: اگر مجبورید کاری را بیش از یک‌بار به‌صورت دستی انجام
   دهید، آن را خودکار کنید تا دیگر نیازی به انجام آن نداشته باشید. این امر در مورد کار عملیاتی صدق می‌کند، در
   مورد هر موقعیت یک‌باره و ad hoc و هر چیزی که نیاز دارید در یک ترمینال تایپ کنید صدق می‌کند، و جای تعجب
   نیست که در مورد اجرای استانداردهای production-readiness در یک سازمان مهندسی صدق می‌کند. اتوماسیون
   بهترین پیازی است که می‌توانید به تیم‌های توسعه خود بدهید.
  </p>
<p>
   ساختن یک لیست از الزامات production-readiness برای هر microservice آسان است. من خودم این کار را در Uber
   انجام داده‌ام، من دیده‌ام که توسعه‌دهندگان دیگر، استانداردهای production-readiness موجود در این کتاب را در
   شرکت‌های خود پیاده‌سازی کرده‌اند، و من یک checklist الگو (پیوست A، Production-Readiness Checklist) ایجاد
   کرده‌ام که شما، خواننده، می‌توانید از آن استفاده کنید. یک لیست مانند این، خودکارسازی checklist را نسبتاً آسان
   می‌کند. به عنوان مثال، برای بررسی تحمل خطا و آمادگی برای فاجعه، شما می‌توانید تست‌های خودکار را اجرا
   کنید تا اطمینان حاصل شود که تست‌های resiliency مناسب در جای خود قرار دارند، در حال اجرا هستند، و هر
   microservice این تست‌ها را با موفقیت پاس می‌کند.
  </p>
<p>
   دشواری در خودکارسازی هر یک از این بررسی‌های production-readiness، کاملاً به پیچیدگی سرویس‌های داخلی شما
   در هر لایه از اکوسیستم microservice بستگی دارد. اگر تمام microservicesها و ابزارهای سلف‌سرویس، APIهای
   مناسبی داشته باشند، اتوماسیون یک کار آسان است. اگر سرویس‌های شما در برقراری ارتباط مشکل داشته باشند، یا
   اگر هر ابزار داخلی سلف‌سرویس، بدقلق یا بد نوشته شده باشد، شما زمان بدی را خواهید داشت (و نه فقط با
   production-readiness، بلکه با یکپارچگی سرویس شما و کل اکوسیستم microservice).
  </p>
<p>
   خودکارسازی production-readiness در چندین روش بسیار مهم و مؤثر، درک سازمانی را افزایش می‌دهد. اگر شما
   این بررسی‌ها را خودکار کنید و آن‌ها را به‌طور مداوم اجرا کنید، تیم‌ها در سازمان همیشه خواهند دانست که هر
   microservice در چه جایگاهی قرار دارد. انتشار داخلی این نتایج، دادن یک امتیاز production-readiness به هر
   microservice که نشان‌دهنده این است که سرویس آن‌ها چقدر آماده production است، مستلزم این است که
   سرویس‌های حیاتی برای کسب‌وکار دارای یک حداقل امتیاز production-readiness بالا باشند، و استقرارها را
   gate کنند. Production-readiness را می‌توان به بخشی از فرهنگ مهندسی تبدیل کرد، و این یک راه مطمئن برای
   انجام این کار است.
  </p>
<h3>ارزیابی Microservice شما</h3>
<p>
   اکنون که درک بهتری از مستندات دارید، از لیست سؤالات زیر برای ارزیابی آمادگی production microservice(های)
   خود و اکوسیستم microservice استفاده کنید. سؤالات بر اساس موضوع سازماندهی شده‌اند و با بخش‌های این فصل
   مطابقت دارند.
  </p>
<p>ارزیابی Microservice | 73</p>
</div>
</div>
                <div class="page-images">
</div>
            </div>
            <div class="page original-page">
                <img src="page_0081_original/original_page.png" alt="Original Page 81">
            </div>
        </div>
        <div class="dual-page-spread">
            <div class="page persian-page">
                <div class="translated-content">
<div>
<h3>مستندات Microservice</h3>
<ul>
<li>آیا مستندات برای تمام microservicesها در یک مکان متمرکز، مشترک و با دسترسی آسان ذخیره
    می‌شود؟</li>
<li>آیا مستندات به راحتی قابل جستجو هستند؟</li>
<li>آیا تغییرات مهم در microservice با به‌روزرسانی مستندات microservice همراه است؟</li>
<li>آیا مستندات microservice شامل توضیحی از microservice است؟</li>
<li>آیا مستندات microservice شامل یک نمودار معماری است؟</li>
<li>آیا مستندات microservice شامل اطلاعات تماس و در دسترس بودن است؟</li>
<li>آیا مستندات microservice شامل پیوندهایی به اطلاعات مهم است؟</li>
<li>آیا مستندات microservice شامل یک راهنمای onboarding و توسعه است؟</li>
<li>آیا مستندات microservice شامل اطلاعاتی در مورد جریان درخواست، endpointsها و وابستگی‌های
    microservice است؟</li>
<li>آیا مستندات microservice شامل یک on-call runbook است؟</li>
<li>آیا مستندات microservice شامل یک بخش سوالات متداول (FAQ) است؟</li>
</ul>
<h3>درک Microservice</h3>
<ul>
<li>آیا هر توسعه‌دهنده در تیم می‌تواند به سؤالات مربوط به production-readiness microservice پاسخ دهد؟</li>
<li>آیا مجموعه‌ای از اصول و استانداردهایی وجود دارد که همه microservicesها به آن‌ها پایبند هستند؟</li>
<li>آیا یک process RFC برای هر microservice جدید وجود دارد؟</li>
<li>آیا microservicesهای موجود به‌طور مکرر بررسی و ممیزی می‌شوند؟</li>
<li>آیا architecture reviewsها برای هر تیم microservice برگزار می‌شود؟</li>
<li>آیا یک process audit برای production-readiness وجود دارد؟</li>
<li>آیا production-readiness roadmapsها برای آوردن microservice به یک حالت آماده برای production استفاده
    می‌شوند؟</li>
<li>آیا استانداردهای production-readiness، OKRهای سازمان را هدایت می‌کنند؟</li>
<li>آیا process production-readiness خودکار است؟</li>
</ul>
<p>74 | فصل 7: مستندات و درک</p>
</div>
</div>
                <div class="page-images">
</div>
            </div>
            <div class="page original-page">
                <img src="page_0082_original/original_page.png" alt="Original Page 82">
            </div>
        </div>
        <div class="dual-page-spread">
            <div class="page persian-page">
                <div class="translated-content">
<div>
<h3>پیوست A</h3>
<h3>Production-Readiness Checklist</h3>
<p>
   این یک checklist خواهد بود که بر روی تمام microservicesها اجرا می‌شود—به‌صورت دستی یا به روشی خودکار.
  </p>
<h3>یک سرویس آماده تولید، پایدار و قابل اعتماد است</h3>
<ul>
<li>دارای یک چرخه توسعه استاندارد است.</li>
<li>کد آن از طریق تست‌های lint، unit، integration و end-to-end کاملاً تست شده است.</li>
<li>process تست، بسته‌بندی، ساخت و release آن کاملاً خودکار است.</li>
<li>دارای یک pipeline استقرار استاندارد است که شامل مراحل staging، canary و production است.</li>
<li>کلاینت‌های آن شناخته شده‌اند.</li>
<li>وابستگی‌های آن شناخته شده‌اند، و پشتیبان‌گیری، جایگزین‌ها، fallbacks و caching در صورت خرابی وجود
    دارد.</li>
<li>دارای routing و کشف پایدار و قابل اعتماد است.</li>
</ul>
<h3>یک سرویس آماده تولید، مقیاس‌پذیر و با عملکرد بالاست</h3>
<ul>
<li>مقیاس‌های رشد کیفی و کمی آن مشخص است.</li>
<li>از منابع سخت‌افزاری به طور کارآمد استفاده می‌کند.</li>
<li>موانع و الزامات منابع آن شناسایی شده‌اند.</li>
<li>capacity planning خودکار است و به‌صورت زمان‌بندی‌شده انجام می‌شود.</li>
<li>وابستگی‌های آن با آن مقیاس‌پذیری خواهند داشت.</li>
</ul>
<p>75</p>
</div>
</div>
                <div class="page-images">
</div>
            </div>
            <div class="page original-page">
                <img src="page_0083_original/original_page.png" alt="Original Page 83">
            </div>
        </div>
        <div class="dual-page-spread">
            <div class="page persian-page">
                <div class="translated-content">
<div>
<ul>
<li>با کلاینت‌هایش مقیاس‌پذیری خواهد داشت.</li>
<li>الگوهای ترافیکی آن درک شده‌اند.</li>
<li>ترافیک را می‌توان در صورت شکست، دوباره هدایت کرد.</li>
<li>به زبان برنامه‌نویسی نوشته شده است که به آن اجازه می‌دهد مقیاس‌پذیر و با عملکرد بالا باشد.</li>
<li>وظایف را به روشی با عملکرد بالا مدیریت و پردازش می‌کند.</li>
<li>داده‌ها را به روشی مقیاس‌پذیر و با عملکرد بالا مدیریت و ذخیره می‌کند.</li>
</ul>
<h3>یک سرویس آماده تولید، تحمل‌پذیر خطا و برای هر فاجعه‌ای آماده است</h3>
<ul>
<li>هیچ نقطه شکست واحدی ندارد.</li>
<li>تمام سناریوهای شکست و فجایع احتمالی شناسایی شده‌اند.</li>
<li>از طریق تست کد، load testing و chaos testing برای resiliency تست شده است.</li>
<li>تشخیص و اصلاح خطا خودکار شده است.</li>
<li>proceduresهای استاندارد برای incident و قطعی در داخل تیم توسعه microservice و در سراسر سازمان
    وجود دارد.</li>
</ul>
<h3>یک سرویس آماده تولید، به‌درستی نظارت می‌شود</h3>
<ul>
<li>معیارهای کلیدی آن در سطح host، زیرساخت و microservice شناسایی و نظارت می‌شوند.</li>
<li>دارای logging مناسبی است که حالت‌های گذشته microservice را به‌طور دقیق منعکس می‌کند.</li>
<li>dashboardهای آن آسان برای تفسیر هستند و شامل تمام معیارهای کلیدی می‌شوند.</li>
<li>هشدارهای آن قابل اجرا هستند و توسط آستانه‌های سیگنال‌دهنده تعریف می‌شوند.</li>
<li>یک چرخش در دسترس بودن اختصاصی برای نظارت و پاسخگویی به هرگونه incident و قطعی وجود دارد.</li>
<li>یک procedure روشن، به‌خوبی تعریف شده و استاندارد در دسترس بودن برای رسیدگی به incident و قطعی وجود
    دارد.</li>
</ul>
<p>76 | پیوست A: Production-Readiness Checklist</p>
</div>
</div>
                <div class="page-images">
</div>
            </div>
            <div class="page original-page">
                <img src="page_0084_original/original_page.png" alt="Original Page 84">
            </div>
        </div>
        <div class="dual-page-spread">
            <div class="page persian-page">
                <div class="translated-content">
<div>
<h3>یک سرویس آماده تولید، مستند شده و درک شده است</h3>
<ul>
<li>دارای مستندات جامع است.</li>
<li>مستندات آن به‌طور منظم به‌روزرسانی می‌شوند.</li>
<li>مستندات آن شامل توضیحی از microservice؛ یک نمودار معماری؛ اطلاعات تماس و در دسترس بودن؛ پیوندهایی به
    اطلاعات مهم؛ یک راهنمای onboarding و توسعه؛ اطلاعاتی در مورد جریان(های) درخواست سرویس، endpointsها و
    وابستگی‌ها؛ یک runbook در دسترس بودن؛ و پاسخ به سؤالات متداول است.</li>
<li>در سطح توسعه‌دهنده، تیم و سازمان به‌خوبی درک شده است.</li>
<li>به مجموعه‌ای از استانداردهای production-readiness پایبند است و الزامات مرتبط را برآورده می‌کند.</li>
<li>معماری آن به‌طور مکرر بررسی و ممیزی می‌شود.</li>
</ul>
<p>Production-Readiness Checklist | 77</p>
</div>
</div>
                <div class="page-images">
</div>
            </div>
            <div class="page original-page">
                <img src="page_0085_original/original_page.png" alt="Original Page 85">
            </div>
        </div>
        <div class="dual-page-spread">
            <div class="page persian-page">
                <div class="translated-content">
<div>
<h3>درباره نویسنده</h3>
<p>
   Susan Fowler یک مهندس قابلیت اطمینان سایت در Uber Technologies است، جایی که او زمان خود را بین اجرای یک initiative
   production-readiness در سراسر تمام microservicesهای Uber و جاسازی در تیم‌های حیاتی برای کسب‌وکار برای آوردن
   سرویس‌هایشان به یک حالت آماده تولید، تقسیم می‌کند. او قبل از پیوستن به Uber، بر روی پلتفرم‌های application و
   زیرساخت در چندین استارتاپ کوچک کار می‌کرد، و قبل از آن، فیزیک ذرات را در Penn مطالعه کرد، جایی که به دنبال
   supersymmetry بود و سخت‌افزار را برای آشکارسازهای ATLAS و CMS طراحی کرد.
  </p>
<h3>Colophon</h3>
<p>
   حیوانات روی جلد Microservices آماده تولید، زنبورهای برگ‌بر (از جنس Megachile) هستند. بیش از 1500 گونه از این
   حشره وجود دارد، که در سراسر جهان گسترده است. تصور می‌شود که یک گونه از اندونزی، Megachile pluto، بزرگترین
   زنبور عسل در جهان است: افراد می‌توانند تا 0.9–1.5 اینچ طول داشته باشند.
  </p>
<p>
   زنبورهای برگ‌بر نام خود را از فعالیت رایج ماده برای بریدن نیم‌دایره‌های مرتب از لبه‌های برگ‌ها به دست می‌آورند. سپس
   او این قطعات برگ دیسکی شکل را به لانه خود حمل می‌کند، که می‌تواند در مکان‌های مختلفی مانند حفره‌های آماده،
   تونل‌ها در زمین یا چوب پوسیده ساخته شود که زنبور عسل می‌تواند در آن سوراخ ایجاد کند. لانه‌ها بین 4–8 اینچ
   طول، استوانه‌ای و با قطعات برگ در یک الگوی همپوشانی خط‌کشی شده‌اند. این حشرات در کلنی زندگی نمی‌کنند، اگرچه
   امکان دارد افراد در نزدیکی یکدیگر لانه کنند.
  </p>
<p>
   ماده‌ها لانه‌های خود را در سلول‌های جداگانه (ساخت از داخل به بیرون) مرتب می‌کنند و یک تخم در هر کدام می‌گذارند،
   همراه با یک توپ گرده و شهد برگشتی برای تغذیه لارو. این نظریه وجود دارد که برگ‌ها از خشک شدن غذای لارو تا
   زمانی که بتواند خورده شود، جلوگیری می‌کنند.
  </p>
<p>
   زنبورهای بالغ نیز از شهد و گرده تغذیه می‌کنند، و به دلیل حرکت شنای پر جنب و جوش خود در داخل گل‌ها (که مقدار
   زیادی گرده را تکان می‌دهد و موهای بلند روی شکم حشره را می‌پوشاند) گرده‌افشانی بسیار کارآمدی دارند. ماده‌ها
   اغلب نیاز دارند که 10–15 سفر برای تأمین یک سلول لانه جداگانه انجام دهند، که بیشتر کارایی آن‌ها را در
   cross-pollination افزایش می‌دهد. بنابراین، این زنبورها ساکنان خوش‌آمدی در بسیاری از باغ‌ها و مزارع هستند؛
   جعبه‌ها یا لوله‌های لانه مصنوعی را می‌توان برای جذب آن‌ها قرار داد.
  </p>
<p>
   بسیاری از حیوانات روی جلد O’Reilly در معرض خطر هستند؛ همه آن‌ها برای جهان مهم هستند. برای کسب اطلاعات
   بیشتر در مورد اینکه چگونه می‌توانید کمک کنید، به animals.oreilly.com بروید.
  </p>
<p>
   تصویر جلد از Royal Natural History Lydekker است. فونت‌های جلد URW Typewriter و Guardian Sans هستند. فونت
   متن، Adobe Minion Pro است؛ فونت عنوان، Adobe Myriad Condensed است؛ و فونت کد، Ubuntu Mono Dalton Maag
   است.
  </p>
</div>
</div>
                <div class="page-images">
</div>
            </div>
            <div class="page original-page">
                <img src="page_0086_original/original_page.png" alt="Original Page 86">
            </div>
        </div>
    </div>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/line-numbers/prism-line-numbers.min.js"></script>
    <script>
        document.addEventListener('DOMContentLoaded', (event) => {
            if (window.Prism) {
                Prism.highlightAll();
            }
        });
    </script>
</body>
</html>